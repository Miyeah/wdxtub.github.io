<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="一个逗比的碎碎念"><title>云计算 第 18 课 用 MapReduce 进行批处理 | 小土刀</title><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/pure-min.css"><link rel="stylesheet" type="text/css" href="/css/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">云计算 第 18 课 用 MapReduce 进行批处理</h1><a id="logo" href="/.">小土刀</a><p class="description">Agony is my triumph</p></div><div id="nav-menu"><a href="/."><i class="icon-home"> 首页</i></a><a href="/about/"><i class="icon-power-cord"> 技术</i></a><a href="/life/"><i class="icon-pacman"> 生活</i></a><a href="/portfolio/"><i class="icon-infinite"> 作品</i></a><a href="/archives/"><i class="icon-floppy-disk"> 归档</i></a><a href="/atom.xml"><i class="icon-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">云计算 第 18 课 用 MapReduce 进行批处理</h1><div class="post-content"><p>从这节课开始我们进入了一个新的阶段，开始具体来应用 MapReduce 编程模型，这次主要是计算文本的 N-Gram 及语言模型并连接到 web 服务中。</p>
<a id="more"></a>
<hr>
<h2 id="u5B66_u4E60_u76EE_u6807"><a href="#u5B66_u4E60_u76EE_u6807" class="headerlink" title="学习目标"></a>学习目标</h2><ol>
<li>列举不同的并行和分布式编程模型</li>
<li>解释 MapReduce 编程的执行流程</li>
<li>使用 MapReduce 处理文本数据集</li>
<li>使用 MapReduce 计算 n-gram 已经构造语言模型</li>
<li>直接把 MapReduce 的结果载入到后端存储</li>
<li>搭建前端用来连接后端并显示结果</li>
</ol>
<p>一般来说我们根据运行时的延迟以及执行的频率会把分布式编程模型分为以下三种：</p>
<ul>
<li>批量数据处理系统 Batch Data Processing Systems    <ul>
<li>用于批量处理历史数据</li>
<li>MapReduce</li>
</ul>
</li>
<li>内存中迭代批量数据处理系统 In-Memory Iterative Batch Data Processing Systems<ul>
<li>MapReduce 需要在每次迭代后保存当前计算结果</li>
<li>对于需要多次迭代直到收敛的问题，不够高效</li>
<li>这种处理方式会把数据保存在内存中来解决这个问题</li>
<li>Spark</li>
</ul>
</li>
<li>流/实时处理系统 Streaming or Real-time processing systems<ul>
<li>前两种都是处理历史数据的</li>
<li>这种处理方式则能够实时处理数据</li>
<li>Spark Streaming, Apache Storm, Apache Samza</li>
</ul>
</li>
</ul>
<h2 id="u80CC_u666F_u77E5_u8BC6"><a href="#u80CC_u666F_u77E5_u8BC6" class="headerlink" title="背景知识"></a>背景知识</h2><h3 id="MapReduce__u4ECB_u7ECD"><a href="#MapReduce__u4ECB_u7ECD" class="headerlink" title="MapReduce 介绍"></a>MapReduce 介绍</h3><p>更加详细的介绍可以看我的<a href="/./2016/03/20/hadoop-guide/">Hadoop 指南</a></p>
<p><a href="http://hadoop.apache.org/" target="_blank" rel="external">Hadoop</a> 是 Google MapReduce 的开源实现。在 MapReduce 程序中，数据以键值对形式存储，然后通过 Mapper 和 Reducer 进行处理：</p>
<p><img src="/images/14597702456209.jpg" alt="MapReduce Overview"></p>
<p><a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputFormat.html" target="_blank" rel="external">InputFormat</a> 定义了 Mapper 如何从文件读入数据，并写入为 <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/Writable.html" target="_blank" rel="external">Writable</a> 类型</p>
<p>Mapper: <code>Map(k1, v1) --&gt; list(k2, v2)</code></p>
<p>然后会进行 Shuffle 和 Sort（按照 key 的值），接着就到 Reducer，会针对同一个 key 的所有 value 进行处理</p>
<p>Reducer: <code>Reduce(k2, list (v2)) --&gt; list(v3)</code></p>
<p>具体的单词统计的例子可以参考以下资料，这里不赘述</p>
<ul>
<li>代码：<a href="http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Example:_WordCount_v1.0" target="_blank" rel="external">简单的例子</a>；<a href="http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Example:_WordCount_v2.0" target="_blank" rel="external">复杂的例子</a></li>
<li>视频：<a href="https://www.youtube.com/watch?v=3O5e6zGb1dw" target="_blank" rel="external">代码讲解</a>；<a href="https://www.youtube.com/watch?v=iWGqAhViyfY" target="_blank" rel="external">EMR 使用指南</a></li>
</ul>
<p>在这个例子中，打包代码的时候不建议使用 maven 或者 eclipse，因为可能会弄错 Hadoop 包的版本，使用下面的命令（代码文件名为 <code>WordCount.java</code>）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">mkdir wordcount_classes</span><br><span class="line">cp /usr/share/aws/emr/hadoop-state-pusher/lib/hadoop-common-<span class="number">2.4</span>.<span class="number">0</span>-amzn-<span class="number">3</span>.jar .</span><br><span class="line">cp /usr/share/aws/emr/hadoop-state-pusher/lib/hadoop-mapreduce-client-core-<span class="number">2.4</span>.<span class="number">0</span>-amzn-<span class="number">3</span>.jar .</span><br><span class="line">cp /usr/share/aws/emr/hadoop-state-pusher/lib/hadoop-mapreduce-client-common-<span class="number">2.4</span>.<span class="number">0</span>-amzn-<span class="number">3</span>.jar .</span><br><span class="line">javac -classpath hadoop-common-<span class="number">2.4</span>.<span class="number">0</span>-amzn-<span class="number">3</span>.jar:hadoop-mapreduce-client-core-<span class="number">2.4</span>.<span class="number">0</span>-amzn-<span class="number">3</span>.jar:hadoop-mapreduce-client-common-<span class="number">2.4</span>.<span class="number">0</span>-amzn-<span class="number">3</span>.jar <span class="operator">-d</span> wordcount_classes WordCount.java</span><br><span class="line">jar -cvf wordcount.jar -C wordcount_classes/ .</span><br></pre></td></tr></table></figure>
<ul>
<li>然后需要把输入数据放入到 HDFS 中，如 <code>hadoop fs -put /input</code></li>
<li>然后执行 <code>hadoop jar wordcount.jar WordCount /input /output</code> 来进行 MapReduce 工作</li>
<li>查看结果 <code>hadoop fs -ls /output</code></li>
</ul>
<p>上面的部分是用命令行来进行执行，实际我们可以直接在 web 界面操作</p>
<ul>
<li>创建 EMR 的时候选择 Advanced Opitons</li>
<li>在 Steps 中选择 Custom JAR，然后 Configure and Add 具体的 JAR 包以及参数（比如 JAR 在 S3 中的位置）</li>
<li>然后执行即可</li>
</ul>
<h2 id="u4EFB_u52A1_u76EE_u6807"><a href="#u4EFB_u52A1_u76EE_u6807" class="headerlink" title="任务目标"></a>任务目标</h2><p>这里我们需要构建一个输入文本预测器，通过 n-gram 及对应的语言模型，预测用户之后可能会输入的内容，具体步骤如下：</p>
<ol>
<li>[40%] 在 Wiki 数据上计算 ngram</li>
<li>[40%] 构造语言模型</li>
<li>[20%] 代码质量</li>
<li>[10%(bonus)] 词语自动完成</li>
</ol>
<p>环境要求</p>
<ul>
<li>打上标签：<code>Project:4.1</code></li>
<li>AWS Elastic MapReducer(EMR)，用 <code>m3</code> 开头的机器</li>
<li>预算 <code>$20</code></li>
<li>MapReduce 的 java 程序需要用 JRE 1.7 编译（因为 Amazon EMR 只支持这个）</li>
</ul>
<h3 id="u6784_u9020_n-gram__u6A21_u578B"><a href="#u6784_u9020_n-gram__u6A21_u578B" class="headerlink" title="构造 n-gram 模型"></a>构造 n-gram 模型</h3><ul>
<li>数据集 <code>s3://cmucc-datasets/enwiki-20160204-pages</code></li>
<li>n-gram 格式 <code>&lt;phrase&gt;&lt;\t&gt;&lt;count&gt;</code></li>
</ul>
<p>n-gram 例子</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>        <span class="number">1000</span></span><br><span class="line"><span class="keyword">this</span> is     <span class="number">500</span></span><br><span class="line"><span class="keyword">this</span> is a   <span class="number">250</span></span><br></pre></td></tr></table></figure>
<h2 id="u53C2_u8003_u94FE_u63A5"><a href="#u53C2_u8003_u94FE_u63A5" class="headerlink" title="参考链接"></a>参考链接</h2><ul>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" target="_blank" rel="external">MapReduce Tutorial</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html" target="_blank" rel="external">HDFS Command Guide</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html" target="_blank" rel="external">Apache Hadoop tutorial</a></li>
</ul>
</div><div data-thread-key="trash/cc-19.html" data-title="云计算 第 18 课 用 MapReduce 进行批处理" data-url="http://wdxtub.com/trash/cc-19.html" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search" class="search-form-input"/><input type="hidden" name="sitesearch" value="http://wdxtub.com"/></form></div><div class="widget"><div class="widget-title">分类</div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Game/">Game</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Gossip/">Gossip</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Memory/">Memory</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Movie/">Movie</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Reading/">Reading</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Story/">Story</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Technique/">Technique</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Thinking/">Thinking</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Traveling/">Traveling</a></li></ul></div><div class="widget"><div class="comments-title">最近评论</div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title">友情链接</div><ul></ul><a href="http://jackqdyulei.github.io" title="Lei YU" target="_blank">Lei YU</a><ul></ul><a href="http://wdxtub.com/bookclips/" title="我的书摘" target="_blank">我的书摘</a><ul></ul><a href="http://wdxtub.com/interview/" title="刷题笔记" target="_blank">刷题笔记</a></div></div></div></div><div id="footer">© <a href="/." rel="nofollow">小土刀.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div><a id="rocket" href="#top" class="show"></a><script src="/js/jquery.min.js" type="text/javascript"></script>
<script src="/js/totop.js" type="text/javascript"></script><script src="/js/fancybox.pack.js" type="text/javascript"></script>
<script src="/js/jquery.fancybox.js" type="text/javascript"></script><link rel="stylesheet" href="/css/jquery.fancybox.css" type="text/css"><script>var duoshuoQuery = {short_name:'wdxblog'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script></div></body></html>