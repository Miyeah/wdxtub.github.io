<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[小土刀]]></title>
  <subtitle><![CDATA[Agony is my triumph]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://wdxtub.com/"/>
  <updated>2016-02-12T16:10:01.000Z</updated>
  <id>http://wdxtub.com/</id>
  
  <author>
    <name><![CDATA[wdxtub]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[不安的终结]]></title>
    <link href="http://wdxtub.com/2016/02/12/end-of-anxiety/"/>
    <id>http://wdxtub.com/2016/02/12/end-of-anxiety/</id>
    <published>2016-02-12T15:05:36.000Z</published>
    <updated>2016-02-12T16:10:01.000Z</updated>
    <content type="html"><![CDATA[<p>当一类事情重复足够多次之后，本能会让我们去选择最安全、最中庸的道路。可是消除了痛苦，也就消除了走向辉煌的可能，这又怎么办呢？</p>
<a id="more"></a>
<hr>
<p>最脆弱不安的时刻，往往也是最接近自己的时刻，但观察自己的过程犹如走钢丝，左一分蒸发，右一分凝结。超然物外已经很难，如何抽离自身，更是值得一生探索。在飞机上经历了回忆杀带来的『臆想恐慌症』之后，抛开封闭环境可能带来的问题，我在想，所谓的不安，到底从哪里来，到哪里去呢？</p>
<p>坏消息是，网上对于不安的讨论，几乎都是『灌鸡汤』；好消息是，我在阿西莫夫的《永恒的终结》中，找到了答案。</p>
<p>所谓不安，大概是预想的和实际发生的不一致，自己却没有办法找到原因，于是胡思乱想的恶性循环就开始了；直到某个契机出现，发现了一个『未必合理』却足以说服自己的理由，这才算『心安理得』。但凡以后再想起某件事，便可以自己用这个『足够好』的理由去搪塞自己。而胡思乱想恐怕是因为过去的经历形成的心理地貌，即使一次次去想去模拟，让自己的心绪像流水一样涌出，因为地貌的缘故，往往只能得到同一个结果，于是逆向合理化开始启动，一切都是那么顺理成章。</p>
<p>这样我们就找到不安的根源——失控，胡思乱想使得心态失控，之后给自己洗脑认为现实也已经失控，最终导致心态爆炸。问题就来了，这种失控有没有可能被控制呢？很遗憾，没有，就像《永恒的终结》中一样，用现在去改变过去，其实是没有太多意义的。生活并非永恒不变，现在也不是唯一的归宿，只是未来无限可能的出发点。只有经过严酷的考验，才能不断前进，高速发展。</p>
<blockquote>
<p>危险的环境和危机感，才是驱使人类不断进步，不断征服新事物的根本动力</p>
</blockquote>
<p>人人都会不安，这是本能，但是本能之上，应该意识到不安的终结并不是避免困难的出现，而是去战胜困难。自信不是把自己当做宠物，当做温室里的花朵来成长，而是相信自己，永远敢于接受下一次的挑战。</p>
<p>从这个角度来看中国历史，漫长的封建社会就类似于某种重复，每个朝代一开始，都会参考前朝的经验去做新的选择，找到『最好』的现实，于是慢慢向着最安全，最中庸，最稳定的结构演变，也就是所谓的『中央集权』。</p>
<p>但是这真的就是某种惯性，也许这么多次的重复，只是为了在下一个瞬间，开启另一个时代，那里没有永恒，更无所谓终结。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>当一类事情重复足够多次之后，本能会让我们去选择最安全、最中庸的道路。可是消除了痛苦，也就消除了走向辉煌的可能，这又怎么办呢？</p>]]>
    
    </summary>
    
      <category term="不安" scheme="http://wdxtub.com/tags/%E4%B8%8D%E5%AE%89/"/>
    
      <category term="困难" scheme="http://wdxtub.com/tags/%E5%9B%B0%E9%9A%BE/"/>
    
      <category term="循环" scheme="http://wdxtub.com/tags/%E5%BE%AA%E7%8E%AF/"/>
    
      <category term="永恒的终结" scheme="http://wdxtub.com/tags/%E6%B0%B8%E6%81%92%E7%9A%84%E7%BB%88%E7%BB%93/"/>
    
      <category term="终结" scheme="http://wdxtub.com/tags/%E7%BB%88%E7%BB%93/"/>
    
      <category term="Thinking" scheme="http://wdxtub.com/categories/Thinking/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[计算机网络]]></title>
    <link href="http://wdxtub.com/2016/02/10/internet-protocol/"/>
    <id>http://wdxtub.com/2016/02/10/internet-protocol/</id>
    <published>2016-02-10T23:51:28.000Z</published>
    <updated>2016-02-11T14:03:07.000Z</updated>
    <content type="html"><![CDATA[<p>这篇文章主要介绍计算机网络的相关知识，因为网络的重要组成不是是协议，所以很大篇幅会是相关协议以及具体的应用。整体的结构基于 <a href="http://www.cnblogs.com/vamei/" target="_blank" rel="external">Vamei</a> 博客中的结构（以及一些配图），加上自己在网络上搜集和日常学习中的一些思考，整理成为本文。</p>
<a id="more"></a>
<hr>
<h2 id="u5206_u5C42_u6A21_u578B"><a href="#u5206_u5C42_u6A21_u578B" class="headerlink" title="分层模型"></a>分层模型</h2><p>首先需要明确的就是，网络通信是基于分层模型的。虽然不同的协议有不同的层级划分（甚至同一种协议也有不同的层级划分），但是都离不开分层。分层的好处有很多，最重要的是能够比较好控制具体实现的复杂度，由于每层之间由事先约定的接口通信，所以其实并不需要在意每层的具体实现。</p>
<p>比较出名的分层模型有 OSI 分层模型和 TCP/IP 分层模型，它们的对应关系如下：</p>
<p><img src="/images/14551385707784.jpg" alt=""></p>
<p>OSI 分层模型将计算机网络体系结构的通信协议划分为七层，自下而上依次为：物理层（Physics Layer）、数据链路层（Data Link Layer）、网络层（Network Layer）、传输层（Transport Layer）、会话层（Session Layer）、表示层（Presentation Layer）、应用层（Application Layer）。其中第四层完成数据传送服务，上面三层面向用户。</p>
<p><strong>物理层(physical layer)</strong></p>
<p>所谓的物理层，是指光纤、电缆或者电磁波等真实存在的物理媒介。这些媒介可以传送物理信号，比如亮度、电压或者振幅。对于数字应用来说，我们只需要两种物理信号来分别表示0和1，比如用高电压表示1，低电压表示0，就构成了简单的物理层协议。针对某种媒介，电脑可以有相应的接口，用来接收物理信号，并解读成为0/1序列。</p>
<p><strong>连接层(link layer)</strong></p>
<p>在连接层，信息以帧(frame)为单位传输。所谓的帧，是一段有限的0/1序列。连接层协议的功能就是识别0/1序列中所包含的帧。比如说，根据一定的0/1组合识别出帧的起始和结束。在帧中，有收信地址(Source, SRC)和送信地址(Destination, DST)，还有能够探测错误的校验序列(Frame Check Sequence)。当然，帧中最重要的最重要是所要传输的数据 (payload)。这些数据往往符合更高层协议，供网络的上层使用。与数据相配套，帧中也有数据的类型(Type)信息。连接层协议不关心数据中到底包含什么。帧就像是一个信封，把数据包裹起来。</p>
<p>以太网(Ethernet)和WiFi是现在最常见的连接层协议。通过连接层协议，我们可以建立局域的以太网或者WiFi局域网，并让位于同一局域网络中的两台计算机通信。</p>
<p><strong>网络层(network layer)</strong></p>
<p>如何让WiFi上的一台计算机和以太网上的另一台计算机通信呢？我们需要一个“中间人”。这个“中间人”必须有以下功能: </p>
<ol>
<li>能从物理层上在两个网络的接收和发送0/1序列</li>
<li>能同时理解两种网络的帧格式</li>
</ol>
<p>路由器(router)就是为此而产生的“翻译”。一个路由器有多个网卡(NIC，Network Interface Controller)，每个NIC可以接入多个网络，并理解相应的连接层协议。在帧经过路由到达另一个网络的时候，路由会读取帧的信息，并改写以发送到另一个网络。</p>
<p>整个通信过程如下:</p>
<p>WiFi上的计算机1 -&gt; 路由WiFi接口 -&gt;  路由以太网接口 -&gt; 以太网上的计算机2</p>
<p>在连接层，我们的一个帧中只能记录SRC和DST两个地址。而上面的过程需要经过四个地址 (计算机1，WiFi接口，以太网接口，计算机2)。显然，仅仅靠连接层协议无法满足我们的需要。由于连接层协议开发在先，我们无法改动连接层协议，只能在连接层的数据(payload)下功夫了，IP协议应运而生。</p>
<p><strong>传输层(transport layer)</strong></p>
<p>上面的三层协议让不同的计算机之间可以通信。但计算机中实际上有许多个进程，每个进程都可能有通信的需求(参看Linux进程基础和Linux进程间通信)。</p>
<p>传输层协议，比如TCP和UDP，使用端口号(port number)来识某个进程。在传输数据的时候，我们写上目的进程的端口。当数据到达另一台计算机时，会根据传输层协议，识别端口号，将信送给不同的进程。</p>
<p>TCP和UDP协议是两种不同的传输层协议。UDP 协议比较简单，但是不太可靠；TCP 协议有着相对复杂的握手机制，比较可靠。TCP协议还有控制网络交通等功能。</p>
<p><strong>应用层(application layer)</strong></p>
<p>通过上面的几层协议，我们已经可以在任意两个进程之间进行通信。应用层协议是对数据内容·进一步的用语规范。应用层的协议包括用于Web浏览的HTTP协议，用于传输文件的FTP协议，用于Email的IMAP等等。</p>
<h2 id="u8FDE_u63A5_u5C42_u534F_u8BAE"><a href="#u8FDE_u63A5_u5C42_u534F_u8BAE" class="headerlink" title="连接层协议"></a>连接层协议</h2><p>以太网和WiFi是连接层的两种协议。在连接层，信息以帧(frame)为单位传输。帧像信封一样将数据(payload)包裹起来，并注明收信地址和送信地址。我们先来看看以太网的帧。</p>
<p><strong>以太网的帧格式</strong></p>
<p>帧本身是一段有限的0/1序列。它可以分为 <code>头部 | 数据(Payload) | 尾部</code> 三部分:</p>
<pre><code>Preamble SFD DST SRC Type | Payload(Data) | Pad FCS Extension
</code></pre><p>帧按照上面的顺序从头到尾依次被发送/接收。我们下面进一步解释各个区域。</p>
<p><strong>头部</strong></p>
<p>帧的最初 7 个 byte 被称为序言(preamble)。它的每个byte都是0xAA(这里是十六进制，也就是二进制的10101010)。通常，我们都会预定好以一定的频率发送0/1序列(比如每秒10bit)。如果接收设备以其他频率接收(比如每秒5bit)，那么就会错漏掉应该接收的0/1信息。但是，由于网卡的不同，发送方和接收方即使预订的频率相同，两者也可能由于物理原因发生偏差。这就好像两个人约好的10点见，结果一个人表快，一个人表慢一样。序言是为了让接收设备调整接收频率，以便与发送设备的频率一致，这个过程就叫做时钟复原(recover the clock)。</p>
<p>时钟调整好之后，我们等待帧的起始信号(SFD, start frame delimiter)。SFD是固定的值0xAB。</p>
<p>紧随SFD之后的是 6 byte的目的地(DST, destination)和 6 byte的发出地(SRC, source)。这里写的是对地址的“本地描述”，也就是MAC地址。MAC地址是物理设备自带的序号，只能在同一个以太网中被识别。</p>
<p>头部的最后一个区域是Type，用以说明数据部分的类型。(比如0x0800为IPv4，0x0806为ARP)</p>
<p><strong>数据</strong></p>
<p>数据一般包含有符合更高层协议的数据，比如IP包。连接层协议本身并不在乎数据是什么，它只负责传输。注意，数据尾部可能填充有一串0(PAD区域)。原因是数据需要超过一定的最小长度。</p>
<p><strong>尾部</strong></p>
<p>跟随在数据之后的是校验序列(FCS, Frame Check Sequence)。校验序列是为了检验数据的传输是否发生错误。</p>
<p>一个方法是将数据发送两遍，然后对比一下是否一样。但这样就大大降低了网络的效率。FCS采用了CRC(Cyclic Redundancy Check)算法。CRC 算法也相类似。n 位 CRC 算法取一个 n bit 的因子，比如下面的 1011。数据序列结尾增加 n-1 个 0。因子与数据序列的不断进行 XOR 运算，直到得到n-1位的余数，也就是100。该余数各位取反(011)，然后存储在FCS的位置。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">11010011101100</span> <span class="number">000</span> &lt;--- 数据序列末尾增加<span class="number">3</span>位<span class="number">0</span></span><br><span class="line"><span class="number">1011</span>               &lt;--- 因子</span><br><span class="line"><span class="number">01100011101100</span> <span class="number">000</span> &lt;--- XOR结果</span><br><span class="line"> <span class="number">1011</span>              &lt;--- 因子</span><br><span class="line"><span class="number">00111011101100</span> <span class="number">000</span></span><br><span class="line">  <span class="number">1011</span></span><br><span class="line"><span class="number">00010111101100</span> <span class="number">000</span></span><br><span class="line">   <span class="number">1011</span></span><br><span class="line"><span class="number">00000001101100</span> <span class="number">000</span></span><br><span class="line">       <span class="number">1011</span></span><br><span class="line"><span class="number">00000000110100</span> <span class="number">000</span></span><br><span class="line">        <span class="number">1011</span></span><br><span class="line"><span class="number">00000000011000</span> <span class="number">000</span></span><br><span class="line">         <span class="number">1011</span></span><br><span class="line"><span class="number">00000000001110</span> <span class="number">000</span></span><br><span class="line">          <span class="number">1011</span></span><br><span class="line"><span class="number">00000000000101</span> <span class="number">000</span> </span><br><span class="line">           <span class="number">101</span> <span class="number">1</span></span><br><span class="line">-----------------</span><br><span class="line"><span class="number">00000000000000</span> <span class="number">100</span> &lt;--- <span class="number">3</span>位余数</span><br></pre></td></tr></table></figure>
<p>上面例子用的是4位CRC。在Ethernet中使用的因子为32位的，以达到更好的检测效果。</p>
<p><strong>集线器(Hub) vs. 交换器(Switch)</strong></p>
<p>以太网使用集线器或者交换器将帧从发出地传送到目的地。一台集线器或交换器上有多个端口，每个端口都可以连接一台计算机(或其他设备)。</p>
<p>集线器像一个广播电台。一台电脑将帧发送到集线器，集线器会将帧转发到所有其他的端口。每台计算机检查自己的MAC地址是不是符合DST。如果不是，则保持沉默。集线器是比较早期的以太网设备。它有明显的缺陷：</p>
<ol>
<li>任意两台电脑的通信在同一个以太网上是公开的。所有连接在同一个集线器上的设备都能收听到别人在传输什么，这样很不安全。可以通过对信息加密提高安全性。</li>
<li>不允许多路同时通信。如果两台电脑同时向集线器发信，集线器会向所有设备发出“冲突”信息，提醒发生冲突。可以在设备上增加冲突检测算法(collision detection)：一旦设备发现有冲突，则随机等待一段时间再重新发送。</li>
</ol>
<p>交换器克服集线器的缺陷。交换器记录有各个设备的MAC地址。当帧发送到交换器时，交换器会检查DST，然后将帧只发送到对应端口。交换器允许多路同时通信。由于交换器的优越性，交换器基本上取代了集线器。但比较老的以太网还有可能在使用集线器。</p>
<p><strong>WiFi</strong></p>
<p>WiFi的工作方式与集线器连接下的以太网类似。一个WiFi设备会向所有的WiFi设备发送帧，其它的WiFi设备检查自己是否符合DST。由于WiFi采取无线电信号，所以很难像交换器一样定向发送，所以WiFi的安全性很值得关注。WiFi采用加密的方法来实现信息的安全性。</p>
<p>(早期的WEP加密方法非常脆弱，建议使用WPA或者WPA2加密方法。隐藏WiFi设备ID的方法不是很有用。)</p>
<h2 id="u7F51_u7EDC_u5C42_u534F_u8BAE"><a href="#u7F51_u7EDC_u5C42_u534F_u8BAE" class="headerlink" title="网络层协议"></a>网络层协议</h2><p>网络层(network layer)是实现互联网的最重要的一层。正是在网络层面上，各个局域网根据 IP 协议相互连接，最终构成覆盖全球的 Internet。更高层的协议，无论是 TCP 还是 UDP，必须通过网络层的 IP 数据包(datagram)来传递信息。操作系统也会提供该层的 socket，从而允许用户直接操作 IP 包。</p>
<p>IP 数据包是符合 IP 协议的信息(也就是0/1序列)，我们后面简称 IP 数据包为 IP 包。IP 包分为头部(header)和数据(Data)两部分。数据部分是要传送的信息，头部是为了能够实现传输而附加的信息。</p>
<p>IP 协议可以分为 IPv4 和 IPv6 两种。IPv6 是改进版本，用于在未来取代 IPv4 协议。下面是 IPv4的格式</p>
<p><img src="/images/14551392855125.jpg" alt=""></p>
<p>与帧类似，IP 包的头部也有多个区域。我们将注意力放在红色的发出地(source address)和目的地(destination address)。它们都是IP地址。IPv4 的地址为 4 bytes的长度(也就是32位)。我们通常将 IPv4 的地址分为四个十进制的数，每个数的范围为 0-255,比如 192.0.0.1 就是一个 IP 地址。填写在 IP 包头部的是该地址的二进制形式。</p>
<p>IP地址是全球地址，它可以识别局域网和主机。这是通过将IP地址分类实现的。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">IP <span class="keyword">class</span>    From          To                Subnet Mask</span><br><span class="line">A           <span class="number">1.0</span><span class="number">.0</span><span class="number">.0</span>       <span class="number">126.255</span><span class="number">.255</span><span class="number">.255</span>    <span class="number">255.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">B           <span class="number">128.0</span><span class="number">.0</span><span class="number">.0</span>     <span class="number">191.255</span><span class="number">.255</span><span class="number">.255</span>    <span class="number">255.255</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">C           <span class="number">192.0</span><span class="number">.0</span><span class="number">.0</span>     <span class="number">223.255</span><span class="number">.255</span><span class="number">.255</span>    <span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>
<p>每个 IP 地址的 32 位分为前后两部分，第一部分用来区分局域网，第二个部分用来区分该局域网的主机。子网掩码(Subnet Mask)告诉我们这两部分的分界线，比如 255.0.0.0 (也就是8个1和24个0)表示前 8 位用于区分局域网，后 24 位用于区分主机。由于 A、B、C 分类是已经规定好的，所以当一个IP地址属于 B 类范围时，我们就知道它的前 16 位和后 16 位分别表示局域网和主机。</p>
<p><strong>网卡与路由器</strong></p>
<p>IP地址实际上识别的是网卡(NIC, Network Interface Card)。网卡是计算机的一个硬件，它在接收到网路信息之后，将信息交给计算机(处理器/内存)。当计算机需要发送信息的时候，也要通过网卡发送。一台计算机可以有不只一个网卡，比如笔记本就有一个以太网卡和一个WiFi网卡。计算机在接收或者发送信息的时候，要先决定想要通过哪个网卡。</p>
<p>路由器(router)实际上就是一台配备有多个网卡的专用电脑。它让网卡接入到不同的网络中。</p>
<h3 id="IP__u5305_u63A5_u529B"><a href="#IP__u5305_u63A5_u529B" class="headerlink" title="IP 包接力"></a>IP 包接力</h3><p>IP 包的传输要通过路由器的接力。每一个主机和路由中都存有一个路由表(routing table)。路由表根据目的地的 IP 地址，规定了等待发送的 IP 包所应该走的路线。</p>
<p>比如我们从主机 145.17 生成发送到 146.21 的IP包，注明目的地IP地址(199.165.146.21)和发出地IP地址(199.165.145.17)。主机 145.17 随后参照自己的 routing table，里面有三行记录：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">145<span class="class">.17</span> <span class="tag">routing</span> <span class="tag">table</span> (<span class="tag">Genmask</span>为子网掩码,<span class="tag">Iface</span>用于说明使用哪个网卡接口)</span><br><span class="line"><span class="tag">Destination</span>        <span class="tag">Gateway</span>             <span class="tag">Genmask</span>             <span class="tag">Iface</span></span><br><span class="line">199<span class="class">.165</span><span class="class">.145</span><span class="class">.0</span>      0<span class="class">.0</span><span class="class">.0</span><span class="class">.0</span>             255<span class="class">.255</span><span class="class">.255</span><span class="class">.0</span>       <span class="tag">eth0</span></span><br><span class="line">0<span class="class">.0</span><span class="class">.0</span><span class="class">.0</span>            199<span class="class">.165</span><span class="class">.145</span><span class="class">.17</span>      0<span class="class">.0</span><span class="class">.0</span><span class="class">.0</span>             <span class="tag">eth0</span></span><br></pre></td></tr></table></figure>
<p>这里有两行记录。</p>
<p>第一行表示，如果 IP 目的地是 199.165.145.0 这个网络的主机，那么只需要自己在 eth0 上的网卡直接传送，不需要前往 router(Gateway 0.0.0.0 = “本地”)。</p>
<p>第二行表示所有不符合第一行的 IP 目的地，都应该送往 Gateway 199.165.145.17，也就是中间 router 接入在 eth0 的网卡 IP 地址。</p>
<p>我们的 IP 包目的地为 199.165.146.21，不符合第一行，所以按照第二行，发送到中间的 router。主机 145.17 会将 IP 包放入帧的 payload，并在帧的头部写上 199.165.145.17 对应的 MAC 地址，这样，就可以在局域网中传送了。</p>
<p>中间的 router 在收到 IP 包之后(实际上是收到以太协议的帧，然后从帧中的 payload 读取 IP 包)，提取目的地IP地址，然后对照自己的routing table：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Destination        Gateway             Genmask             Iface</span><br><span class="line"><span class="number">199.165</span><span class="number">.145</span><span class="number">.0</span>      <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>             <span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span>       eth0</span><br><span class="line"><span class="number">199.165</span><span class="number">.146</span><span class="number">.0</span>      <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>             <span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span>       eth1</span><br><span class="line"><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>            <span class="number">199.165</span><span class="number">.146</span><span class="number">.8</span>       <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>             eth1</span><br></pre></td></tr></table></figure>
<p>从前两行我们看到，由于 router 横跨 eth0 和 eth1 两个网络，它可以直接通过 eth0 和 eth1 上的网卡直接传送IP包。</p>
<p>第三行表示，如果是前面两行之外的 IP 地址，则需要通过 eth1，送往 199.165.146.8(右边的router)。</p>
<p>我们的目的地符合第二行，所以将IP放入一个新的帧中，</p>
<p>在帧的头部写上 199.165.146.21 的MAC地址，直接发往主机 146.21。</p>
<p>(在Linux下，可以使用 <code>$route -n</code> 来查看 routing table)</p>
<p>IP 包可以进一步接力，到达更远的主机。IP 包从主机出发，根据沿途路由器的 routing table 指导，在 router 间接力。IP 包最终到达某个 router，这个 router 与目标主机位于一个局域网中，可以直接建立连接层的通信。最后，IP 包被送到目标主机。这样一个过程叫做 routing(我们就叫 IP 包接力好了，路由这个词实在是混合了太多的意思)。</p>
<p>整个过程中，IP 包不断被主机和路由封装入帧并拆开，然后借助连接层，在局域网的各个 NIC 之间传送帧。整个过程中，我们的 IP 包的内容保持完整，没有发生变化。最终的效果是一个 IP 包从一个主机传送到另一个主机。利用 IP 包，我们不需要去操心底层(比如连接层)发生了什么。</p>
<h3 id="ARP_u534F_u8BAE"><a href="#ARP_u534F_u8BAE" class="headerlink" title="ARP协议"></a>ARP协议</h3><p>在上面的过程中，我们实际上假设了，每一台主机和路由都能了解局域网内的 IP 地址和 MAC 地址的对应关系，这是实现 IP 包封装(encapsulation)到帧的基本条件。IP 地址与 MAC 地址的对应是通过 ARP 协议传播到局域网的每个主机和路由。每一台主机或路由中都有一个 ARP cache，用以存储局域网内 IP 地址和 MAC 地址如何对应。</p>
<p>ARP 协议(ARP 介于连接层和网络层之间，ARP 包需要包裹在一个帧中)的工作方式如下：主机会发出一个 ARP 包，该 ARP 包中包含有自己的 IP 地址和 MAC 地址。通过 ARP 包，主机以广播的形式询问局域网上所有的主机和路由：我是 IP 地址 xxxx，我的 MAC 地址是 xxxx，有人知道 199.165.146.4 的MAC地址吗？拥有该 IP 地址的主机会回复发出请求的主机：哦，我知道，这个 IP 地址属于我的一个 NIC，它的 MAC 地址是 xxxxxx。由于发送 ARP 请求的主机采取的是广播形式，并附带有自己的 IP 地址和 MAC 地址，其他的主机和路由会同时检查自己的 ARP cache，如果不符合，则更新自己的 ARP cache。</p>
<p>这样，经过几次ARP请求之后，ARP cache会达到稳定。如果局域网上设备发生变动，ARP重复上面过程。</p>
<p>(在 Linux 下，可以使用 <code>$arp</code> 命令来查看 ARP 的过程。ARP 协议只用于 IPv4。IPv6 使用Neighbor Discovery Protocol 来替代 ARP 的功能。)</p>
<p><strong>Routing Table 的生成</strong></p>
<p>我们还有另一个假设，就是每个主机和路由上都已经有了合理的 routing table。这个 routing table描述了网络的拓扑(topology)结构。如果你了解自己的网络连接，可以手写自己主机的 routing table。但是，一个路由器可能有多个出口，所以 routing table 可能会很长。更重要的是，周围连接的其他路由器可能发生变动(比如新增路由器或者路由器坏掉)，我们就需要 routing table 能及时将交通导向其他的出口。我们需要一种更加智能的探测周围的网络拓扑结构，并自动生成 routing table。</p>
<p>一种用来生成 routing table 的协议是 RIP(Routing Information Protocol)。它通过距离来决定 routing table，所以属于 distance-vector protocol。对于RIP来说，所谓的距离是从出发地到目的地途径的路由器数目(hop number)。各个点不断重复RIP广播/计算距离/更新routing table的过程，最终所有的主机和路由器都能生成最合理的路径(merge)。</p>
<p>(RIP的基本逻辑是：如果A距离B为6，而我距离A为1，那么我途径A到B的距离为7)</p>
<p>RIP出于技术上的原因(looping hops)，认为距离超过15的IP不可到达。所以RIP更多用于互联网的一部分(比如整个中国电信的网络)。这样一个互联网的部分往往属于同一个 ISP 或者有同一个管理机构，所以叫做自治系统(AS,autonomous system)。自治系统内部的主机和路由根据通向外部的边界路由器来和其它的自治系统通信。各个边界路由器之间通过 BGP(Border Gateway Protocol)来生成自己前往其它 AS 的 routing table，而自治系统内部则参照边界路由器，使用 RIP 来决定 routing table。BGP 的基本工作过程与 RIP 类似，但在考虑距离的同时，也权衡比如政策、连接性能等其他因素，再决定交通的走向(routing table)。</p>
<h3 id="u5730_u5740_u8017_u5C3D_u5371_u673A"><a href="#u5730_u5740_u8017_u5C3D_u5371_u673A" class="headerlink" title="地址耗尽危机"></a>地址耗尽危机</h3><p>IP 地址是 IP 协议的重要组成部分，它可以识别接入互联网中的任意一台设备。在 IP 接力中，我们已经看到，IP 包的头部写有出发地和目的地的 IP 地址。IP 包上携带的 IP 地址和路由器相配合，最终允许 IP 包从互联网的一台电脑传送到另一台。</p>
<p>在 IP 接力中，我们是以 IPv4 为例说明 IP 包的格式的。IPv4 和 IPv6 是先后出现的两个 IP 协议版本。IPv4 的地址就是一个 32 位的 0/1 序列，比如 11000000 00000000 0000000 00000011。为了方便人类记录和阅读，我们通常将 32 位 0/1 分成 4 段 8 位序列，并用 10 进制来表示每一段(这样，一段的范围就是 0 到 255)，段与段之间以 <code>.</code> 分隔。比如上面的地址可以表示成为 192.0.0.3。IPv6 地址是 128 位 0/1 序列，它也按照 8 位分割，以 16 进制来记录每一段(使用 16 进制而不是 10 进制，这能让写出来的 IPv6 地址短一些)，段与段之间以 <code>:</code> 分隔。</p>
<p>IP地址的分配是一个政策性的问题。ICANN(the Internet Corporation for Assigned Names and Numbers) 是 Internet 的中心管理机构。ICANN 的 IANA(Internet Assigned Numbers Authourity)部门负责将 IP 地址分配给 5 个区域性的互联网注册机构(RIR，Reginal Internet Registry)，比如 APNIC，它负责亚太地区的 IP 分配。然后 RIR 将地址进一步分配给当地的ISP(Internet Service Provider)，比如中国电信和中国网通。ISP 再根据自己的情况，将 IP 地址分配给机构或者直接分配给用户，比如将 A 类地址分配给一个超大型机构，而将 C 类地址分配给一个网吧。机构可以进一步在局域网内部分配 IP 地址给各个主机。(A/B/C类地址请参阅IP接力)</p>
<p>并不是所有的地址都会被分配。一些地址被预留，用于广播、测试、私有网络使用等。这些地址被称为专用地址(special-use address)。你可以查询 RFC5735 来了解哪些地址是专用地址。</p>
<p>(RFC，Request For Comments。RFC是一系列的技术文档，用于记录Internet相关的技术和协议规定。每一个RFC文件都有一个固定的编号。它们是互联网的一个重要财产。你可以通过 <a href="http://www.rfc-editor.org/" target="_blank" rel="external">http://www.rfc-editor.org/</a> 来查找RFC文件)</p>
<p>由于IPv4协议的地址为32位，所以它可以提供 <code>2^32</code> , 也就是大约 40 亿个地址。如果地球人每人一个 IP 地址的话，IPv4 地址已经远远不够。更何况，人均持有的入网设备可能要远多于一个</p>
<p>尽管一些技术措施（比如NAT技术）减缓了情况的紧急程度，但 IPv4 地址耗尽的一天终究还是会很快到来。很明显，我们需要更多的 IP 地址，以满足爆炸式增长的互联网设备对 IP 地址的需求。</p>
<p>IPv6协议的地址最重要的改进就是：加长。IPv6的地址为128位。准确的说，IPv4有4,294,967,296个地址，而IPv6有</p>
<p>340,282,366,920,938,463,374,607,431,768,211,456</p>
<p>个地址。这是怎样一个概念呢？我们可以大概计算一下</p>
<p>地球表面积大约为 510,067,866,000,000 平方米。在一平方厘米(大约是指甲盖大小)的面积内，我们可以有 <code>6.67x10^16</code> 个 IP 地址！所以在短期的时间内，我们应该不会看到 IPv6 被用尽的尴尬。(不排除在未来计算机以分子尺寸出现，那么我们就会有IPv6耗尽危机了)</p>
<p>IPv4 地址正在耗尽，而 IPv6 通过更长的序列提供了更多的 IP 地址。IPv4 向 IPv6 的迁移正在发生。</p>
<p>阻碍迁移的过程的主要在于 IPv4 和 IPv6 格式的不兼容性。老的路由器支持 IPv4 格式的IP包，但它们无法理解 IPv6 格式的 IP 包。所以这一迁移过程必然要伴随者设备的更新。然而，我们的许多互联网资产都是建立在 IPv4 网络上的，不可能一夜之间停止 IPv4 网络的服务而整体迁移到 IPv6 网络中。这一迁移过程注定充满坎坷。</p>
<h3 id="IP__u534F_u8BAE_u8BE6_u89E3"><a href="#IP__u534F_u8BAE_u8BE6_u89E3" class="headerlink" title="IP 协议详解"></a>IP 协议详解</h3><p>在粗略了解了IP接力和IP地址后，我们再反过来，看一看IP协议的具体细节和设计哲学。</p>
<p>我们已经在IP接力中介绍过，一个IP包分为头部(header)和数据(payload/data)两部分。头部是为了实现IP通信必须的附加信息，数据是IP通信所要传送的信息。</p>
<p><img src="/images/14551393750144.jpg" alt=""></p>
<p><strong>黄色区域 (同名区域)</strong></p>
<p>我们看到，三个黄色区域跨越了 IPv4 和 IPv6。Version(4位)用来表明 IP 协议版本，是 IPv4 还是 IPv6(IPv4, Version=0100; IPv6, Version=0110)。Source Adrresss 和 Destination Address 分别为发出地和目的地的 IP 地址。</p>
<p><strong>蓝色区域 （名字发生变动的区域）</strong></p>
<p>Time to Live 存活时间(Hop Limit in IPv6)。Time to Live 最初是表示一个 IP 包的最大存活时间：如果 IP 包在传输过程中超过 Time to Live，那么 IP 包就作废。后来，IPv4 的这个区域记录一个整数(比如30)，表示在 IP 包接力过程中最多经过30个路由接力，如果超过30个路由接力，那么这个 IP 包就作废。IP 包每经过一个路由器，路由器就给 Time to Live 减一。当一个路由器发现 Time to Live 为0时，就不再发送该 IP 包。IPv6 中的 Hop Limit 区域记录的也是最大路由接力数，与 IPv4 的功能相同。Time to Live/Hop Limit 避免了 IP 包在互联网中无限接力。</p>
<p>Type of Service 服务类型(Traffic Class in IPv6)。Type of Service 最初是用来给 IP 包分优先级，比如语音通话需要实时性，所以它的 IP 包应该比 Web 服务的 IP 包有更高的优先级。然而，这个最初不错的想法没有被微软采纳。在Windows下生成的 IP 包都是相同的最高优先级，所以在当时造成 Linux 和 Windows 混合网络中，Linux 的 IP 传输会慢于 Windows (仅仅是因为Linux更加守规矩！)。后来，Type of Service 被实际分为两部分：Differentiated Service Field (DS, 前6位)和 Explicit Congestion Notification (ECN, 后2位)，前者依然用来区分服务类型，而后者用于表明 IP 包途径路由的交通状况。IPv6 的T raffic Class 也被如此分成两部分。通过IP包提供不同服务的想法，并针对服务进行不同的优化的想法已经产生很久了，但具体做法并没有形成公认的协议。比如 ECN 区域，它用来表示 IP 包经过路径的交通状况。如果接收者收到的 ECN 区域显示路径上的很拥挤，那么接收者应该作出调整。但在实际上，许多接收者都会忽视 ECN 所包含的信息。交通状况的控制往往由更高层的比如 TCP 协议实现。</p>
<p>Protocol 协议(Next Header in IPv6)。Protocol 用来说明 IP 包 Payload 部分所遵循的协议，也就是 IP 包之上的协议是什么。它说明了 IP 包封装的是一个怎样的高层协议包(TCP? UDP?)。</p>
<p>Total Length, 以及 IPv6 中 Payload Length 的讨论要和 IHL 区域放在一起，我们即将讨论。</p>
<p><strong>红色区域 (IPv6中删除的区域)</strong></p>
<p>我们看一下 IPv4 和 IPv6 的长度信息。IPv4 头部的长度。在头部的最后，是 options。每个 options 有32位，是选填性质的区域。一个 IPv4 头部可以完全没有 options 区域。不考虑 options 的话，整个 IPv4 头部有 20 bytes(上面每行为4 bytes)。但由于有 options 的存在，整个头部的总长度是变动的。我们用 IHL(Internet Header Length)来记录头部的总长度，用 Total Length 记录整个 IP 包的长度。IPv6 没有 options，它的头部是固定的长度 40 bytes，所以 IPv6 中并不需要 IHL 区域。Payload Length 用来表示 IPv6 的数据部分的长度。整个 IP 包为 40 bytes + Payload Length。</p>
<p>IPv4 中还有一个 Header Checksum 区域。这个 checksum 用于校验 IP 包的头部信息。Checksum 与之前的 CRC 算法并不相同。IPv6 则没有 checksum 区域。IPv6 包的校验依赖高层的协议来完成，这样的好处是免去了执行 checksum 校验所需要的时间，减小了网络延迟 (latency)。</p>
<p>Identification, flags 和 fragment offset，这三个包都是为碎片化(fragmentation)服务的。碎片化是指一个路由器将接收到的 IP 包分拆成多个 IP 包传送，而接收这些“碎片”的路由器或者主机需要将“碎片”重新组合(reassembly)成一个 IP 包。不同的局域网所支持的最大传输单元(MTU, Maximum Transportation Unit)不同。如果一个 IP 包的大小超过了局域网支持的MTU，就需要在进入该局域网时碎片化传输(就好像方面面面饼太大了，必须掰碎才能放进碗里)。碎片化会给路由器和网络带来很大的负担。最好在 IP 包发出之前探测整个路径上的最小 MTU，IP 包的大小不超过该最小MTU，就可以避免碎片化。IPv6 在设计上避免碎片化。每一个 IPv6 局域网的 MTU 都必须大于等于1280 bytes。IPv6 的默认发送 IP 包大小为 1280 bytes。</p>
<p><strong>绿色区域 (IPv6新增区域)</strong></p>
<p>Flow Label 是 IPv6 中新增的区域。它被用来提醒路由器来重复使用之前的接力路径。这样IP包可以自动保持出发时的顺序。这对于流媒体之类的应用有帮助。Flow label 的进一步使用还在开发中。</p>
<p><strong>我尽力</strong></p>
<p>IP 协议在产生时是一个松散的网络，这个网络由各个大学的局域网相互连接成的，由一群碰头垢面的 Geek 维护。所以，IP 协议认为自己所处的环境是不可靠(unreliable)的：诸如路由器坏掉、实验室失火、某个 PhD 踢掉电缆之类的事情随时会发生。</p>
<p>这样的凶险环境下，IP 协议提供的传送只能是“我尽力” (best effort)式的。所谓的“我尽力”，其潜台词是，如果事情出错不要怪我，我只是答应了尽力，可没保证什么。所以，如果 IP 包传输过程中出现错误(比如 checksum 对不上，比如交通太繁忙，比如超过 Time to Live)，根据 IP 协议，你的 IP 包会直接被丢掉。Game Over, 不会再有进一步的努力来修正错误。Best effort让IP协议保持很简单的形态。更多的质量控制交给高层协议处理，IP协议只负责有效率的传输。</p>
<p>“效率优先”也体现在IP包的顺序(order)上。即使出发地和目的地保持不变，IP 协议也不保证 IP 包到达的先后顺序。我们已经知道，IP 接力是根据 routing table 决定接力路线的。如果在连续的 IP 包发送过程中，routing table 更新(比如有一条新建的捷径出现)，那么后发出的 IP 包选择走不一样的接力路线。如果新的路径传输速度更快，那么后发出的 IP 包有可能先到。这就好像是多车道的公路上，每辆车都在不停变换车道，最终所有的车道都塞满汽车。这样可以让公路利用率达到最大。</p>
<p>IPv6 中的 Flow Label 可以建议路由器将一些 IP 包保持一样的接力路径。但这只是“建议”，路由器可能会忽略该建议。</p>
<h3 id="Header_Checksum_u7B97_u6CD5"><a href="#Header_Checksum_u7B97_u6CD5" class="headerlink" title="Header Checksum算法"></a>Header Checksum算法</h3><p>Header Checksum 区域有 16 位。它是这样获得的，从 header 取得除 checksum 之外的0/1序列，比如：</p>
<p>9194 8073 0000 4000 4011 C0A8 0001 C0A8 00C7 (十六进制 hex, 这是一个为演示运算过程而设计的header)</p>
<p>按照十六位(也就是 4 位 hex)分割整个序列。将分割后的各个 4 位 hex 累积相加。如果有超过 16 位的进位出现，则将进位加到后 16 位结果的最后一位：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  Binary                Hex</span><br><span class="line">  <span class="number">1001000110010100</span>      <span class="number">9194</span></span><br><span class="line">+ <span class="number">1000000001110011</span>      <span class="number">8073</span></span><br><span class="line">  ----------------</span><br><span class="line"><span class="number">1</span> <span class="number">0001001000000111</span>     <span class="number">11207</span></span><br><span class="line">+                <span class="number">1</span></span><br><span class="line">  ----------------</span><br><span class="line">  <span class="number">0001001000001000</span>      <span class="number">1208</span></span><br></pre></td></tr></table></figure>
<p>上面的计算叫做 one’s complement sum。求得所有十六位数的和，</p>
<p>one’s complement sum(4500, 0073, 0000, 4000, 4011, C0A8, 0001, C0A8, 00C7) = 1433</p>
<p>然后，将1433的每一位取反(0-&gt;1, 1-&gt;0)， 就得到checksum：EBCC</p>
<p>这样，我们的header就是:</p>
<p>9194 8073 0000 4000 4011 EBCC C0A8 0001 C0A8 00C7</p>
<p>IP 包的接收方在接收到 IP 包之后，可以求上面各个 16 位数的 one’s complement sum，应该得到 FFFF。如果不是 FFFF，那么 header 是不正确的，整个 IP 包会被丢弃。</p>
<p>(再次提醒，示例所用的 IP header 不是真实的 header，它只是起演示算法的作用)</p>
<p>每个网络协议的形成都有其历史原因。比如 IP 协议是为了将各个分散的实验室网络连接起来。由于当时的网络很小，所以 IPv4(IPv4产生与70年代)的地址总量为 40 亿。尽管当时被认为是很大的数字，但数字浪潮很快带来了地址耗尽危机。IPv6 的主要目的是增加 IPv4 的地址容量，但同时根据 IPv4 的经验和新时代的技术进步进行改进，比如避免碎片化，比如取消 checksum (由于高层协议 TCP 的广泛使用)。网络协议技术上并不复杂，更多的考量是政策性的。</p>
<p>IP协议是”Best Effort”式的，IP传输是不可靠的。但这样的设计成就了IP协议的效率。</p>
<h3 id="ICMP_u534F_u8BAE"><a href="#ICMP_u534F_u8BAE" class="headerlink" title="ICMP协议"></a>ICMP协议</h3><p>到现在为止，我们讲解了网络层中最重要的IP协议。IP协议的一个重要补充是是ICMP协议。</p>
<p>ICMP(Internet Control Message Protocol)是介于网络层和传输层的协议。它的主要功能是传输网络诊断信息。</p>
<p>ICMP传输的信息可以分为两类，一类是错误(error)信息，这一类信息可用来诊断网络故障。我们已经知道，IP协议的工作方式是“Best Effort”，如果IP包没有被传送到目的地，或者IP包发生错误，IP协议本身不会做进一步的努力。但上游发送 IP 包的主机和接力的路由器并不知道下游发生了错误和故障，它们可能继续发送 IP 包。通过 ICMP 包，下游的路由器和主机可以将错误信息汇报给上游，从而让上游的路由器和主机进行调整。需要注意的是，ICMP 只提供特定类型的错误汇报，它不能帮助 IP 协议成为“可靠”(reliable)的协议。另一类信息是咨询(Informational)性质的，比如某台计算机询问路径上的每个路由器都是谁，然后各个路由器同样用 ICMP 包回答。</p>
<p>(ICMP 基于 IP 协议。也就是说，一个 ICMP 包需要封装在 IP 包中，然后在互联网传送。ICMP 是 IP 套装的必须部分，也就是说，任何一个支持 IP 协议的计算机，都要同时实现 ICMP。)</p>
<p>ICMP包的结构：</p>
<p><img src="/images/14551393925085.jpg" alt=""></p>
<p>ICMP 包都会有 Type, Code 和 Checksum 三部分。Type 表示 ICMP 包的大的类型，而 Code 是一个 Type 之内细分的小类型。针对不同的错误信息或者咨询信息，会有不同的 Type 和 Code。从上面我们可以看到，ICMP 支持的类型非常多，就好像瑞士军刀一样，有各种各样的功能。Checksum 与 IP 协议的 header checksum 相类似，但与 IP 协议中 checksum 只校验头部不同，这里的 Checksum 所校验的是整个 ICMP 包(包括头部和数据)。</p>
<p>余下的 ICMP 包格式根据不同的类型不同。另一方面，ICMP 包通常是由某个 IP 包触发的。这个触发 IP 包的头部和一部份数据会被包含在 ICMP 包的数据部分。</p>
<p>ICMP 协议是实现 ping 命令和 traceroute 命令的基础。这两个工具常用于网络排错。</p>
<h3 id="u5E38_u89C1_u7684ICMP_u5305_u7C7B_u578B"><a href="#u5E38_u89C1_u7684ICMP_u5305_u7C7B_u578B" class="headerlink" title="常见的ICMP包类型"></a>常见的ICMP包类型</h3><p><strong>回音</strong></p>
<p>回音(Echo)属于咨询信息。ping 命令就是利用了该类型的 ICMP包。当使用 ping 命令的时候，将向目标主机发送Echo-询问类型的 ICMP 包，而目标主机在接收到该 ICMP 包之后，会回复Echo-回答类型的 ICMP 包，并将询问 ICMP 包包含在数据部分。ping 命令是我们进行网络排查的一个重要工具。如果一个 IP 地址可以通过 ping 命令收到回复，那么其他的网络协议通信方式也很有可能成功。</p>
<p><strong>源头冷却</strong></p>
<p>源头冷却(source quench)属于错误信息。如果某个主机快速的向目的地传送数据，而目的地主机没有匹配的处理能力，目的地主机可以向出发主机发出该类型的 ICMP 包，提醒出发主机放慢发送速度。</p>
<p><strong>目的地无法到达</strong></p>
<p>目的地无法到达(Destination Unreachable)属于错误信息。如果一个路由器接收到一个没办法进一步接力的 IP 包，它会向出发主机发送该类型的 ICMP 包。比如当 IP 包到达最后一个路由器，路由器发现目的地主机 down 机，就会向出发主机发送目的地无法到达(Destination Unreachable)类型的 ICMP 包。目的地无法到达还可能有其他的原因，比如不存在接力路径，比如不被接收的端口号等等。</p>
<p><strong>超时</strong></p>
<p>超时(Time Exceeded)属于错误信息。IPv4 中的 Time to Live(TTL)和 IPv6 中的 Hop Limit会随着经过的路由器而递减，当这个区域值减为 0 时，就认为该 IP 包超时(Time Exceeded)。Time Exceeded 就是 TTL 减为 0 时的路由器发给出发主机的 ICMP 包，通知它发生了超时错误。</p>
<p>traceroute 就利用了这种类型的ICMP包。traceroute 命令用来发现 IP 接力路径(route)上的各个路由器。它向目的地发送 IP 包，第一次的时候，将 TTL 设置为 1，引发第一个路由器的 Time Exceeded 错误。这样，第一个路由器回复 ICMP 包，从而让出发主机知道途径的第一个路由器的信息。随后 TTL 被设置为 2、3、4，…，直到到达目的主机。这样，沿途的每个路由器都会向出发主机发送 ICMP 包来汇报错误。traceroute 将 ICMP 包的信息打印在屏幕上，就是接力路径的信息了。</p>
<p><strong>重新定向</strong></p>
<p>重新定向(redirect)属于错误信息。当一个路由器收到一个 IP 包，对照其 routing table，发现自己不应该收到该 IP 包，它会向出发主机发送重新定向类型的 ICMP，提醒出发主机修改自己的routing table。比如下面的网络：</p>
<p><img src="/images/14551394092221.jpg" alt=""></p>
<p>假如 145.1 发送到 145.15 的 IP 包，结果被中间的路由器通过 145.17 的 NIC 收到。那么路由器会发现，根据自己的 routing table，这个 IP 包要原路返回。那么 router 就可以判断出 145.1 的 routing table 可能有问题。所以路由器会向 145.1 发送 redirect 类型的 ICMP 包。</p>
<p><strong>IPv6 的 Neighbor Discovery</strong></p>
<p>ARP 协议用于发现周边的 IP 地址和 MAC 地址的对应。然而，ARP 协议只用于 IPv4，IPv6 并不使用 ARP 协议。IPv6 包通过邻居探索(ND, Neighbor Discovery)来实现 ARP 的功能。ND 的工作方式与 ARP 类似，但它基于 ICMP 协议。ICMP 包有 Neighbor Solicitation 和 Neighbor Advertisement 类型。这两个类型分别对应ARP协议的询问和回复信息。</p>
<p>ICMP 协议是 IP 协议的排错帮手，它可以帮助人们及时发现 IP 通信中出现的故障。基于 ICMP 的 ping 和 traceroute 也构成了重要的网络诊断工具。然而，需要注意的是，尽管 ICMP 的设计是出于好的意图，但 ICMP 却经常被黑客借用进行网络攻击，比如利用伪造的 IP 包引发大量的 ICMP 回复，并将这些 ICMP 包导向受害主机，从而形成 DoS 攻击。而 redirect 类型的 ICMP 包可以引起某个主机更改自己的 routing table，所以也被用作攻击工具。许多站点选择忽视某些类型的 ICMP 包来提高自身的安全性。</p>
<h2 id="u4F20_u8F93_u5C42_u534F_u8BAE"><a href="#u4F20_u8F93_u5C42_u534F_u8BAE" class="headerlink" title="传输层协议"></a>传输层协议</h2><h3 id="UDP_u534F_u8BAE"><a href="#UDP_u534F_u8BAE" class="headerlink" title="UDP协议"></a>UDP协议</h3><p>我们已经讲解了物理层、连接层和网络层。最开始的连接层协议种类繁多(Ethernet、Wifi、ARP等等)。到了网络层，我们只剩下一个 IP 协议(IPv4和IPv6是替代关系)。进入到传输层(transport layer)，协议的种类又开始繁多起来(比如 TCP、UDP、SCTP 等)。这就好像下面的大树，根部(连接层)分叉很多，然后统一到一个树干(网络层)，到了树冠(传输层)部分又开始开始分叉，而每个树枝上长出更多的树叶(应用层)。我们在网络层已经看到，通过树干的统一，我们实现了一个覆盖全球的互联网络(Internet)。然而，我们可能出于不同的目的利用这张“网”，随之使用的方式也有所区分。不同的传输层协议(以及更多的应用层协议)正是我们使用“网”的不同方式的体现。</p>
<p>传输层最重要的协议为 TCP 协议和 UDP 协议。这两者使用“网”的方式走了两个极端。两个协议的对比非常有趣。TCP 协议复杂，但传输可靠。UDP 协议简单，但传输不可靠。其他的各个传输层协议在某种程度上都是这两个协议的折中。我们先来看传输层协议中比较简单的 UDP 协议。</p>
<p>UDP(User Datagram Protocol)传输与 IP 传输非常类似。你可以将 UDP 协议看作 IP 协议暴露在传输层的一个接口。UDP 协议同样以数据包(datagram)的方式传输，它的传输方式也是”Best Effort”的，所以 UDP 协议也是不可靠的(unreliable)。那么，我们为什么不直接使用 IP 协议而要额外增加一个 UDP 协议呢？一个重要的原因是 IP 协议中并没有端口(port)的概念。IP 协议进行的是 IP 地址到 IP 地址的传输，这意味者两台计算机之间的对话。但每台计算机中需要有多个通信通道，并将多个通信通道分配给不同的进程使用。一个端口就代表了这样的一个通信通道。正如我们在邮局和邮差中提到的收信人的概念一样。UDP 协议实现了端口，从而让数据包可以在送到 IP 地址的基础上，进一步可以送到某个端口。</p>
<p>尽管 UDP 协议非常简单，但它的产生晚于更加复杂的 TCP 协议。早期的网络开发者开发出 IP 协议和 TCP 协议分别位于网络层和传输层，所有的通信都要先经过 TCP 封装，再经过 IP 封装(应用层-&gt;TCP-&gt;IP)。开发者将 TCP/IP 视为相互合作的套装。但很快，网络开发者发现，IP 协议的功能和 TCP 协议的功能是相互独立的。对于一些简单的通信，我们只需要“Best Effort”式的 IP 传输就可以了，而不需要 TCP 协议复杂的建立连接的方式(特别是在早期网络环境中，如果过多的建立 TCP 连接，会造成很大的网络负担，而 UDP 协议可以相对快速的处理这些简单通信)。UDP 协议随之被开发出来，作为 IP 协议在传输层的”傀儡”。这样，网络通信可以通过应用层-&gt;UDP-&gt;IP 的封装方式，绕过 TCP 协议。由于 UDP 协议本身异常简单，实际上只为 IP 传输起到了桥梁的作用。我们将在 TCP 协议的讲解中看到更多 TCP 协议和 UDP 协议的对比。</p>
<p>UDP 的数据包同样分为头部(header)和数据(payload)两部分。UDP 是传输层(transport layer)协议，这意味着 UDP 的数据包需要经过 IP 协议的封装(encapsulation)，然后通过 IP 协议传输到目的电脑。随后 UDP 包在目的电脑拆封，并将信息送到相应端口的缓存中。</p>
<p><strong>UDP协议的头部</strong></p>
<p><img src="/images/14551394375473.jpg" alt=""></p>
<p>上面的 source port 和 destination port 分别为 UDP 包的出发端口和目的地端口。Length 为整个 UDP 包的长度。</p>
<p>checksum 的算法与 IP 协议的 header checksum 算法相类似。然而，UDP 的 checksum 所校验的序列包括了整个 UDP 数据包，以及封装的 IP 头部的一些信息(主要为出发地 IP 和目的地 IP)。这样，checksum 就可以校验 IP：端口的正确性了。在 IPv4 中，checksum 可以为 0，意味着不使用 checksum。IPv6 要求必须进行 checksum 校验。</p>
<p><strong>端口与 socket</strong></p>
<p>端口(port)是伴随着传输层诞生的概念。它可以将网络层的 IP 通信分送到各个通信通道。UDP 协议和 TCP 协议尽管在工作方式上有很大的不同，但它们都建立了从一个端口到另一个端口的通信。</p>
<p>随着我们进入传输层，我们也可以调用操作系统中的 API，来构建 socket。Socket 是操作系统提供的一个编程接口，它用来代表某个网络通信。应用程序通过 socket 来调用系统内核中处理网络协议的模块，而这些内核模块会负责具体的网络协议的实施。这样，我们可以让内核来接收网络协议的细节，而我们只需要提供所要传输的内容就可以了，内核会帮我们控制格式，并进一步向底层封装。因此，在实际应用中，我们并不需要知道具体怎么构成一个 UDP 包，而只需要提供相关信息(比如 IP 地址，比如端口号，比如所要传输的信息)，操作系统内核会在传输之前会根据我们提供的相关信息构成一个合格的 UDP 包(以及下层的包和帧)。socket 是一个比较大的课题，在这里不会过多深入。</p>
<p>端口是传输层带来的最重要的概念。我们进一步了解了 UDP 协议。如果已经掌握了 IP 协议，那么 UD P协议就没有任何困难可言，它只是 IP 协议暴露在传输层上的接口。</p>
<h3 id="TCP_u534F_u8BAE_u4E0E_u6D41_u901A_u4FE1"><a href="#TCP_u534F_u8BAE_u4E0E_u6D41_u901A_u4FE1" class="headerlink" title="TCP协议与流通信"></a>TCP协议与流通信</h3><p>TCP(Transportation Control Protocol)协议与 IP 协议是一同产生的。事实上，两者最初是一个协议，后来才被分拆成网络层的 IP 和传输层的 TCP。我们已经在 UDP 协议中介绍过，UDP 协议是 IP 协议在传输层的“傀儡”，用来实现数据包形式的通信。而 TCP 协议则实现了“流”形式的通信。</p>
<p>TCP的内容非常丰富。我不能在一篇文章中将TCP讲完。这一篇主要介绍TCP协议的下面几个方面：</p>
<ol>
<li>“流”通信的意义与实现方式</li>
<li>如何实现可靠传输</li>
<li>使用滑窗提高效率</li>
</ol>
<p>TCP 协议是传输层协议，实现的是端口到端口(port)的通信。更进一步，TCP 协议虚拟了文本流(byte stream)的通信。在 Linux 文本流中我们谈到，计算机数据的本质是有序的 0/1 序列 (如果以 byte为单位，就叫做文本流)。计算机的功能就是储存和处理文本流。CPU + memory + 存储设备实现了文本流在同一台计算机内部的加工处理。通过一些 IO，比如屏幕和键盘，文本流实现了人机交互。而进一步，如果网络通信可在不同计算机之间进行文本流的交互，那么我们就和整个计算机系统的数据处理方式实现了对接。</p>
<p>IP 协议和 UDP 协议采用的是数据包的方式传送，后发出的数据包可能早到，我们并不能保证数据到达的次序。TCP 协议确保了数据到达的顺序与文本流顺序相符。当计算机从 TCP 协议的接口读取数据时，这些数据已经是排列好顺序的“流”了。比如我们有一个大文件要从本地主机发送到远程主机，如果是按照“流”接收到的话，我们可以一边接收，一边将文本流存入文件系统。这样，等到“流”接收完了，硬盘写入操作也已经完成。如果采取 UDP 的传输方式，我们需要等到所有的数据到达后，进行排序，才能组装成大的文件。这种情况下，我们不得不使用大量的计算机资源来存储已经到达的数据，直到所有数据都达到了，才能开始处理。</p>
<p>“流”的要点是次序(order)，然而实现这一点并不简单。TCP 协议是基于 IP 协议的，所以最终数据传送还是以 IP 数据包为单位进行的。如果一个文本流很长的话，我们不可能将整个文本流放入到一个 IP 数据包中，那样有可能会超过 MTU。所以，TCP 协议封装到 IP 包的不是整个文本流，而是 TCP 协议所规定的片段(segment)。与之前的一个 IP 或者 UDP 数据包类似，一个 TCP 片段同样分为头部(header)和数据(payload)两部分 (“片段”这个名字更多是起提醒作用：嘿，这里并不是完整的文本流)。整个文本流按照次序被分成小段，而每一段被放入 TCP 片段的数据部分。一个 TCP 片段封装成的 IP 包不超过整个 IP 接力路径上的最小 MTU，从而避免令人痛苦的碎片化(fragmentation)。</p>
<p>(给文本流分段是在发送主机完成的，而碎片化是在网络中的路由器完成的。路由器要处理许多路的通信，所以相当繁忙。文本流提前在发送主机分好段，可以避免在路由器上执行碎片化，可大大减小网络负担)</p>
<p>TCP 片段的头部(header)会存有该片段的序号(sequence number)。这样，接收的计算机就可以知道接收到的片段在原文本流中的顺序了，也可以知道自己下一步需要接收哪个片段以形成流。比如已经接收到了片段1，片段2，片段3，那么接收主机就开始期待片段4。如果接收到不符合顺序的数据包(比如片段8)，接收方的TCP模块可以拒绝接收，从而保证呈现给接收主机的信息是符合次序的“流”。</p>
<p><strong>可靠性</strong></p>
<p>片段编号这个初步的想法并不能解决我们所有的问题。IP 协议是不可靠的，所以 IP 数据包可能在传输过程中发生错误或者丢失。而IP传输是”Best Effort” 式的，如果发生异常情况，我们的IP数据包就会被轻易的丢弃掉。另一方面，如果乱序(out-of-order)片段到达，根据我们上面说的，接收主机不会接收。这样，错误片段、丢失片段和被拒片段的联手破坏之下，接收主机只可能收到一个充满“漏洞”的文本流。</p>
<p>TCP 的补救方法是，在每收到一个正确的、符合次序的片段之后，就向发送方(也就是连接的另一段)发送一个特殊的 TCP 片段，用来知会(ACK，acknowledge)发送方：我已经收到那个片段了。这个特殊的 TCP 片段叫做 ACK 回复。如果一个片段序号为 L，对应 ACK 回复有回复号 L+1，也就是接收方期待接收的下一个发送片段的序号。如果发送方在一定时间等待之后，还是没有收到 ACK 回复，那么它推断之前发送的片段一定发生了异常。发送方会重复发送(retransmit)那个出现异常的片段，等待 ACK 回复，如果还没有收到，那么再重复发送原片段… 直到收到该片段对应的 ACK 回复(回复号为L+1的ACK)。</p>
<p>当发送方收到 ACK 回复时，它看到里面的回复号为 L+1，也就是发送方下一个应该发送的 TCP 片段序号。发送方推断出之前的片段已经被正确的接收，随后发出 L+1 号片段。ACK 回复也有可能丢失。对于发送方来说，这和接收方拒绝发送 ACK 回复是一样的。发送方会重复发送，而接收方接收到已知会过的片段，推断出 ACK 回复丢失，会重新发送 ACK 回复。</p>
<p>通过ACK回复和重新发送机制，TCP 协议将片段传输变得可靠。尽管底盘是不可靠的 IP 协议，但 TCP 协议以一种“不放弃的精神”，不断尝试，最终成功。(技术也可以很励志)</p>
<p>TCP 协议和 UDP 协议走了两个极端。TCP 协议复杂但可靠，UDP 协议轻便但不可靠。在处理异常的时候，TCP 极端负责，而 UDP 一副无所谓的样子。</p>
<h3 id="u6ED1_u7A97"><a href="#u6ED1_u7A97" class="headerlink" title="滑窗"></a>滑窗</h3><p>上面的工作方式中，发送方保持发送-&gt;等待ACK-&gt;发送-&gt;等待ACK…的单线工作方式，这样的工作方式叫做 stop-and-wait。stop-and-wait 虽然实现了 TCP 通信的可靠性，但同时牺牲了网络通信的效率。在等待 ACK 的时间段内，我们的网络都处于闲置(idle)状态。我们希望有一种方式，可以同时发送出多个片段。然而如果同时发出多个片段，那么由于 IP 包传送是无次序的，有可能会生成乱序片段(out-of-order)，也就是后发出的片段先到达。在 stop-and-wait 的工作方式下，乱序片段完全被拒绝，这也很不效率。毕竟，乱序片段只是提前到达的片段。我们可以在缓存中先存放它，等到它之前的片段补充完毕，再将它缀在后面。然而，如果一个乱序片段实在是太过提前(太“乱”了)，该片段将长时间占用缓存。我们需要一种折中的方法来解决该问题：利用缓存保留一些“不那么乱”的片段，期望能在段时间内补充上之前的片段(暂不处理，但发送相应的 ACK)；对于“乱”的比较厉害的片段，则将它们拒绝(不处理，也不发送对应的 ACK)。</p>
<p>滑窗(sliding window)被同时应用于接收方和发送方，以解决以上问题。发送方和接收方各有一个滑窗。当片段位于滑窗中时，表示TCP正在处理该片段。滑窗中可以有多个片段，也就是可以同时处理多个片段。滑窗越大，越大的滑窗同时处理的片段数目越多(当然，计算机也必须分配出更多的缓存供滑窗使用)。TCP协议有实时调整滑窗大小的算法，以实现最优效率。</p>
<p>TCP协议和UDP协议走了两个极端。TCP协议复杂但可靠，UDP协议轻便但不可靠。在处理异常的时候，TCP极端负责，而UDP一副无所谓的样子。在TCP中，分段和编号实现了次序；ACK和重新发送实现了可靠性；sliding window则让上面的机制更加有效率的运行。Never give up，这就是TCP协议的态度。</p>
<h3 id="TCP_u8FDE_u63A5"><a href="#TCP_u8FDE_u63A5" class="headerlink" title="TCP连接"></a>TCP连接</h3><p>在 TCP 协议与”流”通信中，我们概念性的讲解了 TCP 通信的方式。可以看到，TCP 通信最重要的特征是：有序(ordering)和可靠(reliable)。有序是通过将文本流分段并编号实现的。可靠是通过 ACK 回复和重复发送(retransmission)实现的。这一篇文章将引入 TCP 连接(connection)的概念。</p>
<p>网络层在逻辑上提供了端口的概念。一个 I P地址可以有多个端口。一个具体的端口需要 IP 地址和端口号共同确定(我们记为 IP:port 的形式)。一个连接为两个 IP:port 之间建立 TCP 通信。</p>
<p>参与连接的如果是两台电脑，那么两台电脑操作系统的 TCP 模块负责建立连接。每个连接有四个参数(两个 IP，两个端口)，来表明“谁在和谁通话”。每台电脑都会记录有这四个参数，以确定是哪一个连接。如果这四个参数完全相同，则为同一连接；如果这四个参数有一个不同，即为不同的连接。这意味着，同一个端口上可以有多个连接。内核中的TCP模块生成连接之后，将连接分配给进程使用。</p>
<p>TCP 连接是双向(duplex)的。在 TCP 协议与”流”通信中，我们所展示的 TCP 传输是单向的。双向连接实际上就是建立两个方向的 TCP 传输，所以概念上并不复杂。这时，连接的每一方都需要两个滑窗，以分别处理发送的文本流和接收的文本流。由于连接的双向性，我们也要为两个方向的文本流编号。这两个文本流的编号相互独立。为文本流分段和编号由发送方来处理，回复 ACK 则由接收的一方进行。</p>
<p><strong>TCP片段的头部格式</strong></p>
<p>在深入 TCP 连接之前，我们需要对 TCP 片段的头部格式有一些了解。我们知道，TCP 片段分为头部和数据。数据部分为 TCP 真正传输的文本流数据。下面为 TCP 片段的头部格式：</p>
<p><img src="/images/14551394884094.jpg" alt=""></p>
<p>先关注下面几点：</p>
<ol>
<li>一个 TCP 头部需要包含出发端口(source port)和目的地端口(destination port)。这些与 IP 头中的两个 IP 地址共同确定了连接。</li>
<li>每个 TCP 片段都有序号(sequence number)。这些序号最终将数据部分的文本片段整理成为文本流。</li>
<li>ACK 是一位(bit)。只有 ACK 位设定的时候，回复号(Acknowledgement number)才有效。ACK 回复号说明了接收方期待接收的下一个片段，所以 ACK 回复号为最后接收到的片段序号加 1。<ul>
<li>很多时候，ACK 回复“附着”在发送的数据片段中。TCP 协议是双向的。比如 A 和 B 两个电脑。 ACK 回复是接收方回复给发送方 (比如 A 发送给 B， B 回复 A)。但同时，B 也可以是发送方，B 有可能有数据发送给 A，所以 B 就把 ACK 回复附着在它要发送给 A 的数据片段的头部。这样可以减少 ACK 所占用的交通流量。一个片段可以只包含 ACK 回复。一个纯粹的 ACK 回复片段不传送文本流，所以不消耗序列号。如果有下一个正常的数据片段，它的序号将与纯粹 ACK 回复片段的序号相同。</li>
<li>(ACK 回复还可以“附着”在 SYN 片段和 FIN 片段)</li>
</ul>
</li>
<li>ACK 后面还有 SYN 和 FIN，它们也各占据一位(bit)。我将在后面说明这两位。</li>
</ol>
<p><strong>连接的建立</strong></p>
<p>在 TCP 协议与”流”通信中讨论的 TCP 传输需要一个前提：TCP 连接已经建立。然而，TCP 连接从无到有需要一个建立连接的过程。建立连接的最重要目是让连接的双方交换初始序号(ISN, Initial Sequence Number)。根据 TCP 协议的规定，文本流的第一个片段的序号不能是确定的数字(比如说1)。连接的双方各自随机生成自己的 ISN，然后再利用的一定方式让对方了解。这样的规定是出于 TCP 连接安全考虑：如果以一个确定的数字作为初始的 TCP 序号，那么其他人很容易猜出接下来的序列号，并按照正确的序号发送“伪装”的 TCP 片段，以插入到文本流中。</p>
<p>ISN 交换是通过 SYN 片段实现的。SYN 片段由头部的 SYN 位表明，它的序号为发送方的 ISN。该片段由连接的一方首先发给给另一方，我们将发送 SYN 的一方称为客户(client)，而接收 SYN 的一方称为服务器(server)。我们使用 ISN(c) 表示 client 一方的 ISN，使用 ISN(s) 表示 server 一方的 ISN。随后，接收到 SYN 的 server 需要回复 ACK，并发送出包含有 server 的 ISN 的 SYN 片段。下图为建立连接的过程，也就是经典的 TCP 三次握手(three-way handshaking)。两条竖直线分别为 client 和 server 的时间轴。每个箭头代表了一次 TCP 片段的单向传输。</p>
<p><img src="/images/14551395013280.jpg" alt=""></p>
<p><strong>连接的正常终结</strong></p>
<p>一个连接建立之后，连接两端的进程可以利用该连接进行通信。当连接的一方觉得“我讲完了”，它可以终结连接中发送到对方方向的通信。连接最终通过四次握手(four-way handshaking)的方式终结，连接终结使用的是特殊片段 FIN(FIN位为1的片段)。</p>
<p><img src="/images/14551395178688.jpg" alt=""></p>
<p>我们可以看到，连接终结的过程中，连接双方也交换了四片信息(两个 FIN 和两个 ACK)。在终结连接的过程中，TCP 并没有合并 FIN 与 ACK 片段。原因是 TCP 连接允许单向关闭(half-close)。也就是说，TCP 连接关闭了一个方向的传输，成为一个单向连接(half-duplex)。第二个箭头和第三个箭头传递必须分开，才能有空隙在开放的方向上继续传输。如果第二个箭头和第三个箭头合并在一起，那么，随着一方关闭，另一方也要被迫关闭。</p>
<p>第二和第三次握手之间，server 可以继续单向的发送片段给 client，但 client 不能发送数据片段给 server。</p>
<p>(上面的终结从 client 先发起，TCP 连接终结也可以从 server 先发起。)</p>
<p>在 Client 发送出最后的 ACK 回复，但该 ACK 可能丢失。Server 如果没有收到 ACK，将不断重复发送 FIN 片段。所以 Client 不能立即关闭，它必须确认 Server 接收到了该 ACK。Client 会在发送出 ACK 之后进入到 <code>TIME_WAIT</code> 状态。Client 会设置一个计时器，等待 2MSL 的时间。如果在该时间内再次收到 FIN，那么 Client 会重发 ACK 并再次等待 2MSL。所谓的 2MSL 是两倍的 MSL(Maximum Segment Lifetime)。MSL 指一个片段在网络中最大的存活时间，2MSL 就是一个发送和一个回复所需的最大时间。如果直到 2MSL，Client 都没有再次收到 FIN，那么 Client 推断 ACK 已经被成功接收，则结束 TCP 连接。</p>
<p>TCP 是连接导向的协议，与之对应的是像 UDP 这样的非连接导向的协议。连接能带来更好的传输控制，但也需要更多额外的工作，比如连接的建立和终结。</p>
<p>我们还初步了解了 TCP 的头部格式。应该注意到，许多时候我们将 ACK 片段“附着”在其他片段上。相对于纯粹的 ACK 片段，我们这样做节约了 ACK 所需的流量。事实上，由于 ACK 片段所需的 ACK 位和 acknowledge number 区域总是存在于 TCP 的头部，所以附着 ACK 片段的成本基本上等于 0。</p>
<h3 id="TCP_u6ED1_u7A97_u7BA1_u7406"><a href="#TCP_u6ED1_u7A97_u7BA1_u7406" class="headerlink" title="TCP滑窗管理"></a>TCP滑窗管理</h3><p>在 TCP 协议与”流”通信中，我们建立了滑窗(sliding window)的基本概念。通过滑窗与 ACK 的配合，我们一方面实现了 TCP 传输的可靠性，另一方面也一定程度上提高了效率。</p>
<p>然而，之前的解释只是概念性的。TCP 为了达到更好的传输效率，对上面的工作方式进行了许多改进。The devil is in the details. 我们需要深入到细节，才能看清楚TCP协议的智慧所在。</p>
<p><strong>累计ACK</strong></p>
<p>在 TCP 连接中，我们通过将 ACK 回复“附着”在其他数据片段的方式，减少了 ACK 回复所消耗的流量。但这并不是全部的故事。TCP 协议并不是对每个片段都发送 ACK 回复。TCP 协议实际采用的是累计 ACK 回复(accumulative acknowledgement)。接收方往往利用一个 ACK 回复来知会连续多个片段的成功接收。通过累计 ACK，所需要的 ACK 回复通常可以降到 50%。</p>
<p>如下图所示，橙色为已经接收的片段。方框为滑窗，滑窗可容纳 3 个片段。</p>
<p><img src="/images/14551395342559.jpg" alt=""></p>
<p>滑窗还没接收到片段7时，已接收到片段8，9。这样就在滑窗中制造了一个“空穴”(hole)。当滑窗最终接收到片段7时，滑窗送出一个回复号为10的ACK回复。发送方收到该回复，会意识到，片段10之前的片段已经按照次序被成功接收。整个过程中节约了片段7和片段8所需的两个ACK回复。</p>
<p>此外，接收方在接收到片断，并应该回复ACK的时候，会故意延迟一些时间。如果在延迟的时间里，有后续的片段到达，就可以利用累计ACK来一起回复了。</p>
<p><strong>滑窗结构</strong></p>
<p>在之前的讨论中，我们以片段为单位，来衡量滑窗的大小的。真实的滑窗是以 byte 为单位表示大小，但这并不会对我们之前的讨论造成太大的影响。</p>
<p><img src="/images/14551395682155.jpg" alt=""></p>
<p>发送方滑窗可以分为下面两个部分。offered window 为整个滑窗的大小。</p>
<p><img src="/images/14551395777596.jpg" alt=""></p>
<p>可以看到，接收方的滑窗相对于发送方的滑窗多了一个”Received; ACKed; Not Sent to Proc”的部分。接收方接收到的文本流必须等待进程来读取。如果进程正忙于做别的事情，那么这些文本流即使已经正确接收，还是需要暂时占用接收缓存。当出现上述占用时，滑窗的可用部分(也就是图中advertised window)就会缩水。这意味着接收方的处理能力下降。如果这个时候发送方依然按照之前的速率发送数据给接收方，接收方将无力接收这些数据。</p>
<h3 id="u6D41_u91CF_u63A7_u5236"><a href="#u6D41_u91CF_u63A7_u5236" class="headerlink" title="流量控制"></a>流量控制</h3><p>TCP协议会根据情况自动改变滑窗大小，以实现流量控制。流量控制(flow control)是指接收方将advertised window的大小通知给发送方，从而指导发送方修改 offered window 的大小。接收方将该信息放在 TCP 头部的 window size 区域：</p>
<p><img src="/images/14551395892901.jpg" alt=""></p>
<p>发送方在收到 window size 的通知时，会调整自己滑窗的大小，让 offered window 和advertised window 相符。这样，发送窗口变小，文本流发送速率降低，从而减少了接收方的负担。</p>
<p><strong>零窗口</strong></p>
<p>advertised window 大小有可能变为0，这意味着接收方的接收能力降为0。发送方收到大小为0的advertised window 通知时，停止发送。</p>
<p>当接收方经过处理，再次产生可用的 advertised window 时，接收方会通过纯粹的 ACK 回复来通知发送方，让发送方恢复发送。然而，ACK 回复的传送并不是可靠的。如果该 ACK 回复丢失，那么 TCP 传输将陷入死锁(deadlock)状态。</p>
<p>为此，发送方会在零窗口后，不断探测接收方的窗口。窗口探测(window probe)时，发送方会向接收方发送包含 1 byte 文本流的 TCP 片段，并等待 ACK 回复(该 ACK 回复包含有 window size)。由于有 1 byte 的数据存在，所以该传输是可靠的，而不用担心 ACK 回复丢失的问题。如果探测结果显示窗口依然为 0，发送方会等待更长的时间，然后再次进行窗口探测，直到 TCP 传输恢复。</p>
<p><strong>白痴窗口综合症</strong></p>
<p>滑窗机制有可能犯病，比如白痴窗口综合症 (Silly Window Syndrome)。假设这样一种情形：接收方宣布(advertise)一个小的窗口，发送方根据advertised window，发送一个小的片段。接收方的小窗口被填满，经过处理，接收方再宣布一个小的窗口…… 这就是“白痴窗口综合症”：TCP通信的片段中包含的数据量很小。在这样的情况下，TCP 通信的片段所含的信息都很小，网络流量主要是 TCP 片段的头部，从而造成流量的浪费 (由于 TCP 头部很大，我们希望每个 TCP 片段中含有比较多的数据)。</p>
<p>如果发送方不断发送小的片段，也会造成“白痴窗口”。为了解决这个问题，需要从两方面入手。TCP中有相关的规定，要求：</p>
<ol>
<li>接收方宣告的窗口必须达到一定的尺寸，否则等待。</li>
<li>除了一些特殊情况，发送方发送的片段必须达到一定的尺寸，否则等待。特殊情况主要是指需要最小化延迟的 TCP 应用(比如命令行互动)。</li>
</ol>
<p>累计 ACK 减少了 TCP 传输过程中所需的 ACK 流量。通过流量管理，TCP 连接两端的工作能力可以匹配，从而减少不不要的传输浪费。累计 ACK 和流量控制都是 TCP 协议的重要特征。</p>
<p>TCP 协议相当复杂，并充斥着各种细节。然而 TCP 协议又是如此重要的一个协议，引领风骚三十年，可以说是互联网的奇迹。这些细节正是 TCP 协议成功的原因，并值得我们深入了解。</p>
<h3 id="TCP_u91CD_u65B0_u53D1_u9001"><a href="#TCP_u91CD_u65B0_u53D1_u9001" class="headerlink" title="TCP重新发送"></a>TCP重新发送</h3><p>TCP 协议是一个可靠的协议。它通过重新发送(retransmission)来实现 TCP 片段传输的可靠性。简单的说，TCP 会不断重复发送 TCP 片段，直到片段被正确接收。</p>
<p><strong>TCP片段丢失</strong></p>
<p><img src="/images/14551396019064.jpg" alt=""></p>
<p>接收方(receiver)可以通过校验 TCP 片段头部中 checksum 区域来检验 TCP 片段是否出错。我们已经接触过了 IP 协议详解的 checksum 算法。TCP 片段的 checksum 算法与之类似。IP 协议的 checksum 只校验头部，TCP 片段头部的 checksum 会校验包括 IP 头部、TCP 头部和 TCP 数据在内的整个序列，确保 IP 地址、端口号和其他相关信息正确。如果 TCP 片段出错，接收方可以简单的丢弃改 TCP 片段，也就相当于 TCP 片段丢失。</p>
<p>TCP 片段包裹在一个 IP 包中传输。IP 包可能在网络中丢失。导致 IP 包丢失的原因可能有很多，比如 IP 包经过太多的路由器接力，达到 hop limit；比如路由器太过拥挤，导致一些 IP 包被丢弃；再比如路由表(routing table)没有及时更新，导致 IP 包无法送达目的地。</p>
<p>下面我们要介绍两种重新发送 TCP 片段的机制：超时重新发送和快速重新发送。 </p>
<p><strong>超时重新发送</strong></p>
<p>我们之前已经简单介绍过重新发送的机制：当发送方送出一个 TCP 片段后，将开始计时，等待该 TCP 片段的 ACK 回复。如果接收方正确接收到符合次序的片段，接收方会利用 ACK 片段回复发送方。发送方得到 ACK 回复后，继续移动窗口，发送接下来的 TCP 片段。如果直到计时完成，发送方还是没有收到 ACK 回复，那么发送方推断之前发送的 TCP 片段丢失，因此重新发送之前的 TCP 片段。这个计时等待的时间叫做重新发送超时时间(RTO, retransmission timeout)。</p>
<p>发送方应该在等待多长时间之后重新发送呢？这是重新发送的核心问题。上述过程实际上有往返两个方向：</p>
<ol>
<li>发送片段从发送方到接收方的传输，</li>
<li>ACK 片段从接收方到发送方的传输</li>
</ol>
<p>整个过程实际耗费的时间称做往返时间(RTT, round trip time)。如果 RTT 是固定的，比如1秒，那么我们可以让 RTO 等于 RTT。但实际上，RTT 的上下浮动很大。比如某个时刻，网络中有许多交通，那么 RTT 就增加。在 RTT 浮动的情况下，如果我们设置了过小的 RTO，那么 TCP 会等待很短的时间之后重新发送，而实际上之前发送的片段并没有丢失，只是传输速度比较慢而已，这样，网络中就被重复注入 TCP 片段，从而浪费网络传输资源。另一方面，如果 RTO 时间过长，那么当 TCP 片段已经实际丢失的情况下，发送方不能及时重新发送，会造成网络资源的闲置。所以，RTO 必须符合当前网络的使用状况。网络状况越好，RTO 应该越短；网络状况越差，RTO 应该越长。</p>
<p>TCP 协议通过统计 RTT，来决定合理的 RTO。发送方可以测量每一次 TCP 传输的 RTT (从发送出数据片段开始，到接收到 ACK 片段为止)，这样的每次测量得到的往返时间，叫做采样 RTT(srtt, sampling round trip time)。建立连接之后，每次的 srtt 作为采样样本，计算平均值(mean)和标准差(standard deviation)，并让 RTO 等于 srtt 平均值加上四倍的 srtt 标准差。</p>
<p>RTO = mean + 4 std</p>
<p>(上述算法有多个变种，根据平台不同有所变化)</p>
<p>平均值反映了平均意义上的 RTT，平均往返时间越大，RTO 越大。另一方面，标准差越大也会影响 RTO。标准差代表了 RTT 样本的离散程度。如果 RTT 上下剧烈浮动，标准差比较大。RTT 浮动大，说明当前网络状况相对不稳定。因此要设置更长的 RTO，以应对不稳定的网络状况。</p>
<p><strong>快速重新发送</strong></p>
<p>我们刚才介绍了超时重新发送的机制：发送方送出一个 TCP 片段，然后开始等待并计时，如果 RTO 时间之后还没有收到 AC K回复，发送方则重新发送。TCP 协议有可能在计时完成之前启动重新发送，也就是利用快速重新发送(fast-retransmission)。快速发送机制如果被启动，将打断计时器的等待，直接重新发送 TCP 片段。</p>
<p>由于IP包的传输是无序的，所以接收方有可能先收到后发出的片段，也就是乱序(out-of-order)片段。乱序片段的序号并不等于最近发出的ACK回复号。已接收的文本流和乱序片段之间将出现空洞(hole)，也就是等待接收的空位。比如已经接收了正常片段5,6,7，此时又接收乱序片段9。这时片段8依然空缺，片段8的位置就是一个空洞。</p>
<p>TCP 协议规定，当接收方收到乱序片段的时候，需要重复发送 ACK。比如接收到乱序片段 9 的时候，接收方需要回复 ACK。回复号为 8 (7+1)。此后接收方如果继续收到乱序片段(序号不是8的片段)，将再次重复发送 ACK=8。当发送方收到 3 个 ACK=8 的回复时，发送方推断片段 8 丢失。即使此时片段 8 的计时器还没有超时，发送方会打断计时，直接重新发送片段 8，这就是快速重新发送机制(fast-retransmission)。</p>
<p>快速重新发送机制利用重复的 ACK 来提示空洞的存在。当重复次数达到阈值时，认为空洞对应的片段在网络中丢失。快速重新发送机制提高了检测丢失片段的效率，往往可以在超时之前探测到丢失片段，并重复发送丢失的片段。</p>
<h3 id="TCP_u5835_u585E_u63A7_u5236"><a href="#TCP_u5835_u585E_u63A7_u5236" class="headerlink" title="TCP堵塞控制"></a>TCP堵塞控制</h3><p>在 TCP 协议中，我们使用连接记录 TCP 两端的状态，使用编号和分段实现了 TCP 传输的有序，使用 advertised window 来实现了发送方和接收方处理能力的匹配，并使用重复发送来实现 TCP 传输的可靠性。我们只需要将 TCP 片段包装成 IP 包，扔到网络中就可以了。TCP 协议的相关模块会帮我们处理各种可能出现的问题(比如排序，比如TCP片段丢失等等)。最初的 TCP 协议就是由上述的几大块构成的。</p>
<p>然而进入上世纪八十年代，网络开始变的繁忙。许多网络中出现了大量的堵塞(congestion)。堵塞类似于现实中的堵车。网络被称为“信息高速公路”。许多汽车(IP包)在网络中行驶，并经过一个一个路口 (路由器)，直到到达目的地。一个路由器如果过度繁忙，会丢弃一些 IP 包。UDP 协议不保证传输的可靠性，所以丢失就丢失了。而 TCP 协议需要保证传输的可靠性，当包含有 TCP 片段的 IP 包丢失时，TCP 协议会重复发送 TCP 片段。于是，更多的“汽车”进入到公路中，原本繁忙的路由器变得更加繁忙，更多的IP包丢失。这样就构成了一个恶性循环。这样的情况被称为堵塞崩溃(congestion collapse)。每个发送方为了保证自己的发送质量，而不顾及公共领域现状，是造成堵塞崩溃的主要原因。当时的网络中高达90%的传输资源可能被堵塞崩溃所浪费。</p>
<p>为了解决这一缺陷，从八十年代开始，TCP 协议中开始加入堵塞控制(congestion control)的功能，以避免堵塞崩溃的出现。多个算法被提出并实施，大大改善了网络的交通状况。直到今天，堵塞控制依然是互联网研究的一个活跃领域。</p>
<p>现实中，当我们遇到堵车，可能就会希望兴建立交桥和高架，或者希望有一位交警来疏导交通。而 TCP 协议的堵塞控制是通过约束自己实现的。当 TCP 的发送方探测到网络交通拥堵时，会控制自己发送片段的速率，以缓解网络的交通状况，避免堵塞崩溃。简言之，TCP 协议规定了发送方需要遵守的“公德”。</p>
<p>我们先来说明堵塞是如何探测的。在 TCP 重新发送中，我们已经总结了两种推测 TCP 片段丢失的方法：ACK 超时和重复 ACK。一旦发送方认为 TCP 片段丢失，则认为网络中出现堵塞。</p>
<p>另一方面，TCP 发送方是如何控制发送速率呢？TCP 协议通过控制滑窗(sliding window)大小来控制发送速率。在 TCP 滑窗管理中，我们已经见到了一个窗口限制，就是advertised window size，以实现 TCP 流量控制。TCP 还会维护一个congestion window size，以根据网络状况来调整滑窗大小。真实滑窗大小取这两个滑窗限制的最小值，从而同时满足两个限制 (流量控制和堵塞控制)</p>
<p><strong>Congestion Window</strong></p>
<p>congestion window 总是处于两种状态的一个。这两种状态是: 慢起动(slow start)和堵塞避免(congestion avoidance)。</p>
<p><img src="/images/14551396186893.jpg" alt=""></p>
<p>上图是概念性的。实际的实施要比上图复杂，而且根据算法不同会有不同的版本。cwnd 代表congestion window size。我们以片段的个数为单位，来表示 cwnd 的大小 (同样是概念性的)。</p>
<p>Congestion window 从 slow start的状态开始。Slow start 的特点是初始速率低，但速率不断倍增。每次进入到 slow start 状态时，cwnd 都需要重置为初始值 1。发送方每接收到一个正确的 ACK，就会将 congestion window 增加 1，从而实现速率的倍增(由于累计 ACK，速率增长可能会小于倍增)。</p>
<p>当 congestion window 的大小达到某个阈值 ssthresh 时，congestion 进入到 congestion avoidance 状态。发送速率会继续增长。发送方在每个窗户所有片段成功传输后，将窗口尺寸增加 1(实际上就是每个 RTT 增加 1)。所以在 congestion avoidance 下，cwnd 线性增长，增长速率慢。</p>
<p>如果在 congestion avoidance 下有片段丢失，重新回到 slow start 状态，并将 ssthresh 更新为 cwnd 的一半。</p>
<p>我们看到，sshthresh 是 slow start 到 congestion avoidance 的切换点。而片段丢失是 congestion avoidance 到 slow start 的切换点。一开始 sshthresh 的值一般比较大，所以 slow start 可能在切换成 congestion avoidance 之前就丢失片段。这种情况下，slow start 会重新开始，而 ssthresh 更新为 cwnd 的一半。</p>
<p>总的来说，发送速率总是在增长。如果片段丢失，则重置速率为1，并快速增长。增长到一定程度，则进入到慢性增长。快速增长和慢性增长的切换点(sshthred)会随着网络状况(何时出现片段丢失)更新。通过上面的机制，让发送速率处于动态平衡，不断的尝试更大值。初始时增长块，而接近饱和时增长慢。但一旦尝试过度，则迅速重置，以免造成网络负担。</p>
<p>阻塞控制有效的提高了互联网的利用率。阻塞控制的算法多种多样，并且依然不完善。一个常见的问题是cwnd在接近饱和时线性增长，因此对新增的网络带宽不敏感。</p>
<p>互联网利用“公德”来实现效率。“公德”和效率似乎可以并存。</p>
<p>到现在为止，TCP协议的介绍就可以告一段落了。可以回想一下TCP的几大模块：分段与流，滑窗，连接，流量控制，重新发送，堵塞控制。</p>
<h2 id="u5E94_u7528_u5C42_u534F_u8BAE"><a href="#u5E94_u7528_u5C42_u534F_u8BAE" class="headerlink" title="应用层协议"></a>应用层协议</h2><h3 id="DNS_u534F_u8BAE"><a href="#DNS_u534F_u8BAE" class="headerlink" title="DNS协议"></a>DNS协议</h3><p>域名(domain name)是IP地址的代号。域名通常是由字符构成的。对于人类来说，字符构成的域名，比如 www.yahoo.com，要比纯粹数字构成的IP地址(106.10.170.118)容易记忆。域名解析系统(DNS, domain name system)就负责将域名翻译为对应的IP地址。在 DNS 的帮助下，我们可以在浏览器的地址栏输入域名，而不是IP地址。这大大减轻了互联网用户的记忆负担。另一方面，处于维护和运营的原因，一些网站可能会变更 IP 地址。这些网站可以更改 DNS 中的对应关系，从而保持域名不变，而 IP 地址更新。由于大部分用户记录的都是域名，这样就可以降低 IP 变更带来的影响。</p>
<p>从机器和技术的角度上来说，域名并不是必须的。但 Internet 是由机器和用户共同构成的。鉴于 DNS 对用户的巨大帮助，DNS 已经被当作 TCP/IP 套装不可或缺的一个组成部分。</p>
<p>域名和 IP 地址的对应关系存储在 DNS 服务器(DNS server)中。所谓的 DNS 服务器，是指在网络中进行域名解析的一些服务器(计算机)。这些服务器都有自己的 IP 地址，并使用 DNS 协议(DNS protocol)进行通信。DNS 协议主要基于 UDP，是应用层协议。</p>
<p><img src="/images/14551396313267.jpg" alt=""></p>
<p>DNS 服务器构成一个分级(hierarchical)的树状体系。上图中，每个节点(node)为一个 DNS 服务器，每个节点都有自己的 IP 地址。树的顶端为用户电脑出口处的 DNS 服务器。在 Linux 下，可以使用 <code>cat /etc/resolv.conf</code>，在 Windows 下，可以使用 <code>ipconfig /all</code>，来查询出口 DNS 服务器。树的末端是真正的域名/IP对应关系记录。一次 DNS 查询就是从树的顶端节点出发，最终找到相应末端记录的过程。</p>
<p>中间节点根据域名的构成，将 DNS 查询引导向下一级的服务器。比如说一个域名 cs.berkeley.edu，DNS解析会将域名分割为 cs, berkeley, edu，然后按照相反的顺序查询(edu, berkeley, cs)。出口 DNS 首先根据 edu，将查询指向下一层的 edu 节点。然后 edu 节点根据 berkeley，将查询指向下一层的 berkeley 节点。这台 berkeley 服务器上存储有 cs.berkeley.edu 的 IP 地址。所以，中间节点不断重新定向，并将我们引导到正确的记录。</p>
<p>在整个 DNS 查询过程中，无论是重新定向还是最终取得对应关系，都是用户计算机和 DNS 服务器使用 DNS 协议通信。用户计算机根据 DNS 服务器的反馈，依次与下一层的 DNS 服务器建立通信。用户计算机经过递归查询，最终和末端节点通信，并获得IP地址。</p>
<p><img src="/images/14551396446583.jpg" alt=""></p>
<p>用户计算机的操作系统中的域名解析模块(DNS Resolver)负责域名解析的相关工作。任何一个应用程序(邮件，浏览器)都可以通过调用该模块来进行域名解析。</p>
<p>并不是每次域名解析都要完整的经历解析过程。DNS Resolver 通常有 DNS 缓存(cache)，用来记录最近使用和查询的域名/IP关系。在进行 DNS 查询之前，计算机会先查询 cache 中是否有相关记录。这样，重复使用的域名就不用总要经过整个递归查询过程。</p>
<p><img src="/images/14551396560030.jpg" alt=""></p>
<p>上面的DNS查询均为正向DNS查询：已经知道域名，想要查询对应 IP。而反向 DNS(reverse DNS)是已经知道IP的前提下，想要查询域名。反向 DNS 也是采用分层查询方式，对于一个 IP 地址(比如106.10.170.118)，依次查询in-addr.arpa节点(如果是IPv6，则为ip6.arpa节点)，106节点，10节点，170节点，并在该节点获得 106.10.170.118 对应的域名。</p>
<h3 id="HTTP_u534F_u8BAE_u6982_u89C8"><a href="#HTTP_u534F_u8BAE_u6982_u89C8" class="headerlink" title="HTTP协议概览"></a>HTTP协议概览</h3><p>我在 TCP 流通信中说明了，TCP 协议实现了数据流的传输。然而，人们更加习惯以文件为单位传输资源，比如文本文件，图像文件，超文本文档(hypertext document)。</p>
<p>超文本文档中包含有超链接，指向其他的资源。超文本文档是万维网(World Wide Web，即www)的基础。</p>
<p>HTTP 协议解决文件传输的问题。HTTP 是应用层协议，主要建立在 TCP 协议之上(偶尔也可以 UDP 为底层)。它随着万维网的发展而流行。HTTP 协议目的是，如何在万维网的网络环境下，更好的利用 TCP 协议，以实现文件，特别是超文本文件的传输。</p>
<p>早期的 HTTP 协议主要传输静态文件，即真实存储在服务器上的文件。随着万维网的发展，HTTP 协议被用于传输“动态文件”，服务器上的程序根据 HTTP 请求即时生成的动态文件。我们将 HTT P的传输对象统称为资源(resource)。</p>
<p>HTTP实现了资源的订购和传送。其工作方式类似于快餐点单。</p>
<ol>
<li>请求(request): 顾客向服务员提出请求：“来个鸡腿汉堡”。</li>
<li>回复(response):服务员根据情况，回应顾客的请求</li>
</ol>
<p>根据情况的不同，服务员的回应可能有很多，比如:</p>
<ul>
<li>服务员准备鸡腿汉堡，将鸡腿汉堡交给顾客。（一切OK）</li>
<li>服务员发现自己只是个甜品站。他让顾客前往正式柜台点单。（重新定向）</li>
<li>服务员告诉顾客鸡腿汉堡没有了。(无法找到)</li>
</ul>
<p>交易结束后，服务员就将刚才的交易抛到脑后，准备服务下一位顾客。</p>
<p>HTTP协议的通信是一次 request-responce 交流。客户端(guest)向服务器发出请求(request)，服务器(server)回复(response)客户端。</p>
<p><img src="/images/14551396675029.jpg" alt=""></p>
<p>HTTP协议规定了请求和回复的格式:</p>
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">起始行 <span class="comment">(start line)</span></span><br><span class="line">头信息 <span class="comment">(headers)</span></span><br><span class="line"></span><br><span class="line">主体<span class="comment">(entity body)</span></span><br></pre></td></tr></table></figure>
<p>起始行只有一行。它包含了请求/回复最重要的信息。请求的起始行表示(顾客)“想要什么”。回复的起始行表示(后厨)“发生什么”。</p>
<p>头信息可以有多行。每一行是一对键值对(key-value pair)，比如:</p>
<pre><code>Content-type: text/plain 
</code></pre><p>它表示，包含有一个名为 Content-type 的参数，该参数的值为 text/plain。头信息是对起始行的补充。请求的头信息对服务器有指导意义 (好像在菜单上注明: 鸡腿不要辣)。回复的头信息则是提示客户端（比如，在盒子上注明: 小心烫）</p>
<p>主体部分包含了具体的资源。上图的请求中并没有主体，因为我们只是在下单，而不用管后厨送什么东西 (请求是可以有主体内容的)。回复中包含的主体是一段文本文字(Hello World!)。这段文本文字正是顾客所期待的，鸡腿汉堡。</p>
<p>我们深入一些细节。先来看一下请求:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /index<span class="class">.html</span> HTTP/<span class="number">1.1</span></span><br><span class="line">Host: www<span class="class">.example</span><span class="class">.com</span></span><br></pre></td></tr></table></figure>
<p>在起始行中，有三段信息:</p>
<p>GET 方法。用于说明想要服务器执行的操作。<br>/index.html 资源的路径。这里指向服务器上的index.html文件。<br>HTTP/1.1 协议的版本。HTTP第一个广泛使用的版本是1.0，当前版本为1.1。</p>
<p>早期的 HTTP 协议只有 GET 方法。遵从 HTTP 协议，服务器接收到 GET 请求后，会将特定资源传送给客户。这类似于客户点单，并获得汉堡的过程。使用 GET 方法时，是客户向服务器索取资源，所以请求往往没有主体部分。</p>
<p>GET 方法也可以用于传输一些不重要的数据。它是通过改写 URL 的方式实现的。GET 的数据利用 <code>URL?变量名＝变量值</code> 的方法传输。比如向 <a href="http://127.0.0.1" target="_blank" rel="external">http://127.0.0.1</a> 发送一个变量“q”，它的值为“a”。那么，实际的URL为<a href="http://127.0.0.1?q=a。服务器收到请求后，就可以知道&quot;q&quot;的值为&quot;a&quot;。" target="_blank" rel="external">http://127.0.0.1?q=a。服务器收到请求后，就可以知道&quot;q&quot;的值为&quot;a&quot;。</a></p>
<p>GET 方法之外，最常用的是 POST 方法。它用于从客户端向服务器提交数据。使用 POST 方法时，URL 不再被改写。数据位于 http 请求的主体。POST 方法最用于提交 HTML 的 form 数据。服务器往往会对 POST 方法提交的数据进行一定的处理，比如存入服务器数据库。</p>
<p>样例请求中有一行头信息。该头信息的名字是 Host。HTTP 的请求必须有 Host 头信息，用于说明服务器的地址和端口。HTTP 协议的默认端口是 80，如果在 HOST 中没有说明端口，那么将默认采取该端口。在该例子中，服务器的域名为 www.example.com，端口为 80。域名将通过 DNS 服务器转换为 IP 地址，从而确定服务器在互联网上的地址。</p>
<p>服务器在接收到请求之后，会根据程序，生成对应于该请求的回复，比如:</p>
<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="status">HTTP/1.1 <span class="number">200</span> OK</span></span><br><span class="line"><span class="attribute">Content-type</span>: <span class="string">text/plain</span></span><br><span class="line"><span class="attribute">Content-length</span>: <span class="string">12</span></span><br><span class="line"></span><br><span class="line"><span class="erlang-repl"><span class="variable">Hello</span> <span class="variable">World</span><span class="exclamation_mark">!</span></span></span><br></pre></td></tr></table></figure>
<p>回复的起始行同样包含三段信息</p>
<ul>
<li>HTTP/1.1 协议版本</li>
<li>200 状态码(status code)。</li>
<li>OK 状态描述</li>
</ul>
<p>OK 是对状态码 20 0的文字描述，它只是为了便于人类的阅读。电脑只关心三位的状态码(status code)，即这里的 200。200 表示一切 OK，资源正常返回。状态码代表了服务器回应动作的类型。</p>
<p>其它常见的状态码还有:</p>
<ul>
<li>302，重新定向(redirect): 我这里没有你想要的资源，但我知道另一个地方xxx有，你可以去那里找。</li>
<li>404，无法找到(not found): 我找不到你想要的资源，无能为力。</li>
</ul>
<p>(重新定向时，客户端可以根据302的建议前往xxx寻找资源，也可以忽略该建议。)</p>
<p>Content-type 说明了主体所包含的资源的类型。根据类型的不同，客户端可以启动不同的处理程序(比如显示图像文件，播放声音文件等等)。下面是一些常见的资源</p>
<ul>
<li>text/plain 普通文本</li>
<li>text/html HTML 文本</li>
<li>image/jpeg jpeg 图片</li>
<li>image/gif gif 图片</li>
<li>Content-length 说明了主体部分的长度，以字节(byte)为单位。</li>
</ul>
<p>回应的主体部分为一段普通文本，即</p>
<pre><code>Hello World!
</code></pre><p>根据早期的 HTTP 协议，每次 request-reponse 时，都要重新建立 TCP 连接。TCP 连接每次都重新建立，所以服务器无法知道上次请求和本次请求是否来自于同一个客户端。因此，HTTP 通信是无状态(stateless)的。服务器认为每次请求都是一个全新的请求，无论该请求是否来自同一地址。</p>
<p>想象高级餐厅和快餐店。高级餐厅会知道客人所在的位置，如果新增点单，那么服务员知道这和上一单同一桌。而在快餐店中，不好意思，服务员并不记录客人的特征。想再次点单？请重新排队……</p>
<p>随着 HTTP 协议的发展，HTTP 协议允许 TCP 连接复用，以节省建立连接所耗费的时间。但HTTP协议依然保持无状态的特性。</p>
<h2 id="u7EFC_u5408"><a href="#u7EFC_u5408" class="headerlink" title="综合"></a>综合</h2><h3 id="CIDR__u4E0E_NAT"><a href="#CIDR__u4E0E_NAT" class="headerlink" title="CIDR 与 NAT"></a>CIDR 与 NAT</h3><p>IPv4 由于最初的设计原因，长度只有 32 位，所以只提供了大约 40 亿个地址。这造成了 IPv4 地址的耗尽危机。随后，IPv6 被设计出来，并可以提供足够多的 IP 地址。但是 IPv4 与 IPv6 并不兼容，IPv4 向 IPv6 的迁移并不容易。一些技术，比如说这里要说的 CIDR 和 NAT，相继推广。这些技术可以缓解 IPv4 的稀缺状态，成就了 IPv4 一时的逆袭。</p>
<p>CIDR(Classless Inter Domain Routing)改进了传统的 IPv4 地址分类。传统的 IP 分类将 IP 地址直接对应为默认的分类，从而将 Internet 分割为网络。CIDR 在路由表中增加了子网掩码(subnet masking)，从而可以更细分网络。利用 CIDR，我们可以灵活的将某个范围的IP地址分配给某个网络。</p>
<p>1) IP地址分类</p>
<p>在IP接力赛中，我提到，IP地址可以分为如下几类：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">IP <span class="keyword">class</span>    From          To                 Subnet Mask</span><br><span class="line">A           <span class="number">1.0</span><span class="number">.0</span><span class="number">.0</span>       <span class="number">126.255</span><span class="number">.255</span><span class="number">.255</span>    <span class="number">255.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">B           <span class="number">128.0</span><span class="number">.0</span><span class="number">.0</span>     <span class="number">191.255</span><span class="number">.255</span><span class="number">.255</span>    <span class="number">255.255</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">C           <span class="number">192.0</span><span class="number">.0</span><span class="number">.0</span>     <span class="number">223.255</span><span class="number">.255</span><span class="number">.255</span>    <span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>
<p>这是最初的IPv4地址分类设计。一个IPv4地址总共有32位，可以分为网络(network)和主机(host)两部分。子网掩码(subnet mask)是用于表示哪些位代表了网络部分。比如如下 subnet mask 255.0.0.0的二进制表示为：</p>
<p>11111111 00000000 00000000 00000000</p>
<p>它的前八位为 1，所以表示IP地址的前八位为网络部分。而后面的 24 位代指该网络的各个主机。一个 A 类网络可以有 224 台主机，也就是 16777216。由于 IPv4 地址已经分好了类，所以当我们拿到一个 IP 地址，我们就可以通过上面查到它的子网掩码。(B类，216; C类，28)</p>
<p>2) 传统路由表</p>
<p>IP分类的方便了IP包的接力。IP包到达某个路由器后，会根据该路由器的路由表(routing table)，来决定接力的下一站。一个传统的路由表看起来是这样的：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Destination        Gateway             Iface</span><br><span class="line"><span class="number">199.165</span><span class="number">.145</span><span class="number">.0</span>      <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>             eth0</span><br><span class="line"><span class="number">199.165</span><span class="number">.146</span><span class="number">.0</span>      <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>             eth1</span><br><span class="line"><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>            <span class="number">199.165</span><span class="number">.146</span><span class="number">.8</span>       eth1</span><br></pre></td></tr></table></figure>
<p>该路由表代表的网络拓扑如下：</p>
<p><img src="/images/14551396849165.jpg" alt=""></p>
<p>由于 IP 分类，我们不需要记录 subnet mask。当我们要前往 199.165.146.17 时，我们已经知道这台主机位于一个 C 类地址，所以它的子网掩码是 255.255.255.0，也就是说 199.165.146 代表了网络，17 代表了主机。</p>
<p>3) CIDR 路由表</p>
<p>然而，由于默认分类，造成了网络只能按照 A、B、C 的方式存在。假设一个网络(比如 MIT 的网络)分配了一个 A 类地址，那么该网络将容许 16777216 个主机。如果该网络无法用完这些 IP 地址，这些 IP 地址将无法被其他网络使用。再比如上面的网络，199.165.145 必须作为一个整个的网络存在。如果我们只有 10 台主机，那么将会有 200 多个 IP 地址被浪费。CIDR 的本质是在路由表中加入子网掩码，并根据该列信息对网络进行分割，而不是根据默认的 A，B，C 进行分割。比如：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Destination        Gateway             Genmask             Iface</span><br><span class="line"><span class="number">199.165</span><span class="number">.145</span><span class="number">.254</span>    <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>             <span class="number">255.255</span><span class="number">.255</span><span class="number">.254</span>     eth2</span><br><span class="line"><span class="number">199.165</span><span class="number">.145</span><span class="number">.0</span>      <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>             <span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span>       eth0</span><br><span class="line"><span class="number">199.165</span><span class="number">.146</span><span class="number">.0</span>      <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>             <span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span>       eth1</span><br><span class="line"><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>            <span class="number">199.165</span><span class="number">.146</span><span class="number">.8</span>       <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>             eth1</span><br></pre></td></tr></table></figure>
<p>根据路由表的第一条记录，</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">199.165</span><span class="number">.145</span><span class="number">.254</span> (IP address) : <span class="number">11000111</span> <span class="number">10100101</span> <span class="number">10010001</span> <span class="number">11111110</span></span><br><span class="line"><span class="number">255.255</span><span class="number">.255</span><span class="number">.254</span> (subnet mask): <span class="number">11111111</span> <span class="number">11111111</span> <span class="number">11111111</span> <span class="number">11111110</span> (<span class="number">31</span>个<span class="number">1</span>，<span class="number">1</span>个<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>通过子网掩码可以知道，前 31 位表示网络，最后一位表示主机。子网掩码总是有连续多个 1 组成，比如上面的 31 个 1。所以也可记为 199.165.145.254/31，来同时表示 IP 地址和子网掩码。</p>
<p>路由器将原来的 199.165.145 网络中的一部分分割出来。这一网络可以容纳两台电脑，也就是 199.165.145.254 和 199.165.145.255。这个网络对应网卡是 eth2。当有 IP 包通向这两个 IP 地址时，会前往 eth2，而不是 eth0。</p>
<p>网络拓扑如下：</p>
<p><img src="/images/14551396962662.jpg" alt=""></p>
<p>利用 CIDR，我们可以将 IP 地址根据需要进行分割，从而不浪费 IP 地址。</p>
<p>CIDR 虽然可以更加节约 IP 地址，但它并不能创造新的 IP 地址。IP 地址的耗尽危机并不能因此得到解决。我们来看 IPv4 的第二袭，NAT(Network Address Translation)。</p>
<p>理论上，每个 IP 地址代表了 Internet 上的一个设备。但有一些 IP 地址被保留，用于一些特殊用途。下面三段IP地址被保留用作私有 IP 地址：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">From          To             </span><br><span class="line"><span class="number">10.0</span><span class="number">.0</span><span class="number">.0</span>      <span class="number">10.255</span><span class="number">.255</span><span class="number">.255</span></span><br><span class="line"><span class="number">172.16</span><span class="number">.0</span><span class="number">.0</span>    <span class="number">172.31</span><span class="number">.255</span><span class="number">.255</span></span><br><span class="line"><span class="number">192.168</span><span class="number">.0</span><span class="number">.0</span>   <span class="number">192.168</span><span class="number">.255</span><span class="number">.255</span></span><br></pre></td></tr></table></figure>
<p>私有 IP 地址只用于局域网内部。理论上，我们不应该在互联网上看到来自或者发往私有 IP 地址的 IP 包。与私有 IP 地址对应的是全球 IP 地址(global IP address)。</p>
<p>NAT 是为私有网络(private network)服务的。该网络中的主机使用私有IP地址。当私有网络内部主机和外部 Internet 通信时，网关(gateway)路由器负责将私有 IP 地址转换为全球 IP 地址，这个地址转换过程就是 Network Address Translation。网关路由器的 NAT 功能。最极端情况下，我们可以只分配一个全球 IP 地址给网关路由器，而私有网络中的设备都使用私有 IP 地址。由于私有 IP 地址可以在不同私有网络中重复使用，所以就大大减小了设备对 IP 地址的需求。</p>
<p>1) 基础 NAT</p>
<p>NAT 的一种为基础 NAT，也成为一对一(one-to-one)NAT。在基础 NAT 下，网关路由器一一转换一个外部 IP 地址和一个私有 IP 地址。网关路由器保存有 IP 的 NAT 对应关系，比如：</p>
<p><img src="/images/14551397079720.jpg" alt=""></p>
<p>上面网络中，当有 IP 包要前往 199.165.145.1 时，网关路由器会将目的地改写为 10.0.0.1，并接力给私有网络中的 10.0.0.1 的电脑。同样，当 10.0.0.1 的电脑向 Internet 发送 IP 包时，它的发送地为 10.0.0.1。在到达网关路由器时，会将发送地更改为 199.165.145.1。此外，IP 头部的 checksum，以及更高层协议(比如 UDP 和 TCP)中的校验 IP 的 checksum 也会更改。</p>
<p>基础 NAT 尽管是一对一转换 IP 地址，它还是可以减小内部网络对 IP 地址的需求。通常来说，一个局域网中只有少数的设备处于开机状态，并不需要给每个设备对应一个全球 IP 地址。NAT 可以动态的管理全球 IP 地址，并将全球 IP 地址对应到开机设备，从而减小内部网络对 IP 地址的需求。</p>
<p>2) NAPT</p>
<p>NAT 还有一种，被成为 NAPT (Network Address and Port Translation)。在基础 NAT 中，高层协议的端口号并不会改动。NAPT 下，IP 地址和端口号可能同时改动。</p>
<p>我们在 UDP 和 TCP 中提到端口(port)的概念。在建立 UDP 或者 TCP 通信时，我们实际上是用 IP:Port 来代表通信的一端(正如打电话时主机:分机号一样)。NAPT 就是在网关路由器处建立两个通信通道，一个通往内部网络，一个通往外部网络，然后将网关处的通道端口连接，从而让内部和外部通信。比如：</p>
<p><img src="/images/14551397204458.jpg" alt=""></p>
<p>我们看到，通往 IP 199.165.145.1 建立了三个端口的连接：8888, 8889 和 8080。它们分别在 NAPT 处改为通往 10.0.0.1:80, 10.0.0.1:8080 和 10.0.0.3:6000。NAPT 记录有 外部IP:端口 和 内部IP:端口 的一一对应关系。在 IP 包经过时，网关路由器会更改 IP 地址，端口号以及相关的 checksum。</p>
<p>利用 NAPT 我们可以使用一个(或者多个但少量的)外部 IP 和大量的端口号，来对应多个内部 IP 以及相应的端口号，从而大大减小了对全球 IP 地址的需求。</p>
<p>无论是基础 NAT 还是 NAPT，它们的设置都比较复杂，并且从本质上违背了互联网最初的设计理念。但由于 IPv4 的使用惯性，NAT 还是被广泛推广。由于 NAT 所处的网关服务器是理想的设置防火墙的位置，NAT 还往往和防火墙共同建设，以提高私有网络的安全性。</p>
<p>即使是 CIDR 和 NAT 广泛使用，IPv4 还是在不可避免的耗尽。IPv6 正在加紧部署。但上述的两种技术，CIDR 和 NAT 在 IPv6 中同样被采用，所以了解它们依然是有意义的。</p>
<h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><p>下面是一些Mac OS X下常用的网络诊断命令。它们能帮助我们发现网络问题。有些工具，如 <code>arping</code>, <code>arp-scan</code>，需要借助 HomeBrew 安装。</p>
<p>网络诊断的第一步，是了解自己的设备，比如有哪些接口，IP地址都是什么。</p>
<pre><code># 显示网络接口(interface)信息
# 如接口名称，接口类型，接口的 IP 地址，硬件的 MAC 地址等。
ifconfig
</code></pre><p>ARP 协议用在局域网(LAN)内部。借用 ARP 协议，设备可以知道同一局域网内的 IP-MAC 对应关系。当我们访问一个本地 IP 地址时，设备根据该对应关系，与对应的 MAC 地址通信。通过 ARP 工具，我们可以知道局域网内的通信是否正常。</p>
<pre><code># 显示本地存储的 IP-MAC 对应关系
arp -a

# 经 eth0 接口，发送 ARP 请求，查询 IP 为 192.168.1.1 设备的 MAC 地址
sudo arping -I eth0 192.168.1.1

# 查询整个局域网内的所有IP地址的对应 MAC 地址
sudo arp-scan -l

# 监听 en0 接口的 arp 协议通信
sudo tcpdump -i en0 arp
</code></pre><p>网络层是一个广域的互联网，互联网上的设备用 IP 地址识别。ping 是向某个 IP 地址发送 ICMP 协议的 <code>ECHO_REQUEST</code> 请求。收到该请求的设备，将返回 ICMP 回复。如果 ping 到某个 IP 地址，那么说明该IP地址的设备可以经网络层顺利到达。</p>
<pre><code># 向 IP 地址 192.168.1.255 发送 ICMP 请求
# 如果该地址的 ICMP 没有被禁用，那么在该网上的设备将回复。
ping 192.168.1.1

# 向广播(broadcast)地址 192.168.1.255 发送 ICMP 请求
# 如果 ICMP 没有被禁用，那么在该网上的设备将回复
# 需要注意的是，许多设备会禁用 ICMP
# 如果 ping 不到一个设备，并不一定是网络层故障。
ping 192.168.1.255
</code></pre><p>如果两个设备有相同的 IP 地址，将导致 IP 冲突。许多网络中是由 DHCP 协议自动分配 IP 地址的，这样可以极大的减少 IP 冲突的可能性。DHCP 服务器与设备达成协议，设备将在一定时间内占据某个 IP 地址，而 DHCP 服务器不再把该 IP 地址分配给别人。</p>
<pre><code>sudo ipconfig set en0 DHCP
更新 DHCP 租约。设备将释放 IP 地址，再从 DHCP 服务器重新获得 IP 地址。

sudo ipconfig set en0 INFORM 192.168.0.120
将接口 en0 设定为静态 IP 地址。
</code></pre><p>局域网通过路由器，接入广域的互联网。互联网上的通信往往要经过多个路由器接力。途中路由器的故障，可能导致互联网访问异常。</p>
<pre><code># 显示路由表。从路由表中，可以找到网关(Gateway)
# 网关是通向更加广域网络的出口
netstat -nr

# 追踪到达IP目的地的全程路由
traceroute 74.125.128.99

# 通过ICMP协议，追踪路由
# ICMP协议经常会被禁用，所以会返回&quot;*&quot;的字符串。
traceroute -I 74.125.128.99

# 通过TCP协议，经80端口，追踪路由
# TCP协议的默认端口80很少会被禁用
sudo traceroute -T -p 80 74.125.128.99
</code></pre><p>tcpdump 是一款网络抓包工具。它可以监听网络接口不同层的通信，并过滤出特定的内容，比如特定协议、特定端口等等。我们上面已经使用 tcpdump 监听了 ARP 协议通信。这里我们来看更多的监听方式。</p>
<pre><code># 监听en0接口的所有通信
sudo tcpdump -i en0

# 用ASCII显示en0接口的通信内容
sudo tcpdump -A -i en0 

# 显示en0接口的8080端口的通信
sudo tcpdump -i en0 &apos;port 8080&apos;

# 显示eth1接口，来自192.168.1.200的通信
sudo tcpdump -i eth1 src 192.168.1.200

# 显示eth1接口80端口，目的地为192.168.1.101的通信
sudo tcpdump -i eth1 dst 192.168.1.101 and port 80

# 将lo0接口的通信存入文件record.pcap
sudo tcpdump -w record.pcap -i lo0
</code></pre><p>DNS是在域名和IP之间进行翻译。DNS故障会导致我们无法通过域名访问某个网址。 </p>
<pre><code># DNS域名解析。返回域名对应的IP地址
host www.sina.com.cn
</code></pre><h2 id="u53C2_u8003_u8D44_u6599"><a href="#u53C2_u8003_u8D44_u6599" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="http://www.cnblogs.com/vamei/" target="_blank" rel="external">Vamei</a></li>
<li><a href="http://www.cnblogs.com/maybe2030/" target="_blank" rel="external">Poll 的笔记</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>这篇文章主要介绍计算机网络的相关知识，因为网络的重要组成不是是协议，所以很大篇幅会是相关协议以及具体的应用。整体的结构基于 <a href="http://www.cnblogs.com/vamei/">Vamei</a> 博客中的结构（以及一些配图），加上自己在网络上搜集和日常学习中的一些思考，整理成为本文。</p>]]>
    
    </summary>
    
      <category term="协议" scheme="http://wdxtub.com/tags/%E5%8D%8F%E8%AE%AE/"/>
    
      <category term="基础" scheme="http://wdxtub.com/tags/%E5%9F%BA%E7%A1%80/"/>
    
      <category term="网络" scheme="http://wdxtub.com/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="计算机" scheme="http://wdxtub.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[软件架构与设计 第 13 课  Implementing Architecture]]></title>
    <link href="http://wdxtub.com/2016/02/10/sad-13/"/>
    <id>http://wdxtub.com/2016/02/10/sad-13/</id>
    <published>2016-02-10T20:25:53.000Z</published>
    <updated>2016-02-10T18:53:00.000Z</updated>
    <content type="html"><![CDATA[<p>上节课我们非常简略地了解了分析架构的大概方法，这节课我们再来看看如何去实现一个架构。</p>
<a id="more"></a>
<hr>
<p>需要理解的概念主要有：</p>
<ul>
<li>实现是一个映射的过程<ul>
<li>组件、连接器、接口、配置、设计思路</li>
<li>动态特性，非功能属性</li>
</ul>
</li>
<li>架构实现的框架</li>
<li>评价框架<ul>
<li>平台支持：编程语言、操作系统</li>
<li>效率</li>
<li>其他：大小、花费、易用性、可靠性、鲁棒性、是否开源、是否便携、是否易于长期维护 </li>
</ul>
</li>
<li>中间件、架构和组件模型的关系<ul>
<li>CORBA, COM/DCOM, JavaBeans, .NET, JMS, etc</li>
</ul>
</li>
<li>搭建新框架<ul>
<li>理解问题本身</li>
<li>让架构符合问题</li>
<li>选择框架范围</li>
<li>避免过度工程</li>
</ul>
</li>
<li>并行和通用化技术</li>
<li>保证架构到实现的一致性</li>
</ul>
<p>下面举两个例子，来看看如何进行分析和实现，这里偷懒就直接用 PPT 了。</p>
<p><img src="/images/14551296610222.jpg" alt=""></p>
<p><img src="/images/14551297754601.jpg" alt=""></p>
<p><img src="/images/14551298029648.jpg" alt=""></p>
<p><img src="/images/14551303007239.jpg" alt=""></p>
<p>基本上还是比较理论的东西，大概看看有个感觉即可。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>上节课我们非常简略地了解了分析架构的大概方法，这节课我们再来看看如何去实现一个架构。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="架构" scheme="http://wdxtub.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="设计" scheme="http://wdxtub.com/tags/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[软件架构与设计 第 12 课 Analysis of Software Architectures]]></title>
    <link href="http://wdxtub.com/2016/02/10/sad-12/"/>
    <id>http://wdxtub.com/2016/02/10/sad-12/</id>
    <published>2016-02-10T20:24:37.000Z</published>
    <updated>2016-02-10T17:46:24.000Z</updated>
    <content type="html"><![CDATA[<p>这节课我们继续回到课本中，来看看如何对软件架构进行分析，以及一些常见的分析技巧。</p>
<a id="more"></a>
<hr>
<p>架构分析是利用架构模型找出重要的系统属性的工作。我们需要知道：</p>
<ul>
<li>问什么问题</li>
<li>为什么要问这些问题</li>
<li>怎么问这些问题</li>
<li>怎么保证这些问题可以找到答案</li>
</ul>
<p>但是在开始分析之前，还需要确定下面的内容：</p>
<ul>
<li>分析的目标<ul>
<li>四个 C: Completeness, Consistency, Compatibility, Correctness</li>
<li>一致性需要包含：Name, Interface, Behavior, Interaction 和  Refinement</li>
</ul>
</li>
<li>分析的范围<ul>
<li>组件和连接器层级</li>
<li>子系统和系统层级</li>
<li>数据层级</li>
</ul>
</li>
<li>架构中最需要关注的部分<ul>
<li>结构特征</li>
<li>行为特征</li>
<li>交互特征</li>
<li>非功能特征</li>
</ul>
</li>
<li>架构模型的正式程度<ul>
<li>非正式模型</li>
<li>半正式模型</li>
<li>正式模型</li>
</ul>
</li>
<li>分析的类型<ul>
<li>静态分析</li>
<li>动态分析</li>
<li>场景驱动分析（可能是静态以及动态的）</li>
</ul>
</li>
<li>自动化的程度<ul>
<li>手动</li>
<li>半自动</li>
<li>全自动</li>
</ul>
</li>
<li>系统相关人员对分析的兴趣<ul>
<li>架构师</li>
<li>开发者</li>
<li>经理</li>
<li>消费者</li>
<li>销售者</li>
</ul>
</li>
</ul>
<p>架构的分析技术也有分类，比如：</p>
<ul>
<li>基于观察和审核</li>
<li>基于模型</li>
<li>基于模拟</li>
</ul>
<p>这部分讲得比较笼统，大家有个感性的认知即可。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这节课我们继续回到课本中，来看看如何对软件架构进行分析，以及一些常见的分析技巧。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="架构" scheme="http://wdxtub.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="设计" scheme="http://wdxtub.com/tags/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[深入理解计算机系统 第 10 课 Program Optimization]]></title>
    <link href="http://wdxtub.com/2016/02/08/csapp-10/"/>
    <id>http://wdxtub.com/2016/02/08/csapp-10/</id>
    <published>2016-02-09T05:24:11.000Z</published>
    <updated>2016-02-09T04:18:22.000Z</updated>
    <content type="html"><![CDATA[<p>这一讲可谓是全书最实用的部分，介绍如何基于代码执行的机制，去优化我们的代码。</p>
<a id="more"></a>
<hr>
<h2 id="u901A_u7528_u4EE3_u7801_u4F18_u5316_u6280_u5DE7"><a href="#u901A_u7528_u4EE3_u7801_u4F18_u5316_u6280_u5DE7" class="headerlink" title="通用代码优化技巧"></a>通用代码优化技巧</h2><p>即使是常数项系数的操作，同样可能影响性能。性能的优化是一个多层级的过程：算法、数据表示、过程和循环，都是需要考虑的层次。于是，这就要求我们需要对系统有一定的了解，例如：</p>
<ul>
<li>程序是如何编译和执行的</li>
<li>现代处理器和内存是如何工作的</li>
<li>如何衡量程序的性能以及找出瓶颈</li>
<li>如何保持代码模块化的前提下，提高程序性能</li>
</ul>
<p>最根源的优化是对编译器的优化，比方说再寄存器分配、代码排序和选择、死代码消除、效率提升等方面，都可以由编译器做一定的辅助工作。</p>
<p>但是因为这毕竟是一个自动的过程，而代码本身可以非常多样，在不能改变程序行为的前提下，很多时候编译器的优化策略是趋于保守的。并且大部分用来优化的信息来自于过程和静态信息，很难充分进行动态优化。</p>
<p>接下来会介绍一些我们自己需要注意的地方，而不是依赖处理器或者编译器来解决</p>
<h3 id="u4EE3_u7801_u79FB_u52A8"><a href="#u4EE3_u7801_u79FB_u52A8" class="headerlink" title="代码移动"></a>代码移动</h3><p>如果一个表达式总是得到同样的结果，最好把它移动到循环外面，这样只需要计算一次。编译器有时候可以自动完成，比如说使用 <code>-O1</code> 优化。一个例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_row</span><span class="params">(<span class="keyword">double</span> *a, <span class="keyword">double</span> *b, <span class="keyword">long</span> i, <span class="keyword">long</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">long</span> j;</span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)&#123;</span><br><span class="line">        a[n*i + j] = b[j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里 <code>n*i</code> 是重复被计算的，可以放到循环外面</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> j;</span><br><span class="line"><span class="keyword">int</span> ni = n * i;</span><br><span class="line"><span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)&#123;</span><br><span class="line">    a[ni + j] = b[j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="u51CF_u5C11_u8BA1_u7B97_u5F3A_u5EA6"><a href="#u51CF_u5C11_u8BA1_u7B97_u5F3A_u5EA6" class="headerlink" title="减少计算强度"></a>减少计算强度</h3><p>用更简单的表达式来完成用时较久的操作，例如 <code>16*x</code> 就可以用 <code>x &lt;&lt; 4</code> 代替，一个比较明显的例子是，可以把乘积转化位一系列的加法，如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">    <span class="keyword">int</span> ni = n * i;</span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">        a[ni + j] = b[j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以把 <code>n*i</code> 用加法代替，比如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> ni = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">        a[ni + j] = b[j];</span><br><span class="line">    ni += n;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="u516C_u5171_u5B50_u8868_u8FBE_u5F0F"><a href="#u516C_u5171_u5B50_u8868_u8FBE_u5F0F" class="headerlink" title="公共子表达式"></a>公共子表达式</h3><p>可以重用部分表达式的计算结果，例如：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Sum neighbors of i, j */</span></span><br><span class="line">up =    val[(i-<span class="number">1</span>)*n + j  ];</span><br><span class="line">down =  val[(i+<span class="number">1</span>)*n + j  ];</span><br><span class="line">left =  val[i*n     + j-<span class="number">1</span>];</span><br><span class="line">right = val[i*n     + j+<span class="number">1</span>];</span><br><span class="line">sum = up + down + left + right;</span><br></pre></td></tr></table></figure>
<p>可以优化为</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> inj = i*n + j;</span><br><span class="line">up =    val[inj - n];</span><br><span class="line">down =  val[inj + n];</span><br><span class="line">left =  val[inj - <span class="number">1</span>];</span><br><span class="line">right = val[inj + <span class="number">1</span>];</span><br><span class="line">sum = up + down + left + right;</span><br></pre></td></tr></table></figure>
<p>虽然说，现代处理器对乘法也有很好的优化，但是从 3 次乘法优化到 1 次，总是不错的主意</p>
<h2 id="u963B_u788D_u4EE3_u7801_u4F18_u5316_u7684_u56E0_u7D20"><a href="#u963B_u788D_u4EE3_u7801_u4F18_u5316_u7684_u56E0_u7D20" class="headerlink" title="阻碍代码优化的因素"></a>阻碍代码优化的因素</h2><h3 id="u8FC7_u7A0B_u8C03_u7528"><a href="#u8FC7_u7A0B_u8C03_u7528" class="headerlink" title="过程调用"></a>过程调用</h3><p>我们先来看一段代码，找找有什么问题：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lower1</span><span class="params">(<span class="keyword">char</span> *s)</span></span>&#123;</span><br><span class="line">    <span class="keyword">size_t</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="built_in">strlen</span>(s); i++)</span><br><span class="line">        <span class="keyword">if</span> (s[i] &gt;= <span class="string">'A'</span> &amp;&amp; s[i] &lt;= <span class="string">'Z'</span>)</span><br><span class="line">            s[i] -= (<span class="string">'A'</span> - <span class="string">'a'</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>问题在于，在字符串长度增加的时候，时间复杂度是二次方的！</p>
<p><img src="/images/14549871142268.jpg" alt=""></p>
<p>问题就在于，每次循环中都会调用一次 <code>strlen(s)</code>，而这个函数本身需要通过遍历字符串来取得长度，因此时间复杂度就成了二次方。</p>
<p>可以怎么优化呢？简单，那么只计算一次就好了：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lower2</span><span class="params">(<span class="keyword">char</span> *s)</span></span>&#123;</span><br><span class="line">    <span class="keyword">size_t</span> i;</span><br><span class="line">    <span class="keyword">size_t</span> len = <span class="built_in">strlen</span>(s);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; len; i++)</span><br><span class="line">        <span class="keyword">if</span> (s[i] &gt;= <span class="string">'A'</span> &amp;&amp; s[i] &lt;= <span class="string">'Z'</span>)</span><br><span class="line">            s[i] -= (<span class="string">'A'</span> - <span class="string">'a'</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>于是曲线图就成了这样，变成线性时间：</p>
<p><img src="/images/14549872807057.jpg" alt=""></p>
<p>有的同学可能就问了，为什么编译器不能自动把这个过程调用给移到外面去呢？</p>
<p>前面说过，编译器的策略必须是保守的，因为过程调用之后所发生的事情是不可控的，所以不能直接改变代码逻辑，比方说，假如 <code>strlen</code> 这个函数改变了字符串 <code>s</code> 的长度，那么每次都需要重新计算。如果移出去的话，就会导致问题。</p>
<p>所以很多时候只能靠程序员自己进行代码优化。</p>
<h3 id="u5185_u5B58_u95EE_u9898"><a href="#u5185_u5B58_u95EE_u9898" class="headerlink" title="内存问题"></a>内存问题</h3><p>接下来我们看另一段代码和由编译器生成的对应汇编：</p>
<p><img src="/images/14549903615932.jpg" alt=""></p>
<p>可以看到在汇编中，每次都会把 <code>b[i]</code> 存进去再读出来，为什么编译器会有这么奇怪的做法呢？</p>
<p>因为有可能这里的 <code>a</code> 和 <code>b</code> 指向的是同一块内存地址，那么每次更新，都会使得值发生变化：</p>
<p><img src="/images/14549904790912.jpg" alt=""></p>
<p>但是中间过程是什么，实际上是没有必要存储起来的，所以我们引入一个临时变量，这样就可以消除 Memory Aliasing 的问题</p>
<p><img src="/images/14549905195484.jpg" alt=""></p>
<h2 id="u5904_u7406_u6761_u4EF6_u5206_u652F"><a href="#u5904_u7406_u6761_u4EF6_u5206_u652F" class="headerlink" title="处理条件分支"></a>处理条件分支</h2><p>这个问题，如果不是对处理器执行指令的机制有一定了解的话，可能会难以理解。</p>
<p><img src="/images/14549908658078.jpg" alt=""></p>
<p>现代处理器普遍采用超标量设计，也就是基于流水线来进行指令的处理，也就是说，当执行当前指令时，接下来要执行的几条指令已经进入流水线的处理流程了。</p>
<p>这个很重要，对于顺序执行来说，不会有任何问题，但是对于条件分支来说，在跳转指令时可能会改变程序的走向，也就是说，之前载入的指令可能是无效的。这个时候就只能清空流水线，然后重新进行载入。处理器内部会采用称为『分支预测』的技术：</p>
<p><img src="/images/14549910810612.jpg" alt=""></p>
<p>比方说在一个循环中，根据预测，可能除了最后一次跳出循环的时候会判断错误之外，其他都是没有问题的。这就可以接受，但是如果处理器不停判断错误的话（比方说代码逻辑写得很奇怪），性能就会得到极大的拖累：</p>
<p><img src="/images/14549912099144.jpg" alt=""></p>
<p>分支问题有些时候会成为最主要的影响性能的因素，但有的时候其实很难避免。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><ul>
<li>用好编译器及其不同的参数设定</li>
<li>不要做蠢事<ul>
<li>注意算法可能隐藏的低效</li>
<li>写堆编译器友好的代码，尤其是过程调用和内存引用</li>
<li>注意内层循环</li>
</ul>
</li>
<li>根据机器来优化代码<ul>
<li>利用指令级并行</li>
<li>避免不可以预测的分支</li>
<li>有效利用缓存 </li>
</ul>
</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一讲可谓是全书最实用的部分，介绍如何基于代码执行的机制，去优化我们的代码。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="程序优化" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E4%BC%98%E5%8C%96/"/>
    
      <category term="组成原理" scheme="http://wdxtub.com/tags/%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"/>
    
      <category term="计算机" scheme="http://wdxtub.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[云计算 反思课 1 试验分析的策略与思考]]></title>
    <link href="http://wdxtub.com/2016/02/08/cc-rethink-1/"/>
    <id>http://wdxtub.com/2016/02/08/cc-rethink-1/</id>
    <published>2016-02-08T16:25:13.000Z</published>
    <updated>2016-02-08T15:49:40.000Z</updated>
    <content type="html"><![CDATA[<p>学习是一个不断改进方法论的过程，从<a href="http://wdxtub.com/2016/02/01/cc-11/">第 11 课</a>中，我学到了一个很重要的东西，就是要对问题本身进行细致分析，并且找到最基本的指标以衡量工作效果。</p>
<a id="more"></a>
<hr>
<p>这节课更多是记录自己思考和反思的过程，以便之后更好地了解问题，解决问题。上次作业的任务大概是这样的：通过模拟一个网站两天的流量，来测试负载均衡器以及自动扩展的功能。也就是说，假设一个网站的访问记录大概是这样的：</p>
<p><img src="/images/14549391991095.jpg" alt=""></p>
<p>我们需要做的是，在高峰期启用更多的机器满足用户需求，在低谷期降低机器数量节约经费，使得总体的性能达到一个令人满意的数值。并且我们可以使用的资源是有限的，如果全程都用多台机器，预算会超出，同样算任务失败。</p>
<p>所以简单来说，这实际上是一个有一个限制条件的优化问题，约束是总的机器时间，目标函数是成功处理的访问请求数量。也就是说，怎么能用最小的成本，获取最大的性能。</p>
<p>机器时间是一个对应的概念，和自然时间不同的是，需要乘以一个性能系数，比方说，我们可以选择『中』或『大』两种不同的机器，同样是开一个小时，『中』的机器时间是 2 小时，『大』的机器时间是 4 小时。</p>
<p>一拿到这个问题，本能的反应就是，可以通过云服务的监控加反馈机制，来对应进行调整，只要策略得当，就可以很好地拟合流量曲线。本着这个思路，就开始各种试验了，但是无论怎么试，都没有办法找到一个很好的解决方案，总是会错过一些流量高峰。模拟实验有时候还会让服务器假装『挂掉』，这样有一段时间就无法处理任何请求，最后的结果一塌糊涂。</p>
<p>现在想想，我犯了两个巨大的错误：</p>
<ol>
<li>我真的细致分析了问题本身吗？或者说，真的考虑到了模拟实验和真实情况的不同吗？</li>
<li>我拿什么来判断多变量的问题的优化呢？数学上可以用梯度下降，针对这个问题，我的梯度下降在哪里呢？</li>
</ol>
<p>先来说第一个问题，我们的模拟实验中，2 分钟相当于现实世界的 1 个小时，这是三十倍的缩放，这一点很重要，也就是说，假设现实的有两个小时的高峰期，那么对应到我们的实验中，就只有 4 分钟。而通过云服务，从申请机器到可以使用，大概有 3-5 分钟的延迟，基本上就意味着，高峰期过了，为了高峰期所申请的机器才可以用，但是已经并没有什么用了。</p>
<p>问题出在哪里，出在云服务申请机器并没有 30 倍的缩放，如果每次申请机器只需要 10 秒，那么还是有机会的。这就说明，因为模拟实验的时间尺度和云服务的时间尺度不一样，灵活策略基本没有意义，还不如直接开够机器，以不变应万变。</p>
<p>如果当初在分析问题的时候意识到这一点，就可以少走很多弯路。</p>
<p>第二个问题，因为每一次成功测试之后课程网站就会给出分数，我就没有想过要如何去有针对性地挑参数（云服务增减机器的策略，虽然通过前面的分析我们已经知道并没有什么用）。</p>
<p>回顾下之前解最优化问题的方式，KKT 条件是要有的，这样就保证了可以通过某种方式找到可能的最优解（哪怕是局部的）。虽然我对具体的参数调整还没有所谓的『直觉』，但是至少应该设定一个基准，比方说先全程拿 4 台『中』机器或者 2 台『大』机器跑一跑，来看看整体的表现。同样因为缺少了这一步，导致最后损失惨重，费用超支要扣分不说，还浪费了很多时间。</p>
<p>接下来无论是生活和学习，都要多去思考场景和问题本身，而不是想当然套用所谓『理所当然』，这就是我学到的一点小小的经验教训。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>学习是一个不断改进方法论的过程，从<a href="http://wdxtub.com/2016/02/01/cc-11/">第 11 课</a>中，我学到了一个很重要的东西，就是要对问题本身进行细致分析，并且找到最基本的指标以衡量工作效果。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="云计算" scheme="http://wdxtub.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="思考" scheme="http://wdxtub.com/tags/%E6%80%9D%E8%80%83/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[云计算 第 12 课 深入负载均衡器及其使用策略]]></title>
    <link href="http://wdxtub.com/2016/02/08/cc-12/"/>
    <id>http://wdxtub.com/2016/02/08/cc-12/</id>
    <published>2016-02-08T16:09:38.000Z</published>
    <updated>2016-02-10T19:04:00.000Z</updated>
    <content type="html"><![CDATA[<p>上一讲中我们接触负载均衡器，并且通过一个模拟实验进行了基本的体验，这节课我们通过 Azure 来探索一下负载均衡器的工作原理。</p>
<a id="more"></a>
<hr>
<h2 id="u5B66_u4E60_u76EE_u6807"><a href="#u5B66_u4E60_u76EE_u6807" class="headerlink" title="学习目标"></a>学习目标</h2><ol>
<li>了解负载均衡器内部的基本组件</li>
<li>理解可能影响负载分配策略的各种因素</li>
<li>理解不同的负载分配策略如何影响应用的服务质量(QoS)</li>
<li>使用 Round-Robin 策略来实现一个负载均衡器</li>
<li>学会如何观察和分析实例池中的资源使用情况，并基于这些信息实现一个高效的负载分配策略</li>
<li>在不丢弃请求的前提下，学会如何监控实例的健康状况，并处理实例挂掉的情况</li>
</ol>
<h2 id="u9879_u76EE_u7B80_u4ECB"><a href="#u9879_u76EE_u7B80_u4ECB" class="headerlink" title="项目简介"></a>项目简介</h2><h3 id="u8D1F_u8F7D_u5747_u8861_u5668_u590D_u4E60"><a href="#u8D1F_u8F7D_u5747_u8861_u5668_u590D_u4E60" class="headerlink" title="负载均衡器复习"></a>负载均衡器复习</h3><p>在 web 服务中，负载均衡器是非常重要的，为什么呢？原因有二：</p>
<ol>
<li>提高服务质量(QoS)，包括吞吐量及延迟等等</li>
<li>高可用性(HA)，也就是保证接近 100% 的可用性（用户在不同时间地点都可以访问）</li>
</ol>
<p>前面的项目中，我们使用 Amazon ELB 和 Azure 的 Load Balancer 服务来提高服务质量以及减小花费和处理实例失败。</p>
<p>在 Horizontal Scaling 的时候，负载均衡是由 load generator 完成的。每次添加新机器，load generator 会维护一个列表，并把不同的请求发送给不同的 data center。而在 Auto Scaling 中，我们则是使用 ELB 来完成负载均衡，也就使得我们可以不借助客户端（这里 load generator 可以看作是客户端的集合），就能快速增加机器数量（之前是需要通知客户端来发送给不同的机器d而）。换句话说，我们可以在不更新客户端程序的前提下，根据需求灵活调整机器数量。</p>
<p>除了分配流量，负载均衡器还需要负责处理实例失败。只要 ELB 背后还有一个健康的实例，Load Generator 就会继续发送请求。而 ELB 本身是通过一段时间给实例发消息来检测该实例是否存活的。</p>
<p>看起来很美，对不对，但实际上不同的负载分配策略对性能也会有极大的影响，这个我们后面接着讨论。</p>
<h3 id="u8D1F_u8F7D_u5206_u914D_u7B56_u7565"><a href="#u8D1F_u8F7D_u5206_u914D_u7B56_u7565" class="headerlink" title="负载分配策略"></a>负载分配策略</h3><p>Amazon 的 ELB 使用 Round-Robin 策略来分配负载，并不考虑服务器当前的状况（即使不同的服务器在不同的区域，也不管，反正对于所有机器一视同仁）</p>
<p>上一次我们发送的请求，每一个所需要的服务器资源（CPU，内存，磁盘 IO，网络 IO） 都是类似的，所以我们可以方便地通过增加或减少机器数量来进行调整。</p>
<p>可是实际生活中，不同的请求可能需要的资源差异也很大，如果有些请求需要大量的资源怎么办，这个时候 Round-Robin 策略还是不是高效呢？资源的使用率还会不会平衡呢？这又会如何影响整体的服务质量呢？</p>
<p>这一次我们需要自己实现一个负载均衡的策略，同时还要了解如何监控实例的健康状况，确保只发送请求给健康的实例。</p>
<p>最后需要说明的是，这次的项目主要在 Azure 平台上进行，在 AWS 上重复一次可以得到 10% 的加分，但只能使用 Java</p>
<h3 id="u955C_u50CF_u5217_u8868"><a href="#u955C_u50CF_u5217_u8868" class="headerlink" title="镜像列表"></a>镜像列表</h3><p><strong>Azure</strong></p>
<ul>
<li>Data Center, <code>Standard_A1</code>, <code>https://cc15319619.blob.core.windows.net/system/Microsoft.Compute/Images/vhds/cc15619p22dcv6-osDisk.b0c453f3-f75f-4a2d-bd9c-ae055b830124.vhd</code></li>
<li>Load Generator, <code>Standard_D1</code>, <code>https://cc15319619.blob.core.windows.net/system/Microsoft.Compute/Images/vhds/cc15619p22lgv7-osDisk.c0410b8f-821e-4de3-b725-2a834fd10060.vhd</code></li>
<li>Load Balancer, <code>Standard_D1</code>, <code>https://cc15319619.blob.core.windows.net/system/Microsoft.Compute/Images/vhds/cc15619p22lbv2-osDisk.1cf68388-ac67-4165-bec0-67341257d50a.vhd</code></li>
</ul>
<p><strong>AWS</strong></p>
<ul>
<li>Load Generator, <code>m3.medium</code>, <code>ami-0d4e6067</code></li>
<li>Data Center, <code>m3.medium</code>, <code>ami-6f486605</code></li>
<li>Load Balancer, <code>m3.medium / m3.large</code>, <code>ami-f44c629e</code></li>
<li>标签：<code>Project: 2.2</code></li>
</ul>
<p>因为 Azure 的机制，我们需要把镜像先复制到自己的存储账户中，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LG</span></span><br><span class="line">azure storage blob copy start https://cc15319619.blob.core.windows.net/system/Microsoft.Compute/Images/vhds/cc15619p22lgv7-osDisk.c0410b8f-<span class="number">821</span>e-<span class="number">4</span>de3-b725-<span class="number">2</span>a834fd10060.vhd --dest-account-name wdxstore --dest-account-key Xc6DDXunKq44PQe3Jhey07fRKeFfPqTm8JBU8CFTPNnj4nCzdgXbWEFvAiM+<span class="number">5</span>F16XBSzwgRyLp0c+os24p4W1w== --dest-container p22</span><br><span class="line"></span><br><span class="line"><span class="comment"># DC</span></span><br><span class="line">azure storage blob copy start https://cc15319619.blob.core.windows.net/system/Microsoft.Compute/Images/vhds/cc15619p22dcv6-osDisk.b0c453f3<span class="operator">-f</span>75f-<span class="number">4</span>a2d-bd9c-ae055b830124.vhd  --dest-account-name wdxstore --dest-account-key Xc6DDXunKq44PQe3Jhey07fRKeFfPqTm8JBU8CFTPNnj4nCzdgXbWEFvAiM+<span class="number">5</span>F16XBSzwgRyLp0c+os24p4W1w== --dest-container p22</span><br><span class="line"></span><br><span class="line"><span class="comment"># LB</span></span><br><span class="line">azure storage blob copy start https://cc15319619.blob.core.windows.net/system/Microsoft.Compute/Images/vhds/cc15619p22lbv2-osDisk.<span class="number">1</span>cf68388-ac67-<span class="number">4165</span>-bec0-<span class="number">67341257</span>d50a.vhd --dest-account-name wdxstore --dest-account-key Xc6DDXunKq44PQe3Jhey07fRKeFfPqTm8JBU8CFTPNnj4nCzdgXbWEFvAiM+<span class="number">5</span>F16XBSzwgRyLp0c+os24p4W1w== --dest-container p22</span><br></pre></td></tr></table></figure>
<h2 id="u8D1F_u8F7D_u5747_u8861_u5668_u7B56_u7565"><a href="#u8D1F_u8F7D_u5747_u8861_u5668_u7B56_u7565" class="headerlink" title="负载均衡器策略"></a>负载均衡器策略</h2><h3 id="u8D1F_u8F7D_u6A21_u5F0F_-__u8D44_u6E90_u7ADE_u4E89"><a href="#u8D1F_u8F7D_u6A21_u5F0F_-__u8D44_u6E90_u7ADE_u4E89" class="headerlink" title="负载模式 - 资源竞争"></a>负载模式 - 资源竞争</h3><p>对于每一台 EC2 实例来说，有如下限制：</p>
<ol>
<li>计算能力 - 每个请求的计算复杂度越高，能够处理的请求总数越低</li>
<li>内存容量 - 每个请求所需要的内存越多，能够处理的请求总数越低</li>
<li>磁盘 IO - 因为每秒中的读写次数是有上限的，每个请求所需要磁盘读写越多，能够处理的请求总数越低</li>
<li>网络 I/O - 带宽是有上限的，传输大的数据包会影响到其他数据的传输速度</li>
</ol>
<p>通常来说，一旦出现资源过载的现象，系统就不得不杀死当前的进程，也就会导致服务质量的下降。那么我们怎么办呢？之前我们的策略是申请更好的实例或者更多的实例，但是随之而来的就是要花更多的钱，即使如此有时候还是不够（有些实例会超载），所以我们需要想办法，让所有的实例一同承受流量冲击</p>
<h3 id="Round_Robin"><a href="#Round_Robin" class="headerlink" title="Round Robin"></a>Round Robin</h3><p>Round Robin 策略很简单，就是轮转着把每个请求分配到不同的实例上去，而不考虑优先级什么的。这个方法的优势在于：超™简单。</p>
<p>这种策略一旦遇到需要特别多资源的请求时，就可能造成某一台实例超载的同时，其他实例都闲着没啥事儿，服务质量降低了不说，钱也没花到刀刃上。</p>
<p>但是当有一个比较大的实例池的时候，所有需要很多资源的请求集中在一个实例上的机会是很小的（但是并不是没有，还是需要具体情况具体分析）</p>
<h3 id="u806A_u660E_u7684_u8D1F_u8F7D_u5206_u914D_u7B56_u7565"><a href="#u806A_u660E_u7684_u8D1F_u8F7D_u5206_u914D_u7B56_u7565" class="headerlink" title="聪明的负载分配策略"></a>聪明的负载分配策略</h3><p>相信聪明的同学已经想到可能的解决办法了，我们只需要找到最合适的实例，把请求对应发过去即可，而不是按顺序一个一个发送。那么问题就来了，怎么找到这个『最合适的』呢？</p>
<ol>
<li>我们需要了解针对一个请求，是要竞争哪一类资源</li>
<li>我们需要知道每个 data center 的工作情况</li>
<li>我们需要根据使用情况来决定下一个请求要发到哪里</li>
</ol>
<p>于是可以继续问自己，针对上述情况，什么策略是最好的，又需要通过什么样的数据结构来存储这些信息呢？</p>
<p>这个方法一定会比 Round-Robin 好吗？不一定，因为判断『最合适』本身，就需要一定资源，带来一定延迟，除非有很大提高，不然功不抵过呀。</p>
<p>下面是两个可能的策略：</p>
<p><strong>基于请求执行时间的策略</strong></p>
<p>这种策略的难点在于，如何预测一个请求需要执行多长时间。</p>
<p><strong>基于资源使用率的策略</strong></p>
<p>平衡所有 data center 的使用率，维护一个有序列表，把请求发给负载最小的实例。</p>
<h2 id="Round_Robin__u5B9E_u6218"><a href="#Round_Robin__u5B9E_u6218" class="headerlink" title="Round Robin 实战"></a>Round Robin 实战</h2><p>我们先来实现一个基于 Round-Robin 的负载均衡器并评估它的效率。这里用两种不同的流量模式来进行测试：</p>
<ol>
<li>周末流量包（测试 Round-Robin 调度）</li>
<li>工作日流量包（测试自定义调度）</li>
</ol>
<h3 id="u4EFB_u52A1_u5217_u8868"><a href="#u4EFB_u52A1_u5217_u8868" class="headerlink" title="任务列表"></a>任务列表</h3><ol>
<li>在 Azure 中启动一台 load balancer 虚拟机</li>
<li>SSH 到 load balancer 上(用户名 <code>ubuntu</code>, 密码 <code>Cloud@123</code>)，需要做的内容在 <code>/home/ubuntu/Project22/</code> 文件夹中</li>
<li>了解给出的框架代码<ul>
<li>可以在 <code>Main.java</code> 找到放置虚拟机 DNS 地址的地方</li>
<li>在 <code>LoadBalancer.java</code> 的 start() 方法中开始写自定义的负载均衡策略</li>
</ul>
</li>
<li>补充完整 <code>LoadBalancer.java</code> 中的 <code>start()</code> 方法，使其可以用 round robin 的方式给已连接的实例分配负载，完成之后使用 <code>javac *.java</code> 来进行编译 </li>
<li>如果你确定自己的代码是对的，那么开启三个 data center 虚拟机，并在 <code>Main.java</code> 中填写的 <code>http://[your DC DNS]</code> 里填好对应的 DNS 地址</li>
<li>使用 <code>./run</code> 来执行你的代码</li>
<li>可以在浏览器中访问 <code>http://[your load balancer DNS]</code> 看到测试 UI</li>
<li>确定 load balancer 的 round robin 没有问题后，开启一个 load generator 虚拟机</li>
<li>提交密码和 andrew id</li>
<li>开始 round robin 测试，目标是达到平均每秒 59 的 RPS</li>
<li>访问 <code>http://[your DC DNS]:8080/info/cpu</code> 来查看 data center 的 CPU 使用率</li>
</ol>
<p>负载是否均衡？在这个测试中，round robin 是一个好的策略吗？</p>
<p>接下来我们就要进入自定义调度算法的测试了。</p>
<h3 id="u5907_u6CE8"><a href="#u5907_u6CE8" class="headerlink" title="备注"></a>备注</h3><ul>
<li>可以在终端使用提供的 Java/Python 代码来开启所有的虚拟机。但是如果一个虚拟机没能通过健康检查，你需要在 load balancer 的代码中完成虚拟机的启动。</li>
<li>注意代码的整洁和模块化。多写点注释，阐述自己的思路</li>
<li>只能修改 <code>LoadBalancer.java</code>, <code>Main.java</code> 和 <code>DataCenterInstance.java</code></li>
<li>不能修改 <code>Request.java</code>, <code>RequestHandler.java</code>, <code>Response.java</code> 和 <code>ResponseBuilder.java</code></li>
</ul>
<h3 id="u89E3_u9898_u6B65_u9AA4"><a href="#u89E3_u9898_u6B65_u9AA4" class="headerlink" title="解题步骤"></a>解题步骤</h3><p>先用之前的代码复制镜像，然后开启 1 个 Load Balancer，1 个 Load Generator 和 3 个 Data Center。然后 SSH 到 Load Balancer 上：<code>ssh ubuntu@lbvmwdx.eastus.cloudapp.azure.com</code> 密码是 <code>Cloud@123</code>。然后我们把项目代码拷贝回本地 <code>scp -r ubuntu@yourdns.eastus.cloudapp.azure.com:~/Project22/* ./</code></p>
<p>接着大概观察一下代码，主要做两件事情：</p>
<ol>
<li>把 Data Center 的 DNS 填到 <code>Main.java</code> 中</li>
<li>补充完全 <code>LoadBalancer.java</code> 中的 <code>start()</code> 方法</li>
</ol>
<p>这里注意以下几个地方：</p>
<ol>
<li><code>LoadBalancer</code> 类在被创建的时候就把 <code>instances</code> 的列表传进来了，直接调用即可</li>
<li>默认是把所有请求都发给第一个 Data Center 的，只需要改一下这里的索引就好。</li>
<li>修改完成之后整个文件夹上传回去 <code>scp -r ./* ubuntu@yourdns.eastus.cloudapp.azure.com:~/Project22/</code></li>
<li>提交 dns 的时候，不用前面的 <code>http</code> 和最后的 <code>/</code> 之类的，注意下格式</li>
</ol>
<p>接着就和前面任务列表中的一致了，这里不赘述。</p>
<h2 id="u6539_u8FDB_u8D1F_u8F7D_u5747_u8861_u5668_u7B56_u7565"><a href="#u6539_u8FDB_u8D1F_u8F7D_u5747_u8861_u5668_u7B56_u7565" class="headerlink" title="改进负载均衡器策略"></a>改进负载均衡器策略</h2><p>下一个任务是开发一个负载均衡的策略，以便通过 自定调度算法测试。</p>
<p>可以通过 <code>http://[data center virtual machine dns]:8080/info/cpu</code> 来了解 data center 的 CPU 使用情况，能否通过这个方法，来通过测试呢？</p>
<h3 id="u4EFB_u52A1_u5217_u8868-1"><a href="#u4EFB_u52A1_u5217_u8868-1" class="headerlink" title="任务列表"></a>任务列表</h3><ol>
<li>在 Azure 中启动一台 load balancer 虚拟机</li>
<li>SSH 到 load balancer 上(用户名 <code>ubuntu</code>, 密码 <code>Cloud@123</code>)，需要做的内容在 <code>/home/ubuntu/Project22/</code> 文件夹中</li>
<li>补充完整 <code>LoadBalancer.java</code> 中的 <code>start()</code> 方法，使其可以通过查询 CPU 使用率的方式给已连接的实例分配负载，完成之后使用 <code>javac *.java</code> 来进行编译 </li>
<li>如果你确定自己的代码是对的，那么开启三个 data center 虚拟机，并在 <code>Main.java</code> 中填写的 <code>http://[your DC DNS]</code> 里填好对应的 DNS 地址</li>
<li>使用 <code>./run</code> 来执行你的代码</li>
<li>可以在浏览器中访问 <code>http://[your load balancer DNS]</code> 看到测试 UI</li>
<li>确定 load balancer 的自定义调度算法没有问题后，开启一个 load generator 虚拟机</li>
<li>开始 自定义调度算法 测试，目标是达到平均每秒 41 的 RPS</li>
<li>访问 <code>http://[your DC DNS]:8080/info/cpu</code> 来查看 data center 的 CPU 使用率</li>
</ol>
<p>负载是否均衡？在这个测试中，你的算法是一个好的策略吗？</p>
<h3 id="u7591_u96BE_u6742_u75C7"><a href="#u7591_u96BE_u6742_u75C7" class="headerlink" title="疑难杂症"></a>疑难杂症</h3><p>这里我遇到一个问题，就是 RPS 一直徘徊在 21 左右，死活上不去。我觉得可能是以下几个问题：</p>
<ol>
<li>Load Generator 发送请求不正常，因为之前强行停止过测试，不知道有没有影响</li>
<li>Load Balancer 判断的时候花费的时间太长，如果是这样的话需要优化代码</li>
<li>发送请求的间隔数目可能太小，导致检查过于频繁</li>
</ol>
<p>我觉得很可能是第二个，因为总是能看到选择的 Data Center 的 CPU 使用率为 0，估计是 Load Generator 分发不够快所致。不过我们还是一个一个来试一次</p>
<ol>
<li>重启之后发现并没有什么影响，还是处于比较低的 RPS，所以可以先试试看修改间隔数目</li>
<li>间隔数目改成 20 之后并没有特别大的改变，所以可以确定是 Load Balancer 的问题</li>
<li>经过问同学和排查，发现了问题所在，需要在选择最空闲的机器之后，继续使用 round robin 的策略</li>
</ol>
<p>然后问题得以解决。</p>
<h2 id="u76D1_u63A7_Data_Center__u7684_u72B6_u6001"><a href="#u76D1_u63A7_Data_Center__u7684_u72B6_u6001" class="headerlink" title="监控 Data Center 的状态"></a>监控 Data Center 的状态</h2><p>下一步是让我们的 Load Balancer 能够处理某个 Data Center 挂掉的情况。一旦某个虚拟机挂掉，就开启一个新的，用以代替旧的。</p>
<p>可以通过发送 HTTP 请求来查看 Data Center 的状况，只有返回 200 的时候，才认为它是在工作的。</p>
<h3 id="u4EFB_u52A1_u5217_u8868-2"><a href="#u4EFB_u52A1_u5217_u8868-2" class="headerlink" title="任务列表"></a>任务列表</h3><ol>
<li>在 Azure 中启动一台 load balancer 虚拟机</li>
<li>SSH 到 load balancer 上(用户名 <code>ubuntu</code>, 密码 <code>Cloud@123</code>)，需要做的内容在 <code>/home/ubuntu/Project22/</code> 文件夹中</li>
<li>实现带有健康检查的负载均衡器，也就是说，能检测出机器挂掉并停止向其发送请求，然后开启一个新的虚拟机，直到它能工作时，就用新的代替旧的。</li>
<li>完成之后使用 <code>javac *.java</code> 来进行编译</li>
<li>如果你确定自己的代码是对的，那么开启三个 data center 虚拟机，并在 <code>Main.java</code> 中填写的 <code>http://[your DC DNS]</code> 里填好对应的 DNS 地址</li>
<li>使用 <code>./run</code> 来执行你的代码</li>
<li>可以在浏览器中访问 <code>http://[your load balancer DNS]</code> 看到测试 UI</li>
<li>确定 load balancer 的自定义调度算法以及健康检查没有问题后，开启一个 load generator 虚拟机</li>
<li>开始 自定义调度算法+健康检查 测试，目标是达到平均每秒 41 的 RPS</li>
<li>一切完成之后可以进入最后的测试，目标是 30 RPS</li>
</ol>
<p>所有测试结束之后，关闭除了 load generator 的其他虚拟机，然后上传代码，包括 <code>/home/ubuntu/Project22</code> 下的所有 java 文件和 <code>references</code> 文件。上传完毕之后可以关闭 load generator</p>
<blockquote>
<p>提示</p>
</blockquote>
<p>可以用 <code>[dns of a virtual machine]/lookup/random</code> 作为健康检查的链接</p>
<p>在 <code>pom.xml</code> 中配置好</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">sourceDirectory</span>&gt;</span><span class="tag">&lt;/<span class="title">sourceDirectory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">outputDirectory</span>&gt;</span><span class="tag">&lt;/<span class="title">outputDirectory</span>&gt;</span></span><br><span class="line">        ....</span><br><span class="line"><span class="tag">&lt;<span class="title">build</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>就可以编译同一层级的文件了，注意要把 <code>run</code> 文件改为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/bash</span></span><br><span class="line">rm *.class</span><br><span class="line">mvn compile &amp;&amp; sudo mvn <span class="built_in">exec</span>:java -Dexec.mainClass=<span class="string">"Main"</span></span><br></pre></td></tr></table></figure>
<p>性能优化考虑：</p>
<ol>
<li>去掉测试用的输出语句，会比较影响性能</li>
<li>Health Check 测试中会挂掉其中两台 DC，其中间隔 6 分钟左右（第 6 分钟，第 12 分钟），注意可能出现的异常情况</li>
<li>一旦发送请求给挂了的机器，因为需要等待 Timeout，所以会占用很多时间，但是其实很难避免发送请求给已挂的机器，除非增加健康检查的间隔，但是增加间隔本身也会</li>
<li>每次访问实际上会调用两次 <code>start()</code> 函数，注意这里可能会导致一些问题；网络访问有比较多需要处理的异常，注意保证逻辑的一致性</li>
<li>选择下一个的时候性能太差，可能的话改动一下，应该一开始的 RPS 有 50 多</li>
<li>需要开新线程，<code>new Thread(new Runnable).start()</code></li>
<li>新开的机器各种不稳定，需要等待一段时间再进行查询</li>
</ol>
<h2 id="AWS_Bonus"><a href="#AWS_Bonus" class="headerlink" title="AWS Bonus"></a>AWS Bonus</h2><p>在 AWS 上完成前面的三个任务，这里不再重复任务描述。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>上一讲中我们接触负载均衡器，并且通过一个模拟实验进行了基本的体验，这节课我们通过 Azure 来探索一下负载均衡器的工作原理。</p>]]>
    
    </summary>
    
      <category term="AWS" scheme="http://wdxtub.com/tags/AWS/"/>
    
      <category term="Azure" scheme="http://wdxtub.com/tags/Azure/"/>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="云计算" scheme="http://wdxtub.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="负载均衡器" scheme="http://wdxtub.com/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[【火影忍者】一半良心，一半黑心]]></title>
    <link href="http://wdxtub.com/2016/02/07/naruto-ios/"/>
    <id>http://wdxtub.com/2016/02/07/naruto-ios/</id>
    <published>2016-02-08T07:17:34.000Z</published>
    <updated>2016-02-08T06:15:53.000Z</updated>
    <content type="html"><![CDATA[<p>当我们慢慢接受『免费玩家』没人权这样的游戏规则时，火影忍者手游跳出来告诉大家：不多花点钱，你还是没人权。一款制作精良的游戏却处处故意让玩家感到憋屈，先端上来满汉全席，然后故意往里面扔老鼠屎，这个饭店到底是图啥呢？</p>
<a id="more"></a>
<hr>
<p>『火影忍者』对于我来说，与其说是一部漫画作品，一部动画作品，更多是那些年中二的自己留下的回忆。但是在微信的游戏中心里看到『火影忍者』官方授权的手游，我的心情是复杂的。毕竟大家都知道，腾讯的作风基本上可以用六个字总结——『不充值，无游戏』。</p>
<p>截至今天，我所在的服务最高的等级是 58 级，我作为非 RMB 玩家坚持到了 53 级，应该也有一定的发言权了。至于为什么没有彻底通关后再动笔，实在是因为春节活动『恶心』到我了，『充值有积分，积分换奖品』，罢了，我去买 PS4 上原汁原味的火影忍者好了（过两天发售）。</p>
<p>看到下面的主界面，大概就能体会到『想钱想疯了』的感觉。体力、金钱旁边的加号是充钱的地方就算了，旁边的 V0（VIP 等级）、活动、招募、商城全都是要玩家花钱的地方，这还不过瘾，直接两个大大的『充值』往上一摆，得了，没钱的咱们不伺候哟！</p>
<p><img src="/images/IMG_2763.jpg" alt="主界面"></p>
<p>（但是无论是图标还是整体的界面设计都是非常好的，相信看过动画漫画的朋友都能感受到，这个不黑不吹，顶尖）</p>
<h2 id="u753B_u9762_u53CA_u58F0_u4E50"><a href="#u753B_u9762_u53CA_u58F0_u4E50" class="headerlink" title="画面及声乐"></a>画面及声乐</h2><p>因为有了官方的授权以及提供的素材，无论是场景动作忍术特效过场动画还是配音音效都是百分百原汁原味，有些剧情限定的关卡真的是让人玩得仿佛回到过去。再加上美术人员细致的加工处理，一招一式，有板有眼。</p>
<p><img src="/images/IMG_2783.jpg" alt="过场动画"></p>
<p>可是你若是不充钱，可能就得像我一样每天重复去完成各种各样的任务，提高自己的战斗力，然后才能接着把剧情继续下去。虽然剧情的进展非常缓慢，基本上满级也才刚刚到纲手当上火影的剧情。可是，这也许是唯一让我坚持下去的理由了，可是，原本可以做得更好的，不是吗？</p>
<h2 id="u5FCD_u8005_u53CA_u6218_u6597"><a href="#u5FCD_u8005_u53CA_u6218_u6597" class="headerlink" title="忍者及战斗"></a>忍者及战斗</h2><p>因为剧情还处于前中期阶段，所以登场的都是大家熟悉的下忍加上几个中坚力量（比如卡卡西）。不过考虑到这是第一部，腾讯之后完全可以出个疾风传什么的新游戏，让大家再来从头充一次钱。</p>
<p><img src="/images/IMG_2787.jpg" alt="忍者列表"></p>
<p>不过对于出场的忍者，还原度很高，手感也不错，不会给人只是换个贴图其他都一样的感觉，比方说不同的攻击范围和判定，不同的技能指向和伤害模式。让我觉得很有趣的是雏田的『白眼』技能，开启之后屏幕进入『白眼』模式，并且所有的普攻和技能都百分百暴击。</p>
<p><img src="/images/IMG_2786.jpg" alt="剧情限定"></p>
<p>很多传奇忍者，例如上图中的这仨，在剧情限定关卡中，也有机会使用，甚至还有配合召唤兽的战斗，虽然触屏战斗或多或少让人出戏，但是不得不说，我还是要给 9 分，剩下 1 分怕忍者们骄傲。</p>
<p><img src="/images/IMG_2785.jpg" alt="战斗画面"></p>
<p>战斗就没有主界面这么拖泥带水了，普通攻击 + 两个基本技能 + 大招 + 卷轴技能 + 召唤兽，就是全部的攻击方式了，当然不想自己这么累，左上角也可以自动。战斗的模式主要有三种，第一种就是图中所示的，抵御 4 波敌人；第二种是在限定时间清除场景中的敌人；最后一种就是和 Boss 单挑了。在单挑模式下会多一个『替身术』的技能（就是用一截木头代替自己吃技能），不过无伤大雅，反正最后都可以自动。</p>
<p>另外一个值得一提的是组队 PK 模式，但是默认是自动的，如下图（感谢不知道是谁的老瞎眼同学）：</p>
<p><img src="/images/IMG_2782.jpg" alt="组队战斗"></p>
<p>自动打自动，赢了加分输了减分，玩家看个热闹，基本就是这样了。当然不同的关卡可能会有一些微小的差异，比如说大石头堵路（可以打爆）或者大雾弥漫，但是总体的模式就三种，并没有脱离传统 PVP/PVE 的设定，没有耐心的玩家，可能上手第二条就会开始全程自动了。</p>
<p>还有一些属性是和忍者无关的，比方说天赋、装备、通灵术、勾玉、秘卷（也就是卷轴忍术）和神器（主要用来坑钱）。天赋部分比较简单，没啥可选择的，就是剧情过一关可以花一堆金币点一次天赋。装备和勾玉这个黄金搭档则是氪金组合。</p>
<p><img src="/images/IMG_2765.jpg" alt="装备"></p>
<p><img src="/images/IMG_2767.jpg" alt="勾玉"></p>
<p>装备需要材料进行升级和进阶，这些都可以挂机取得，操作很傻瓜，基本就是体力换装备，人民币换体力。比较坑的是这个勾玉，首先勾玉至少有六个等级，每三个低等级的可以合成一个高等级的，但是，注意这个但是，合成之后只提高两倍的属性。</p>
<p>举个例子，假设你有 3 个加攻击的 1 级红勾玉，每个 +5 点攻击，但是合成变为 2 级红勾玉之后，只 +10 点攻击力。那么问题就来了，如果这样一路升级到 6 级红勾玉，就合成这一项，玩家要被『火耗』多少呢？我们来算一下：</p>
<ul>
<li>1 个 6 级红勾玉 = 3 个 5 级红勾玉 = 9 个 4 级红勾玉 = … = 243 个 1 级红勾玉</li>
<li>1 个 1 级红勾玉 = 5 攻击力（用上面的假设）</li>
<li>1 个 6 级红勾玉 = 160 攻击力</li>
<li>243 个 1 级红勾玉 = 1215 攻击力</li>
</ul>
<p>也就是说，通过合成，你的攻击力从原本可以加 1215 变成了 160。你™在逗我，真的，不带这么坑的。</p>
<p>召唤兽和秘卷还算是中规中矩，至少都是拿多少钱办多少事儿，数值也还算合理，至少我这个免费玩家也能比较顺利升级（但是有些高级的就只能用钱买，呵呵）</p>
<p><img src="/images/IMG_2766.jpg" alt="通灵术"></p>
<p><img src="/images/IMG_2768.jpg" alt="秘卷"></p>
<p>最后就是这个『神器』部分了，这个真的是为了坑人才设计出来的，不信我们来看看。</p>
<p><img src="/images/IMG_2769.jpg" alt="神器"></p>
<p>首先，原著里什么时候出现过所谓幌金绳，不过我现在明白了，晃的是玩家口袋里的金，真是恶意满满的名字。需要升级不说，升级所用的还是游戏里最贵的资源，然后，每个『神器』有三个可以镶嵌的位置，每个位置有三个属性，这三个属性是可以『洗炼』的，好了，这下玩家们为了更高更快更强，开始砸钱和随机数玩游戏吧。</p>
<p>我还能说什么？我™都升到 59 级了！</p>
<h2 id="u6A21_u5F0F"><a href="#u6A21_u5F0F" class="headerlink" title="模式"></a>模式</h2><p>游戏中的模式还是比较丰富的，剧情模式名为冒险副本。旁边的精英副本，是掉落忍者碎片的地方。</p>
<p><img src="/images/IMG_2773.jpg" alt="冒险副本"></p>
<p>这个忍者碎片就有讲究了，获得一个 C 级忍者（也就是最差的），要十个碎片，然后升级需要 30 个，再之后是 60。正常免费游戏节奏，大概每天你能获得 4-8 个不同忍者的碎皮，喜欢夕日红？对不起，你得花钱抽，除了普通招募，还有高级招募，反正就是一个字——钱。</p>
<p><img src="/images/IMG_2774.jpg" alt="精英副本"></p>
<p>更搞笑的是，花了钱，可能还是不行。比方说限定招募，还必须要要 V7 特权，从特权 V0（也就是我现在），充值到 V7，真是人傻钱多速来，不带这么践踏我对火影的爱的。</p>
<p><img src="/images/IMG_2771.jpg" alt="忍者招募"></p>
<p>配套的排行榜和竞技场，也就是给 大RMB 玩家一个殴打免费玩家或者 小RMB 玩家的地方，再加上海外的线路延迟 500ms 以上，基本上我都是不知道发生啥就被打死，这游戏太难玩。</p>
<p><img src="/images/IMG_2777.jpg" alt="决斗场 PVP"></p>
<p>剩余的模式基本上就是给玩家一个把时间和金钱转换成游戏中资源的场所，不是为了完成每日任务，我是碰都不会碰的。</p>
<p><img src="/images/IMG_2776.jpg" alt="忍者组织"></p>
<p>组织就是类似与部落的地方，有一些额外的副本，和为组织祈福的任务，当然了，总而言之还是那六个字：『无充值，不游戏』</p>
<p>游戏中的资源其实来来去去大概就三种吧，但是玩着玩着就会发现，不是缺这个就是缺那个。370 万金币那都不是事儿（就是我截图中的金币数目），要知道现在升级一点天赋，就要差不多 20 万，我觉得完全可以去掉『万』字，让玩家知道自己穷得 有多可怜。</p>
<h2 id="u603B_u8BC4"><a href="#u603B_u8BC4" class="headerlink" title="总评"></a>总评</h2><p>在做游戏上，腾讯旗下的工作室有几把刷子，完成度高，没啥 bug，各个系统和模式大而全，尽量覆盖了所有的玩家类型，但是真的，做游戏是需要钱，但是接着大家的喜爱和情怀，人为恶意制造麻烦不让玩家玩得痛快，迟早会被玩家所抛弃。游戏明明是第九艺术，怎么到了腾讯手里就成了坑钱的法宝呢？</p>
<p>估计很长一段时间不会再碰腾讯出的手游了，操心，闹心，甚至有点恶心。</p>
<p>参考 FAMI通 的评分标准</p>
<ul>
<li>画面: 9 (原汁原味的火影体验）</li>
<li>音乐: 7 (就是那些年的味道，但是背景音乐有些单调)</li>
<li>操作: 5 (作为一个挂机游戏，其实没啥操作好谈的，技能好了就戳，就酱)</li>
<li>故事: 7 (剧情太慢，故意不让玩家玩剧情，虽然不少地方地处理颇为画龙点睛)</li>
<li>乐趣: 3 (无充值，不游戏，给 3 分真的已经是看情怀)</li>
</ul>
<p>总评: 8 - 4 = 4 (不差钱的话—— 8 分，普通玩家的话—— 4 分，因为最初的乐趣都会被一心朝钱看的嘴啃得渣都不剩)</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>当我们慢慢接受『免费玩家』没人权这样的游戏规则时，火影忍者手游跳出来告诉大家：不多花点钱，你还是没人权。一款制作精良的游戏却处处故意让玩家感到憋屈，先端上来满汉全席，然后故意往里面扔老鼠屎，这个饭店到底是图啥呢？</p>]]>
    
    </summary>
    
      <category term="人民币玩家" scheme="http://wdxtub.com/tags/%E4%BA%BA%E6%B0%91%E5%B8%81%E7%8E%A9%E5%AE%B6/"/>
    
      <category term="手游" scheme="http://wdxtub.com/tags/%E6%89%8B%E6%B8%B8/"/>
    
      <category term="火影忍者" scheme="http://wdxtub.com/tags/%E7%81%AB%E5%BD%B1%E5%BF%8D%E8%80%85/"/>
    
      <category term="网游" scheme="http://wdxtub.com/tags/%E7%BD%91%E6%B8%B8/"/>
    
      <category term="腾讯" scheme="http://wdxtub.com/tags/%E8%85%BE%E8%AE%AF/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[软件架构与设计 习题课 4 面向服务系统架构设计]]></title>
    <link href="http://wdxtub.com/2016/02/07/sad-r4/"/>
    <id>http://wdxtub.com/2016/02/07/sad-r4/</id>
    <published>2016-02-08T05:28:50.000Z</published>
    <updated>2016-02-08T04:07:29.000Z</updated>
    <content type="html"><![CDATA[<p>这一次的作业，是结合面向服务架构设计的思想，来优化我们之前的 ATM 设计。这次只需要围绕一个主题来思考，所以会稍微深入一些。</p>
<a id="more"></a>
<hr>
<h2 id="u7CFB_u7EDF_u4E2D_u7684_u5546_u52A1_u670D_u52A1_u4E0E_u53EF_u91CD_u7528_u670D_u52A1"><a href="#u7CFB_u7EDF_u4E2D_u7684_u5546_u52A1_u670D_u52A1_u4E0E_u53EF_u91CD_u7528_u670D_u52A1" class="headerlink" title="系统中的商务服务与可重用服务"></a>系统中的商务服务与可重用服务</h2><p>之前的作业中，我主要是在 ATM 的设计上尝试不同的架构风格。不同的架构风格均有其优势和劣势，经过一些简单的分析，我得到了如下结论：之所以会出现这种情况，是因为各种架构风格都针对某一类具体的问题，并且试图给出完美的解决方案。但是完美常常也是脆弱的，虽然每个组件都是自洽的，但是他们之间没有一个通用的沟通方式（尤其是在需要进行逻辑调整的时候）</p>
<p>SOA 可以是用另一种不同的思路来解决这个问题。通过把不同的功能切分成不同类别的服务。这些服务可以通过一个通用的协议来进行重组和复用。所以我也视图把我的设计往这个方向上靠。经过这样的改动，可以方便地通过配置文件来修改业务逻辑，而无须对代码进行改动。</p>
<p>商务服务和可重用的服务主要有：</p>
<ul>
<li>用户验证服务</li>
<li>卡/支票验证服务</li>
<li>查询服务</li>
<li>转账服务</li>
<li>存款服务</li>
<li>异常处理服务</li>
<li>打印服务</li>
<li>等等</li>
</ul>
<h2 id="u7CFB_u7EDF_u5206_u5C42_u8BBE_u8BA1"><a href="#u7CFB_u7EDF_u5206_u5C42_u8BBE_u8BA1" class="headerlink" title="系统分层设计"></a>系统分层设计</h2><p>根据上面的说明，大致的分层设计为：</p>
<p><img src="/images/14549044328044.jpg" alt=""></p>
<p>我感觉还是比较一目了然的，这里就不再赘述了</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一次的作业，是结合面向服务架构设计的思想，来优化我们之前的 ATM 设计。这次只需要围绕一个主题来思考，所以会稍微深入一些。</p>]]>
    
    </summary>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[第四周 - 鹿港小镇]]></title>
    <link href="http://wdxtub.com/2016/02/05/small-town/"/>
    <id>http://wdxtub.com/2016/02/05/small-town/</id>
    <published>2016-02-06T03:59:05.000Z</published>
    <updated>2016-02-06T04:49:58.000Z</updated>
    <content type="html"><![CDATA[<p>有一种预感，路的终点是迷宫。出发啦，不要问那路在哪！</p>
<a id="more"></a>
<hr>
<p>实话说，临近春节的这一周，过得并不算特别好。除了之前去西雅图欠下的一屁股作业之外，一封封拒信也让我倍受打击，说打击可能有点过分，但是自己觉得表现不错却无法得到认同，总是有些伤感。俗话说得好『千里马常有，而伯乐不常有』，即使没有伯乐，也还是要按照千里马的标准去跑，至少不能对不起自己嘛。</p>
<p>说没有一点动摇，自己都不相信。一直以来按照自己觉得对的的方式去走，开始半接触社会总是有些不适应，无论是待人接物，还是临场应变，都有很多需要学，需要提高的地方。不过这倒不打紧，总是有机会比上次做得更好的嘛。</p>
<p>随着年龄增长，自我也在慢慢成长，甚至变得有些过分坚硬，虽然刀枪不入，但静静想来，也有点残酷无情。刚体容易出现不可逆的结构性损伤，所以还是要加点弹性，方能百折不挠。</p>
<p>Kindle 终于在除夕前迎来了本年度最大的升级（界面上），好看了不少，但是我的脚本工具依然停留在上个时代，得找机会把它们都升级一下（估计毕业前没多少时间）。不夸张地说，kindle 在我成长过程中起到了重要作用，从 K6 到 KPW 再到 Voyage ，机器一直在变，但不变的是『阅读富一生』的主题。</p>
<p>一开始读书，没多少思考，靠着笨办法积累；后来读书，虽然拾人牙慧，但也算有了点自己的新意；现在读书，更像是和作者跨越时间空间讨论着，无论是辨析力和判断力，都有了很大的提高。这带来的一个好处就是，很多时候能够用淡定代替焦虑，或者说，会更加理智用思考去代替本能，因为很多时候本能并不太靠谱。</p>
<p>举个例子，老师给出了很多阅读材料，和作业题，在时间不算太宽裕也不算太紧张的情况下，应不应该直接做题目呢？很多着急的同学，估计就直接开动了，然后在做题目的过程中磕磕绊绊，最后怪老师坑爹。但实际情况是不是这样的呢？大部分时候不是，反而是如果先进行阅读理解，掌握问题背后的要点所在，那么在做题目的过程中，就可以见招拆招，至少不至于像无头苍蝇一样漫无目的慌张焦虑。</p>
<p>再仔细思考一下，老师给出的材料，是站在更高的视角给出的更中肯的建议，假如现在让我们重新学习一次我们已经学会的东西，可能自学的顺序以及材料都会和第一次不一样，因为我们有了经验，更知道怎么样的学习路径更加合适和有效率。但是为什么放到学校里，就变成不相信老师给出的材料，而自顾自想当然先开始做题了呢？</p>
<p>做事情的道理亦是如此。</p>
<p>马上就要春节了，祝大家在新的一年里，心想事成万事如意，最重要的，身体健健康康，每天都有好心情。第一次没有和爸爸妈妈一起过年，没有特别的感受，就是两个字——『想家』</p>
<p>自己想了一个蹩脚的对联，也算是给大家拜个早年啦：</p>
<blockquote>
<p>大圣归来，身手不凡飞天外<br>小马奔腾，所向无前事竟成<br>横批：安身立命</p>
</blockquote>
<p>迎风向前，是唯一的方法。出发啦，不想问那路在哪！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>有一种预感，路的终点是迷宫。出发啦，不要问那路在哪！</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="周记" scheme="http://wdxtub.com/tags/%E5%91%A8%E8%AE%B0/"/>
    
      <category term="峡谷" scheme="http://wdxtub.com/tags/%E5%B3%A1%E8%B0%B7/"/>
    
      <category term="Gossip" scheme="http://wdxtub.com/categories/Gossip/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[软件架构与设计 第 11 课 Service-Oriented Architecture]]></title>
    <link href="http://wdxtub.com/2016/02/04/sad-11/"/>
    <id>http://wdxtub.com/2016/02/04/sad-11/</id>
    <published>2016-02-04T17:51:56.000Z</published>
    <updated>2016-02-10T17:07:48.000Z</updated>
    <content type="html"><![CDATA[<p>这一课是根据老师的课程安排添加的，之后应该会按照课本的脉络结合老师的思路来进行讲解。</p>
<a id="more"></a>
<hr>
<h2 id="u4EC0_u4E48_u662F_u9762_u5411_u670D_u52A1_u67B6_u6784"><a href="#u4EC0_u4E48_u662F_u9762_u5411_u670D_u52A1_u67B6_u6784" class="headerlink" title="什么是面向服务架构"></a>什么是面向服务架构</h2><p>简单来理解，服务计算就是利用现有的服务，通过逻辑组合和分支，来构造新的应用。这里的服务，是一个可以重用的组件，由服务提供者提供并由服务请求者请求。</p>
<p>课堂上介绍了很多概念和定义，但是我觉得其实意义不算特别大，理解 SOA 还是要抓住重点，重点其实很简单，一个是强调复用性，一个是强调拓展性。复用性值得是基本功能的模块化标准化，拓展性指的是用户量实际上已经由架构本身的特点进行了高层次的处理，很多是具体面对并发时候的技术细节。</p>
<p>最为突出的代表是 web 服务了，比方说网站提供一系列 api，我们不需要知道他们是怎么实现的，只要按照一定的规范去使用即可。仔细思考下前面的不同角色和使用场景，就可以得出下面的架构：</p>
<p><img src="/images/14548907014827.jpg" alt=""></p>
<p>这里了解两个术语：WSDL(Web Services Description Language) 和 RESTful API(Represnetational State Transfer)，后者的著名代表就是 HTTP Request/Response。服务请求者通过 SOAP(Simple Object Access Protocol) 来和服务提供者沟通。</p>
<p>沟通就两个字，但是在 web 这里，不知道为什么，复杂度就蹭蹭往上飙，各种协议真是乱花渐欲迷人眼，可以看看下图：</p>
<p><img src="/images/14548913482297.jpg" alt=""></p>
<p>这么多不同的子系统组合在一起，实际上就是一个 SOA 的架构，通过松散耦合来构造一个灵活、可拓展的系统。</p>
<p>不过说到底，SOA 可以说是一种设计思想，既然是思想，就可以应用在不同的层级，比方说</p>
<ul>
<li>在编程层级，可以用 SOA 的思想来进行组件设计——称之为 SCA(Service Component Architecture)</li>
<li>在中间件环节，可以利用 SOA 来指导设计，比方说 ESB(single Enterprise Service Bus)</li>
<li>在过程层级，SOA 可以用于集成和管理，甚至可以驱动架构设计</li>
<li>在企业层级，可以通过 SOA 的思想具体把任务细分</li>
</ul>
<p>具体到代码上，其实也还是老生常谈的几个概念，无非是重用性，扩展性，合作性，平台无关，语言无关这之类的。用水做例子，以前挖井打水，那么每个不同的部件就千奇百怪了，不同的桶不同的绳子不同的口径，现在直接水成为一种服务，打开水龙头就有，和你在哪里是谁无关，这就是 SOA 的思想。</p>
<p>也就是因为这种设计思路和不同的抽象层级，就有了 IaaS, PaaS 和 SaaS，这里主要说 Saas(Software as a Service)。举几个例子</p>
<ul>
<li>固话 - 多租户</li>
<li>分时系统 - 多实例</li>
<li>在线支付 - 多租户</li>
<li>电子邮件 - 多租户</li>
</ul>
<p>但是这两天 LinkedIn 和 Tabluea 被腰斩的股价说明，发展才是硬道理，SaaS 什么的，也就是炒炒概念罢了。</p>
<p>对于 SaaS 来说，提供定制化服务，实际上就是提供不同的配置方案，也就是说，一个足够灵活的系统，通过不同的配置（默认或定制），来进行统一服务。</p>
<p>最近的一个同样非常火热的概念就是云计算了，我也在连载对应的课程，可以结合来看看，从思想和工程两个不同的角度，也是很有意思的。比方说下面的几个原则：</p>
<ul>
<li>Principle 1: Integrated Ecosystem Management for Cloud</li>
<li>Principle 2: Virtualization of Cloud Infrastructure</li>
<li>Principle 3: Service-Orientation for Common Reusable Services</li>
<li>Principle 4: Extensible Provisioning and Subscrption for Cloud</li>
<li>Principle 5: Configurable Enablement for Cloud Offerings</li>
<li>Principle 6: Unified Information Representation and Exchange Framework</li>
<li>Principle 7: Cloud Quality and Governance</li>
</ul>
<p>合起来就是</p>
<p><img src="/images/14548946708473.jpg" alt=""><br>（一定要用心感受下）</p>
<h2 id="SOA_Reference_Architecture__28SOA-RA_29"><a href="#SOA_Reference_Architecture__28SOA-RA_29" class="headerlink" title="SOA Reference Architecture (SOA-RA)"></a>SOA Reference Architecture (SOA-RA)</h2><p>SOA-RA 把一个基于 SOA 的系统分隔成可重用的架构组件。下面是一个 SOA 的抽象分层</p>
<p><img src="/images/14551174098822.jpg" alt=""></p>
<p>其他的例子：</p>
<p><img src="/images/14551174702617.jpg" alt=""></p>
<p><img src="/images/14551174911905.jpg" alt=""></p>
<p><img src="/images/14551175074227.jpg" alt=""></p>
<p>一个更加清晰的描述：</p>
<p><img src="/images/14551175363986.jpg" alt=""></p>
<p>加上不同的组件之后就是</p>
<p><img src="/images/14551176317606.jpg" alt=""></p>
<p>这样分层的一个好处就是可以极大减少接口的数量，如下图所示：</p>
<p><img src="/images/14551177297106.jpg" alt=""></p>
<p>接下来我们来说说 REST 设计，举个例子，某公司部署了一个 web 服务，可以让用户：</p>
<ul>
<li>获取部件的列表</li>
<li>获取某个部件的详细信息</li>
<li>提交一个购买请求（Purchase Order, PO）</li>
</ul>
<p>那么用 REST 的方式来实现就是：</p>
<p><img src="/images/14551179020138.jpg" alt=""></p>
<p>这样的实现有什么特点呢：</p>
<ul>
<li>客户端和服务器之间是 pull-based 的交互风格，也就是客户端在需要的时候，向服务器端请求数据</li>
<li>Stateless，从客户端发出的每个请求都包含所需的所有信息，不利用任何存储在服务器端的上下文信息</li>
<li>可以通过缓存来提高网络的效率</li>
<li>统一的接口（比如 HTTP GET, POST, PUT, DELETE）</li>
<li>资源都是命名的（比如使用 URL 命名）</li>
<li>不同的资源可能相互连接，允许从一个过程跳转到另一个过程（URL 的链接跳转）</li>
</ul>
<p>综上所述，我们可以得到 REST web 服务设计的原则：</p>
<ol>
<li>找出所有需要通过服务暴露的概念实体（在上个例子中就是 part list, detailed part data 和 purchase order）</li>
<li>给每个资源创建一个 URL</li>
<li>把客户端只读的资源（使用 HTTP GET），和客户端可以修改的资源（使用 HTTP POST, PUT, DELETE）分类</li>
<li>所有通过 HTTP GET 访问的资源都不应该有副作用，不能修改。</li>
<li>在资源间增加超链接使得客户端可以在不同信息间跳转</li>
<li>逐渐显示所有的信息，不要在一个响应中展示所有信息</li>
<li>确定展示数据的 schema（如 DTD, W3C Schema, RelaxNG, Schematron），对于需要 POST 或者 PUT 的内容，也要提供响应的描述</li>
<li>用 WSDL 文档来描述如何调用这些服务</li>
</ol>
<p>整个的生命周期是</p>
<p><img src="/images/14551192696261.jpg" alt=""></p>
<p>具体每个阶段及简要介绍</p>
<ul>
<li>建模：第一阶段，利用概念建模技术，自顶向下，用基于 WSDL 的分解方法，难点在于如何让方法调用包含更多的语义信息</li>
<li>开发：包括设计、开发和测试，这一部分是通常的软件开发方法（Ration Unified Process，敏捷开发，瀑布模型），和基于 XML 的协议绑定（如 SOAP）</li>
<li>发布：如何连接</li>
<li>探索：从不同的 web 服务中找到最合适的</li>
</ul>
<h3 id="u76D1_u63A7_u548C_u7BA1_u7406"><a href="#u76D1_u63A7_u548C_u7BA1_u7406" class="headerlink" title="监控和管理"></a>监控和管理</h3><p>主要包括：</p>
<ul>
<li>性能监控：主要是保证其服务质量（Quality of Service, QoS）</li>
<li>实现 Service Level Agreement(SLA)，是一个服务提供者和服务请求者间的协议，保证提供一定质量的服务</li>
<li>异常处理</li>
<li>访问控制</li>
<li>数据和信息分析</li>
</ul>
<h3 id="u91CD_u7528"><a href="#u91CD_u7528" class="headerlink" title="重用"></a>重用</h3><p>重用可以看作是一个循序渐进，甚至有点后期的工作，一个可能的发展阶段是：</p>
<p><img src="/images/14551199022753.jpg" alt=""></p>
<p>可以看到随着业务的增长，重用的重要性才慢慢凸现出来。具体的方法有：</p>
<ul>
<li>利用面向对象思想重新设计</li>
<li>重新设计架构</li>
<li>直接推倒重来</li>
</ul>
<h2 id="u4E91_u8BA1_u7B97"><a href="#u4E91_u8BA1_u7B97" class="headerlink" title="云计算"></a>云计算</h2><p>云计算的目标是在用户间共享资源，具体的方式是通过 provisioning（针对服务提供者）和 subscription（服务消费者）。不同层级的资源共享就形成不同的云服务：</p>
<ul>
<li>Infrastructure Cloud (e.g. Storage as a service, hardware and IT infrastructure management as a service)</li>
<li>Software Cloud (e.g. SaaS focusing on middleware as a service or traditional CRM as a service)</li>
<li>Application Cloud (e.g. Application as a Service, UML modeling tools as a service, social network as a service)</li>
<li>Business Cloud (e.g. business process as a service)</li>
</ul>
<h2 id="Big_Data_as_a_Service"><a href="#Big_Data_as_a_Service" class="headerlink" title="Big Data as a Service"></a>Big Data as a Service</h2><p>大数据的应用及处理的基本流程是：</p>
<p><img src="/images/14551227915870.jpg" alt=""></p>
<ul>
<li>Discover: 主要指大数据的发现及数据清洗<ul>
<li>Data collection</li>
<li>Stakeholder communications</li>
<li>Documentation</li>
<li>Reverse engineering</li>
<li>Blind spots</li>
</ul>
</li>
<li>Evaluate: 分析和评估这些数据<ul>
<li>Diagnosis</li>
<li>maturity level</li>
<li>Adoption lifecycle view</li>
<li>Target state formulation</li>
<li>Strategization</li>
</ul>
</li>
<li>Evolve: 根据这些数据来进行只能的进化，或者说对于某一特定领域的熟悉<ul>
<li>Blueprint</li>
<li>Metrics and criteria</li>
<li>Technology option screening</li>
<li>Prioritization</li>
<li>Tradeoffs</li>
</ul>
</li>
<li>Recommend: 利用新的信息进行信息或者资源的推荐<ul>
<li>Roadmapping</li>
<li>Organization model</li>
<li>Resource and skillset</li>
<li>PMO governace</li>
<li>Action plan </li>
</ul>
</li>
</ul>
<p><img src="/images/14551236654152.jpg" alt=""></p>
<ul>
<li>Date Gateway: ActiveMQ, Apache Camel</li>
<li>Data quality, ELT: OPEN Refine, talend*</li>
<li>NoSQL Store: HBase, mongoDB</li>
<li>Analytics: HIVE, Impala</li>
<li>Reporting: pentaho, R</li>
<li>Visualization: visual.ly, Quantum4D</li>
<li>Machine Learning: WEKA, mahout</li>
<li>Cloud Hosting: Openstack, Amazon EC2</li>
<li>Monitoring Management: Ganglla, docker, hyperic</li>
</ul>
<p>Best Practice</p>
<ul>
<li>Iterative</li>
<li>Holistic</li>
<li>Pragmatic</li>
<li>Converged</li>
<li>Prescriptive</li>
<li>Incremental</li>
<li>Disciplined</li>
<li>Proactive</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一课是根据老师的课程安排添加的，之后应该会按照课本的脉络结合老师的思路来进行讲解。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="架构" scheme="http://wdxtub.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="设计" scheme="http://wdxtub.com/tags/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[软件架构与设计 第 10 课 Visualizing Software Architectures]]></title>
    <link href="http://wdxtub.com/2016/02/04/sad-10/"/>
    <id>http://wdxtub.com/2016/02/04/sad-10/</id>
    <published>2016-02-04T17:51:51.000Z</published>
    <updated>2016-02-04T16:33:25.000Z</updated>
    <content type="html"><![CDATA[<p>前面我们了解了基本的建模概念和方法，现在我们来看看如何把整个模型可视化。</p>
<a id="more"></a>
<hr>
<p>模型和可视化很容易搞混，因为它们是紧密相关的。模型是抽象的信息——一系列设计选择。可视化给这些设计选择具体的形式，我们能够来描述不同的模型。下面是一个对比：</p>
<p><img src="/images/14546024342899.jpg" alt=""></p>
<p>具体的评价标准，也其实和建模的很类似，包括：</p>
<ul>
<li>Scope &amp; Purpose</li>
<li>Basic Type</li>
<li>Depiction</li>
<li>Interaction</li>
<li>Fidelity</li>
<li>Consistency</li>
<li>Comprehensibility</li>
<li>Dynamism</li>
<li>View Coordination</li>
<li>Aesthetics</li>
<li>Extensibility</li>
</ul>
<p>具体的方式很多，例如</p>
<ul>
<li>Text Visualizations<ul>
<li>优点：提供了一种通用的描述标记，很多编辑器可以用</li>
<li>缺点：模型变大之后复杂度增加，没有办法描述图结构和复杂的交互</li>
</ul>
</li>
</ul>
<p><img src="/images/14546029716427.jpg" alt=""></p>
<ul>
<li>General Graphical Visualizations<ul>
<li>优点：可以创建好看的描述，没有信息隐藏</li>
<li>缺点：没有深层语义，难以和其他的可视化图形连接</li>
</ul>
</li>
</ul>
<p><img src="/images/14546030577559.jpg" alt=""></p>
<ul>
<li>UML Visualizations<ul>
<li>优点：许多工具可以用，类似图形化描述，但可以添加  UML 语义</li>
<li>缺点：没有一个通用的标准，难以描述什么时候开始什么时候结束，许多工具只支持标准 UML</li>
</ul>
</li>
</ul>
<p><img src="/images/14546031639442.jpg" alt=""></p>
<p>那么如何创建新的可视化描述呢，可以遵循以下几个步骤：</p>
<ol>
<li>Borrow elements from similar visualizations</li>
<li>Be consistent among visualizations</li>
<li>Give meaning to each visual aspect of elements</li>
<li>Document the meaning of visualizations</li>
<li>Balance traditional and innovative interfaces</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>前面我们了解了基本的建模概念和方法，现在我们来看看如何把整个模型可视化。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="架构" scheme="http://wdxtub.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="设计" scheme="http://wdxtub.com/tags/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[软件架构与设计 第 9 课 Introduction to Modeling]]></title>
    <link href="http://wdxtub.com/2016/02/04/sad-9/"/>
    <id>http://wdxtub.com/2016/02/04/sad-9/</id>
    <published>2016-02-04T17:51:47.000Z</published>
    <updated>2016-02-04T16:03:43.000Z</updated>
    <content type="html"><![CDATA[<p>既然建模很重要，我们这节课就来了解一下关于建模的基本知识。</p>
<a id="more"></a>
<hr>
<p>前面提到，所谓的架构，其实是一系列关于系统的原则性设计选择。所以我们可以说，一个架构模型是一个包含部分或所有设计选择的制品。架构建模的过程就是进行设计选择的具体化和文档化。如何建模和我们所采用的标记符号很有关系。</p>
<p>具体需要从不同的使用角色来进行考虑，还需要考虑的有细节的层次，描述的清晰度以及成本和收益的权衡。</p>
<h2 id="Stakeholder__u9A71_u52A8_u7684_u5EFA_u6A21"><a href="#Stakeholder__u9A71_u52A8_u7684_u5EFA_u6A21" class="headerlink" title="Stakeholder 驱动的建模"></a>Stakeholder 驱动的建模</h2><p>从 Stakeholder 的角度来说，不同的设计点有不同的重要性。但是万变不离其宗，重要的还是：组件、连接器、接口、配置以及设计原则这几个项目。对于架构风格，可能还需要考虑交互上行为上和并行性上的限制。</p>
<p>还有一个需要注意的是，区分好功能性和非功能性需求，比方说『系统打印医疗记录』是一个功能性需求，但是『系统快速和秘密打印』就不算一个功能性需求了。通常来说，我们主要注意功能性需求，但是非功能性需求也很重要，因为这可能表现了功能背后的动机。</p>
<h2 id="u6A21_u578B_u7684_u91CD_u8981_u7279_u5F81"><a href="#u6A21_u578B_u7684_u91CD_u8981_u7279_u5F81" class="headerlink" title="模型的重要特征"></a>模型的重要特征</h2><ul>
<li>Ambiguity：如果一个模型有多说解释，那么就是不清晰的</li>
<li>Accuracy &amp; Precision：这两个概念不大一样，但是常常被放在一起<ul>
<li>如果一个模型是正确的，符合事实的，那么说是 accurate</li>
<li>如果一个模型是精确界定的，那么说是 precise</li>
<li>可以参考下图来进行理解</li>
</ul>
</li>
</ul>
<p><img src="/images/14545985041272.jpg" alt=""></p>
<h2 id="u89C6_u56FE_u4E0E_u89C6_u70B9"><a href="#u89C6_u56FE_u4E0E_u89C6_u70B9" class="headerlink" title="视图与视点"></a>视图与视点</h2><p>横看成岭侧成峰，很多时候我们需要从多个角度来描述系统，才能得到一个比较准确的模型。下面是一个例子：</p>
<p><img src="/images/14545985821981.jpg" alt=""></p>
<p>常用的视角有：</p>
<ul>
<li>逻辑视角：描述系统中的逻辑实体以及它们的交互</li>
<li>物理视角：描述系统中的物理实体以及它们的交互</li>
<li>部署视角：描述系统中的逻辑实体如何映射到对应的物理实体上</li>
<li>并行视角：描述系统如何处理并行</li>
<li>行为视角：描述系统的预期表现</li>
</ul>
<p>因为有这么多视角，所以需要保证不同视角描述的东西是一致的，不能说一个视角中的逻辑是 A 到 B，在另一个视角中就成为 B 到 A 了（因为不同视角肯定有重合的地方，所以需要保证一致性）</p>
<p><img src="/images/14545988003911.jpg" alt=""></p>
<p>常见的不一致有：</p>
<ul>
<li>方向不一致</li>
<li>精细化不一致：高层的描述和底层的描述冲突</li>
<li>静态动态不一致</li>
<li>动态与动态不一致</li>
<li>功能性与非功能行需求不一致</li>
</ul>
<h2 id="u8BC4_u4F30_u5EFA_u6A21_u65B9_u6CD5"><a href="#u8BC4_u4F30_u5EFA_u6A21_u65B9_u6CD5" class="headerlink" title="评估建模方法"></a>评估建模方法</h2><p>我们可以从下面几个角度来评估一个建模方法是否合适：</p>
<ul>
<li>范围和目的</li>
<li>基础元素</li>
<li>风格</li>
<li>静态和动态方面</li>
<li>动态建模</li>
<li>非功能方面</li>
<li>Ambiguity</li>
<li>Accuracy</li>
<li>Precision</li>
<li>视角</li>
<li>视角一致性</li>
</ul>
<p>一些常见的建模方法有</p>
<h3 id="u901A_u7528_u65B9_u6CD5"><a href="#u901A_u7528_u65B9_u6CD5" class="headerlink" title="通用方法"></a>通用方法</h3><ul>
<li>自然语言<ul>
<li>优点：描述性高，所有 stakeholder 都可以查看，擅长捕捉非严格和非正式的架构元素，许多可用的工具</li>
<li>缺点：模糊，宽松，不正式，通常比较冗长，没有办法用软件进行处理分析</li>
</ul>
</li>
</ul>
<p><img src="/images/14546006145499.jpg" alt=""></p>
<ul>
<li>PPT 建模<ul>
<li>优点：看起来漂亮，大小有限制，非常灵活</li>
<li>缺点：模糊，宽松，不正式，没有办法用软件进行处理分析</li>
</ul>
</li>
</ul>
<p><img src="/images/14546006273259.jpg" alt=""></p>
<ul>
<li>UML<ul>
<li>优点：支持不同视角，易理解，许多工具</li>
<li>缺点：需要确定 profile 来降低模糊性，难以保证一致性，难以描述外来概念或视图</li>
</ul>
</li>
</ul>
<p><img src="/images/14546006393742.jpg" alt=""></p>
<h3 id="u65E9_u671F_u67B6_u6784_u63CF_u8FF0_u8BED_u8A00"><a href="#u65E9_u671F_u67B6_u6784_u63CF_u8FF0_u8BED_u8A00" class="headerlink" title="早期架构描述语言"></a>早期架构描述语言</h3><ul>
<li>Darwin<ul>
<li>优点：简单直接描述结构依赖，可以进行正规分析，支持层级结构</li>
<li>缺点：仅在简单的架构模型中比较有用，没有办法表达显式连接器</li>
</ul>
</li>
</ul>
<p><img src="/images/14546008499085.jpg" alt=""></p>
<p><img src="/images/14546008685270.jpg" alt=""></p>
<ul>
<li>Rapide<ul>
<li>优点：可以描述异步沟通组件，支持模型模拟和事件的可视化追踪</li>
<li>缺点：无法自然映射到已开发的系统，学习曲线陡峭，在现代计算机上难以运行</li>
</ul>
</li>
</ul>
<p><img src="/images/14546010836111.jpg" alt=""></p>
<p><img src="/images/14546010964130.jpg" alt=""></p>
<ul>
<li>Wright<ul>
<li>优点：类似 Darwin 和 Rapide 的结构描述语言，可以用工具来分析（可以检测死锁）</li>
<li>缺点：学习曲线陡峭，无法自然映射到已开发的系统</li>
</ul>
</li>
</ul>
<p><img src="/images/14546011979672.jpg" alt=""></p>
<p><img src="/images/14546012076721.jpg" alt=""></p>
<h3 id="u9886_u57DF_u7279_u5B9A/_u98CE_u683C_u7279_u5B9A_u8BED_u8A00"><a href="#u9886_u57DF_u7279_u5B9A/_u98CE_u683C_u7279_u5B9A_u8BED_u8A00" class="headerlink" title="领域特定/风格特定语言"></a>领域特定/风格特定语言</h3><ul>
<li>Koala<ul>
<li>优点：可以在一个模型中描述许多系统，可以直接映射到已开发的系统并进行代码重用</li>
<li>缺点：需要特定设计的接口才能应用</li>
</ul>
</li>
</ul>
<p><img src="/images/14546013363062.jpg" alt=""></p>
<p><img src="/images/14546013486686.jpg" alt=""></p>
<ul>
<li>Weaves<ul>
<li>优点：语法很简单，可以几乎映射到已开发的系统</li>
<li>缺点：只能描述结构和数据流</li>
</ul>
</li>
</ul>
<p><img src="/images/14546013962768.jpg" alt=""></p>
<p><img src="/images/14546014089340.jpg" alt=""></p>
<ul>
<li>AADL  <ul>
<li>优点：可以详细规定软件硬件，有自动分析工具</li>
<li>缺点：冗长，即使是简单的系统也需要大量描述，需要工具支持以及 UML profile 辅助描述</li>
</ul>
</li>
</ul>
<p><img src="/images/14546014835760.jpg" alt=""></p>
<p><img src="/images/14546014920803.jpg" alt=""></p>
<h3 id="u62D3_u5C55_u67B6_u6784_u63CF_u8FF0_u8BED_u8A00"><a href="#u62D3_u5C55_u67B6_u6784_u63CF_u8FF0_u8BED_u8A00" class="headerlink" title="拓展架构描述语言"></a>拓展架构描述语言</h3><ul>
<li>Acme<ul>
<li>优点：结构化描述，可以描述现存元素，工具支持（AcmeStudio）</li>
<li>缺点：无法添加新的视图，属性规范可能非常复杂且有另外的语法</li>
</ul>
</li>
</ul>
<p><img src="/images/14546015630249.jpg" alt=""></p>
<p><img src="/images/14546015726906.jpg" alt=""></p>
<ul>
<li>ADML<ul>
<li>优点：可以使用 XML 解析器，通过元描述增加表达能力</li>
<li>缺点：属性仍然是键值对，没有利用 XML 扩展机制</li>
</ul>
</li>
</ul>
<p><img src="/images/14546016742192.jpg" alt=""></p>
<ul>
<li>xADL <ul>
<li>优点：内置一些常用模块，工具支持（ArchStudio），用户可以添加模块</li>
<li>缺点：添加模块机制复杂，学习曲线陡峭，过于依赖工具</li>
</ul>
</li>
</ul>
<p><img src="/images/14546017950085.jpg" alt=""></p>
<p><img src="/images/14546018068416.jpg" alt=""></p>
<p><img src="/images/14546018228100.jpg" alt=""></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>既然建模很重要，我们这节课就来了解一下关于建模的基本知识。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="架构" scheme="http://wdxtub.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="设计" scheme="http://wdxtub.com/tags/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[小方]]></title>
    <link href="http://wdxtub.com/2016/02/03/xiao-fang/"/>
    <id>http://wdxtub.com/2016/02/03/xiao-fang/</id>
    <published>2016-02-04T07:44:12.000Z</published>
    <updated>2016-02-04T05:24:49.000Z</updated>
    <content type="html"><![CDATA[<p>要知道，一枚连续二十次都抛出反面的硬币，也有它的正面。</p>
<a id="more"></a>
<hr>
<p>奇怪的是，他既没有太多棱角，也没有太多慌张，大家却都叫他小方。每当被问起名字的来由，小方总是笑着说：『之所以方，是因为少了点缘』。但是坊间的传闻可不是这样，每个人都不知道从哪里听说过，小方是因为有反骨，所以才叫小方的。</p>
<p>这个世界的可怕之处在于，哪怕谁也不知道反骨是什么，又长在哪里，只要大家都这么认为，那你就只能长着反骨，或者稍微好一点，能给自己起个名字，叫小方。</p>
<p>既然反骨是什么说不清楚，那么一百个人心中，就有一百种反骨。丢了东西，坏了器具，总可以怪罪到小方头上。偶尔也有人好奇，为什么小方从来不去解释和证明自己。小方只是笑笑，因为他们没有意识到，再多的解释和证明，恐怕都无法撼动盘根错节的猜忌和怀疑。</p>
<p>但是小方也有朋友，可是朋友并不多，甚至一年也见不了几次面，也许只有提到小方时他们明亮的神情，会显露出一丝蛛丝马迹。</p>
<p>不知道某一年的某一天，小方决定离开，离开这个被『反骨』诅咒的地方。走之前，他抓了一大把硬币，哗啦哗啦甩了一地，人们惊异地发现，这些硬币，竟然都是反面。</p>
<p>小方离开之后，日子一如既往，该不见的东西还是会不见，该倒霉的人还是会倒霉，只是现在大家再也没有借口去怪罪了。</p>
<p>一个人踏上旅途的小方，有时候还会拿出一枚硬币，一次次抛着，他总是相信，一枚连续二十次都抛出反面的硬币，也有它的正面。或者说，若无正面，何来反面呢？</p>
<p>如果你不知道自己讨厌什么，很可能也不太清楚自己喜欢什么。若一时找不到喜欢的方向，那至少可以弄清楚自己讨厌什么，然后尽可能离它们远一些。</p>
<p>毕竟很多时候我们要的是一个绝对值，如果正向太陡，那么反着走，也能达到一样的效果。或者说，有多大的绝望，才有多大的希望。</p>
<p>小方就是这样走过来的，正因为体验了残忍，才更珍惜温柔。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>要知道，一枚连续二十次都抛出反面的硬币，也有它的正面。</p>]]>
    
    </summary>
    
      <category term="反骨" scheme="http://wdxtub.com/tags/%E5%8F%8D%E9%AA%A8/"/>
    
      <category term="硬币" scheme="http://wdxtub.com/tags/%E7%A1%AC%E5%B8%81/"/>
    
      <category term="英雄" scheme="http://wdxtub.com/tags/%E8%8B%B1%E9%9B%84/"/>
    
      <category term="Story" scheme="http://wdxtub.com/categories/Story/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[深入理解计算机系统 习题课 2 Bomblab]]></title>
    <link href="http://wdxtub.com/2016/02/02/csapp-lab2/"/>
    <id>http://wdxtub.com/2016/02/02/csapp-lab2/</id>
    <published>2016-02-03T02:32:36.000Z</published>
    <updated>2016-02-03T18:31:33.000Z</updated>
    <content type="html"><![CDATA[<p>这一讲主要是介绍第二次作业 Bomblab 的相关内容以及解法。</p>
<a id="more"></a>
<hr>
<h2 id="u603B_u4F53_u4ECB_u7ECD"><a href="#u603B_u4F53_u4ECB_u7ECD" class="headerlink" title="总体介绍"></a>总体介绍</h2><p>一定要仔细阅读给出的文档，虽然很重要但是我就不打算说三次了。每个人的炸弹都是不一样的，完整的拆弹包括 6 个阶段。这些炸弹只能在 shark 机器上运行，在本地运行会炸。</p>
<p>炸弹每次爆炸都会通知 Autolab，也就是说自动帮你扣掉 0.5 分，只有解开当前阶段才能进入下一阶段。每个炸弹包含三个部分：</p>
<ul>
<li>一个可执行文件</li>
<li>一个说明文档</li>
<li>一个源文件</li>
</ul>
<p>源文件就是来搞笑的，要从可执行文件入手。可以用 <code>./bomb psol.txt</code> 这样来输入已经拆弹成功的部分，省得每次重复输入了。</p>
<h2 id="u6C47_u7F16_u5668_u590D_u4E60"><a href="#u6C47_u7F16_u5668_u590D_u4E60" class="headerlink" title="汇编器复习"></a>汇编器复习</h2><p>我们来复习下寄存器的布局，不同寄存器存什么值可能就是拆弹的关键！</p>
<p><img src="/images/14544624274905.jpg" alt=""></p>
<p>操作符同样很重要，这样我们才能明白反汇编出来的程序到底在做什么：</p>
<table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">语法</th>
<th style="text-align:center">例子</th>
<th style="text-align:center">备注</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">常量</td>
<td style="text-align:center">符号<code>$</code> 开头</td>
<td style="text-align:center"><code>$-42</code>, <code>$0x15213</code></td>
<td style="text-align:center">一定要注意十进制还是十六进制</td>
</tr>
<tr>
<td style="text-align:center">寄存器</td>
<td style="text-align:center">符号 <code>%</code> 开头</td>
<td style="text-align:center"><code>%esi</code>, <code>%rax</code></td>
<td style="text-align:center">可能存的是值或者地址</td>
</tr>
<tr>
<td style="text-align:center">内存地址</td>
<td style="text-align:center">括号括起来</td>
<td style="text-align:center"><code>(%rbx)</code>, <code>0x1c(%rax)</code>, <code>0x4(%rcx, %rdi, 0x1)</code></td>
<td style="text-align:center">括号实际上是去寻址的意思</td>
</tr>
</tbody>
</table>
<p>一些汇编语句与实际命令的转换：</p>
<p><img src="/images/14544632845984.jpg" alt=""></p>
<p>比较与跳转是拆弹的关键，基本所有的字符判断就是通过比较来实现的，比方说 <code>cmp b,a</code> 会计算 <code>a-b</code> 的值，<code>test b, a</code> 会计算 <code>a&amp;b</code>，注意运算符的顺序</p>
<p><img src="/images/14544635389728.jpg" alt=""></p>
<p>各种不同的跳转：</p>
<p><img src="/images/14544636231513.jpg" alt=""></p>
<p>举几个例子</p>
<figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmp <span class="variable">$0x15213</span>, <span class="decorator">%r12</span></span><br><span class="line">jge deadbeef</span><br></pre></td></tr></table></figure>
<p>若 <code>%r12 &gt;= 0x15213</code>，则跳转到 <code>0xdeadeef</code></p>
<figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmp</span> %<span class="literal">rax</span>, %<span class="literal">rdi</span></span><br><span class="line"><span class="keyword">jae</span> 15213b</span><br></pre></td></tr></table></figure>
<p>如果 <code>%rdi</code> 的无符号值大于等于 <code>%rax</code>，则跳转到 <code>0x15213b</code></p>
<figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">test</span> %<span class="literal">r8</span>, %<span class="literal">r8</span></span><br><span class="line"><span class="keyword">jnz</span> (%<span class="literal">rsi</span>)</span><br></pre></td></tr></table></figure>
<p>如果 <code>%r8 &amp; %r8</code> 不为零，那么跳转到 <code>%rsi</code> 存着的地址中。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查符号表</span></span><br><span class="line"><span class="comment"># 然后可以寻找跟 bomb 有关的内容</span></span><br><span class="line">objdump -t bomb | less </span><br><span class="line"></span><br><span class="line"><span class="comment"># 反编译</span></span><br><span class="line"><span class="comment"># 搜索 explode_bomb</span></span><br><span class="line">objdump <span class="operator">-d</span> bomb &gt; bomb.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示所有字符</span></span><br><span class="line">strings bomb | less</span><br></pre></td></tr></table></figure>
<h2 id="GDB__u4ECB_u7ECD"><a href="#GDB__u4ECB_u7ECD" class="headerlink" title="GDB 介绍"></a>GDB 介绍</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">gdb bomb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取帮助</span></span><br><span class="line"><span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置断点</span></span><br><span class="line"><span class="built_in">break</span> explode_bomb</span><br><span class="line"><span class="built_in">break</span> phase_1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始运行</span></span><br><span class="line">run</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查汇编 会给出对应的代码的汇编</span></span><br><span class="line">disas </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看寄存器内容</span></span><br><span class="line">info registers</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印指定寄存器</span></span><br><span class="line"><span class="built_in">print</span> <span class="variable">$rsp</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每步执行</span></span><br><span class="line">stepi</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查寄存器或某个地址</span></span><br><span class="line">x/<span class="number">4</span>wd <span class="variable">$rsp</span></span><br></pre></td></tr></table></figure>
<p>用 ctl+c 可以退出，每次进入都要设置断点（保险起见），炸弹会用 <code>sscanf</code> 来读取字符串，了解清除到底需要输入什么</p>
<h2 id="u62C6_u5F39_u51C6_u5907"><a href="#u62C6_u5F39_u51C6_u5907" class="headerlink" title="拆弹准备"></a>拆弹准备</h2><p>老规矩，先登录 <code>ssh -X dawang@shark.ics.cs.cmu.edu</code>，然后在 513 文件夹中，把我的炸弹上传上去，命令是 <code>scp bomb_mine.tar dawang@shark.ics.cs.cmu.edu:~/513</code>。传上去之后，解压 <code>tar xvf bomb_mine.tar</code>，就可以看到我的炸弹了</p>
<p><img src="/images/14544647437846.jpg" alt=""></p>
<p>哇，居然还有源文件，我们来看看（虽然知道肯定并没有什么用）</p>
<p><img src="/images/14544648434106.jpg" alt=""></p>
<p>唯一能够知道的事情，就是一共有 6 个阶段了。</p>
<h2 id="u7B2C_u4E00_u5173"><a href="#u7B2C_u4E00_u5173" class="headerlink" title="第一关"></a>第一关</h2><p>我们先来看看符号表 <code>objdump -t bomb | less</code> </p>
<p><img src="/images/14544652386936.jpg" alt=""></p>
<p>就会发现这是天书，什么鬼！不过既然我们是要拆炸弹，不如就搜索一下 <code>bomb</code>，看看有没有什么线索。在 less 下输入 <code>/bomb</code> 然后不断回车，看到以下这些关键字：</p>
<ul>
<li><code>bomb.c</code></li>
<li><code>initialize_bomb_solve</code></li>
<li><code>explode_bomb</code></li>
<li><code>bomb_id</code></li>
<li><code>initialize_bomb</code></li>
</ul>
<p>看来这里唯一有用的就是这个 <code>explode_bomb</code>，顾名思义，估计是在拆弹失败的时候用来爆炸的，所以我们可以直接设个断点，暂停运行，不让它爆炸。</p>
<p>然后我们就可以反编译一下炸弹看看到底里面是怎么回事了：<code>objdump -d bomb &gt; bomb.txt</code>，然后我们把这个炸弹的汇编代码搞到本地方便查看：<code>scp dawang@shark.ics.cs.cmu.edu:~/513/bomb114/bomb.txt ./</code></p>
<p><img src="/images/14544657722862.jpg" alt=""></p>
<p>比方说我们大概可以看出来，这里就是 main 函数执行的地方了。往下找找就可以看到第一阶段的代码了，如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0000000000400f</span>b0 &lt;phase_1&gt;:</span><br><span class="line">  <span class="number">400f</span>b0:	<span class="number">48</span> <span class="number">83</span> ec <span class="number">08</span>          sub    $<span class="number">0x8</span>,%rsp</span><br><span class="line">  <span class="number">400f</span>b4:	be f0 <span class="number">27</span> <span class="number">40</span> <span class="number">00</span>       mov    $<span class="number">0x4027f0</span>,%esi</span><br><span class="line">  <span class="number">400f</span>b9:	e8 <span class="number">72</span> <span class="number">04</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401430</span> &lt;strings_not_equal&gt;</span><br><span class="line">  <span class="number">400f</span>be:	<span class="number">85</span> c0                test   %eax,%eax</span><br><span class="line">  <span class="number">400f</span>c0:	<span class="number">74</span> <span class="number">05</span>                je     <span class="number">400f</span>c7 &lt;phase_1+<span class="number">0x17</span>&gt;</span><br><span class="line">  <span class="number">400f</span>c2:	e8 <span class="number">3</span>d <span class="number">07</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">400f</span>c7:	<span class="number">48</span> <span class="number">83</span> c4 <span class="number">08</span>          add    $<span class="number">0x8</span>,%rsp</span><br><span class="line">  <span class="number">400f</span>cb:	c3                   retq</span><br></pre></td></tr></table></figure>
<p>先来简单观察下这段程序在做什么，<code>callq</code> 的两行就是调用 <code>strings_not_equal</code> 和 <code>explode_bomb</code> 这两个函数的，而这里 <code>%esi</code> 对应的是第二个参数，第一个参数呢？当然就是我们拆弹时需要输入的字符串了。之后的 <code>test</code> 是用来判断函数的返回值 <code>%eax</code> 是否为 0， 如果为 0 则进行跳转，否则炸弹爆炸，所以我们实际上要做的，就是看看 <code>$0x4027f0</code> 这个地址里对应存放的是什么字符串，也就是拆炸弹的关键了。</p>
<p>先 <code>gdb bomb</code>，然后设置断点 <code>break explode_bomb</code> 和 <code>break phase_1</code></p>
<p><img src="/images/14544673817513.jpg" alt=""></p>
<p>接着运行 <code>run</code>，就会在断点处停下，这里会先让我们输入第一关的密码，随便输入一个抵达断点再说。</p>
<p><img src="/images/14544675211698.jpg" alt=""></p>
<p>我们现在到断点了，可以利用 <code>disas</code> 来看看对应的汇编代码，其实就和我们之前反汇编出来的一致：</p>
<p><img src="/images/14544676048852.jpg" alt=""></p>
<p>然后我们看看寄存器里的内容 <code>info registers</code>:</p>
<p><img src="/images/14544677052252.jpg" alt=""></p>
<p>诶，不是说我们输入的字符串（也就是 abc）会存放在 <code>eax</code> 里面吗？怎么列表里没有？其实 <code>eax</code> 是 <code>rax</code> 的低位，我们可以直接利用 <code>print $eax</code> 把它打印出来，就会发现，是一个地址，我们再用 <code>x/s $eax</code> 就可以看到我们刚才输入的字符串了。</p>
<p><img src="/images/14544680308984.jpg" alt=""></p>
<p>然后我们继续回到汇编语句，用 <code>stepi</code> 来逐步执行，就可以看到箭头的变化：</p>
<p><img src="/images/14544681259153.jpg" alt=""></p>
<p>这里我们看到 <code>mov</code> 语句已经执行完成了，那么好，可以直接用 <code>x $esi</code> 来看看传进去的到底是什么内容了：</p>
<p><img src="/images/14544682048627.jpg" alt=""></p>
<p>Bingo！这就是第一关的答案了，赶紧记下来吧！（注意每个人的都是不同的）</p>
<p><code>Why make trillions when we could make... billions?</code></p>
<p>然后输入 <code>quit</code> 退出 gdb，新建一个文本文件 <code>touch sol.txt</code>，方便以后输入答案。</p>
<h2 id="u7B2C_u4E8C_u5173"><a href="#u7B2C_u4E8C_u5173" class="headerlink" title="第二关"></a>第二关</h2><p>这次因为我们有了输入，所以需要在进入 gdb，设置好断点后，设置命令参数</p>
<p><img src="/images/14544708331343.jpg" alt=""></p>
<p>然后试着运行一下，在 <code>phase_1</code> 停住了，然后我们输入 <code>continue</code>，来看看答案到底对不对，如果正确，应该会在 <code>phase_2</code> 停住，如果错误，则会在 <code>explode_bomb</code> 停住。</p>
<p><img src="/images/14544713961334.jpg" alt=""></p>
<p>然后就发现，第一关已经顺利完成了，然后挑战第二关。我们再随便输入一些内容，触发 <code>phase_2</code> 的断点。（这次输入 abcd，结果如下）</p>
<p><img src="/images/14544714769384.jpg" alt=""></p>
<p>这一段代码比较长，我们还是来看看到底在做什么。从函数名可以得知，这一次要读入六个数字 <code>read_six_numbers</code>。</p>
<p>从 <code>compl $0x1, (%rsp)</code> 看出第一个数字一定是 1，然后跳转到 +24 的位置，然后把 1 移动到 <code>%ebx</code> 中，跳转到 +57 的位置，然后和 5 进行比较，因为 1 比 5 小，所以会跳转到 +31 的位置。</p>
<p>接着是 <code>movslq</code> 语句，这个语句是带符号地把第一个寄存器扩展并复制到第二个寄存器中，所以现在 <code>%rdx</code> 的值也是 1。<code>lea</code> 之后 <code>%eax</code> 等于 0，然后用 <code>cltq</code> 扩展到 64 位（也就是 <code>%rax</code> 等于 0），接着的语句相当于是 <code>%eax = (%rsp) + 4 * %rax</code> 即 <code>%eax</code>  等于 1。然后与自己相加等于乘以 2，现在 <code>%eax</code> 等于 2，然后等于是判断第二个参数(<code>(%rsp, %rdx, 4)</code>)和 2 是否相等，所以第二个数字是 2。</p>
<p>然后进行循环的累加并返回到 +31 的位置，继续循环。接着就是类似的操作了，最后分析可以得到每次增大一倍，答案就是 1 2 4 8 16 32。</p>
<h2 id="u7B2C_u4E09_u5173"><a href="#u7B2C_u4E09_u5173" class="headerlink" title="第三关"></a>第三关</h2><p>第三关的代码很长，而且猛看上去，到处都可能触发炸弹。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0000000000401010</span> &lt;phase_3&gt;:</span><br><span class="line">  <span class="number">401010</span>:	<span class="number">48</span> <span class="number">83</span> ec <span class="number">18</span>          sub    $<span class="number">0x18</span>,%rsp</span><br><span class="line">  <span class="number">401014</span>:	<span class="number">4</span>c <span class="number">8</span>d <span class="number">44</span> <span class="number">24</span> <span class="number">0</span>c       lea    <span class="number">0xc</span>(%rsp),%r8</span><br><span class="line">  <span class="number">401019</span>:	<span class="number">48</span> <span class="number">8</span>d <span class="number">4</span>c <span class="number">24</span> <span class="number">07</span>       lea    <span class="number">0x7</span>(%rsp),%rcx</span><br><span class="line">  <span class="number">40101</span>e:	<span class="number">48</span> <span class="number">8</span>d <span class="number">54</span> <span class="number">24</span> <span class="number">08</span>       lea    <span class="number">0x8</span>(%rsp),%rdx</span><br><span class="line">  <span class="number">401023</span>:	be <span class="number">4</span>e <span class="number">28</span> <span class="number">40</span> <span class="number">00</span>       mov    $<span class="number">0x40284e</span>,%esi</span><br><span class="line">  <span class="number">401028</span>:	b8 <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x0</span>,%eax</span><br><span class="line">  <span class="number">40102</span>d:	e8 <span class="number">7</span>e fc ff ff       callq  <span class="number">400</span>cb0 &lt;__isoc99_sscanf@plt&gt;</span><br><span class="line">  <span class="comment">// %eax为sscanf的返回值，正确值为3</span></span><br><span class="line">  <span class="number">401032</span>:	<span class="number">83</span> f8 <span class="number">02</span>             cmp    $<span class="number">0x2</span>,%eax</span><br><span class="line">  <span class="number">401035</span>:	<span class="number">7f</span> <span class="number">05</span>                jg     <span class="number">40103</span>c &lt;phase_3+<span class="number">0x2c</span>&gt;</span><br><span class="line">  <span class="number">401037</span>:	e8 c8 <span class="number">06</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="comment">// 说明第一个数小于等于7</span></span><br><span class="line">  <span class="number">40103</span>c:	<span class="number">83</span> <span class="number">7</span>c <span class="number">24</span> <span class="number">08</span> <span class="number">07</span>       cmpl   $<span class="number">0x7</span>,<span class="number">0x8</span>(%rsp)</span><br><span class="line">  <span class="number">401041</span>:	<span class="number">0f</span> <span class="number">87</span> fc <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>    ja     <span class="number">401143</span> &lt;phase_3+<span class="number">0x133</span>&gt;</span><br><span class="line">  <span class="number">401047</span>:	<span class="number">8</span>b <span class="number">44</span> <span class="number">24</span> <span class="number">08</span>          mov    <span class="number">0x8</span>(%rsp),%eax</span><br><span class="line">  <span class="comment">// 跳转，0x402860为起始地址，%rax为偏移</span></span><br><span class="line">  <span class="number">40104</span>b:	ff <span class="number">24</span> c5 <span class="number">60</span> <span class="number">28</span> <span class="number">40</span> <span class="number">00</span> jmpq   *<span class="number">0x402860</span>(,%rax,<span class="number">8</span>)</span><br><span class="line">  <span class="number">401052</span>:	b8 <span class="number">6</span>e <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x6e</span>,%eax</span><br><span class="line">  <span class="number">401057</span>:	<span class="number">81</span> <span class="number">7</span>c <span class="number">24</span> <span class="number">0</span>c df <span class="number">00</span> <span class="number">00</span> cmpl   $<span class="number">0xdf</span>,<span class="number">0xc</span>(%rsp)</span><br><span class="line">  <span class="number">40105</span>e:	<span class="number">00</span> </span><br><span class="line">  <span class="number">40105f</span>:	<span class="number">0f</span> <span class="number">84</span> e8 <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>    je     <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">401065</span>:	e8 <span class="number">9</span>a <span class="number">06</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">40106</span>a:	b8 <span class="number">6</span>e <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x6e</span>,%eax</span><br><span class="line">  <span class="number">40106f</span>:	e9 d9 <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       jmpq   <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">401074</span>:	b8 <span class="number">6</span>a <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x6a</span>,%eax</span><br><span class="line">  <span class="number">401079</span>:	<span class="number">81</span> <span class="number">7</span>c <span class="number">24</span> <span class="number">0</span>c <span class="number">01</span> <span class="number">03</span> <span class="number">00</span> cmpl   $<span class="number">0x301</span>,<span class="number">0xc</span>(%rsp)</span><br><span class="line">  <span class="number">401080</span>:	<span class="number">00</span> </span><br><span class="line">  <span class="number">401081</span>:	<span class="number">0f</span> <span class="number">84</span> c6 <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>    je     <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">401087</span>:	e8 <span class="number">78</span> <span class="number">06</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">40108</span>c:	b8 <span class="number">6</span>a <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x6a</span>,%eax</span><br><span class="line">  <span class="number">401091</span>:	e9 b7 <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       jmpq   <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">401096</span>:	b8 <span class="number">63</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x63</span>,%eax</span><br><span class="line">  <span class="number">40109</span>b:	<span class="number">81</span> <span class="number">7</span>c <span class="number">24</span> <span class="number">0</span>c <span class="number">1</span>d <span class="number">01</span> <span class="number">00</span> cmpl   $<span class="number">0x11d</span>,<span class="number">0xc</span>(%rsp)</span><br><span class="line">  <span class="number">4010</span>a2:	<span class="number">00</span> </span><br><span class="line">  <span class="number">4010</span>a3:	<span class="number">0f</span> <span class="number">84</span> a4 <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>    je     <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">4010</span>a9:	e8 <span class="number">56</span> <span class="number">06</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">4010</span>ae:	b8 <span class="number">63</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x63</span>,%eax</span><br><span class="line">  <span class="number">4010</span>b3:	e9 <span class="number">95</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       jmpq   <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">4010</span>b8:	b8 <span class="number">70</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x70</span>,%eax</span><br><span class="line">  <span class="number">4010</span>bd:	<span class="number">81</span> <span class="number">7</span>c <span class="number">24</span> <span class="number">0</span>c <span class="number">16</span> <span class="number">02</span> <span class="number">00</span> cmpl   $<span class="number">0x216</span>,<span class="number">0xc</span>(%rsp)</span><br><span class="line">  <span class="number">4010</span>c4:	<span class="number">00</span> </span><br><span class="line">  <span class="number">4010</span>c5:	<span class="number">0f</span> <span class="number">84</span> <span class="number">82</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>    je     <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">4010</span>cb:	e8 <span class="number">34</span> <span class="number">06</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">4010</span>d0:	b8 <span class="number">70</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x70</span>,%eax</span><br><span class="line">  <span class="number">4010</span>d5:	eb <span class="number">76</span>                jmp    <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">4010</span>d7:	b8 <span class="number">77</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x77</span>,%eax</span><br><span class="line">  <span class="number">4010</span>dc:	<span class="number">81</span> <span class="number">7</span>c <span class="number">24</span> <span class="number">0</span>c cd <span class="number">00</span> <span class="number">00</span> cmpl   $<span class="number">0xcd</span>,<span class="number">0xc</span>(%rsp)</span><br><span class="line">  <span class="number">4010e3</span>:	<span class="number">00</span> </span><br><span class="line">  <span class="number">4010e4</span>:	<span class="number">74</span> <span class="number">67</span>                je     <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">4010e6</span>:	e8 <span class="number">19</span> <span class="number">06</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">4010</span>eb:	b8 <span class="number">77</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x77</span>,%eax</span><br><span class="line">  <span class="number">4010f</span>0:	eb <span class="number">5</span>b                jmp    <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">4010f</span>2:	b8 <span class="number">70</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x70</span>,%eax</span><br><span class="line">  <span class="number">4010f</span>7:	<span class="number">81</span> <span class="number">7</span>c <span class="number">24</span> <span class="number">0</span>c <span class="number">9</span>a <span class="number">00</span> <span class="number">00</span> cmpl   $<span class="number">0x9a</span>,<span class="number">0xc</span>(%rsp)</span><br><span class="line">  <span class="number">4010f</span>e:	<span class="number">00</span> </span><br><span class="line">  <span class="number">4010f</span>f:	<span class="number">74</span> <span class="number">4</span>c                je     <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">401101</span>:	e8 fe <span class="number">05</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">401106</span>:	b8 <span class="number">70</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x70</span>,%eax</span><br><span class="line">  <span class="number">40110</span>b:	eb <span class="number">40</span>                jmp    <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">40110</span>d:	b8 <span class="number">74</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x74</span>,%eax</span><br><span class="line">  <span class="number">401112</span>:	<span class="number">81</span> <span class="number">7</span>c <span class="number">24</span> <span class="number">0</span>c <span class="number">13</span> <span class="number">01</span> <span class="number">00</span> cmpl   $<span class="number">0x113</span>,<span class="number">0xc</span>(%rsp)</span><br><span class="line">  <span class="number">401119</span>:	<span class="number">00</span> </span><br><span class="line">  <span class="number">40111</span>a:	<span class="number">74</span> <span class="number">31</span>                je     <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">40111</span>c:	e8 e3 <span class="number">05</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">401121</span>:	b8 <span class="number">74</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x74</span>,%eax</span><br><span class="line">  <span class="number">401126</span>:	eb <span class="number">25</span>                jmp    <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">401128</span>:	b8 <span class="number">79</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x79</span>,%eax</span><br><span class="line">  <span class="number">40112</span>d:	<span class="number">81</span> <span class="number">7</span>c <span class="number">24</span> <span class="number">0</span>c <span class="number">3</span>b <span class="number">01</span> <span class="number">00</span> cmpl   $<span class="number">0x13b</span>,<span class="number">0xc</span>(%rsp)</span><br><span class="line">  <span class="number">401134</span>:	<span class="number">00</span> </span><br><span class="line">  <span class="number">401135</span>:	<span class="number">74</span> <span class="number">16</span>                je     <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">401137</span>:	e8 c8 <span class="number">05</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">40113</span>c:	b8 <span class="number">79</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x79</span>,%eax</span><br><span class="line">  <span class="number">401141</span>:	eb <span class="number">0</span>a                jmp    <span class="number">40114</span>d &lt;phase_3+<span class="number">0x13d</span>&gt;</span><br><span class="line">  <span class="number">401143</span>:	e8 bc <span class="number">05</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">401148</span>:	b8 <span class="number">63</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x63</span>,%eax</span><br><span class="line">  <span class="number">40114</span>d:	<span class="number">3</span>a <span class="number">44</span> <span class="number">24</span> <span class="number">07</span>          cmp    <span class="number">0x7</span>(%rsp),%al</span><br><span class="line">  <span class="number">401151</span>:	<span class="number">74</span> <span class="number">05</span>                je     <span class="number">401158</span> &lt;phase_3+<span class="number">0x148</span>&gt;</span><br><span class="line">  <span class="number">401153</span>:	e8 ac <span class="number">05</span> <span class="number">00</span> <span class="number">00</span>       callq  <span class="number">401704</span> &lt;explode_bomb&gt;</span><br><span class="line">  <span class="number">401158</span>:	<span class="number">48</span> <span class="number">83</span> c4 <span class="number">18</span>          add    $<span class="number">0x18</span>,%rsp</span><br><span class="line">  <span class="number">40115</span>c:	c3                   retq</span><br></pre></td></tr></table></figure>
<p>可以看到一开始的 <code>0x40284e</code> 非常突兀，我们可以打印它的值：</p>
<p><img src="/images/14544764186906.jpg" alt=""></p>
<p>就可以发现本题要输入的格式了，接着看到这么多分片的语句，非常类似于我们的 switch 语句。所以第一个数字是用来进行跳转的，如下图所示</p>
<p><img src="/images/14544776193511.jpg" alt=""></p>
<p>比方说如果输入 0，那么就直接执行下一条 mov 语句，然后是比较第三个参数是否和 0xdf 相等，所以我们知道第三个参数是 223（如果第一个参数是 0）的话。如果一切正常，那么就会跳转到 +317 的位置，也就是：</p>
<p><img src="/images/14544777298994.jpg" alt=""></p>
<p>我们只要搞清楚 <code>%al</code> 里面的值是什么就好（会和第二个参数进行比较），具体的值，其实就是前面 mov 语句读入的 0x6e（110），对应的字符是 n。</p>
<p>所以答案是 0 n 223，当然选择不同的分支就有不同的答案，其他分支的分析也都是类似的。运行一下，就可以发现这一关又过了</p>
<p><img src="/images/14544780985022.jpg" alt=""></p>
<h2 id="u7B2C_u56DB_u5173"><a href="#u7B2C_u56DB_u5173" class="headerlink" title="第四关"></a>第四关</h2><p>这一关要涉及到一个函数，我们先把 <code>phase_4</code> 的代码弄出来：</p>
<p><img src="/images/14544781877930.jpg" alt=""></p>
<p>而对应 func4 的汇编代码是：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">000000000040115</span>d &lt;func4&gt;:</span><br><span class="line">  <span class="number">40115</span>d:	<span class="number">41</span> <span class="number">54</span>                push   %r12</span><br><span class="line">  <span class="number">40115f</span>:	<span class="number">55</span>                   push   %rbp</span><br><span class="line">  <span class="number">401160</span>:	<span class="number">53</span>                   push   %rbx</span><br><span class="line">  <span class="number">401161</span>:	<span class="number">89</span> fb                mov    %edi,%ebx</span><br><span class="line">  <span class="number">401163</span>:	<span class="number">85</span> ff                test   %edi,%edi</span><br><span class="line">  <span class="number">401165</span>:	<span class="number">7</span>e <span class="number">24</span>                jle    <span class="number">40118</span>b &lt;func4+<span class="number">0x2e</span>&gt;</span><br><span class="line">  <span class="number">401167</span>:	<span class="number">89</span> f5                mov    %esi,%ebp</span><br><span class="line">  <span class="number">401169</span>:	<span class="number">89</span> f0                mov    %esi,%eax</span><br><span class="line">  <span class="number">40116</span>b:	<span class="number">83</span> ff <span class="number">01</span>             cmp    $<span class="number">0x1</span>,%edi</span><br><span class="line">  <span class="number">40116</span>e:	<span class="number">74</span> <span class="number">20</span>                je     <span class="number">401190</span> &lt;func4+<span class="number">0x33</span>&gt;</span><br><span class="line">  <span class="number">401170</span>:	<span class="number">8</span>d <span class="number">7f</span> ff             lea    -<span class="number">0x1</span>(%rdi),%edi</span><br><span class="line">  </span><br><span class="line">  <span class="number">401173</span>:	e8 e5 ff ff ff       callq  <span class="number">40115</span>d &lt;func4&gt;</span><br><span class="line">  <span class="number">401178</span>:	<span class="number">44</span> <span class="number">8</span>d <span class="number">24</span> <span class="number">28</span>          lea    (%rax,%rbp,<span class="number">1</span>),%r12d</span><br><span class="line">  <span class="number">40117</span>c:	<span class="number">8</span>d <span class="number">7</span>b fe             lea    -<span class="number">0x2</span>(%rbx),%edi</span><br><span class="line">  <span class="number">40117f</span>:	<span class="number">89</span> ee                mov    %ebp,%esi</span><br><span class="line">  </span><br><span class="line">  <span class="number">401181</span>:	e8 d7 ff ff ff       callq  <span class="number">40115</span>d &lt;func4&gt;</span><br><span class="line">  <span class="number">401186</span>:	<span class="number">44</span> <span class="number">01</span> e0             add    %r12d,%eax</span><br><span class="line">  <span class="number">401189</span>:	eb <span class="number">05</span>                jmp    <span class="number">401190</span> &lt;func4+<span class="number">0x33</span>&gt;</span><br><span class="line">  <span class="number">40118</span>b:	b8 <span class="number">00</span> <span class="number">00</span> <span class="number">00</span> <span class="number">00</span>       mov    $<span class="number">0x0</span>,%eax</span><br><span class="line">  <span class="number">401190</span>:	<span class="number">5</span>b                   pop    %rbx</span><br><span class="line">  <span class="number">401191</span>:	<span class="number">5</span>d                   pop    %rbp</span><br><span class="line">  <span class="number">401192</span>:	<span class="number">41</span> <span class="number">5</span>c                pop    %r12</span><br><span class="line">  <span class="number">401194</span>:	c3                   retq</span><br></pre></td></tr></table></figure>
<p>和上一关类似，我们可以先从 <code>0x402b56</code> 这个地址获取到具体的输入格式：</p>
<p><img src="/images/14545016028067.jpg" alt=""></p>
<p>可以看到这一关我们需要输入两个数字，在检查输入参数的个数是否为 2 个之后，先判断第一个参数是否小于等于 1，如果是就爆炸，所以第一个数字需要大于等于 1。然后判断第一个参数是否小于等于 4，这里需要满足这个条件，所以第一个参数可能的取值（目前来看）是 2, 3, 4。</p>
<p>然后是把函数调用的参数传到 <code>%edi</code> 中，也就是说传入的参数是 9 和 2（我们输入的第 2 参数），然后需要用我们之前输入的第 1 个参数来和函数的返回值比较，于是我们需要弄明白这个递归函数在做什么。</p>
<p>一开始的 jle 跳转相当于是递归的退出条件，可以看到只有当 <code>%edi</code> 为 0 时，才会退出（现在 <code>%edi</code> 的值是 9），接着把我们输入的第一个参数存到 <code>%ebp</code> 和 <code>%eax</code> 中。之后又是跳转，因为 <code>%edi</code> 的值不等于 1，所以会继续执行。<code>lea</code> 那一句的左右就是让 <code>%edi</code> 的值减一（变成 8），然后开始递归调用。（可能需要 <code>delete [断点编号]</code> 方便调试）</p>
<p>递归部分有两个参数，第一个参数是程序中给出的 9，第二个参数是我们之前输入的参数中的第二个（也就是说可以是 2/3/4），程序的返回值会和我们输入的第一个参数进行比较。整个递归函数可以转换成如下的语句：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">f</span><span class="params">(x, y)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (x == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (x == <span class="number">1</span>) <span class="keyword">return</span> y;</span><br><span class="line">    <span class="keyword">return</span> f(x-<span class="number">1</span>,y) + f(x-<span class="number">2</span>,y) + y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所以其中一个答案就是 <code>264 3</code>，测试一下，发现顺利通过！</p>
<p><img src="/images/14545084801542.jpg" alt=""></p>
<h2 id="u7B2C_u4E94_u5173"><a href="#u7B2C_u4E94_u5173" class="headerlink" title="第五关"></a>第五关</h2><p>根据代码来判断，我们要输入的是一个长度为 6 的字符串（+9 那一句）。然后会经过一系列复杂的跳转，匹配的话就正常返回。</p>
<p><img src="/images/14545086537046.jpg" alt=""></p>
<p>代码不算很长，通过第一个验证（长度位 6）之后，会把 <code>%edx</code> 和 <code>%eax</code> 都赋值为 0，然后用 <code>%eax</code> 和 5 进行比较，相当于是循环的计数，于是我们跳转回 +31 句。这里有两个新指令 <code>movslq</code>（扩展到64位，但是不填充符号位） 和 <code>movzbl</code>（扩展到 32 位，填充 0），然后我们取得到的值的最后四位。</p>
<p>接着出现了一个地址，我们来看看地址里面的内容是什么</p>
<p><img src="/images/14545104158997.jpg" alt=""></p>
<p>可以看到是一个数组，而后面的代码等于是根据我们的输入在这个数组中选取数字进行累加，选取的规则是用输入字符的最低四位，最后的结果要和 <code>0x34</code> 进行比较，也就是需要六个数字加起来是 52。</p>
<p>那么这六个数字可以怎么凑到 52 呢？我随便凑了一下，16+16+10+6+2+2=52。对应的偏移量是 5, 5, 1, 2, 0, 0，然后我们找一个 ASCII 表：</p>
<p><img src="/images/14545105868475.jpg" alt=""></p>
<p>按照最低位的取值来选符合条件的字母，我这里挑了 <code>eeabpp</code>，然后测试一下，再次通关！</p>
<p><img src="/images/14545106954452.jpg" alt=""></p>
<h2 id="u7B2C_u516D_u5173"><a href="#u7B2C_u516D_u5173" class="headerlink" title="第六关"></a>第六关</h2><p>最后一关！代码非常长：</p>
<p><img src="/images/14545109182445.jpg" alt=""><br><img src="/images/14545113919133.jpg" alt=""></p>
<p>一开始读取六个数字进来，后面一顿疯狂跳转，到底在做什么呢？我用笨办法，一句一句先翻译出来，注意跳转的时候最好标记一下</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">Dump of assembler code <span class="keyword">for</span> function phase_6:</span><br><span class="line">=&gt; <span class="number">0x40122c</span> &lt;+<span class="number">0</span>&gt;:     push   %r12</span><br><span class="line">   <span class="number">0x40122e</span> &lt;+<span class="number">2</span>&gt;:     push   %rbp</span><br><span class="line">   <span class="number">0x40122f</span> &lt;+<span class="number">3</span>&gt;:     push   %rbx</span><br><span class="line">   <span class="number">0x401230</span> &lt;+<span class="number">4</span>&gt;:     sub    $<span class="number">0x50</span>,%rsp</span><br><span class="line">   <span class="number">0x401234</span> &lt;+<span class="number">8</span>&gt;:     mov    %rsp,%rsi</span><br><span class="line">   <span class="number">0x401237</span> &lt;+<span class="number">11</span>&gt;:    callq  <span class="number">0x40173a</span> &lt;read_six_numbers&gt;</span><br><span class="line"></span><br><span class="line">   <span class="number">0x40123c</span> &lt;+<span class="number">16</span>&gt;:    mov    $<span class="number">0x0</span>,%ebp               <span class="preprocessor"># ebp = <span class="number">0</span></span></span><br><span class="line">   <span class="number">0x401241</span> &lt;+<span class="number">21</span>&gt;:    jmp    <span class="number">0x40127d</span> &lt;phase_6+<span class="number">81</span>&gt;</span><br><span class="line"></span><br><span class="line">   <span class="number">0x401243</span> &lt;+<span class="number">23</span>&gt;:    movslq %ebp,%rax</span><br><span class="line">   <span class="number">0x401246</span> &lt;+<span class="number">26</span>&gt;:    mov    (%rsp,%rax,<span class="number">4</span>),%eax      <span class="preprocessor"># 取以 rsp 开头第 rax 个数，放到 eax 中</span></span><br><span class="line">   <span class="number">0x401249</span> &lt;+<span class="number">29</span>&gt;:    sub    $<span class="number">0x1</span>,%eax               <span class="preprocessor"># eax -= <span class="number">1</span></span></span><br><span class="line">   <span class="number">0x40124c</span> &lt;+<span class="number">32</span>&gt;:    cmp    $<span class="number">0x5</span>,%eax</span><br><span class="line">   <span class="number">0x40124f</span> &lt;+<span class="number">35</span>&gt;:    jbe    <span class="number">0x401256</span> &lt;phase_6+<span class="number">42</span>&gt;   <span class="preprocessor"># 小于等于 <span class="number">5</span> 则跳转</span></span><br><span class="line">   <span class="number">0x401251</span> &lt;+<span class="number">37</span>&gt;:    callq  <span class="number">0x401704</span> &lt;explode_bomb&gt;</span><br><span class="line"></span><br><span class="line">   <span class="number">0x401256</span> &lt;+<span class="number">42</span>&gt;:    lea    <span class="number">0x1</span>(%rbp),%r12d         <span class="preprocessor"># r12d(地址) = rbp 存放的地址 + <span class="number">0x1</span></span></span><br><span class="line">   <span class="number">0x40125a</span> &lt;+<span class="number">46</span>&gt;:    mov    %r12d,%ebx</span><br><span class="line">   <span class="number">0x40125d</span> &lt;+<span class="number">49</span>&gt;:    movslq %ebp,%rbp</span><br><span class="line">   <span class="number">0x401260</span> &lt;+<span class="number">52</span>&gt;:    jmp    <span class="number">0x401275</span> &lt;phase_6+<span class="number">73</span>&gt;</span><br><span class="line"></span><br><span class="line">   <span class="number">0x401262</span> &lt;+<span class="number">54</span>&gt;:    movslq %ebx,%rax</span><br><span class="line">   <span class="number">0x401265</span> &lt;+<span class="number">57</span>&gt;:    mov    (%rsp,%rax,<span class="number">4</span>),%eax      <span class="preprocessor"># 取以 rsp 开头的第 rax 个数，放到 eax 中</span></span><br><span class="line">   <span class="number">0x401268</span> &lt;+<span class="number">60</span>&gt;:    cmp    %eax,(%rsp,%rbp,<span class="number">4</span>)</span><br><span class="line">   <span class="number">0x40126b</span> &lt;+<span class="number">63</span>&gt;:    jne    <span class="number">0x401272</span> &lt;phase_6+<span class="number">70</span>&gt;   <span class="preprocessor"># 不能相等</span></span><br><span class="line">   <span class="number">0x40126d</span> &lt;+<span class="number">65</span>&gt;:    callq  <span class="number">0x401704</span> &lt;explode_bomb&gt;</span><br><span class="line">   <span class="number">0x401272</span> &lt;+<span class="number">70</span>&gt;:    add    $<span class="number">0x1</span>,%ebx               <span class="preprocessor"># ebx += <span class="number">1</span></span></span><br><span class="line"></span><br><span class="line">   <span class="number">0x401275</span> &lt;+<span class="number">73</span>&gt;:    cmp    $<span class="number">0x5</span>,%ebx               <span class="preprocessor"># ebx 与 <span class="number">5</span> 比较</span></span><br><span class="line">   <span class="number">0x401278</span> &lt;+<span class="number">76</span>&gt;:    jle    <span class="number">0x401262</span> &lt;phase_6+<span class="number">54</span>&gt;   <span class="preprocessor"># 小于的时候跳转</span></span><br><span class="line">   <span class="number">0x40127a</span> &lt;+<span class="number">78</span>&gt;:    mov    %r12d,%ebp              <span class="preprocessor"># ebp = r12d</span></span><br><span class="line"></span><br><span class="line">   <span class="number">0x40127d</span> &lt;+<span class="number">81</span>&gt;:    cmp    $<span class="number">0x5</span>,%ebp               <span class="preprocessor"># ebp 与 <span class="number">5</span> 比较</span></span><br><span class="line">   <span class="number">0x401280</span> &lt;+<span class="number">84</span>&gt;:    jle    <span class="number">0x401243</span> &lt;phase_6+<span class="number">23</span>&gt;   <span class="preprocessor"># 小于的时候跳转</span></span><br><span class="line">   <span class="preprocessor"># 前面相当于判断输入的六个数是否一样，并且要小于 <span class="number">6</span></span></span><br><span class="line">   <span class="number">0x401282</span> &lt;+<span class="number">86</span>&gt;:    mov    $<span class="number">0x0</span>,%esi               <span class="preprocessor"># esi = <span class="number">0</span></span></span><br><span class="line">   <span class="number">0x401287</span> &lt;+<span class="number">91</span>&gt;:    jmp    <span class="number">0x4012af</span> &lt;phase_6+<span class="number">131</span>&gt;</span><br><span class="line"></span><br><span class="line">   <span class="number">0x401289</span> &lt;+<span class="number">93</span>&gt;:    mov    <span class="number">0x8</span>(%rdx),%rdx          <span class="preprocessor"># rdx(地址) = rdx 存着的地址 + <span class="number">0x8</span></span></span><br><span class="line">   <span class="number">0x40128d</span> &lt;+<span class="number">97</span>&gt;:    add    $<span class="number">0x1</span>,%eax               <span class="preprocessor"># eax += <span class="number">1</span></span></span><br><span class="line">   <span class="number">0x401290</span> &lt;+<span class="number">100</span>&gt;:   jmp    <span class="number">0x40129f</span> &lt;phase_6+<span class="number">115</span>&gt;</span><br><span class="line"></span><br><span class="line">   <span class="number">0x401292</span> &lt;+<span class="number">102</span>&gt;:   mov    $<span class="number">0x1</span>,%eax               <span class="preprocessor"># eax = <span class="number">1</span></span></span><br><span class="line">   <span class="number">0x401297</span> &lt;+<span class="number">107</span>&gt;:   mov    $<span class="number">0x604300</span>,%edx          <span class="preprocessor"># edx = <span class="number">0x604300</span></span></span><br><span class="line">   <span class="number">0x40129c</span> &lt;+<span class="number">112</span>&gt;:   movslq %esi,%rcx               <span class="preprocessor"># rcx = esi</span></span><br><span class="line"></span><br><span class="line">   <span class="number">0x40129f</span> &lt;+<span class="number">115</span>&gt;:   cmp    %eax,(%rsp,%rcx,<span class="number">4</span>)      <span class="preprocessor"># 以 rsp 开头的第 rcx 个数与 eax 比较</span></span><br><span class="line">   <span class="number">0x4012a2</span> &lt;+<span class="number">118</span>&gt;:   jg     <span class="number">0x401289</span> &lt;phase_6+<span class="number">93</span>&gt;   <span class="preprocessor"># 大于的时候跳转</span></span><br><span class="line">   <span class="number">0x4012a4</span> &lt;+<span class="number">120</span>&gt;:   movslq %esi,%rax               <span class="preprocessor"># rax = esi</span></span><br><span class="line">   <span class="number">0x4012a7</span> &lt;+<span class="number">123</span>&gt;:   mov    %rdx,<span class="number">0x20</span>(%rsp,%rax,<span class="number">8</span>)  <span class="preprocessor"># 把 rdx 存着的地址放到某个位置</span></span><br><span class="line">   <span class="number">0x4012ac</span> &lt;+<span class="number">128</span>&gt;:   add    $<span class="number">0x1</span>,%esi               <span class="preprocessor"># esi += <span class="number">1</span></span></span><br><span class="line"></span><br><span class="line">   <span class="number">0x4012af</span> &lt;+<span class="number">131</span>&gt;:   cmp    $<span class="number">0x5</span>,%esi               <span class="preprocessor"># esi 与 <span class="number">5</span> 比较</span></span><br><span class="line">   <span class="number">0x4012b2</span> &lt;+<span class="number">134</span>&gt;:   jle    <span class="number">0x401292</span> &lt;phase_6+<span class="number">102</span>&gt;  <span class="preprocessor"># 小于的时候跳转</span></span><br><span class="line">   <span class="number">0x4012b4</span> &lt;+<span class="number">136</span>&gt;:   mov    <span class="number">0x20</span>(%rsp),%rbx         <span class="preprocessor"># rbx = rsp 存着的地址 + <span class="number">0x20</span> 的新地址</span></span><br><span class="line">   <span class="number">0x4012b9</span> &lt;+<span class="number">141</span>&gt;:   mov    %rbx,%rcx               <span class="preprocessor"># rcx = rbx</span></span><br><span class="line">   <span class="number">0x4012bc</span> &lt;+<span class="number">144</span>&gt;:   mov    $<span class="number">0x1</span>,%eax               <span class="preprocessor"># eax = <span class="number">1</span></span></span><br><span class="line">   <span class="number">0x4012c1</span> &lt;+<span class="number">149</span>&gt;:   jmp    <span class="number">0x4012d5</span> &lt;phase_6+<span class="number">169</span>&gt;</span><br><span class="line"></span><br><span class="line">   <span class="number">0x4012c3</span> &lt;+<span class="number">151</span>&gt;:   movslq %eax,%rdx               <span class="preprocessor"># rdx = eax</span></span><br><span class="line">   <span class="number">0x4012c6</span> &lt;+<span class="number">154</span>&gt;:   mov    <span class="number">0x20</span>(%rsp,%rdx,<span class="number">8</span>),%rdx  <span class="preprocessor"># rdx = 以 rsp 开头加上 <span class="number">8</span> 个 rdx 偏移再加 <span class="number">0x20</span></span></span><br><span class="line">   <span class="number">0x4012cb</span> &lt;+<span class="number">159</span>&gt;:   mov    %rdx,<span class="number">0x8</span>(%rcx)          <span class="preprocessor"># rcx 存着的地址 + <span class="number">0x8</span> = rdx 存着的地址</span></span><br><span class="line">   <span class="number">0x4012cf</span> &lt;+<span class="number">163</span>&gt;:   add    $<span class="number">0x1</span>,%eax               <span class="preprocessor"># eax += <span class="number">1</span></span></span><br><span class="line">   <span class="number">0x4012d2</span> &lt;+<span class="number">166</span>&gt;:   mov    %rdx,%rcx               <span class="preprocessor"># rcx = rdx</span></span><br><span class="line"></span><br><span class="line">   <span class="number">0x4012d5</span> &lt;+<span class="number">169</span>&gt;:   cmp    $<span class="number">0x5</span>,%eax               <span class="preprocessor"># eax 与 <span class="number">5</span> 比较</span></span><br><span class="line">   <span class="number">0x4012d8</span> &lt;+<span class="number">172</span>&gt;:   jle    <span class="number">0x4012c3</span> &lt;phase_6+<span class="number">151</span>&gt;  <span class="preprocessor"># 小于的时候跳转</span></span><br><span class="line">   <span class="number">0x4012da</span> &lt;+<span class="number">174</span>&gt;:   movq   $<span class="number">0x0</span>,<span class="number">0x8</span>(%rcx)          <span class="preprocessor"># rcx 存着的地址 + <span class="number">0x8</span> = <span class="number">0</span></span></span><br><span class="line">   <span class="number">0x4012e2</span> &lt;+<span class="number">182</span>&gt;:   mov    $<span class="number">0x0</span>,%ebp               <span class="preprocessor"># ebp = <span class="number">0</span></span></span><br><span class="line">   <span class="number">0x4012e7</span> &lt;+<span class="number">187</span>&gt;:   jmp    <span class="number">0x4012ff</span> &lt;phase_6+<span class="number">211</span>&gt;</span><br><span class="line"></span><br><span class="line">   <span class="number">0x4012e9</span> &lt;+<span class="number">189</span>&gt;:   mov    <span class="number">0x8</span>(%rbx),%rax          <span class="preprocessor"># rax(地址) = rbx 存着的地址 + <span class="number">0x8</span></span></span><br><span class="line">   <span class="number">0x4012ed</span> &lt;+<span class="number">193</span>&gt;:   mov    (%rax),%eax             <span class="preprocessor"># eax = rax 地址中的值</span></span><br><span class="line">   <span class="number">0x4012ef</span> &lt;+<span class="number">195</span>&gt;:   cmp    %eax,(%rbx)             <span class="preprocessor"># rbx 地址中的值与 eax 比较</span></span><br><span class="line">   <span class="number">0x4012f1</span> &lt;+<span class="number">197</span>&gt;:   jge    <span class="number">0x4012f8</span> &lt;phase_6+<span class="number">204</span>&gt;  <span class="preprocessor"># 大于等于的时候跳转</span></span><br><span class="line">   <span class="number">0x4012f3</span> &lt;+<span class="number">199</span>&gt;:   callq  <span class="number">0x401704</span> &lt;explode_bomb&gt;</span><br><span class="line">   <span class="number">0x4012f8</span> &lt;+<span class="number">204</span>&gt;:   mov    <span class="number">0x8</span>(%rbx),%rbx          <span class="preprocessor"># rbx(地址) = rbx 存着的地址 + <span class="number">0x8</span></span></span><br><span class="line">   <span class="number">0x4012fc</span> &lt;+<span class="number">208</span>&gt;:   add    $<span class="number">0x1</span>,%ebp               <span class="preprocessor"># ebp += <span class="number">1</span></span></span><br><span class="line">   <span class="preprocessor"># 以上部分等于是用我们输入的顺序去验证内存中数据的顺序是否正确</span></span><br><span class="line">   <span class="number">0x4012ff</span> &lt;+<span class="number">211</span>&gt;:   cmp    $<span class="number">0x4</span>,%ebp               <span class="preprocessor"># ebp 与 <span class="number">4</span> 比较</span></span><br><span class="line">   <span class="number">0x401302</span> &lt;+<span class="number">214</span>&gt;:   jle    <span class="number">0x4012e9</span> &lt;phase_6+<span class="number">189</span>&gt;  <span class="preprocessor"># 小于等于的时候跳转</span></span><br><span class="line">   <span class="number">0x401304</span> &lt;+<span class="number">216</span>&gt;:   add    $<span class="number">0x50</span>,%rsp</span><br><span class="line">   <span class="number">0x401308</span> &lt;+<span class="number">220</span>&gt;:   pop    %rbx</span><br><span class="line">   <span class="number">0x401309</span> &lt;+<span class="number">221</span>&gt;:   pop    %rbp</span><br><span class="line">   <span class="number">0x40130a</span> &lt;+<span class="number">222</span>&gt;:   pop    %r12</span><br><span class="line">   <span class="number">0x40130c</span> &lt;+<span class="number">224</span>&gt;:   retq</span><br><span class="line">End of assembler dump.</span><br></pre></td></tr></table></figure>
<p>这里发现一个奇怪的地址 <code>0x604300</code>，我们来看看里面的内容是什么：</p>
<p><img src="/images/14545155501283.jpg" alt=""></p>
<p>发现其实是一个结构体，类似于</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">    <span class="keyword">int</span> order;</span><br><span class="line">    node* next;</span><br><span class="line">&#125; node;</span><br></pre></td></tr></table></figure>
<p>我们要做的，就是输入正确的 order（从大到小），这样程序在验证顺序的时候，就不会出问题，打印出来节点里的内容，人工排个序，就可以发现正确答案是 <code>6 2 1 6 4 3</code>。</p>
<p><img src="/images/14545157165813.jpg" alt=""></p>
<p>拆弹任务成功！</p>
<h2 id="u79D8_u5BC6_u5173_u5361"><a href="#u79D8_u5BC6_u5173_u5361" class="headerlink" title="秘密关卡"></a>秘密关卡</h2><p>接着往反编译出来的源代码下看，发现还有一个隐藏关！但是之前过程中并没有任何需要给隐藏关输入的地方，那么就得先看看怎么进入隐藏关。在源代码中搜索 <code>secret_phase</code>，然后就可以发现，在 <code>phase_defused</code> 中会对其进行调用，那么我们就先来设个断点，看看能够怎么进去。</p>
<p><img src="/images/14545166333931.jpg" alt=""></p>
<p><code>phase_defused</code> 函数内容如下，我们在调用 <code>secret_phase</code> 的指令加个断点(<code>break *0x40191d</code>)，然后看看到底需要输入什么。</p>
<p>然后发现上面把两个参数放到了 <code>%edi</code> 中，我们来看看里面放了什么。结果发现是挑衅</p>
<p><img src="/images/14545168650220.jpg" alt=""></p>
<p>继续网上找，在 <code>0x402ba0</code> 这个地址里，可以发现输入格式</p>
<p><img src="/images/14545176516067.jpg" alt=""></p>
<p>但是并没有任何印象要输入这个，继续往上翻，发现又有一个地址：</p>
<p><img src="/images/14545178110834.jpg" alt=""></p>
<p>唯一有类似输入格式的就是第四题，所以我们试试看在第四题的后面加上 <code>213rocks!</code>。果然，就可以进入到秘密关卡了。</p>
<p><img src="/images/14545195897356.jpg" alt=""></p>
<p>这一段代码一开始就调用 <code>read_line</code>，然后会把内容用 <code>strtol</code> 转成十进制证书，然后和 <code>0x3e8</code>（也就是 1000）进行比较，如果小于等于的话就执行 <code>fun7</code>，然后返回值需要等于 5，于是问题就变成，给定一个值，让 <code>fun7</code> 的输出为 5。我们就先来看看 <code>fun7</code> 具体做了什么。</p>
<p><img src="/images/14545211010609.jpg" alt=""></p>
<p>一眼就能看出这是一个递归函数了，然后我们观察一下传进来作为第一个参数的地址 <code>0x604120</code></p>
<p><img src="/images/14545215838752.jpg" alt=""></p>
<p>虽然比较乱，但是可以看出是一棵树，有不同的层级。画出来的话大概是</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">              <span class="number">36</span></span><br><span class="line">        /           \</span><br><span class="line">      <span class="number">8</span>               <span class="number">50</span></span><br><span class="line">    /    \          /    \</span><br><span class="line">   /      \        /      \</span><br><span class="line">  <span class="number">6</span>       <span class="number">22</span>      <span class="number">45</span>      <span class="number">107</span></span><br><span class="line"> / \     /  \    /  \    /   \</span><br><span class="line"><span class="number">1</span>   <span class="number">7</span>   <span class="number">20</span>  <span class="number">35</span>  <span class="number">40</span>  <span class="number">47</span>  <span class="number">99</span>  <span class="number">1001</span></span><br></pre></td></tr></table></figure>
<p>递归实际上的逻辑类似于下面代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> treeNode</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> data;</span><br><span class="line">    <span class="keyword">struct</span> treeNode* leftChild;</span><br><span class="line">    <span class="keyword">struct</span> treeNode* rightChild;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fun7</span><span class="params">(<span class="keyword">struct</span> treeNode* p, <span class="keyword">int</span> v)</span></span><br><span class="line"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (v &lt; p-&gt;data)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span> * fun7(p-&gt;leftChild, v);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (v == p-&gt;data)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span> * fun7(p-&gt;rightChild, v) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了要凑成 5，我们需要的值是 47（根据递归规律来找到合适的数字即可）</p>
<p><img src="/images/14545241927519.jpg" alt=""></p>
<p>通关！最后的答案是</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Why make trillions when we could make... billions?</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> <span class="number">4</span> <span class="number">8</span> <span class="number">16</span> <span class="number">32</span></span><br><span class="line"><span class="number">0</span> n <span class="number">223</span></span><br><span class="line"><span class="number">264</span> <span class="number">3</span> <span class="number">213</span>rocks!</span><br><span class="line">eeabpp</span><br><span class="line"><span class="number">6</span> <span class="number">2</span> <span class="number">1</span> <span class="number">5</span> <span class="number">4</span> <span class="number">3</span></span><br><span class="line"><span class="number">47</span></span><br></pre></td></tr></table></figure>
<p>虽然每个人的答案是不一样的，但是思路还是可以借鉴的，这次作业还是非常有意思的，好顶赞！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一讲主要是介绍第二次作业 Bomblab 的相关内容以及解法。</p>]]>
    
    </summary>
    
      <category term="Bomblab" scheme="http://wdxtub.com/tags/Bomblab/"/>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="习题课" scheme="http://wdxtub.com/tags/%E4%B9%A0%E9%A2%98%E8%AF%BE/"/>
    
      <category term="计算机" scheme="http://wdxtub.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[云计算 第 11 课 Horizontal Scaling and Advanced Resource Scaling]]></title>
    <link href="http://wdxtub.com/2016/02/01/cc-11/"/>
    <id>http://wdxtub.com/2016/02/01/cc-11/</id>
    <published>2016-02-01T22:55:20.000Z</published>
    <updated>2016-02-08T13:11:11.000Z</updated>
    <content type="html"><![CDATA[<p>经过上一节课的『锻炼』，这一次我们要迎来更大的挑战。前面很多时候都是通过 Web 界面来进行云资源的管理，这里我们需要学会如何用代码来申请和控制各种资源。</p>
<a id="more"></a>
<hr>
<h2 id="u5B66_u4E60_u76EE_u6807"><a href="#u5B66_u4E60_u76EE_u6807" class="headerlink" title="学习目标"></a>学习目标</h2><p>这一次课时间紧任务重，需要掌握的知识和技能有：</p>
<ol>
<li>根据需求利用代码通过云 API 来申请所需资源</li>
<li>能够在故障、花费和性能等限制条件下完成 web 服务的部署</li>
<li>对比 AWS 和 Azure 在 API 使用上的不同</li>
<li>能够识别和说明处理资源故障的必要性</li>
<li>能够解释在所有资源间保证负载均衡的必要性</li>
<li>在 Azure 的 VM Scale Set 上配置和部署一个负载均衡器 Load Balancer</li>
<li>在 AWS 的 Auto Scaling Group 上配置和部署一个 Elastic Load Balancer</li>
<li>完成能够处理资源失败的解决方案</li>
<li>在申请云资源的时候考虑花费这一限制因素</li>
<li>分析最大化性能和可靠性与成本之间的权衡</li>
</ol>
<p>有一些需要注意的地方</p>
<ul>
<li>记得打标签（EC2, ELB, ASG）</li>
<li>不要在代码里包含 AWS 的密钥</li>
<li>AWS 中只能使用 <code>m3.medium</code> 或 <code>m3.large</code></li>
<li>Azure 中只能使用 <code>Standard_A1(DC)</code> 和 <code>Standard_D1(LG)</code></li>
</ul>
<h2 id="u57FA_u7840_u77E5_u8BC6"><a href="#u57FA_u7840_u77E5_u8BC6" class="headerlink" title="基础知识"></a>基础知识</h2><p>上一课里，我们使用云来进行了大数据处理和分析，只需要几行代码，就可以启动一个 EMR 集群来进行并行处理运算。但是，类似 EMR 这种服务通常很贵，并且内部具体的运行状况我们很多时候无从得知。另外，虽然 EMR 支持很多不同的应用，但是实际上还是有诸多限制，比方说主要是应用在批处理和分析上。这一次我们会部署一个 web 服务，用来响应各种 web 请求（类似于<a href="http://wdxtub.com/2016/01/16/cc-7">第 7 课 AWS 动手玩</a>）</p>
<p>在<a href="http://wdxtub.com/2016/01/20/cc-9/">第 9 课 Sequential Programming</a>中，我们故意选择了一个 <code>t1.micro</code> 实例，只有很有限的硬件资源。在这种条件的制约下，就很容易出现运行缓慢，甚至内存不够的问题，于是需要我们去尽可能优化代码。</p>
<p>但是代码优化总有一个极限，很多时候我们必须指定合适的硬件资源才能更有效率地完成各项任务。在云计算中，调整分配给不同工作/任务/服务的资源的过程称为 scaling。</p>
<p>Scaling 具体来说，可以分成两类</p>
<h3 id="Scaling__u7684_u5206_u7C7B"><a href="#Scaling__u7684_u5206_u7C7B" class="headerlink" title="Scaling 的分类"></a>Scaling 的分类</h3><p><strong>Vertical Scaling</strong></p>
<p>这是最简单的方法，也就是提高系统中资源的容量。例如，改变核心的数量，内存的大小或者处理器的计算速度。我们在之前的课程中也进行过测试。</p>
<p><strong>Horizontal Scaling</strong></p>
<p>Horizontal scaling 就复杂很多，因为需要把任务进行切分，然后分配到不同的资源上。一个比较简单的机制就是不断增加相同的资源（实例），这次我们主要以这种方式来完成 horizontal scaling</p>
<p>在没有云之前，要对资源进行 scaling 是一个很复杂的任务，云的其中一个突出好处就是可以动态添加资源，也就是这节课着重要强调的内容。</p>
<p>这里我们要做的就是写代码来和云上的资源进行交互，简单来说，就是把各种 API 连起来用正确的顺序进行调用，但是需要注意代码的可靠性和容错性。因为实际上是发送过去一个请求，然后得到一个返回结果，所以需要做好各种可能的预防措施，比如失败的话，可能需要重新申请。</p>
<h2 id="u5267_u60C5_u6897_u6982"><a href="#u5267_u60C5_u6897_u6982" class="headerlink" title="剧情梗概"></a>剧情梗概</h2><p>设定很有意思，居然强行扯上了<a href="http://www.wikiwand.com/en/Orwellian" target="_blank" rel="external">奥威尔的世界观</a>，简单来说，这个世界观比这门课有意思多啦！《1984》+《动物农场》，你值得拥有。大概是这样的：</p>
<p><img src="/images/14543608717887.jpg" alt=""></p>
<h2 id="Azure_Horizontal_Scaling"><a href="#Azure_Horizontal_Scaling" class="headerlink" title="Azure Horizontal Scaling"></a>Azure Horizontal Scaling</h2><ul>
<li>Scaling out: 从一个 <code>Standard_A1</code> 虚拟机扩展到很多个 <code>Standard_A1</code> 虚拟机</li>
<li>Scaling in: 减少虚拟机的数量</li>
</ul>
<p>这里我们会用到两种不同的实例：</p>
<ul>
<li>Load Generator: 产生请求 </li>
<li>Data Center: 处理和响应请求</li>
</ul>
<p>目标也很简单，不断开启实例，直到最终满足能够处理每秒 3000 次的请求(3000 RPS)</p>
<p><strong>第一步</strong></p>
<p>因为 Azure 的限制，所以需要把镜像先拷贝到自己的账户中：</p>
<ul>
<li>Data Center, <code>Standard_A1</code>, <code>https://cmucc.blob.core.windows.net/public/Microsoft.Compute/Images/vhds/cc15619p21dcv5-osDisk.e27faca3-f177-40ea-a740-9a1838326ae6.vhd</code></li>
<li>Load Generator, <code>Standard_D1</code>, <code>https://cmucc.blob.core.windows.net/public/Microsoft.Compute/Images/vhds/cc15619p21lgv10-osDisk.f6be8828-8cab-45ae-a611-904aeeef3c9e.vhd</code></li>
</ul>
<p>命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 复制</span></span><br><span class="line">azure storage blob copy start https://cmucc.blob.core.windows.net/public/Microsoft.Compute/Images/vhds/cc15619p21dcv5-osDisk.e27faca3<span class="operator">-f</span>177-<span class="number">40</span>ea<span class="operator">-a</span>740-<span class="number">9</span>a1838326ae6.vhd --dest-account-name YOURNAME --dest-account-key YOURKEY --dest-container YOURCONTAINER</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">azure storage blob copy show --account-name YOURNAME --account-key YOURKEY --container system --blob Microsoft.Compute/Images/vhds/cc15619p21dcv5-osDisk.e27faca3<span class="operator">-f</span>177-<span class="number">40</span>ea<span class="operator">-a</span>740-<span class="number">9</span>a1838326ae6.vhd</span><br></pre></td></tr></table></figure>
<p>大概要等一阵子，可以先来看看具体的测试规则：</p>
<ol>
<li>Data Center 必须用 <code>Standard_A1</code>，Load Generator 必须用 <code>Standard_D1</code></li>
<li>所有的虚拟机都必须通过代码启动，所有的 data center（除了第一个）都必须要在测试开始之后创建</li>
<li>代码需要完成处理当前每秒的请求并决定是否需要启动另一台虚拟机</li>
<li>不要 hardcode 虚拟机的数量</li>
<li>代码不应该连续开启多个 data center 虚拟机</li>
<li>每开启一个虚拟机，需要等待 100 秒才可以开启下一个虚拟机</li>
<li>测试一旦开始，除了关机没有其他办法可以停止，所以确定准备好了再开始</li>
<li>除了复制镜像的部分，程序必须是全自动并且可以容忍错误的。也就是说，从开启虚拟机到提交密码和 andrewid 再到开始测试再到添加需要的虚拟机最后测试完成退出都必须是自动的。</li>
<li>代码中不需要关闭 load generator，之后还会用到。不过 data center 可以删除（不一定需要在代码中完成）</li>
</ol>
<p>再来是给出的一些提示：</p>
<ol>
<li>可以利用之前给出的 Azure API 代码来从镜像创建虚拟机</li>
<li>使用 DNS 而不是 IP 地址</li>
<li>如果不大清楚程序在做什么，可以用浏览器体验一下整个过程</li>
<li>如果不熟悉如何通过代码提交请求，看看浏览器是怎么做的</li>
<li>使用 GET 和 POST 来完成请求</li>
<li>Horizontal Scaling Test 在达到指定的 RPS 后会结束，可以通过检查 log 来判断测试的状况</li>
<li>测试文件是 ini 格式的，可能需要用 <code>ConfigParser</code>(Python) 或 <code>ini4j</code>(Java) 来进行解析</li>
</ol>
<p>经过漫长的等待，复制完成，我们可以开始这次的任务了。首先是把之前的 Azure Demo 的代码导入到 Eclipse 里面。（代码在<a href="http://wdxtub.com/2016/01/15/cc-5/">第 5 课 Azure API</a>中，感谢 @jiexing 提供的具体步骤）</p>
<ol>
<li>eclipse-&gt;help-&gt;install new software-&gt;<a href="http://download.eclipse.org/technology/m2e/releases/" target="_blank" rel="external">http://download.eclipse.org/technology/m2e/releases/</a></li>
<li>eclipse-&gt;file-&gt;import-&gt;existing maven projects</li>
<li>在运行设置中，设置命令行参数：<code>RESOURCEGROUP STORAGEACCOUNT VHDNAME SUBSCRIPTIONID TENANTID APPLICATIONID APPLICATIONKEY</code>（和之前启动的一样）</li>
</ol>
<p><strong>第二步</strong></p>
<p>修改样例代码，让它能够启动一个 Load Generator 和一个 Data Center 的虚拟机。然后要去 load generator 那里注册一下 andrewid 和提交密码。地址是</p>
<p><code>http://[your-load-generator-instance-dns-name]/password?passwd=[your submission password]&amp;andrewid=[your andrew id]</code></p>
<p>这里我遇到了个问题，就是创建了虚拟机之后却没办法访问页面，好的暂时没办法继续了。</p>
<p>原因找到了，因为少了一段设置 DNS 的代码（后来更新的，在<a href="https://s3.amazonaws.com/15619public/webcontent/azureDemo.tar.gz" target="_blank" rel="external">这里</a>）</p>
<p><strong>第三步</strong></p>
<p>就是按部就班来完成任务了，不停测试是少不了的，说一些需要注意的地方：</p>
<ul>
<li>注意每一步操作之后均需要等待一段时间，这样一来更准确，二来不用反复重试</li>
<li>整体的逻辑最好先想好，不然写着写着容易乱</li>
<li>把访问网络的部分封装好，自动处理连接失败的问题，这样就可以避免很多麻烦</li>
<li>解析 RPS 数值可以使用 ini 解析器，也可以直接处理纯文本，我觉得纯文本比较好处理，就没用 ini 来解析了</li>
<li>访问 log 需要利用之前开始测试时返回的 log id，需要解析出来之后进行使用。</li>
<li>确保这一步没错才开始下一步，这样比较保险。</li>
</ul>
<p>这里我判断重试的逻辑有一点问题，注意 try catch 语句可能引起的特殊流程</p>
<h2 id="Azure_Autoscaling"><a href="#Azure_Autoscaling" class="headerlink" title="Azure Autoscaling"></a>Azure Autoscaling</h2><p>在前面的任务中，我们做的是 horizontal scaling，利用代码来增加 data center 虚拟机的数量。这种方法的局限性在于：</p>
<p>整个 scale 的过程需要程序执行，如果程序因为某些原因关闭了，那么就不会再发送 API 请求了。而且，这种情况下负载是不均衡了，每次增加 data center，需要通知 load generator，这之后才能对其发送请求。</p>
<p>诸如 AWS 和 Azure 的云服务提供商都可以自动进行资源扩展和负载均衡。我们所要做的就是进行一些配置，一旦配置成功，就会自动进行资源调度了。接下来我们会在 Azure 上体验一下</p>
<h3 id="Virtual_Machine_Scale_Sets"><a href="#Virtual_Machine_Scale_Sets" class="headerlink" title="Virtual Machine Scale Sets"></a>Virtual Machine Scale Sets</h3><p><img src="/images/14545355285392.jpg" alt=""></p>
<p>Azure 的 Virtual Machine Scale Sets 其实就是一个集群，集群中的每个虚拟机都是一样的。我们可以利用基于 json 的部署脚本，通过 Azure 资源管理器或者命令行工具来进行配置。使用之前我们需要对 json 脚本进行一些配置。</p>
<ul>
<li>Virtual Machine Configuration<ul>
<li>包括虚拟机的镜像文件，虚拟机类型和其他一些虚拟机相关问题。</li>
</ul>
</li>
<li>Virtual Network<ul>
<li>在 scaling set 中的每一台机器都必须被配置为在特定的虚拟网络中</li>
</ul>
</li>
<li>Load Balancer Configuration<ul>
<li>负载均衡器通常用 round-robin 方式来发送请求，虽然这种调度方式并不算完美，但是面对来自大量用户的简单请求，已经足够了。</li>
</ul>
</li>
<li>Scaling Policies<ul>
<li>Scaling policies 决定何时从 scaling set 增加和减少虚拟机</li>
</ul>
</li>
</ul>
<p>因为是动态资源管理，所以负载均衡器需要对其背后的机器有一些了解。所以通常会定期检查各个主机是否正常运行，如果不正常，就会停止对其发送请求。</p>
<p>因此，我们的负载均衡器必须配置好 IP 地址，负载均衡规则（决定需要进行转发的琉璃那个），以及探测器（检查实例是否正常运行）</p>
<h3 id="Configuring_an_Azure_VM_Scaling_Set"><a href="#Configuring_an_Azure_VM_Scaling_Set" class="headerlink" title="Configuring an Azure VM Scaling Set"></a>Configuring an Azure VM Scaling Set</h3><p>这里，我们可以自动进行 scaling，而不需要像第一个任务那样手动申请。Load Generator 会不断增加发送的请求，从一台 data center 虚拟机开始，Azure 会自动增加虚拟机的数量，以便处理更多的请求。</p>
<p>我们还会用之前的 data center 和 load generator 虚拟机镜像。接着我们会用 JSON 格式的模板来创建 auto scaling set。下载 <a href="https://s3.amazonaws.com/15619public/webcontent/azuredeploy.json" target="_blank" rel="external">Azuredeploy.json</a> 和 <a href="https://s3.amazonaws.com/15619public/webcontent/azuredeploy.parameters.json" target="_blank" rel="external">Azuredeploy.parameters.json</a>。下面是运行部署命令会创建的资源列表：</p>
<blockquote>
<p>azuredeploy.json</p>
</blockquote>
<ul>
<li>Virtual Network: All the NICs and IP addresses associated with the virtual machines and load balancers will be deployed in this virtual network.</li>
<li>IP Address: This will be assigned to the NIC on the load balancer.<ul>
<li>Note: Azure VM set does not assign IP addresses to the backend machines.</li>
<li><code>domainNameLabel</code>: This is a DNS prefix for the load balancer DNS name. The load balancer DNS name will thus have the format <code>${prefix}.eastus.cloudapp.azure.com</code>. The provided JSON template currently uses the <code>vmScalingSetName</code> (explained below) as the DNS prefix.</li>
</ul>
</li>
<li>Load Balancer: As the frontend of the VM set, the load balancer will receive HTTP requests and forward them to the backend machines using round robin strategy.<ul>
<li><code>frontendIPConfigurations</code>: Provide the resource name of the IP Address created above.</li>
<li><code>backendAddressPools</code>: Configure the backend machines. Azure allows users to put machines in a pool and use this set as a backend for a load balancer. In this JSON template, we will use the VM set as the backend pool of data center VMs.</li>
<li><code>loadBalancingRules</code>: You can configure the traffic type you want to forward from the frontend to the backend machines. In this template, we will forward TCP traffic from port 80 to port 80, which is typically used for HTTP requests.</li>
<li><code>probes</code>: This is the health checker for the load balancer. The load balancer will send a request to a user specified path in a fixed interval. If no reply is received from a backend machine within a specified threshold, the load balancer will mark the machine as unhealthy and stop forwarding traffic to it.</li>
</ul>
</li>
<li>Virtual Machine Scale Set: You need to specify the image URL for this Azure VM set. The new machines will be created from this image if necessary.<ul>
<li><code>sku</code>: You can configure the virtual machine type (<code>Standard_A1</code> in this case) for the data center VMs and the initial number of machines (<code>1</code> in this case).</li>
<li><code>virtualMachineProfile</code>: Provide a VM image URL in this section, the machines at the backend will be created from this image.</li>
<li><code>extensionProfile</code>: Here we will configure a <code>LinuxDiagnostic</code> extension for the VM set. This will help us collect the CPU utilization of a VM, which we will use as the basis for triggering any scaling actions.</li>
</ul>
</li>
<li>Auto Scale Setting: In Azure, the autoscale setting policy is used to configure an autoscaling event trigger and action. For example, you can configure the autoScalingSetting section in the JSON file to make the VM set scale up when the CPU Utilization Percentage is above a threshold.<ul>
<li><code>profiles.rules</code>: You need to configure the scaling policy in this section.</li>
</ul>
</li>
</ul>
<p>大概了解之后，具体配置的时候需要修改 <code>azuredeploy.json</code> 和 <code>azuredeploy.parameters.json</code> 中的一些参数的内容。在 <code>azuredeploy.json</code> 中只需要修改下面的部分：</p>
<blockquote>
<p>azuredeploy.json</p>
</blockquote>
<p>The profiles under Microsoft.Insights/autoscaleSettings: You need to consider the capacity and rules.</p>
<p>在 <code>azuredeploy.parameters.json</code> 中，配置下面的参数：</p>
<blockquote>
<p>azuredeploy.parameters.json</p>
</blockquote>
<ul>
<li><code>vmScalingSetName</code>: Name for your Virtual Machine Scaling Set and Load Balancer DNS prefix. Give a global unique name for this. (This name should match <code>^[a-z][a-z0-9-]{1,61}[a-z0-9]$</code>).</li>
<li><code>storageAccName</code>: Storage Account name where your data center VM image is in.</li>
<li><code>resourceGroupNameForStorageAcc</code>: Resource Group name where your data center VM image is in.</li>
<li><code>instanceCount</code>: Leave it at <code>1</code> for this project.</li>
<li><code>vmSize</code>: Keep it <code>Standard_A1</code> for this project.</li>
<li><code>location</code>: Keep it <code>East US</code> for this project.</li>
<li><code>sourceImageVhdUri</code>: The data center VM image URL in your strorage account.</li>
<li><code>frontEndLBPort</code>: Keep it <code>80</code>. The http request to frontEndLBPort will be forwarded to the backEndLBPort on the data center VMs.</li>
<li><code>backEndLBPort</code>: Keep it <code>80</code>.</li>
</ul>
<p>配置好了对应参数，就可以用下面的命令来创建了，注意需要提供一个新的 <code>RESOURCE_GROUP_NAME</code>（除了虚拟机磁盘，都会在这个资源组创建）以及你的 <code>AZURE_SUBSCRIPTION_ID</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">azure group create  <span class="operator">-f</span> ./azuredeploy.json <span class="operator">-e</span>  ./azuredeploy.parameters.json -n &lt;RESOURCE_GROUP_NAME&gt; <span class="operator">-l</span> <span class="string">"East US"</span> --subscription &lt;AZURE_SUBSCRIPTION_ID&gt;</span><br></pre></td></tr></table></figure>
<p>之后注意去 web 界面检查下是不是真的开启成功了。</p>
<h3 id="Running_the_Autoscaling_Test"><a href="#Running_the_Autoscaling_Test" class="headerlink" title="Running the Autoscaling Test"></a>Running the Autoscaling Test</h3><p>部署成功之后就可以进行测试了。具体的任务步骤如下：</p>
<ol>
<li>根据之前给出的配置文件，用命令行工具进行部署</li>
<li>确保部署成功，并且 load generator 正常运行。可以通过访问 <code>http://${vmScalingSetName}.eastus.cloudapp.azure.com/lookup/random</code> 来进行测试（注意修改为自己的地址）</li>
<li>向 Load Generator 提交负载均衡起的地址以进行测试 <code>http://[your-load-generator-instance-dns-name]/junior?dns=[your-loadbalancer-dns-name]</code>（如果是新开的机器，需要提交密码和 andrewid）</li>
<li>可以不断刷新网页来查看 log</li>
</ol>
<p>测试规则和提示：</p>
<ul>
<li>开始测试时只能启动一个 data center 虚拟机来进行测试</li>
<li>设定的 autoscaling policy 应该在负载加大的时候自动增加机器</li>
<li>目标是 30 分钟达到 900 rps</li>
<li>Load Generator 只使用 <code>Standard_D1</code>，Data Center 只使用 <code>Standard_A1</code> </li>
</ul>
<h2 id="AWS_Horizontal_Scaling"><a href="#AWS_Horizontal_Scaling" class="headerlink" title="AWS Horizontal Scaling"></a>AWS Horizontal Scaling</h2><p>AWS 的这个部分需要完成的和 Azure 类似，需要注意以下几点：</p>
<ol>
<li>使用 <code>m3.medium</code> 用 <code>ami-8ac4e9e0</code> 来作为 load generator</li>
<li>使用 <code>m3.medium</code> 用 <code>ami-349fbb5e</code> 来作为 data center</li>
<li>用下面的 URL 来提交密码和 andrew id：<code>http://[your-load-generator-instance-dns-name]/password?passwd=[your submission password]&amp;andrewId=[your andrewId]</code></li>
<li>用下面的 URL 来提交 data center 的 dns 来开始测试：<code>http://[your-load-generator-instance-dns-name]/test/horizontal?dns=[your-instance-dns-name]</code></li>
<li>打标签需要在代码中完成，要确保 security group 设置所有的端口都打开</li>
<li>可以通过下面的 URL 来查看 log：<code>http://[your-load-generator-instance-dns-name]/log?name=test.[test-number].log</code></li>
<li>为了通过测试，需要保证 RPS 达到 4000，测试开始之后可以通过发送请求来添加实例：<code>http://[your-load-generator-instance-dns-name]/test/horizontal/add?dns=[your-instance-dns-name]</code></li>
<li>所有 data center 的规格应该是一样的</li>
</ol>
<p>就是按部就班来完成任务了，不停测试是少不了的，说一些需要注意的地方：</p>
<ul>
<li>注意每一步操作之后均需要等待一段时间，这样一来更准确，二来不用反复重试</li>
<li>整体的逻辑最好先想好，不然写着写着容易乱</li>
<li>把访问网络的部分封装好，自动处理连接失败的问题，这样就可以避免很多麻烦</li>
<li>解析 RPS 数值可以使用 ini 解析器，也可以直接处理纯文本，我觉得纯文本比较好处理，就没用 ini 来解析了</li>
<li>访问 log 需要利用之前开始测试时返回的 log id，需要解析出来之后进行使用。</li>
<li>确保这一步没错才开始下一步，这样比较保险。</li>
</ul>
<p>完成之后，就可以发现现在这种方法的局限：</p>
<p>我们有一个 Load Generator，若干个 data center 会试着从中获取数据。每次添加实例，都需要通知 load generator，然后需要进行一些计算使得各个 data center 获得相同的流量。但是如果不想要这么多 data center，或者忽然有一个实例挂掉了呢？怎么去监控这个事情呢？怎么保证每个 data center 的负载均衡呢？</p>
<p>所以 AWS 提供一个叫做 Elastic Load Balancing 的服务，可以自动把流量均分给连接的实例，也能处理好实例挂掉的情况。接下来我们会做一些这个方面的尝试。</p>
<h2 id="AWS_Autoscaling"><a href="#AWS_Autoscaling" class="headerlink" title="AWS Autoscaling"></a>AWS Autoscaling</h2><p>服务质量（QoS）和花费是部署云服务时非常重要的两个方面。如果不能提供高质量的服务，肯定会损失用户。性能，可用性，可靠性和安全性都是服务质量中很重要的因素。</p>
<p>Elastic Load Balancer 像是一个网络路由器，会用 round-robin 的方式转发进入的请求给不同的 EC2 实例。</p>
<p>ELB 指向的机器可以通过 web 界面手动添加，也可以写代码或者通过 Auto Scaling Group(ASG)，这里 AWS 会有一个实例池。ELB 同时也会检查实例是否正常运行，如果不是的话会停止发送请求。目前，ELB 每小时花费 <code>$0.025</code> 加 <code>$0.008</code> 每 GB 数据传输费。下图大概描述了 ELB 的功能。<a href="https://youtu.be/Fw0aNoMZesg" target="_blank" rel="external">Video</a> 中也对 ELB 有详细的介绍。</p>
<p><img src="/images/14545429009811.jpg" alt=""></p>
<p>界面创建 ELB：点击左边的页面，选择 Load Balancer，设定名字以及转发规则，然后配置 Health Check，设定间隔和超时的规则，然后选择安全组，最后选择需要 ELB 的 EC2 实例，就可以启动了。然后访问 ELB 的地址，就可以看到会把请求发送到不同的实例上，用完记得删除 ELB 和 EC2 实例。</p>
<p>可以用下面的方式来跟 ELB 进行交互</p>
<ol>
<li><a href="http://aws.amazon.com/cli/" target="_blank" rel="external">The AWS Command Line Interface (AWS CLI)</a></li>
<li><a href="http://aws.amazon.com/sdk-for-java/" target="_blank" rel="external">The AWS SDK for Java</a></li>
<li><a href="https://boto.readthedocs.org/en/latest/" target="_blank" rel="external">boto for Python</a></li>
</ol>
<p>AWS Auto Scaling 服务会根据使用需求自动添加或移除分配给一个应用的资源，使用的是 horizontal scaling 的机制，也就是加机器，而非加硬件。AWS Auto Scaling 会根据需求来增加或减少同样的资源。我们可以通过命令行工具或者 API 来进行控制。这个 <a href="https://youtu.be/WsGpj5eZaS4" target="_blank" rel="external">视频</a> 是一个简要的介绍。</p>
<p>视频内容大致为：</p>
<p>我们可以利用 Auto Scaling 来处理流量突然增大的状况。传统的方式不够灵活，闲时浪费计算能力，忙时可能计算能力又不够。整体的机制是：</p>
<p><img src="/images/14546095526247.jpg" alt=""></p>
<p>Amazon CloudWatch 是用来监控不同的资源指标的，当达到某个占用量时，可以执行某些操作，如下</p>
<p><img src="/images/14546096167784.jpg" alt=""></p>
<p>Amazon Simple Notification Service 是一个快速且灵活的消息发送服务，当特定事件发生的时候会推送消息，然后订阅者可以接受并做对应的操作，比方说，下图就描述了在发生 ScaleOut/ScaleIn 时发送邮件通知的大概流程</p>
<p><img src="/images/14546097067092.jpg" alt=""></p>
<p>Amazon’s Auto Scaling 在 EC2 实例上提供下列部署模式：</p>
<ul>
<li>一直维护固定数量的 EC2 实例，定期检查状况，替换掉不健康的实例</li>
<li>调用 Auto Scaling 来调整实例数量</li>
<li>根据开发者指定的调度计划来进行调整（比方说可以设定周五晚上增加机器，周一早上减少机器）</li>
<li>根据开发者设定的条件来动态调整（比如 CPU 的利用率）</li>
</ul>
<p>这里我们会用 Auto Scaling 根据不同的流量状况来调整机器数量。流量增大，每台机器的负载加大，那么就增加服务器数量，反之亦然。我们可以编写代码让 Auto Scaling 根据 CPU 负载（或者其他指标）来申请机器。</p>
<p><img src="/images/14545494776601.jpg" alt="Auto Scaling Architecture in Amazon EC2"></p>
<p>使用 Auto Scaling 需要满足以下条件：</p>
<ul>
<li>一个 Auto Scaling 组在创建的时候需要定义最小/最大和预期实例数量 </li>
<li>需要定义一个启动配置模板，包括 AMI id，实例类型，key pair 和安全组等等信息</li>
<li>需要创建 Auto Scaling policy，其中定义了当特定事件（如 CloudWatch 的警报）触发时需要执行的操作。</li>
</ul>
<p>这个<a href="https://youtu.be/MchfwYakgWU" target="_blank" rel="external">视频</a>简要介绍了如何使用 Auto Scaling。</p>
<p>要创建一个 Auto Scaling Group，我们需要</p>
<ol>
<li>一个激活的 Elastic Load Balancer</li>
<li>启动实例的配置</li>
<li>ASG 定义和 Scaling policies</li>
</ol>
<p>所以我们先创建好 ELB，然后来到 Auto Scaling 的页面，选择一个镜像，然后创建启动配置，这里勾上 CloudWatch 监控选项，接着一路继续，可以选择和 ELB 一样的安全组，接着就可以创建了。</p>
<p>下一步需要起个名字，从 1 台机器开始，然后给定之前创建的 ELB，然后可以自定义最大和最小的机器数量，这里可以自定各种 CloudWatch 的警报然后设定对应要做的事情。这里也可以设定一个冷却时间（即一次 scaling 之后多久才能继续 scaling）</p>
<p>如何删除呢？如果在 EC2 页面删除，那么 ASG 会认为是实例失败，然后重新创建。所以需要改 ASG 的规则，设置最大和最小都是 0，就会自动进行关闭了。然后才可以删除对应的 ASG，一定要注意这个顺序。</p>
<h2 id="Amazon_CloudWatch"><a href="#Amazon_CloudWatch" class="headerlink" title="Amazon CloudWatch"></a>Amazon CloudWatch</h2><p>我们在项目中会使用 CloudWatch 来制定高效的 auto scaling policy。Amazon CloudWatch 让开发者可以监控 AWS 资源的状态。通过 API，开发者就可以知道最新的信息，并且据此来进行自动调整。CloudWatch 允许你设置警报，并且可以设置警报触发时需要完成的一系列动作。</p>
<p>CloudWatch 可以监控的 AWS 资源有：</p>
<ul>
<li>EC2 instances</li>
<li>EBS volumes</li>
<li>EMR job flows etc</li>
<li>ELB Loads</li>
</ul>
<p>对于 EC2 实例, CloudWatch 能帮助我们监控 CPU，内存和磁盘占用率（在网页上的监控那一栏可以看到）。更多信息可以参考 <a href="http://aws.amazon.com/documentation/cloudwatch/" target="_blank" rel="external">Amazon CloudWatch 文档</a>。这里是一个<a href="https://youtu.be/cu2_AbfXn2k" target="_blank" rel="external">介绍视频</a></p>
<p>视频主要讲解 CloudWatch 设定 Alarm 的一些逻辑，某条命令：</p>
<p><code>aws cloudwatch put-metric-data --metric-name PageViewCount --namespace &quot;MyService&quot; -- value 2 --timestamp 2014-02-14T12:00:00:00.000Z</code></p>
<h2 id="Advanced_Auto_Scaling_in_AWS"><a href="#Advanced_Auto_Scaling_in_AWS" class="headerlink" title="Advanced Auto Scaling in AWS"></a>Advanced Auto Scaling in AWS</h2><p>这里我们需要用 AWS API 来创建或者启动最终测试所需的所有资源。最终测试中，load generator 会给你的 ELB 发送动态负载，然后 autoscale policy 会自动调整实例的数量，最终以实例的小时数和每秒的请求来进行统计。</p>
<blockquote>
<p>因为时间限制，我们会用 48 分钟的测试代替实际的 1 天，也就是说，现实世界中的 1 个小时相当于测试中的 2 分钟。</p>
</blockquote>
<p>系统每天会有早晚两次访问高峰（超过 1800 rps，访问 <code>/lookup/random</code> 页面），但是不巧的是，系统每天有 200 个实例小时的限制</p>
<blockquote>
<p>关于实例小时 Instance Hour<br>一个 m3.medium 实例跑一个小时相当于 2 个实例小时，一个 m3.large 实例跑一个小时相当于 4 个实例小时。（注意这里会把分钟换算成小时数目）</p>
</blockquote>
<p><strong>预算控制</strong></p>
<p>每超出限制的 1 个实例小时，就会对应在工资中扣一部分，所以要根据流量来进行调整。可以在 ELB  的 <code>Healthy Hosts</code> 图中看到具体的实例小时使用。</p>
<p>应该使用 ELB 来在实例间平分流量。借助 Auto Scaling 和 CloudWatch 能够对系统进行调整以适应流量变化。后面会给出一个例子，不过只要能完成任务，也可以自己设定具体的规则。</p>
<p><strong>错误容忍</strong></p>
<p>我们的 data center 实例可能会时不时崩溃，除非被标记为不健康，load balancer 还是会一直发送请求，你需要设置 ELB 来检测崩溃的实例以避免这种情况，当实例失败时，可能需要做对应的处理</p>
<h3 id="u603B_u4F53_u6D41_u7A0B"><a href="#u603B_u4F53_u6D41_u7A0B" class="headerlink" title="总体流程"></a>总体流程</h3><p>需要用 Java, Python 或者命令行工具来完成下列步骤，并且在完成之后上传源代码。这个流程可以在网页上模拟运行来了解具体的步骤。</p>
<p>一开始你可以不设置 CloudWatch 和 Auto Scaling Group，而是先用固定数量的实例来了解流量的模式。一旦清楚了流量的波动，就可以进行下面的测试了（对应步骤的图片有编号放在最后）</p>
<ol>
<li>创建两个允许所有流量进出的且所有端口打开的安全组，其中一个会被关联到 ELB 和 ASG 上（之后需要通过代码删除）</li>
<li>创建一个 m3.medium 大小的 Load Generator（用之前的 ami，并且使用另外的安全组）。这个安全组可以事先创建，之后手动删除。</li>
<li>创建一个 ELB:<ul>
<li>重定向来自 load balance 的 HTTP:80 请求到 data center 的 HTTP:80</li>
<li>设置 <code>/heartbeat?lg=[your-load-generator-instance-dns-name]</code> 页面作为健康状况检查的页面</li>
<li>不提供正确的健康检查页面会使测试无效</li>
</ul>
</li>
<li>为那些将要成为 Auto Scaling Group 的实例创建一个 Launch Configuration，参数为:<ul>
<li>AMI ID</li>
<li>实例类型: m3.medium 或 m3.large</li>
<li>详细监控: enabled</li>
</ul>
</li>
<li>分析了流量模式，设定一个好的调整规则。这里提供了一个参考的参数设置，但是用这个很难通过测试：<ul>
<li>Group Size Start With: 1 instance</li>
<li>Subnet: Recommeded to choose the same availability zone(s) corresponding to your ELB</li>
<li>Load Balancing: Receive traffic from Elastic Load Balancer and choose your ELB</li>
<li>ELB Name: Choose your ELB name, make sure it’s alphanumeric</li>
<li>Health Check Type: ELB</li>
<li>Detailed Monitoring: enabled</li>
</ul>
</li>
<li>创建 Auto Scale Policies: 这里提供了一个参考的参数设置，但是用这个很难通过测试：<ul>
<li>Minimum Instance Size: 1</li>
<li>Maximum Instance Size: 2</li>
<li>Create a ScaleOut policy that automatically adds 1 instance to the auto scaling group.</li>
<li>Create a ScaleIn policy that automatically removes 1 instance from the auto scaling group.</li>
</ul>
</li>
<li>创建 CloudWatch 警报，会在下列情境时触发合适的政策，这里提供了一个参考的参数设置，但是用这个很难通过测试：<ul>
<li>Scale out when the group’s CPU load exceeds 80% on average over a 5 minute interval.</li>
<li>Scale in when the group’s CPU load is below 20% on average over a 5 minute interval.</li>
</ul>
</li>
<li>把 CloudWatch 警报和 Auto Scaling Group 的 ScaleOut/ScaleIn 规则关联起来</li>
<li>设置好合适的标签，实在不行可以用命令行工具来进行设置。</li>
<li>开始测试前需要在 <code>http://[your-load-generator-instance-dns-name]/password?passwd=[your-submission-password]</code> 提交密码和 andrewid</li>
<li>最好让负载均衡器热个身，可以访问 <code>http://[your-load-generator-instance-dns-name]/warmup?dns=[your-elb-dns]</code>。Load Generator 会在 15 分钟内发送大量请求，可以在 ELB 达到你满意的状况下多做几次。热身时候花费的实例小时不算在总评里。</li>
<li>ELB 热身完毕之后，访问 <code>http://[your-load-generator-instance-dns-name]/junior</code> 并输入你的 ELB DNS 来开始测试<ul>
<li>代码需要访问 <code>http://[your-load-generator-instance-dns-name]/junior?dns=[your-elb-dns]</code></li>
<li>可以在下面的网址查看具体的测试情况 <code>http://[your-load-generator-instance-dns-name]/log?name=test.[testId].log</code></li>
</ul>
</li>
<li>也可以通过 web 界面来监控 ELB，对应的图片是 HTTP 2XX 的请求（成功请求），如果你发现自己有很多失败的请求，那么可能是因为 ELB 没有配置好，不能根据情况进行资源调整</li>
<li>测试的最后会告知你的平均 RPS 和所有的实例小时</li>
<li>代码需要关闭除了 Load Generator 之外的其他所有资源。</li>
</ol>
<p><img src="/images/14546135447665.jpg" alt="5. An example of Auto Scaling Group configuration"></p>
<p><img src="/images/14546136129421.jpg" alt="6. An example of Auto Scaling Group configuration"></p>
<p><img src="/images/14546136709666.jpg" alt="10. Enter Submission Password Page on Load Generator"></p>
<p><img src="/images/14546137397449.jpg" alt="11. Warmup Page on Load Generator"></p>
<p><img src="/images/14546137648910.jpg" alt="12. Junior System Architect Test Page on Load Generator"></p>
<p><img src="/images/14546138087809.jpg" alt="12. A sample Junior System Architect test log"></p>
<p><img src="/images/14546138484700.jpg" alt="13. Sum of 2XX Https of ELB in CloudWatch"></p>
<p><img src="/images/14546138793040.jpg" alt="A sample test result"></p>
<p><strong>性能目标和得分</strong></p>
<p><img src="/images/14546139265354.jpg" alt=""></p>
<p>如果你的 rps = 1350 用了 150 实例小时, 那么得分是 18.75 + 25 = 43.75</p>
<p>如果你的 rps = 1800 用了 250 实例小时, 那么得分是 25 + 22.5 = 47.5</p>
<p>代码最后需要手动提交</p>
<h3 id="u4EFB_u52A1_u76EE_u6807"><a href="#u4EFB_u52A1_u76EE_u6807" class="headerlink" title="任务目标"></a>任务目标</h3><ol>
<li>用 Java, Python 或者命令行工具来使用 AWS API</li>
<li>程序要启动一个 load generator 和多个 data center，注意 ami 和 类型要保证正确</li>
<li>程序需要创建安全组，启动 ELB 和初始化 ASG（包括启动配置，Auto Scale Policies 和 CloudWatch 警报）。需要等待所有资源创建完毕才能继续</li>
<li>程序需要在开始测试前给 ELB 热身，并且需要记录返回的 testId</li>
<li>程序需要等待测试完成，终止除 Load Generator 外的所有资源（安全组，ELB，ASG 和对应的其他资源）</li>
<li>在 <code>http://[your-load-generator-instance-dns-name]/upload</code> 提交源代码 <code>[testId].zip</code> 和 <code>references</code> 包含两部分的代码。这里 <code>references</code> 是必须要的。不要上传其他东西，只有上传代码才会对测试评分</li>
<li>如果还有预算剩余，可以测试不同的配置</li>
<li>不要忘记关闭 Load Generator</li>
</ol>
<p><strong>Hints</strong></p>
<ul>
<li>一次完整测试要 48 分钟，注意时间</li>
<li>可能需要手动运行几次测试</li>
<li>热身是必须的</li>
<li>Scaling out 同样有些技巧，找到减轻添加新实例可能带来的影响的方法</li>
<li>Scale out 和 scale in 的规则很重要</li>
<li>选择的地区可能会影响到测试结果</li>
<li>不要同时开启多个 Load Generators，这样会给计算实例小时带来麻烦</li>
<li>如果 rps 几乎是 0，看看 ELB 有没有连接到至少一台健康的实例，注意容错性</li>
<li>如果实例小时是 0 (ih=0)，检查下 ELB 的健康检查页面有没有正确设置</li>
<li>最好禁止 ELB 的跨区域负载均衡，把所有的 data center 放到一个地区</li>
<li>会以最新的提交来评分，而不是最高的那次</li>
</ul>
<h2 id="u4E00_u4E9B_u8D44_u6E90"><a href="#u4E00_u4E9B_u8D44_u6E90" class="headerlink" title="一些资源"></a>一些资源</h2><ul>
<li><a href="http://awsdocs.s3.amazonaws.com/AutoScaling/latest/as-dg.pdf" target="_blank" rel="external">Autoscaling Developer Guide</a></li>
<li><a href="http://awsdocs.s3.amazonaws.com/AutoScaling/latest/as-api.pdf" target="_blank" rel="external">Autoscaling API Guide</a></li>
<li><a href="http://aws.amazon.com/documentation/cloudwatch/" target="_blank" rel="external">CloudWatch Documentation</a></li>
<li><a href="http://aws.amazon.com/documentation/elastic-load-balancing/" target="_blank" rel="external">Elastic Load Balancing Documentation</a></li>
</ul>
<h2 id="u4E00_u4E9B_u95EE_u9898_u4EE5_u53CA_u5BF9_u7B56"><a href="#u4E00_u4E9B_u95EE_u9898_u4EE5_u53CA_u5BF9_u7B56" class="headerlink" title="一些问题以及对策"></a>一些问题以及对策</h2><ul>
<li>Load Generator 有时候会发送消息让 Data Center 自杀<ul>
<li>解决方法是尽快让 ELB 发现挂了的 dc，快速反应重启</li>
</ul>
</li>
<li>ELB warmup 也很重要<ul>
<li>要注意 warmup 的时间</li>
</ul>
</li>
<li>可能机器提升的数量赶不上实际的峰值<ul>
<li>长期保持多几台机器，并且让机器减少的速度变慢</li>
<li>调整 policy 检测的数量</li>
<li>让 ASG 的 cooldown 减小，快速反应</li>
<li>5 台 基本是够用的</li>
<li>可以一开始直接 boost 到最大，然后慢慢滑落，遇到峰值，直接再 boost 到最大</li>
<li>policy 中的数值都需要是 60 的倍数</li>
</ul>
</li>
<li>要想办法减少开机导致的性能损失</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>经过上一节课的『锻炼』，这一次我们要迎来更大的挑战。前面很多时候都是通过 Web 界面来进行云资源的管理，这里我们需要学会如何用代码来申请和控制各种资源。</p>]]>
    
    </summary>
    
      <category term="AWS" scheme="http://wdxtub.com/tags/AWS/"/>
    
      <category term="Azure" scheme="http://wdxtub.com/tags/Azure/"/>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="云计算" scheme="http://wdxtub.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to Write Fast Code 第 2 课 Multicore 编程]]></title>
    <link href="http://wdxtub.com/2016/02/01/fastcode-2/"/>
    <id>http://wdxtub.com/2016/02/01/fastcode-2/</id>
    <published>2016-02-01T17:51:26.000Z</published>
    <updated>2016-02-01T18:18:21.000Z</updated>
    <content type="html"><![CDATA[<p>这一课主要是介绍 Multicore 编程以及 OpenMP 的相关内容，OpenMP 会另外专门做一个配套的教程，稍后共享给大家。</p>
<a id="more"></a>
<hr>
<p>先要了解几个不同的并行层级，如下图所示：</p>
<p><img src="/images/14543461995158.jpg" alt=""></p>
<p>OpenMP 实际上就是在代码中标记出可以并行执行的部分，由编译器来完成最终并行化处理的过程。具体的怎么做到的呢？参考下图：</p>
<p><img src="/images/14543462820858.jpg" alt=""></p>
<p>OpenMP 这部分会专门写一次课来具体进行讲解，所以这里主要把理论上的东西提一下。</p>
<p>课程作业中另一个问题就是矩阵相乘，矩阵相乘是非常经典的问题，为了降低计算复杂度提高效率，这么多年来出现了各种各样的方法（不过基本也到极限了）。比方说利用分而治之的方式，利用内存排列的方式等等，具体来说可以考虑下面的方法:</p>
<ul>
<li>Block size adaptation for appropriate caches</li>
<li>Register-level blocking</li>
<li>Copy optimization(data layout)</li>
<li>Optimizing the mini-matrix-multiply (base case)</li>
<li>Multi-level blocking</li>
<li>Multi-level copying</li>
</ul>
<p>这部分也会专门写一课来进行讲解。</p>
<p>最后是很重要的一个用来分析性能的模型：Roofline Model。主要是理解下面几个图：</p>
<p><img src="/images/14543502445260.jpg" alt=""></p>
<p><img src="/images/14543502605039.jpg" alt=""></p>
<p><img src="/images/14543502758805.jpg" alt=""></p>
<p><img src="/images/14543502946889.jpg" alt=""></p>
<p><img src="/images/14543503147538.jpg" alt=""></p>
<p>尤其是最后一张，超级重要：</p>
<p><img src="/images/14543503391932.jpg" alt=""></p>
<p>具体的优化分类如下，大家在实践的时候可以思考下具体是在哪个类别进行优化，有没有其他类别的方法可以尝试：</p>
<p><img src="/images/14543505552239.jpg" alt=""></p>
<p>最后再说一个概念：</p>
<p><img src="/images/14543506076660.jpg" alt=""></p>
<p>可以通过汇编指令来进行查看</p>
<p><img src="/images/14543506249554.jpg" alt=""></p>
<p>接下的两课就不会这么泛泛了，主要来聊聊 Kmeans 和 矩阵相乘。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一课主要是介绍 Multicore 编程以及 OpenMP 的相关内容，OpenMP 会另外专门做一个配套的教程，稍后共享给大家。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="Multicore" scheme="http://wdxtub.com/tags/Multicore/"/>
    
      <category term="OpenMP" scheme="http://wdxtub.com/tags/OpenMP/"/>
    
      <category term="并行" scheme="http://wdxtub.com/tags/%E5%B9%B6%E8%A1%8C/"/>
    
      <category term="编程" scheme="http://wdxtub.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to Write Fast Code 第 1 课 背景知识]]></title>
    <link href="http://wdxtub.com/2016/02/01/fastcode-1/"/>
    <id>http://wdxtub.com/2016/02/01/fastcode-1/</id>
    <published>2016-02-01T17:51:22.000Z</published>
    <updated>2016-02-01T17:00:07.000Z</updated>
    <content type="html"><![CDATA[<p>这一课主要介绍并行编程的背景知识和一些基本的技巧，给大家一个整体的认知。</p>
<a id="more"></a>
<hr>
<p>简单来说，提高程序运行速度的方式有很多种，除了算法优化，还有其他许多软件硬件相结合的技巧。不同层级上的优化，带来的收益也会不一样，比方说在软件架构上的优化，可能可以带来 20-100 倍的收益，算法层面上的优化是 10-40 倍，而数据结构上的优化是 1.5-8 倍（当然这些数字都不是绝对的）</p>
<p>这门课主要涉及 OpenMP，CUDA 和 Hadoop（也会有一些 Spark 的内容，机器学习的部分还在商量中）。我主要负责 OpenMP 和 Hadoop 的部分。</p>
<p>具体需要理解的概念，基本上在第 0 课中我的笔记都有涉及，课件里的例子一定要重点掌握，比如：</p>
<ul>
<li>Instruction level parallelism 的原理和机制</li>
<li>SIMD 的原理和机制（SSE 的用法）</li>
<li>Simultaneous Multithreading(SMT)的概念</li>
<li>Memory Hierarchy 的原理及如何进行利用（矩阵相乘的例子）</li>
<li>Compulsory miss / Capacity / Conflict</li>
</ul>
<p>接着是两幅图：Platform + Technique</p>
<p><img src="/images/14543452357180.jpg" alt=""></p>
<p><img src="/images/14543452584935.jpg" alt=""></p>
<p>最后说一下 Kmeans 这个算法，具体的算法过程这里不赘述了，基本的过程参见下图：</p>
<p><img src="/images/14543458160793.jpg" alt=""></p>
<p>如果想要理解更清楚一些，还需要去看看 EM 算法（这里同样不写）。然后对应到具体的代码，看看有哪些地方可以并行，哪些地方不行，如何根据不同的策略来优化代码。这些会在之后的习题课进行详细一点的讲解。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一课主要介绍并行编程的背景知识和一些基本的技巧，给大家一个整体的认知。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="并行" scheme="http://wdxtub.com/tags/%E5%B9%B6%E8%A1%8C/"/>
    
      <category term="架构" scheme="http://wdxtub.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="编程" scheme="http://wdxtub.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to Write Fast Code 第 0 课 往年笔记与问题集]]></title>
    <link href="http://wdxtub.com/2016/02/01/fastcode-0/"/>
    <id>http://wdxtub.com/2016/02/01/fastcode-0/</id>
    <published>2016-02-01T17:51:17.000Z</published>
    <updated>2016-02-01T15:19:50.000Z</updated>
    <content type="html"><![CDATA[<p>本来打算借着当助教，看看这门课有没有什么变化。事实上，没啥变化，所以这里先把当时我的笔记放出来，之后的课程可能会主要集中于代码和项目的思路分析，具体理论的东西不会再重复太多。</p>
<a id="more"></a>
<hr>
<h1 id="Lecture_Note"><a href="#Lecture_Note" class="headerlink" title="Lecture Note"></a>Lecture Note</h1><ul>
<li>Fast Platforms (Multicore platforms, Manycore platforms, Cloud platform) + Good Techniques (Data structure, Algorithm, Software Architecture)</li>
<li>Need is driven by the applications, NOT by the availability of the platform.</li>
<li>Background -&gt; Multicore(openmp) -&gt; Manycore(CUDA) -&gt; cluster(Hadoop) -&gt; Special Topics</li>
</ul>
<h2 id="Multicore_vs_Manycore"><a href="#Multicore_vs_Manycore" class="headerlink" title="Multicore vs Manycore"></a>Multicore vs Manycore</h2><ul>
<li>Multicore: yoke of oxen. Each core optimized for executing a single thread.</li>
<li>Manycore: flock of chickens. Cores optimized for aggregate throughput, deemphasizing individual performance.</li>
</ul>
<h2 id="Instruction_Level_Parallelism__28ILP_29"><a href="#Instruction_Level_Parallelism__28ILP_29" class="headerlink" title="Instruction Level Parallelism (ILP)"></a>Instruction Level Parallelism (ILP)</h2><p>Instructions in a sequence that can be computed at the same time.</p>
<ul>
<li>Advantages<ul>
<li>No changes in sequential software necessary</li>
</ul>
</li>
<li>Disadvantages<ul>
<li>Significantly more complex processor architecture</li>
<li>Longer to design the processor</li>
<li>Longer to verify the correctness of the processor design</li>
<li>Consumes more energy than simple in-order processor</li>
</ul>
</li>
</ul>
<h2 id="Out-of-order_Pipelines"><a href="#Out-of-order_Pipelines" class="headerlink" title="Out-of-order Pipelines"></a>Out-of-order Pipelines</h2><p>Allows instruction re-ordering, register-renaming</p>
<h2 id="SIMD"><a href="#SIMD" class="headerlink" title="SIMD"></a>SIMD</h2><ul>
<li>can be area and power efficient</li>
<li>parallelism exposed to programmer &amp; compiler</li>
</ul>
<p>Locality, Temporal Locality, Spatial Locality</p>
<p>Compulsory misses, Capacity misses, Conflict misses</p>
<ul>
<li>Advantages<ul>
<li>Power-efficient wya to improve instruction throughput</li>
<li>Exploitable in many compute-intensive applications</li>
</ul>
</li>
<li>Disadvantages<ul>
<li>Explicit representation in vector instructions</li>
<li>Software requires re-compilation to take advantage of new SIMD capabilites.</li>
<li>May require hand-tuning to expoit full benefit</li>
</ul>
</li>
</ul>
<h2 id="Simultaneous_multithreading"><a href="#Simultaneous_multithreading" class="headerlink" title="Simultaneous multithreading"></a>Simultaneous multithreading</h2><p>Capturing the opportunity to run faster when more than one thread of instructions are available.</p>
<ul>
<li>Advantages<ul>
<li>Gain power-efficiency by increase processor pipeline utilization</li>
</ul>
</li>
<li>Disadvantages<ul>
<li>Requires multiple threads available</li>
<li>May trigger confilicts in shared cache during execution</li>
<li>Does not improve latency of each thread</li>
</ul>
</li>
</ul>
<h2 id="Concurrency_vs_Parallelism"><a href="#Concurrency_vs_Parallelism" class="headerlink" title="Concurrency vs Parallelism"></a>Concurrency vs Parallelism</h2><ul>
<li>Concurrency: We expose concurrency in our application</li>
<li>Parallelism: We exploit parallelism in our platform</li>
</ul>
<p>Concurrency: A sequence of instructions executes concurrently if they execute independent of each other as if they were executed at the same time.</p>
<ul>
<li>They do not need to be executed truly at the same time though.</li>
<li>On a single processor computer, multi-tasking systems execute programs concurrently by interleaving their operations such that they appear to execute at the same time.</li>
</ul>
<p>Parallelism: Instruction streams that execute in parallel actually execute at the same time</p>
<ul>
<li>Parallelism allows multiple instructions to be executed at the exact same time</li>
<li>Parallelism requires multiple processing units, ranging from small pipeline stages up through multithreaded architectures and multicore and multiprocessing systems</li>
</ul>
<p>Difference</p>
<ul>
<li>Time</li>
<li>In concurrency, at any given time, a single operation is occurring.<ul>
<li>High clock rates and clever interleaving can give the illusion of parallelism</li>
<li>All modern desktop/server OS give you this. Embedded, maybe not.</li>
</ul>
</li>
<li>In parallelism, at a given point in time, multiple operations are occurring.<ul>
<li>This is important to distinguish. Parallelism means it is extremely difficult (often impossible) to predict the interleaving of instructions.</li>
</ul>
</li>
</ul>
<h2 id="The_process_of_problem_solving_3A"><a href="#The_process_of_problem_solving_3A" class="headerlink" title="The process of problem solving:"></a>The process of problem solving:</h2><ul>
<li>Understand the current state<ul>
<li>Running on a platform</li>
<li>Using a specific set of resources</li>
<li>Achieving a specific performance</li>
<li>Meeting a specific criteria/requirement</li>
</ul>
</li>
<li>Observe the internal representation<ul>
<li>Application structure</li>
<li>Implementation concerns<ul>
<li>Task considerations</li>
<li>Data representations</li>
<li>concurrency opportunities</li>
</ul>
</li>
</ul>
</li>
<li>Search among alternatives</li>
<li>Select from a set of choices</li>
</ul>
<h2 id="Kmeans_Problem"><a href="#Kmeans_Problem" class="headerlink" title="Kmeans Problem"></a>Kmeans Problem</h2><ul>
<li>Find K cluster centers that minimize the distance from each data point to a cluster center (centroid)</li>
<li>Important algorithm in machine learning</li>
<li>NP-hard for arbitrary input</li>
<li>Issues<ul>
<li>Worst case running time is super-polynomial</li>
<li>Approximation can be arbitrarily bad</li>
</ul>
</li>
</ul>
<h2 id="How_to_write_fast_code"><a href="#How_to_write_fast_code" class="headerlink" title="How to write fast code"></a>How to write fast code</h2><ul>
<li><strong>Expose</strong> concurrencies in applications and algorithms</li>
<li><strong>Exploit</strong> parallelisms on application platform</li>
<li><strong>Explore</strong> mapping between concurrency and parallelism</li>
</ul>
<h2 id="The_phases_28kmeans_29"><a href="#The_phases_28kmeans_29" class="headerlink" title="The phases(kmeans)"></a>The phases(kmeans)</h2><ul>
<li>Initialization: Randomly select k cluster centers<ul>
<li>Select k samples from data as initial centers [Forgy Partition]</li>
</ul>
</li>
<li>Expectation: Assign each data point go closest center<ul>
<li>Compare each data point (N) to each cluster center (K)</li>
<li>Distance Metric: Euclidean distance (D dimensions)</li>
</ul>
</li>
<li>Maximization: Update centers based on assignments</li>
<li>Evaluate: Re-iterate steps 2-3 until convergence or stopping criteria.</li>
</ul>
<h2 id="Performance_Analysis_3A_Roofline_Model"><a href="#Performance_Analysis_3A_Roofline_Model" class="headerlink" title="Performance Analysis: Roofline Model"></a>Performance Analysis: Roofline Model</h2><ul>
<li>Observe the phases of execution</li>
<li>Characterize the execution time break downs</li>
<li>Reason about why a piece of code is slow</li>
<li>Identify performance bottleneck</li>
</ul>
<h2 id="How_to_evaluate_a_mapping"><a href="#How_to_evaluate_a_mapping" class="headerlink" title="How to evaluate a mapping"></a>How to evaluate a mapping</h2><ul>
<li>Efficiency: Runs quickly, makes good use of computational resources</li>
<li>Simplicity: Easy to understand code is easier to develop, debug, verify and modify</li>
<li>Portability: Should run on widest range of parallel computers</li>
<li>Scalability: Should be effective on a wide range of processing elements</li>
</ul>
<h2 id="Exploiting_Different_Levels_of_Parallelism"><a href="#Exploiting_Different_Levels_of_Parallelism" class="headerlink" title="Exploiting Different Levels of Parallelism"></a>Exploiting Different Levels of Parallelism</h2><ul>
<li>SIMD-Level: using vectorizing compiler and hand-code intrinsics</li>
<li>SMT-Level: OS abstract it to core-level parallelism</li>
<li>Core-Level: Using threads to describe work done on different cores</li>
</ul>
<h2 id="False_Sharing"><a href="#False_Sharing" class="headerlink" title="False Sharing"></a>False Sharing</h2><ul>
<li>Cache loads and stores work with 4-16 word long cache lines(64B for Intel)<ul>
<li>If two threads are wrting to the same cache line, conflicts occurs</li>
</ul>
</li>
<li>Even if the address differs, one will still suffer performance penalty</li>
</ul>
<h2 id="Optimization_Categorization"><a href="#Optimization_Categorization" class="headerlink" title="Optimization Categorization"></a>Optimization Categorization</h2><ul>
<li>Maximizing In-core Performance<ul>
<li>Exploit in-core parallelism (reorder, unroll, SIMD, eliminate branch)</li>
</ul>
</li>
<li>Maximizing Memory Bandwidth<ul>
<li>Exploit NUMA, Hide memory latency (unit-stride streams, memory affinity, sw prefetch, DMA Lists, TLB Blocking)</li>
</ul>
</li>
<li>Minimizing Memory Traffic<ul>
<li>Eliminate Capacity/Conflict/Compulsory misses (cache blocking, array padding, compress data, streaming stores)</li>
</ul>
</li>
</ul>
<h2 id="Measuring_Arithmetic_Intensity"><a href="#Measuring_Arithmetic_Intensity" class="headerlink" title="Measuring Arithmetic Intensity"></a>Measuring Arithmetic Intensity</h2><p>Arithmetic Intensity = (# of FP Operations to run the program) / (# of Bytes Accessed in the Main Memory)</p>
<p>Arithmetic Intensity = FLOPs / (Allocations + Compulsory + Conflict + Capacity)</p>
<h2 id="Roofline_Model"><a href="#Roofline_Model" class="headerlink" title="Roofline Model"></a>Roofline Model</h2><p>Attainable Performance(ij) = min(FLOP/s with Optimization(1-i), AI*Bandwidth with Optimization(1-j)</p>
<p>Plot on log-log scale</p>
<p>Lantency -&gt; Runtime</p>
<p>Throughput -&gt; Performance</p>
<ul>
<li>Throughput<ul>
<li>Usually measured in floating point operations per second(FLOPS)</li>
<li>Floating point operations = addition + multiplication</li>
</ul>
</li>
</ul>
<p>Higher Performance != Shorter Runtime</p>
<p>True Arithmetic Intensity (AI) ~ Total Flops / Total DRAM Bytes</p>
<ul>
<li>Arithmetic intensity is ultimately limited by compulsory traffic</li>
<li>Arithmetic intensity is diminished by conflict or capacity misses</li>
</ul>
<h2 id="Data_3A_Three_Classes_of_Locality"><a href="#Data_3A_Three_Classes_of_Locality" class="headerlink" title="Data: Three Classes of Locality"></a>Data: Three Classes of Locality</h2><ul>
<li>Spatial Locality<ul>
<li>data is transferred from cache to registers in words</li>
<li>However, data is transferred to the cache in 64-128 Byte lines</li>
<li>using every word in a line maximizes spatial locality</li>
<li>transform data structures into struct of arrays(SoA) layout</li>
</ul>
</li>
<li>Temporal Locality<ul>
<li>reusing data(either registers or cachelines) multiple times</li>
<li>amortizes the impact of limited bandwidth</li>
<li>transform loop s or algorithms to maximize reuese.</li>
</ul>
</li>
<li>Sequential Locality<ul>
<li>Many memory address patterns access cache lines sequentially</li>
<li>CPU’s hardware stream prefetchers exploit this observation to hide speculatively load data to memory lantency</li>
<li>Tansform loops to generate long, unit-stride accesses</li>
</ul>
</li>
</ul>
<h2 id="GPU_is_an_Accelerator"><a href="#GPU_is_an_Accelerator" class="headerlink" title="GPU is an Accelerator"></a>GPU is an Accelerator</h2><ul>
<li>Host System (CPU) &lt;—&gt; Device System (GPU)</li>
<li>When Does Using GPU Make Sense?<ul>
<li>Application with a lot of concurrency (1000-way, fine-grained concurrency)</li>
<li>Some memory intensive applications (Aggregate memory bandwidth is higher)</li>
<li>Advantage diminishes when task granularity becomes too large to fit in shared memory</li>
</ul>
</li>
</ul>
<h2 id="GPU_Programming_Model_3A_Stream"><a href="#GPU_Programming_Model_3A_Stream" class="headerlink" title="GPU Programming Model: Stream"></a>GPU Programming Model: Stream</h2><ul>
<li>Stream -&gt; kernel -&gt; stream</li>
<li>Streams: An array of data units</li>
<li>Kernels<ul>
<li>Take streams as input, produce streams at output</li>
<li>Perform computation on streams</li>
<li>Kernels can be linked together</li>
</ul>
</li>
</ul>
<h2 id="CUDA_3A_Compute_Unified_Device_Architecture"><a href="#CUDA_3A_Compute_Unified_Device_Architecture" class="headerlink" title="CUDA: Compute Unified Device Architecture"></a>CUDA: Compute Unified Device Architecture</h2><ul>
<li>Integrated host + device app C program</li>
<li>Serial or modestly parallel parts in host C code</li>
<li>Highly Parallel parts in device SPMP kernel C code</li>
</ul>
<h2 id="CUDA_Programming_Model"><a href="#CUDA_Programming_Model" class="headerlink" title="CUDA Programming Model"></a>CUDA Programming Model</h2><ul>
<li>Executing kernel functions within threads</li>
<li>Threads organization<ul>
<li>Blocks and Grids</li>
</ul>
</li>
<li>Hardware mapping of threads<ul>
<li>Computation-to-core mapping<ul>
<li>Thread -&gt; Core</li>
<li>Thread blocks -&gt; Multi-processors</li>
</ul>
</li>
</ul>
</li>
<li>Thread organization<ul>
<li>an array of threads -&gt; block</li>
<li>an array of blocks -&gt; grid</li>
</ul>
</li>
<li>All threads in one grid execute the same kernel</li>
<li>Grids are executed sequentially</li>
<li>Thread Cooperation<ul>
<li>Threads within a block<ul>
<li>Shared memory</li>
<li>Atomic operation on Share memory &amp; global memory</li>
<li>Barrier</li>
</ul>
</li>
<li>Threads between blocks<ul>
<li>Atomic operation on global memory</li>
</ul>
</li>
<li>Threads between grids<ul>
<li>NO WAY!</li>
</ul>
</li>
</ul>
</li>
<li>Thread Mapping and Scheduling<ul>
<li>A grid of threads takes over the whole device</li>
<li>A block of threads is mapped on one multi-processor<ul>
<li>A multi-processor can take more than one blocks.(Occupancy)</li>
<li>A block can not be preempted until finish</li>
</ul>
</li>
<li>Threads within a blocks are shceduled to run on multi-processors</li>
<li>Threads are grouped into warps(32) as scheduling units</li>
</ul>
</li>
<li>Parallel Memory Sharing<ul>
<li>Local Memory: per-thread</li>
<li>Shared Memory: per-Block</li>
<li>Global Memory: per-application</li>
</ul>
</li>
<li>Shared Memory<ul>
<li>Each Multi-processor has 32KB of Shared Memory - 32 banks of 32bit words</li>
<li>Visible to all threads in a thread block</li>
</ul>
</li>
</ul>
<h2 id="Why_Warps"><a href="#Why_Warps" class="headerlink" title="Why Warps"></a>Why Warps</h2><p>Each Fermi core can maintain 48 warps of architecural context.</p>
<p>Each warp manages a 32-wide SIMD vector worth of computation</p>
<p>With ~20 registers for each trhead:</p>
<p>4(Bytes/register) x 20(Registers) x 32(SIMD lanes) x 48 (Warps) = 128KB per core x 16 (core) = 2MB total of register files</p>
<ul>
<li>Software abstract info hid an extra level of architecture complexity</li>
<li>A 128KB register file is a large memory (takes more than one cycle)</li>
<li>Hardware provide 160wide physical SIMD units, half-pump register files</li>
<li>To simplify the programming model</li>
</ul>
<h2 id="How_to_Deal_with_GPUs_of_Different_Sizes_3F"><a href="#How_to_Deal_with_GPUs_of_Different_Sizes_3F" class="headerlink" title="How to Deal with GPUs of Different Sizes?"></a>How to Deal with GPUs of Different Sizes?</h2><ul>
<li>CUDA provides an abstract infor concurrency to be fully exposed</li>
<li>HW/Runtime provides capability to schedule the computation</li>
</ul>
<h2 id="Thread_Blocks"><a href="#Thread_Blocks" class="headerlink" title="Thread Blocks"></a>Thread Blocks</h2><ul>
<li>Computation is grouped into blocks of independent concurrently execrable work</li>
<li>Fully exposed the concurrency in the application</li>
<li>The HW/Runtime makes the decision to selectively sequentialize the execution as necessary</li>
</ul>
<h2 id="21_21_Threads"><a href="#21_21_Threads" class="headerlink" title="!! Threads"></a>!! Threads</h2><ul>
<li>Threads are the computation performed in each SIMD lane in a core<ul>
<li>CUDA provides a SIMT programming abstraction to assist users</li>
</ul>
</li>
<li>SIMT: Single Instruction Multiple Threads<ul>
<li>A single instruction multiple processing elements</li>
<li>Different from SIMD</li>
<li>SIMT abstract the # threads in a thread block as a user-specified parameter</li>
</ul>
</li>
<li>SIMT enables programmers to write thread-level parallel code for<ul>
<li>Independent, Scalar threads</li>
<li>Data-parallel code fro coordinated threads</li>
</ul>
</li>
<li>For function correctness, programmers can ignore SIMT behavior</li>
<li>For performance, programmer can tune applications with SIMT in mind</li>
</ul>
<h2 id="About_Data"><a href="#About_Data" class="headerlink" title="About Data"></a>About Data</h2><ul>
<li>SIMD style programming can be very restrictive for communication between SIMD lanes.</li>
<li>On the same chip, in the same core, computations in SMD lanes (physically) takes places very close to each other</li>
</ul>
<h2 id="Shared_Memory/L1_cache"><a href="#Shared_Memory/L1_cache" class="headerlink" title="Shared Memory/L1 cache"></a>Shared Memory/L1 cache</h2><ul>
<li>Manycore processors provide memory local to each core</li>
<li>Computations in SIMD-lanes in the same core can communicate via memory read / write</li>
<li>Two types of memory:<ul>
<li>Programmer-managed scratch pad memory</li>
<li>HW-managed L1 cache</li>
</ul>
</li>
<li>For NVIDIA Fermi architecture, you get 64KB per core with 2 configurations:<ul>
<li>48KB scratch pad (Shared Memory), 16KB L1 cache</li>
<li>16KB scratch pad (Shared Memory), 48KB L1 cache</li>
</ul>
</li>
<li>How many Threads per Thread Block<ul>
<li>In Fermi, 48 warps of context are maintained per core</li>
<li>In Fermi, each thread block can have up to 1024 threads</li>
</ul>
</li>
</ul>
<h2 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h2><ul>
<li><code>__syncthreads()</code><ul>
<li>waits until all threads in the thread block have reached this point and all global and shared memory accesses made by these threads prior to <code>__syncthreads()</code> are visible to all threads in the block</li>
<li>used to coordinate communication between the threads of the same block</li>
</ul>
</li>
</ul>
<h2 id="Compilation"><a href="#Compilation" class="headerlink" title="Compilation"></a>Compilation</h2><ul>
<li>Any source file containing CUDA language extensions must be compiled with NVCC<ul>
<li>NVCC is a compiler driver</li>
<li>Works by invoking all the necessary tools and compilers like cudacc, g++, …</li>
</ul>
</li>
<li>NVCC outputs<ul>
<li>C code (host CPU code)<ul>
<li>Must be compiled with the rest of the application using another tool</li>
</ul>
</li>
<li>PTX<ul>
<li>object code directly</li>
<li>or, PTX source, interpreted at runtime</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="SOA_vs_AOS"><a href="#SOA_vs_AOS" class="headerlink" title="SOA vs AOS"></a>SOA vs AOS</h2><p>Struct of Arrays: 一共只有一个 struct</p>
<pre><code>typedef struct
{
    float* x;
    float* y;
    float* z;
} Constraints;
</code></pre><p>x | x | x | y | y | y | z | z | z</p>
<p>Array of Struct</p>
<pre><code>typedef struct __align__(16)
{
    float3 position;
} Constraint;
</code></pre><p>x | y | z | x | y | z | x | y | z</p>
<p>It depends on the usage of the data.</p>
<p>Note that AoS pads within each struct. While SoA pads between the arrays.</p>
<p>These have the following trade-offs:</p>
<ol>
<li>AoS tends to be more readable to the programmer as each “object” is kept together.</li>
<li>AoS may have better cache locality if all the members of the struct are accessed together.</li>
<li>SoA could potentially be more efficient since grouping same datatypes together sometimes exposes vectorization.</li>
<li>In many cases SoA uses less memory because padding is only between arrays rather than between every struct.</li>
</ol>
<h2 id="Optimization_Strategies"><a href="#Optimization_Strategies" class="headerlink" title="Optimization Strategies"></a>Optimization Strategies</h2><ul>
<li>Global Memory Access Pattern -&gt; Coalescing</li>
<li>Control Flow -&gt; Divergent branch</li>
</ul>
<h2 id="Memory_Coalescing"><a href="#Memory_Coalescing" class="headerlink" title="Memory Coalescing"></a>Memory Coalescing</h2><ul>
<li>Hardware Constraint: DRAM is accessed in ‘segments’ of 32B/64B/128B</li>
<li>Goal: combine multiple memory accesses generated from multiple threads into a single physical transaction</li>
<li>Rules for maximizing DRAM memory bandwidth:<ul>
<li>Possible bus transaction sizes: 32B, 64B, or 128B</li>
<li>Memory segment must be aligned: First address = multiple of segment</li>
<li>Hardware coalescing fro each half-warp: 16-word wide</li>
</ul>
</li>
</ul>
<p>Threads can access any words in any order, including the same words, and a single memory transaction for each segment addressed by a half-warp.</p>
<p>核心想法就是一次载入，尽量多次使用，减少访问次数。</p>
<h2 id="Use_of_Shared_Memory"><a href="#Use_of_Shared_Memory" class="headerlink" title="Use of Shared Memory"></a>Use of Shared Memory</h2><ul>
<li>Process:<ul>
<li>Load from DRAM to shared memory</li>
<li>Synchronize</li>
<li>Perform work on data in shared memory</li>
<li>Synchronize</li>
<li>Write out results to DRAM</li>
</ul>
</li>
</ul>
<p>Trick: Double Buffering</p>
<p>先载入到 global memory 再折腾到 shared memory</p>
<p>Declared a fixed sized variable at compile time</p>
<pre><code>__shared__ float As[BLOCK_SIZE][BLOCK_SIZE];
</code></pre><p>Define a size to be used at run time</p>
<pre><code>mykernel &lt;&lt;&lt;nBloks, nThds, shmemByteSize&gt;&gt;&gt;(a, objects);
在 kernel 函数中也需要进一步处理
</code></pre><h2 id="Memory_Bank_Conflicts"><a href="#Memory_Bank_Conflicts" class="headerlink" title="Memory Bank Conflicts"></a>Memory Bank Conflicts</h2><ul>
<li>Shared memory has 32 banks<ul>
<li>Organized such that successive 32-bit words are assigned to successive banks</li>
<li>Each bank has a bandwidth of 32 bits per two clock cycles (2 cycle latency)</li>
</ul>
</li>
</ul>
<p>A bank conflict occurs if two or more threads access any bytes within different 32-bit words belonging to the same bank.</p>
<p>如果访问的是同一个 bank 的同一个数据，那么多少个线程一起访问也不 conflict</p>
<h2 id="Padding_Technique"><a href="#Padding_Technique" class="headerlink" title="Padding Technique"></a>Padding Technique</h2><p>矩阵的那个如果不是整数可以考虑 padding</p>
<h2 id="Branch_divergence"><a href="#Branch_divergence" class="headerlink" title="Branch divergence"></a>Branch divergence</h2><p>Optimization: Factor out decision variables to have shorter sequence of divergent code</p>
<p>Branch divergence occurs only within a warp</p>
<h2 id="Optimizing_Instruction_Mix"><a href="#Optimizing_Instruction_Mix" class="headerlink" title="Optimizing Instruction Mix"></a>Optimizing Instruction Mix</h2><ul>
<li>Compiler Assisted Loop Unrolling<ul>
<li>Provides more instruction level parallelism for the compiler to use</li>
<li>Improves the ability for the compiler to find the instruction mix that instructions executed per cycle(IPC)</li>
</ul>
</li>
<li>By default, the compiler unrolls small loops with a know trip count</li>
<li>In CUDA, <code>#pragma unroll</code> directive can control unrolling of any given loop<ul>
<li>Must be placed immediately before the loop and only applies to that loop</li>
<li>Optionally followed by a number</li>
</ul>
</li>
</ul>
<h3 id="Device-only_CUDA_intrinsic_function"><a href="#Device-only_CUDA_intrinsic_function" class="headerlink" title="Device-only CUDA intrinsic function"></a>Device-only CUDA intrinsic function</h3><p>常用的数学计算有 gpu 版本替代</p>
<h2 id="Data_Parallel_Algorithms_-_Map"><a href="#Data_Parallel_Algorithms_-_Map" class="headerlink" title="Data Parallel Algorithms - Map"></a>Data Parallel Algorithms - Map</h2><p>Map: A fucntion that applies a given function to each element of a list , and returning a list of results</p>
<p>Two important properties:</p>
<ul>
<li>Side-effect free: Only returning a value, no modifications of state with the rest of the application</li>
<li>Independent: Has an independent piece of work, where its input does not depend on another function</li>
</ul>
<h2 id="Data_Parallel_Algorithm_-_Reduce"><a href="#Data_Parallel_Algorithm_-_Reduce" class="headerlink" title="Data Parallel Algorithm - Reduce"></a>Data Parallel Algorithm - Reduce</h2><p>Reduce: A function that takes in a list of objects and builds up a return value.</p>
<p>Important properties for parallel reduction:</p>
<ul>
<li>Associativity: a+(b+c) == (a+b)+c</li>
<li>Allows elements to be reduced in prarallel in a ‘tree’</li>
</ul>
<h2 id="Data_Parallel_Algorithms_-_Scan"><a href="#Data_Parallel_Algorithms_-_Scan" class="headerlink" title="Data Parallel Algorithms - Scan"></a>Data Parallel Algorithms - Scan</h2><p>Scan(prefix-sum): Takes a binary associative operator ⊕ with identity I, and an array of n elements [a0, a1, …, an-1] and returns the ordered set [I, a0, (a0⊕a1),…, (a0⊕a1⊕…⊕an-2)]</p>
<p>Example:</p>
<p>if ⊕ is addition, than scan on the set [3 1 7 0 4 1 6 3 ] returns the set [0 3 4 11 11 15 16 22]</p>
<p>Scan Algorithm in CUDA 4.0</p>
<h2 id="Data_Parallel_Algorithms_-_Compact"><a href="#Data_Parallel_Algorithms_-_Compact" class="headerlink" title="Data Parallel Algorithms - Compact"></a>Data Parallel Algorithms - Compact</h2><p>Compaction: Removing elements from an array - take in an array and produce an shorter array.</p>
<p>How do we perform removal in parallel?</p>
<ul>
<li>Map - create flags (1 keep, 0 remove)</li>
<li>Scan - compute index</li>
<li>Map - copy to new array</li>
</ul>
<p><img src="/images/14543391583932.jpg" alt=""></p>
<h2 id="Data_Parallel_Algorithms_-_FindUniq"><a href="#Data_Parallel_Algorithms_-_FindUniq" class="headerlink" title="Data Parallel Algorithms - FindUniq"></a>Data Parallel Algorithms - FindUniq</h2><p>FindUniq: Removing duplicates from an array - take in an set, produces an equal or smaller set of unique values</p>
<p><img src="/images/14543391502961.jpg" alt=""></p>
<p>在某些特殊情况可以利用 hash insertion 去掉 sort 的步骤, hash table 已经是有序的，就是打表的方法。</p>
<h2 id="Parallel_Software_Patterns"><a href="#Parallel_Software_Patterns" class="headerlink" title="Parallel Software Patterns"></a>Parallel Software Patterns</h2><p>A parallel software pattern is a generalizable solution to a class of recurring problems that occurs in the design of parallel software.</p>
<p>Attaches names to well-analyzed solutions that encapsulate the way an expert in the field solves problems.</p>
<p>Aims to achieve three goals:</p>
<ul>
<li>Define a set of vocabularies to communicate</li>
<li>Present a set of expert techniques for beginners to learn</li>
<li>Allows experts to more quickly design complex systems</li>
</ul>
<p><a href="http://parlab.eecs.berkely.edu/wiki/patterns/patterns" target="_blank" rel="external">Our Pattern Language</a></p>
<p>OPL: The Organization</p>
<p><img src="/images/14543391400653.jpg" alt=""></p>
<p>Structural Patterns:</p>
<ul>
<li>!Pipe-and-Filter</li>
<li>Agent-and-Repository</li>
<li>Event-based</li>
<li>Layered Systems</li>
<li>Model-view-constroller</li>
<li>Arbitrary Task Graphs</li>
<li>Puppeteer</li>
<li>Iterator/BSP</li>
<li>!MapReduce</li>
</ul>
<p>Monte Carlo Methods</p>
<h3 id="Applications_to_Your_Term_Projects"><a href="#Applications_to_Your_Term_Projects" class="headerlink" title="Applications to Your Term Projects"></a>Applications to Your Term Projects</h3><p><img src="/images/14543391286447.jpg" alt=""></p>
<h2 id="Distributed_Computing"><a href="#Distributed_Computing" class="headerlink" title="Distributed Computing"></a>Distributed Computing</h2><ul>
<li>Speedup not necessarily from better algorithm, but from scale</li>
<li>When an algorithms is converted to MapReduce it may operate significantly slower than sequential code on a single node</li>
<li>Mapping algorithms to a MapReduce framework is the challenge</li>
</ul>
<h2 id="Big_Data"><a href="#Big_Data" class="headerlink" title="Big Data"></a>Big Data</h2><ul>
<li>Web Data: Search, Advertisements, Behavioral data, Social graphs</li>
<li>Computational Physics Experiments<ul>
<li>Atomic Energy Research</li>
<li>Numerical Wind Tunnels</li>
</ul>
</li>
<li>The Earth Simulator<ul>
<li>Global Climate Change Research</li>
</ul>
</li>
<li>Weather Forecasting</li>
<li>The Human Genome Project, AIDS Research</li>
</ul>
<h2 id="Distributed_and_Cloud_Computing"><a href="#Distributed_and_Cloud_Computing" class="headerlink" title="Distributed and Cloud Computing"></a>Distributed and Cloud Computing</h2><ul>
<li>Distributed Computing<ul>
<li>Using distributed systems to solve computational problems.</li>
<li>Problem is divided in to many tasks, each of which is solved by one or more computers.</li>
</ul>
</li>
<li>Cloud Computing<ul>
<li>Distributed Computing on Cloud Resources</li>
</ul>
</li>
</ul>
<p>Distributed Computing on Cloud Computing Infrastructure = Scalable Computing</p>
<h2 id="Scalabel_Computing"><a href="#Scalabel_Computing" class="headerlink" title="Scalabel Computing"></a>Scalabel Computing</h2><ul>
<li>Embarrassingly parallel problems<ul>
<li>Shared Nothing Architecture</li>
</ul>
</li>
<li>Two dimensions of scalability<ul>
<li>Data: Given twice the amount of data, the same algorithm should take no more than twice as long to run</li>
<li>Resources: Given a cluster of twice the size, the same algorithm should take no more than half as long to run</li>
</ul>
</li>
</ul>
<h2 id="Big_Data-1"><a href="#Big_Data-1" class="headerlink" title="Big Data"></a>Big Data</h2><ul>
<li>Decompose the original problem in smaller, parallel tasks</li>
<li>Schedule tasks on workers distributed in a cluster<ul>
<li>Data locality</li>
<li>Resource availability</li>
</ul>
</li>
<li>Ensure Workers get the data they need</li>
<li>Coordinate synchronization among workers</li>
<li>Share partial results</li>
<li>Handle failures</li>
<li>Implementation details are complex</li>
<li>Shared memory approach(OpenMP)<ul>
<li>Developer needs to take case of almost everything</li>
<li>Synchronization, Concurrency</li>
<li>Resource Allocation</li>
</ul>
</li>
<li>MapReduce: a shared nothing approach<ul>
<li>Most of the above issures are taken care of</li>
<li>Problem decomposition and sharing partial results need particular attention</li>
<li>Optimization(memory and network consumption) are tricky</li>
</ul>
</li>
</ul>
<h2 id="Failures_in_Distributed_Computing"><a href="#Failures_in_Distributed_Computing" class="headerlink" title="Failures in Distributed Computing"></a>Failures in Distributed Computing</h2><ul>
<li>In large-scale distriuted computing, failure is ensured</li>
<li>Without fail-safe mechanisms distributed computing cannot work</li>
<li>HADOOP: MapReduce + HDFS(Hadoop Distributed Filesystem)<ul>
<li>Fail-safe Storage: By default stores 3 separate copies of each block</li>
<li>Fail-safe Task Management: Failed tasks re-scheduled up to 4 times</li>
</ul>
</li>
</ul>
<p>-&gt; Reliable and scalable computing</p>
<h2 id="HADOOP_-_26gt_3B_MapReduce"><a href="#HADOOP_-_26gt_3B_MapReduce" class="headerlink" title="HADOOP -&gt; MapReduce"></a>HADOOP -&gt; MapReduce</h2><ul>
<li>What is MapReduce?<ul>
<li>A programming model<ul>
<li>Inspired by function programming</li>
<li>Model to express distributed computations on massive amounts of data</li>
</ul>
</li>
<li>An execution framework<ul>
<li>Designed for large-scale data processing</li>
<li>Designed to run on clusters of commodity hardware</li>
</ul>
</li>
</ul>
</li>
<li>Separate the what from how<ul>
<li>Abstract away the “distributed” part of the system -&gt; handled by framework</li>
</ul>
</li>
<li>For optimal performance knowledge of framework is key<ul>
<li>Custom data reader/writer</li>
<li>Custom data partitioning</li>
<li>Memory utilization</li>
</ul>
</li>
</ul>
<h3 id="Map__26amp_3B_Reduce"><a href="#Map__26amp_3B_Reduce" class="headerlink" title="Map &amp; Reduce"></a>Map &amp; Reduce</h3><ul>
<li>Map: (map operation in functional programming)<ul>
<li>Transformation over a dataset</li>
<li>Apply a function f(x) to all elements in isolation</li>
<li>The application of f(x) to each element of a dataset can be parallelized in a straightforward manner</li>
</ul>
</li>
<li>Reduce: (fold operation in functional programming)<ul>
<li>Aggregation operation defined by a function g(x)</li>
<li>Data locality: elements in the list brought together</li>
<li>If we can group elements of the list, then reduce phase can proceed in parallel</li>
</ul>
</li>
<li>The framework coordinates the map and reduce phases<ul>
<li>How intermediate results are grouped for the reduce to happen in parallel</li>
</ul>
</li>
</ul>
<h3 id="Designing_a_MapReduce_algorithm"><a href="#Designing_a_MapReduce_algorithm" class="headerlink" title="Designing a MapReduce algorithm"></a>Designing a MapReduce algorithm</h3><ul>
<li>Key-value pairs are the basic data structures in MapReduce<ul>
<li>Keys and values can be: integers, strings, arbitrary data structures</li>
</ul>
</li>
<li>The design of a MapReduce algorithm involves:<ul>
<li>Define a key-value structures for application</li>
<li>Define mapper and reducer functions<ul>
<li>map: (k1,v1)-&gt;[(k2,v2)]</li>
<li>reduce: (k2,[v2]) -&gt; [(k3,v3)]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="A_MapReduce_Job"><a href="#A_MapReduce_Job" class="headerlink" title="A MapReduce Job"></a>A MapReduce Job</h3><ul>
<li>Dataset: stored on the underlying distributed filesystem<ul>
<li>Split across files and across machines</li>
</ul>
</li>
<li>Mapper: The mapper is applied to every input key-value pair to generate intermediate key-value pairs</li>
<li>Reducer: The reducer is applied to all values associated with the same intermediate key to generate output key-value pairs</li>
<li>A distributed “group by” operation is implicitly performed between the map and reduce phases<ul>
<li>Intermediate data arrives at each reducer in order, sorted by the key</li>
<li>No ordering is guaranteed across reducers</li>
</ul>
</li>
<li>Output Keys from reducers are written to distributed filesystem</li>
<li>Intermediate keys are transient</li>
</ul>
<h3 id="Simplified_View_of_MapReduce"><a href="#Simplified_View_of_MapReduce" class="headerlink" title="Simplified View of MapReduce"></a>Simplified View of MapReduce</h3><ul>
<li>Mappers applied to all input key-value pairs -&gt; generate intermediate pairs</li>
<li>Reducers applied to all intermediate values associated with the same intermediate key</li>
<li>Between map and reduce lies a barrier that involves a large distributed sort and group by</li>
</ul>
<h3 id="Word_Count_in_MapReduce"><a href="#Word_Count_in_MapReduce" class="headerlink" title="Word Count in MapReduce"></a>Word Count in MapReduce</h3><ul>
<li>Define the appropriate key-value structures?<ul>
<li>Input (docid, doc)</li>
<li>Mapper (word, 1)</li>
<li>Output (word, C(word))</li>
</ul>
</li>
<li>Define Mapper and Reducer functions<ul>
<li>Mapper: tokenize the document, outputs key-value (word, 1)</li>
<li>The framework guarantees all values associated with the same key(word) are brought to the same reducer</li>
<li>Reducer: receives all values associated to some key (word)</li>
<li>Sums the values and writes output key-value pairs(word, C(word))</li>
</ul>
</li>
</ul>
<h3 id="Implementation_Details"><a href="#Implementation_Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><ul>
<li>A partitioned is in charge of assigning intermediate keys(words) to reducers<ul>
<li>Partitioner can be customized</li>
</ul>
</li>
<li>How many map and reduce tasks?<ul>
<li>The framework essentially takes care of map tasks</li>
<li>The designer/developer takes care of reduce tasks</li>
</ul>
</li>
</ul>
<h3 id="A_MapReduce_Job_on_Hadoop"><a href="#A_MapReduce_Job_on_Hadoop" class="headerlink" title="A MapReduce Job on Hadoop"></a>A MapReduce Job on Hadoop</h3><p>Master-slave architecture</p>
<ul>
<li>JobTrackerNode creating object for the job, determines number of mappers/reduces, schedules jobs, bookkeeping tasks’ status and progress</li>
<li>TaskTrackerNode: slaves manages individual tasks</li>
</ul>
<h2 id="HADOOP_-_26gt_3B_HDFS"><a href="#HADOOP_-_26gt_3B_HDFS" class="headerlink" title="HADOOP -&gt; HDFS"></a>HADOOP -&gt; HDFS</h2><ul>
<li>Improve computing throughput by co-locating data and computation</li>
<li>Abandon the separation between compute and storage nodes<ul>
<li>Not mandatory but highly desirable for MapReduce computing</li>
</ul>
</li>
<li>Distributed filesystems:<ul>
<li>Write once, read many workloads</li>
<li>Does not handle concurrency, but allows replication</li>
<li>Optimized for throughput not latency</li>
</ul>
</li>
<li>HDFS(Hadoop Distributed FileSystem)<ul>
<li>Tailored to the specific requirements of MapReduce</li>
</ul>
</li>
</ul>
<h3 id="HDFS_I/O"><a href="#HDFS_I/O" class="headerlink" title="HDFS I/O"></a>HDFS I/O</h3><ul>
<li>A typical read from a client involves:<ul>
<li>Contact the NameNode to determine where the actual data is stored</li>
<li>NameNode replies with block identifiers and locations(which DataNode)</li>
<li>Contact the DataNode to fetch data</li>
</ul>
</li>
<li>A typical write from a client invovles:<ul>
<li>Contact the NameNode to update the namespace and verify permissions</li>
<li>NameNode allocates a new block on a suitable DataNode</li>
<li>The client directly streams to the selected DataNode</li>
<li>HDFS files are immutable</li>
</ul>
</li>
<li>Data is never moved through the NameNode -&gt; no bottleneck</li>
</ul>
<h3 id="HDFS_Replication"><a href="#HDFS_Replication" class="headerlink" title="HDFS Replication"></a>HDFS Replication</h3><ul>
<li>By default, HDFS stores 3 separate copies of each block<ul>
<li>Ensures reliability, availability and performance</li>
</ul>
</li>
<li>Replication policy<ul>
<li>Spread replicas across different racks -&gt; Robust against cluster node and rack failures</li>
</ul>
</li>
<li>Block replication benefits MapReduce<ul>
<li>Scheduling decisions can take replicas into account</li>
<li>Exploit better data locality</li>
</ul>
</li>
<li>HDFS also transparently checksums all data during I/O</li>
</ul>
<h3 id="HDFS_Constraints"><a href="#HDFS_Constraints" class="headerlink" title="HDFS Constraints"></a>HDFS Constraints</h3><ul>
<li>Input splits for MapReduce based on individual files<ul>
<li>Mappers are launched for every file</li>
<li>High startup correctness</li>
<li>Inefficient “shuffle and sort”</li>
</ul>
</li>
</ul>
<p>Small number of large files preferred over a large number of small files</p>
<h2 id="Cloud_Computing_-_Advantages"><a href="#Cloud_Computing_-_Advantages" class="headerlink" title="Cloud Computing - Advantages"></a>Cloud Computing - Advantages</h2><ul>
<li>Illusion of infinite computing resources on demand</li>
<li>Elimination of an up-front commitment by user</li>
<li>Ability to pay for use of computing resources on a short-term basis as needed</li>
<li>Lowering entry barrier for large scale computing<ul>
<li>Removing equipment fixed cost</li>
</ul>
</li>
<li>Making available economy-of-scale<ul>
<li>Reducing operating variable cost</li>
</ul>
</li>
</ul>
<h2 id="Developing_Algorithms_in_Hadoop"><a href="#Developing_Algorithms_in_Hadoop" class="headerlink" title="Developing Algorithms in Hadoop"></a>Developing Algorithms in Hadoop</h2><ul>
<li>Algorithm development involves:<ul>
<li>preparing the input data</li>
<li>Implement the mapper and the reducer</li>
<li>Optionally, design the combiner and the partitioner</li>
</ul>
</li>
<li>How to recast existing algorithms in MapReduce?<ul>
<li>It is not always obvious how to express algorithms</li>
<li>Data structures play an important role</li>
<li>Optimization is hard</li>
</ul>
</li>
<li>Developer needs to understand the framework</li>
<li>Learn by examples<ul>
<li>Design Patterns</li>
<li>Synchronization is most trick aspect</li>
</ul>
</li>
</ul>
<h2 id="Efficiency_2C_Bottlenecks__26amp_3B_Precautions"><a href="#Efficiency_2C_Bottlenecks__26amp_3B_Precautions" class="headerlink" title="Efficiency, Bottlenecks &amp; Precautions"></a>Efficiency, Bottlenecks &amp; Precautions</h2><ul>
<li>Efficiency<ul>
<li>Reduces I/O bandwidth(number of intermediate key-value pairs)</li>
<li>Un-necessary object creation and destruction(garbage collection)</li>
</ul>
</li>
<li>Bottlenecks<ul>
<li>In-mapper combining depends on having sufficient memory</li>
<li>Multiple threads compete for same resources</li>
</ul>
</li>
<li>Precautions<ul>
<li>Breaks functional programming paradigm due to state preservation</li>
<li>Preserving state -&gt; algorithm behavior might depend on execution order</li>
</ul>
</li>
</ul>
<h2 id="How_do_you_interpret_speedup_results_3F"><a href="#How_do_you_interpret_speedup_results_3F" class="headerlink" title="How do you interpret speedup results?"></a>How do you interpret speedup results?</h2><p>Based on the PALLAS paper from UC Berkeley</p>
<ul>
<li>(SW) Application Developers<ul>
<li>Provide end-user with new capabilites within cost constraints</li>
<li>Concerned about a specific subset of applications at a time</li>
<li>Pragmatic towards processor platform choices</li>
<li>Gains no value from documenting multiple implementation platforms</li>
<li><strong>Platform as a black box</strong></li>
</ul>
</li>
<li>(HW) Architecture Researchers<ul>
<li>Develop new micro-architectures features for next-gen processors</li>
<li>Understand the pros and cons of architectural features of a <strong>broad range</strong> of platform for a <strong>broad range</strong> of applications</li>
<li>Use <strong>toy problems</strong> to exercise all features</li>
<li><strong>Application as a black box</strong></li>
</ul>
</li>
</ul>
<h2 id="Computational_Finance"><a href="#Computational_Finance" class="headerlink" title="Computational Finance"></a>Computational Finance</h2><p>Use Value-at-Risk(VaR) estimates - based on Monte Carlo methods Pattern.</p>
<ul>
<li><p>VaR</p>
<ul>
<li>Maximum expected loss that will not be exceeded</li>
<li>under normal market considerations</li>
<li>over a predetermined period</li>
<li>at a given confidence level</li>
</ul>
</li>
<li><p>Different Optimization Across Platforms</p>
<ul>
<li>Oganization &amp; Structure: Reduce Computation</li>
<li>Algorithm Strategies: Fast Convergence</li>
<li>Implementation Strategies: Saving Memory BW / Kernel Merge Vectorization</li>
</ul>
</li>
</ul>
<h2 id="Speedup"><a href="#Speedup" class="headerlink" title="Speedup"></a>Speedup</h2><p>Before: Performance x  – After: Performance y – ROI(speedup): y/x</p>
<h2 id="Term_Project_Report"><a href="#Term_Project_Report" class="headerlink" title="Term Project Report"></a>Term Project Report</h2><ul>
<li>Clearly describe what is the <strong>baseline</strong> you are comparing to, in terms of:<ul>
<li>Platform used</li>
<li>Software architecture</li>
<li>Algorithm strategies</li>
<li>Implementation strategies</li>
</ul>
</li>
<li>Present your speed ups, which is often <strong>NOT</strong> only the result of differences in the processor or the platform, but also include:<ul>
<li>Differences in application architecture</li>
<li>Differences in algorithm strategy</li>
<li>Differences in implementation strategy techniques</li>
<li>Differences in the fine-tuning of parameters</li>
</ul>
</li>
</ul>
<hr>
<h1 id="Question_Set"><a href="#Question_Set" class="headerlink" title="Question Set"></a>Question Set</h1><h2 id="Module_1-2"><a href="#Module_1-2" class="headerlink" title="Module 1.2"></a>Module 1.2</h2><ul>
<li>What are the differences between multicore and manycore processors?<ul>
<li>Multicore: yoke of oxen. Each core optimized for executing a single thread.</li>
<li>Manycore: flock of chickens. Cores optimized for aggregate throughput, deemphasizing individual performance.</li>
</ul>
</li>
<li>What is instruction level parallelism? What is SIMD?<ul>
<li>ILP: Instructions in a sequence that can be computed at the same time.</li>
<li>ILP(wiki): a measure of how many of the operations in a computer program can be performed simultaneously</li>
<li>SIMD(wiki): computers with multiple processing elements that perform the same operation on multiple data points simultaneously. data level parallelism. </li>
</ul>
</li>
<li>What is simultaneous multithreading?<ul>
<li>a technique for improving the overall efficiency of superscalar CPUs with hardware multithreading. SMT permits multiple independent threads of execution to better utilize the resources provided by modern processor architectures.</li>
</ul>
</li>
<li>What are the three metrics for a memory hierarchy?<ul>
<li>Capacity: Size, e.g. number of bytes of data</li>
<li>Latency: From start to finish, in units of time, e.g. CPU clock cycles</li>
<li>Throughput: Tasks accomplished per unit time, e.g. GB/s</li>
</ul>
</li>
<li>What are the different system granularity?<ul>
<li>Remote Procedure Call based Implementations</li>
<li>MPI-based Implementations</li>
<li>Pthread-based Implementations</li>
<li>Multicore Task Queue-based Implementations</li>
<li>Manycore Throughput Optimized Implementations</li>
</ul>
</li>
</ul>
<h2 id="Module_1-3"><a href="#Module_1-3" class="headerlink" title="Module 1.3"></a>Module 1.3</h2><ul>
<li>What is the different between concurrency and parallelism?<ul>
<li>Concurrency: We expose concurrency in our application</li>
<li>Parallelism: We exploit parallelism in our platform</li>
</ul>
</li>
<li>What are the four key elements of the human problem solving process?<ul>
<li>Understand the current state</li>
<li>Observe the internal representation</li>
<li>Search among alternatives</li>
<li>Select from a set of choices</li>
</ul>
</li>
<li>What are the characteristics of a current algorithm implementation?<ul>
<li>Efficiency</li>
<li>Simplicity</li>
<li>Portablility</li>
<li>Scalability</li>
</ul>
</li>
<li>What levels of concurrency can be exposed in the kmeans algorithm?<ul>
<li>Expectation: N(independent) k(min reduction) D(sum reduction)</li>
<li>Maximization: D(independent) N(Histogram computation into k bins)</li>
</ul>
</li>
<li>What levels of parallelism are available to be exploited?<ul>
<li>Core level Parallelism</li>
<li>SIMD level parallelism</li>
</ul>
</li>
<li>What mapping between concurrency and parallelism can be explored?<ul>
<li>One level of concurrency could map to multiple levels of parallelism</li>
<li>SIMD &amp; core-level parallelism across data-points<ul>
<li>Update membership for each data point sequentially</li>
<li>Histogram computation</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Module_2-1"><a href="#Module_2-1" class="headerlink" title="Module 2.1"></a>Module 2.1</h2><ul>
<li>What are the exploitable levels of parallelism in a multicore processor?<ul>
<li>SIMD-Level: using vectorizing compiler and hand-code intrinsics</li>
<li>SMT-Level: OS abstract it to core-level parallelism</li>
<li>Core-Level: Using threads to describe work done on different cores</li>
</ul>
</li>
<li>What is SPMD? And how to use OpenMP to do SPMD?<ul>
<li>OpenMP - Pthread-based Implementations(granularity)</li>
<li>SPMD(wiki): SPMD (single program, multiple data) is a technique employed to achieve parallelism; it is a subcategory of MIMD. Tasks are split up and run simultaneously on multiple processors with different input in order to obtain results faster.</li>
<li>OpenMP managed <strong>Fork-Join</strong> Parallelism to do SPMD</li>
</ul>
</li>
<li>What is the difference between critical and atomic?<ul>
<li>critical: 并行程序块，同时只能有一个线程能访问该并行程序块</li>
<li>atomic: 只适用于两种情况：自加减操作以及基本的操作符</li>
<li>critical 与 atomic 的区别在于，atomic 仅适用于两种基本类型操作，而且 atomic 所防护的仅为一句代码。critical 可以对某个并行程序块进行防护。</li>
</ul>
</li>
<li>How to reduce synchronization cost and avoid false sharing?<ul>
<li>Be aware of the cache line sizes for a platform</li>
<li>Avoid accessing the same cache line from different threads</li>
</ul>
</li>
<li>What are the scheduling, reduction, data sharing, and synchronization options for OpenMP?<ul>
<li>scheduling<ul>
<li>static</li>
<li>dynamic</li>
<li>guided</li>
</ul>
</li>
<li>data sharing<ul>
<li>shared</li>
<li>private</li>
<li>firstprivate</li>
<li>lastprivate</li>
</ul>
</li>
<li>synchronization<ul>
<li>ordered</li>
<li>barrier</li>
<li>single</li>
<li>nowait</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="21_21_Module_2-2"><a href="#21_21_Module_2-2" class="headerlink" title="!! Module 2.2"></a>!! Module 2.2</h2><ul>
<li>Why naive matrix-multiply does not achieve peak performance on the CPU?<ul>
<li>Deep memory hierarchy</li>
<li>Pipeline, ILP</li>
<li>Free operations are not free</li>
</ul>
</li>
<li>What are the different data layouts for matrices?<ul>
<li>Column major</li>
<li>Row major</li>
</ul>
</li>
<li>What is cache blocking? Why do we need it?</li>
<li>Is blocking sufficient? What more can we do?<ul>
<li>Strength reduction</li>
<li>Function inlining</li>
<li>Loop unrolling</li>
<li>Common subexpression elimination</li>
<li>Load/Store elimination</li>
<li>Table lookups</li>
<li>Branch elimination</li>
</ul>
</li>
</ul>
<h2 id="Module_2-3"><a href="#Module_2-3" class="headerlink" title="Module 2.3"></a>Module 2.3</h2><ul>
<li>What is the roofline model? What are the metrics and axis used?<ul>
<li>Roofline model: a pedagogical tool for program analysis and optimization</li>
<li>Metric of interest: DRAM bandwidth(GB/s)</li>
<li>y-axis: FLOPs; x-axis: AI</li>
</ul>
</li>
<li>What is the difference between “flop’s per memory instruction” from “flop’s per DRAM byte”?<ul>
<li>?</li>
</ul>
</li>
<li>Consider an image <code>Image[height][width]</code>. If one were to stride through the columns of values, what would be the effects? How would they be mapped to the roofline?<ul>
<li>?</li>
</ul>
</li>
<li>How does one model incomplete SIMDization (e.g. half the flop’s can be SIMDized). insufficient ILP(some dependent flop’s), or an imbalance between FDMUL’s and FPADD’s on the roofline?<ul>
<li>See the complete graph below</li>
</ul>
</li>
<li>How would one model {branch mispredicts, TLB misses, or too many streams for the prefetchers} on the roofline.<ul>
<li>See the complete graph below</li>
</ul>
</li>
</ul>
<p><img src="/images/14543392317490.jpg" alt=""></p>
<h2 id="Module_3-1"><a href="#Module_3-1" class="headerlink" title="Module 3.1"></a>Module 3.1</h2><ul>
<li>What’s the Difference between Multicore and Manycore?<ul>
<li>Multicore: yoke of oxen. Each core optimized for executing a single thread.</li>
<li>Manycore: flock of chickens. Cores optimized for aggregate throughput, deemphasizing individual performance.</li>
</ul>
</li>
<li>When does using a GPU make sense?<ul>
<li>Application with a lot of concurrency (1000-way, fine-grained concurrency)</li>
<li>Some memory intensive applications (Aggregate memory bandwidth is higher)</li>
<li>Advantage diminishes when task granularity becomes too large to fit in shared memory</li>
</ul>
</li>
<li>What is the memory hierarchy inversion? And why is it there?<ul>
<li>Memory hierarchy inversion: more registers than shared memory</li>
<li>Single thread won’t see inverse hierarchy</li>
<li>Inversion comes from parallelism</li>
<li>Registers scale with SIMD and multithreading (Shared memory/L1 cache don’t have to)</li>
</ul>
</li>
<li>What is the memory wall? How to get around it?<ul>
<li>Memory wall: Increasing gap between Processor and DRAM performance</li>
<li>Many core Processors utilize application concurrency to hide memory latency (aka get around the memory wall)</li>
</ul>
</li>
<li>Why warps?<ul>
<li>Software abstract info hid an extra level of architecture complexity</li>
<li>A 128KB register file is a large memory (takes more than one cycle)</li>
<li>Hardware provide 160wide physical SIMD units, half-pump register files</li>
<li>To simplify the programming model</li>
</ul>
</li>
<li>How do we deal with GPUs of different sizes?<ul>
<li>CUDA provides an abstract infor concurrency to be fully exposed</li>
<li>HW/Runtime provides capability to schedule the computation</li>
</ul>
</li>
<li>What are the implications of the thread block abstraction?<ul>
<li>Computation is grouped into blocks of independent concurrently execrable work</li>
<li>Fully exposed the concurrency in the application</li>
<li>The HW/Runtime makes the decision to selectively sequentialize the execution as necessary</li>
</ul>
</li>
<li>How do threads communicate with each other?<ul>
<li>Shared Memory</li>
<li>Manycore processors provide memory local to each core</li>
<li>Computations in SIMD-lanes in the same core can communicate via memory read / write</li>
</ul>
</li>
<li>What is the caveat in synchronizing threads in a thread block?<ul>
<li><code>__syncthreads()</code> 必须在每个线程中都能执行到，而不能有的有有的没有</li>
</ul>
</li>
</ul>
<h2 id="Module_3-2"><a href="#Module_3-2" class="headerlink" title="Module 3.2"></a>Module 3.2</h2><ul>
<li>What are the three ways to improve execution throughput?<ul>
<li>Maximizing Memory Throughput<ul>
<li>SoA vs AoS</li>
<li>Memory coalescing</li>
<li>Use of shared memory</li>
<li>Memory bank conflict</li>
<li>Padding</li>
</ul>
</li>
<li>Maximizing Instruction Throughput<ul>
<li>Branch divergence</li>
<li>Optimize instruction mix</li>
</ul>
</li>
<li>Maximizing Scheduling Throughput</li>
</ul>
</li>
<li>When to use SOA vs AOS?<ul>
<li>Unfortunately, the SoA form is not ideal in all circumstances. For random or incoherent circumstances, gathers are used to access the data and the SoA form can result in extra unneeded data being read into cache, thus reducing performance. In this case, use of the AoS form instead will result in a smaller working set and improved performance. Generally, though, if the computation is to be vectorized, the SoA form is preferred.</li>
</ul>
</li>
<li>What is memory coalescing? When to use it? Why is it important?<ul>
<li>Memory coalescing: combine multiple memory accesses generated from multiple threads into a single physical transaction</li>
<li>Hardware Constraint: DRAM is accessed in ‘segments’ of 32B/64B/128B</li>
</ul>
</li>
<li>What is shared memory? How to use it?<ul>
<li>Manycore processors provide memory local to each core</li>
<li><code>__share__</code></li>
</ul>
</li>
<li>What is memory bank conflict? How to work around it?<ul>
<li>A bank conflict occurs if two or more threads access any bytes within different 32-bit words belonging to the same bank.</li>
<li>If each thread in a halfwarp accesses successive 32bit values there are no bank conflicts.</li>
</ul>
</li>
<li>What is branch divergence?<ul>
<li>threads of a warp diverge via a data-dependent conditional branch</li>
</ul>
</li>
<li>How to optimize for instruction mix?<ul>
<li>Compiler Assisted Loop Unrolling</li>
<li>#pragma unroll</li>
</ul>
</li>
<li>What is occupancy? How to model/measure it?<ul>
<li>Occupancy: Ability of a CUDA kernel to occupy concurrent contexts in a SM</li>
<li>CUDA Occupancy Calculator</li>
<li><code>--ptxas-options=-v</code></li>
</ul>
</li>
<li>How to use the code profiler with CUDA?<ul>
<li>CUDA Profiler Tutorial by Erik Reed</li>
</ul>
</li>
</ul>
<h2 id="Module_3-3"><a href="#Module_3-3" class="headerlink" title="Module 3.3"></a>Module 3.3</h2><ul>
<li>What are the important properties of a Map function?<ul>
<li>Side-effect free: Only returning a value, no modifications of state with the rest of the application</li>
<li>Independent: Has an independent piece of work, where its input does not depend on another function</li>
</ul>
</li>
<li>What are the important properties of a Reduce function?<ul>
<li>Associativity: a+(b+c) == (a+b)+c</li>
<li>Allows elements to be reduced in prarallel in a ‘tree’</li>
</ul>
</li>
<li>What are the important properties of s Scan function?<ul>
<li>return a ordered set</li>
</ul>
</li>
<li>How to compact an array in a data-parallel way?<ul>
<li>Map - create flags (1 keep, 0 remove)</li>
<li>Scan - compute index</li>
<li>Map - copy to new array</li>
</ul>
</li>
<li>How to find unique elements in an array in a data-parallel way?<ul>
<li>Sort</li>
<li>Map - create flags (1 keep, 0 remove)</li>
<li>Scan - compute index</li>
<li>Map - copy to new array</li>
</ul>
</li>
</ul>
<h2 id="Module_3-4"><a href="#Module_3-4" class="headerlink" title="Module 3.4"></a>Module 3.4</h2><ul>
<li>What are parallel software patterns?</li>
<li>What are the three goals the software patterns aim to achieve?</li>
<li>What is a software architecture?</li>
<li>How is it important for writing fast code?</li>
<li>What the the five categories of patterns in OPL?</li>
<li>What are the nine sections in an OPL pattern?</li>
<li>What are the areas of consideration for your Term Project?</li>
</ul>
<h2 id="Module_4-1"><a href="#Module_4-1" class="headerlink" title="Module 4.1"></a>Module 4.1</h2><ul>
<li>Why Distributed Computing?</li>
<li>How common are failures in Large Scale Distributed Computing?</li>
<li>How are failures handled in HADOOP?</li>
<li>What is MapReduce?</li>
<li>When developing a MapReduce application what components and functions need to be defined?</li>
<li>How are data bottlenecks reduced in HDFS?</li>
<li>What are the advantages of Cloud Computing?</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>本来打算借着当助教，看看这门课有没有什么变化。事实上，没啥变化，所以这里先把当时我的笔记放出来，之后的课程可能会主要集中于代码和项目的思路分析，具体理论的东西不会再重复太多。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="思考题" scheme="http://wdxtub.com/tags/%E6%80%9D%E8%80%83%E9%A2%98/"/>
    
      <category term="笔记" scheme="http://wdxtub.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="编程" scheme="http://wdxtub.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[游戏引进评估的一些思考]]></title>
    <link href="http://wdxtub.com/2016/02/01/game-import/"/>
    <id>http://wdxtub.com/2016/02/01/game-import/</id>
    <published>2016-02-01T14:57:08.000Z</published>
    <updated>2016-02-01T14:23:15.000Z</updated>
    <content type="html"><![CDATA[<p>最近要面一个游戏引进评估的职位，因为网上的资料实在很少，所以自己总结思考了三个方面。虽然难免流于纸上谈兵，但也比什么都不准备想当然要好得多。</p>
<a id="more"></a>
<hr>
<p>游戏评估算是非技术类职位，因为面试内容不是算法题，所以前期准备的空间很大。这也就意味着，首先需要确定一个整体的思路，不然很容易迷失在繁杂的细节当中。对于任何一场面试，面任何一个职位，从公司发布的职位描述开始，往往不会错。虽然职位描述大多比较宽泛抽象，但至少可以给我们一个大方向。</p>
<p>例如，我大致浏览了一下不同公司对游戏评估类似职位的描述，主要强调的工作内容和能力有以下几点：</p>
<ul>
<li>寻找、评估、谈判，完善甄别评估体系</li>
<li>了解市面上的游戏，对行业有基本了解</li>
<li>市场和竞争产品的关注与分析</li>
</ul>
<p>游戏评估其实和其他的可行性分析工作一样，需要在确定的大方向下，可以切分出不同的维度，在各个维度上进行调查、研究和分析，对于是否要引进一个游戏来说，主要可以分成这三个维度：</p>
<ol>
<li>游戏质量评估：游戏本身的质量如何，涉及到许多关于游戏设计的概念，也是本文着力想要说明的</li>
<li>游戏运营评估：游戏是否适合本地化运营，包括对应的改动及处理好文化差异</li>
<li>具体事务评估：这一部分比较杂，是除了质量和运营外的诸多因素的综合考虑，比方说研发团队的从业经历，是否是经典题材，投资方等等</li>
</ol>
<p>因为不确定面试时具体要讨论哪方面（当然也可能我想得全 miss），所以这三个方面都会写一下，算是一个思考和总结</p>
<h2 id="u6E38_u620F_u8D28_u91CF_u8BC4_u4F30"><a href="#u6E38_u620F_u8D28_u91CF_u8BC4_u4F30" class="headerlink" title="游戏质量评估"></a>游戏质量评估</h2><p>对一个游戏进行评估，主要可以从以下五个维度来进行（这些同时也与营销策略的制定密切相关）：</p>
<ul>
<li>核心体验：游戏类型，游戏乐趣的主要来源，玩家进行游戏的主要动机</li>
<li>基础机制：长中短期目标是否明确，规则是否清晰，策略与运气（其实就是数值）是否平衡</li>
<li>奖惩系统：玩家在胜利和失败时会得到什么，是用什么方式来处理可能产生的挫败感</li>
<li>长期激励：游戏通过什么方式让玩家愿意持续去进行游戏，荣誉/惊喜/等级/任务/社交/玩法/奖励/活动等等</li>
<li>美学布局：剧情，画面，界面设计，音乐音效，动画效果，色彩色调及它们对玩家心理的影响</li>
</ul>
<p>这里面每一点如果展开，都是几天几夜说不完的，所以简单挑一些比较清晰直白的来进行描述。比方说，如果要分析游戏乐趣从哪里来，那么基本就逃不开下面八种模式：</p>
<ol>
<li>竞争：竞速，占领版图等等</li>
<li>达到目标：比方说达到一定等级或者是拥有某些装备</li>
<li>战胜：可以是 PVP，PVE，也可以是完成设定好的挑战</li>
<li>合作：多人副本，公会，社交</li>
<li>角色扮演：属性成长，剧情带入</li>
<li>探索和建设：开放世界沙盒类游戏</li>
<li>收集：一些需要积累的任务，或者是类似偷菜这种以收集为主体的游戏</li>
<li>解决问题或制定策略：即时战略与益智游戏等等</li>
</ol>
<p>我们发现，其实目前许多游戏早已涵盖了几个甚至全部的游戏模式。通过这种大而全的策略来笼络各类玩家。而这些乐趣的来源，实际上是玩家进行游戏的动机的具象化，玩家的动机主要是以下这些：权力、好奇心、独立性、地位、社会联系、复仇、荣誉、理想主义、锻炼身体、浪漫、嫁人、整理、饮食、接受、宁静、存储等等。</p>
<p>玩家的类型也是多种多样的，评估的时候也需要考虑到游戏的主要受众，比方说：社交家，自由者，成就者，慈善家，玩家（这里指研究游戏系统），破坏者等等。最好根据不同的特点来进行对应的评估。</p>
<p>最重要的一个部分，可能是文化层面的契合度分析。日韩游戏和我们的理念比较接近，但是欧美的可能就差别比较大了。经济、文化、信息渠道和用户习惯的巨大差异，使得游戏引进需要更加细致的评估。比方说，欧美玩家更加崇尚通过长时间的努力来磨练技艺，而中国玩家则更愿意直接砸钱甩出优越感，这可能就需要对游戏本身的玩法和逻辑进行一定调整了。</p>
<p>而文化层面的评估，还可以更加细化，如：</p>
<ul>
<li>人文：背景、故事、历史、神话、宗教、民俗、语言（不同文化间可能差异巨大）</li>
<li>视听：画面、布局、声乐、美术、色彩、动画</li>
<li>资源管理：人口、管理、经济、数值、统计</li>
<li>空间：建筑、地理、气候、农业、畜牧业、化学</li>
<li>用户行为：玩家类型、社交、心理、战略</li>
</ul>
<p>这里就不展开了。</p>
<h2 id="u6E38_u620F_u8FD0_u8425_u8BC4_u4F30"><a href="#u6E38_u620F_u8FD0_u8425_u8BC4_u4F30" class="headerlink" title="游戏运营评估"></a>游戏运营评估</h2><p>如果游戏的质量过硬，还需要考虑具体运营的时候，能否顺利进行本土化处理，比方说，处理好文本，表达方式，接受习惯的差异，添加本地化支付方式等。还需要考虑的问题有；</p>
<ul>
<li>依赖鲸鱼玩家 vs 依赖众多小额付费玩家（微交易-比方说花一块钱复活）</li>
<li>性能数据、过程数据、用户数据</li>
<li>消费者指标、社区指标、玩法指标（可以通过观察不同地区 App Store 排行榜，百度指数，贴吧论坛等的人气变化来进行评估）</li>
<li>能够让玩家维持多久的游戏时间，这种玩法的接受度有多高</li>
<li>目标群体（人数，人口特征，消费能力）以及游戏地点（居家休闲，旅途，工作间隙，还是需要专门拿出一段时间来游戏）</li>
</ul>
<h2 id="u5177_u4F53_u4E8B_u52A1_u8BC4_u4F30"><a href="#u5177_u4F53_u4E8B_u52A1_u8BC4_u4F30" class="headerlink" title="具体事务评估"></a>具体事务评估</h2><p>这里简单提一些需要注意的问题：</p>
<ul>
<li>研发团队的从业经历</li>
<li>是否源自经典题材的拓展（横向、纵向）</li>
<li>游戏数据表现</li>
<li>投资方与并购方</li>
<li>游戏题材的情怀与玩家共鸣</li>
<li>与当红游戏进行对比</li>
<li>是否有明星等进行广泛影响（比方说 Guitar Hero 在北美就有很多大牌明星代言）</li>
<li>行业竞赛及所得奖项</li>
</ul>
<p>具体工作中肯定还会遇到比这个详尽繁杂得多的问题，这里就算是梳理下思路了。</p>
<h2 id="u9644_u5F55_uFF1A_u817E_u8BAF_u5F15_u8FDB/_u4EE3_u7406_u6E38_u620F_u5217_u8868"><a href="#u9644_u5F55_uFF1A_u817E_u8BAF_u5F15_u8FDB/_u4EE3_u7406_u6E38_u620F_u5217_u8868" class="headerlink" title="附录：腾讯引进/代理游戏列表"></a>附录：腾讯引进/代理游戏列表</h2><p>手游：</p>
<p>火影忍者 / 奇迹暖暖 / 糖果传奇 / 我叫 MT 2 / 仙剑 / 宫爆老奶奶 / Two Dots / 全民切水果 / 胜利足球 / FIFA ONLINE 3 M / 复仇者联盟</p>
<p>端游</p>
<p>剑灵（NCSoft）/ 地下城与勇士 / 寻仙 / 天堂（NCSoft）/ 英雄联盟 / 穿越火线 / NBA 2K OL（Take-Two）/ Call of Duty Online（动视暴雪）/ 自由足球 / 战争前线（Crytek）/ 战地之王（Redduck）/ 超神英雄HON（S2 Games）/ 上古世纪 / 怪物猎人（Capcom）/ 疾风之刃（Allm）/ 兽人必须死（Robot）/ 全职大师（NCSoft）/</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>最近要面一个游戏引进评估的职位，因为网上的资料实在很少，所以自己总结思考了三个方面。虽然难免流于纸上谈兵，但也比什么都不准备想当然要好得多。</p>]]>
    
    </summary>
    
      <category term="引进" scheme="http://wdxtub.com/tags/%E5%BC%95%E8%BF%9B/"/>
    
      <category term="游戏" scheme="http://wdxtub.com/tags/%E6%B8%B8%E6%88%8F/"/>
    
      <category term="评估" scheme="http://wdxtub.com/tags/%E8%AF%84%E4%BC%B0/"/>
    
      <category term="面试" scheme="http://wdxtub.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Game" scheme="http://wdxtub.com/categories/Game/"/>
    
  </entry>
  
</feed>
