<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[小土刀]]></title>
  <subtitle><![CDATA[Agony is my triumph]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://wdxtub.com/"/>
  <updated>2016-02-02T20:59:49.000Z</updated>
  <id>http://wdxtub.com/</id>
  
  <author>
    <name><![CDATA[wdxtub]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[云计算 第 11 课 Horizontal Scaling and Advanced Resource Scaling]]></title>
    <link href="http://wdxtub.com/2016/02/01/cc-11/"/>
    <id>http://wdxtub.com/2016/02/01/cc-11/</id>
    <published>2016-02-01T19:55:20.000Z</published>
    <updated>2016-02-02T20:59:49.000Z</updated>
    <content type="html"><![CDATA[<p>经过上一节课的『锻炼』，这一次我们要迎来更大的挑战。前面很多时候都是通过 Web 界面来进行云资源的管理，这里我们需要学会如何用代码来申请和控制各种资源。</p>
<a id="more"></a>
<hr>
<h2 id="u5B66_u4E60_u76EE_u6807"><a href="#u5B66_u4E60_u76EE_u6807" class="headerlink" title="学习目标"></a>学习目标</h2><p>这一次课时间紧任务重，需要掌握的知识和技能有：</p>
<ol>
<li>根据需求利用代码通过云 API 来申请所需资源</li>
<li>能够在故障、花费和性能等限制条件下完成 web 服务的部署</li>
<li>对比 AWS 和 Azure 在 API 使用上的不同</li>
<li>能够识别和说明处理资源故障的必要性</li>
<li>能够解释在所有资源间保证负载均衡的必要性</li>
<li>在 Azure 的 VM Scale Set 上配置和部署一个负载均衡器 Load Balancer</li>
<li>在 AWS 的 Auto Scaling Group 上配置和部署一个 Elastic Load Balancer</li>
<li>完成能够处理资源失败的解决方案</li>
<li>在申请云资源的时候考虑花费这一限制因素</li>
<li>分析最大化性能和可靠性与成本之间的权衡</li>
</ol>
<p>有一些需要注意的地方</p>
<ul>
<li>记得打标签（EC2, ELB, ASG）</li>
<li>不要在代码里包含 AWS 的密钥</li>
<li>AWS 中只能使用 <code>m3.medium</code> 或 <code>m3.large</code></li>
<li>Azure 中只能使用 <code>Standard_A1(DC)</code> 和 <code>Standard_D1(LG)</code></li>
</ul>
<h2 id="u57FA_u7840_u77E5_u8BC6"><a href="#u57FA_u7840_u77E5_u8BC6" class="headerlink" title="基础知识"></a>基础知识</h2><p>上一课里，我们使用云来进行了大数据处理和分析，只需要几行代码，就可以启动一个 EMR 集群来进行并行处理运算。但是，类似 EMR 这种服务通常很贵，并且内部具体的运行状况我们很多时候无从得知。另外，虽然 EMR 支持很多不同的应用，但是实际上还是有诸多限制，比方说主要是应用在批处理和分析上。这一次我们会部署一个 web 服务，用来响应各种 web 请求（类似于<a href="http://wdxtub.com/2016/01/16/cc-7">第 7 课 AWS 动手玩</a>）</p>
<p>在<a href="http://wdxtub.com/2016/01/20/cc-9/">第 9 课 Sequential Programming</a>中，我们故意选择了一个 <code>t1.micro</code> 实例，只有很有限的硬件资源。在这种条件的制约下，就很容易出现运行缓慢，甚至内存不够的问题，于是需要我们去尽可能优化代码。</p>
<p>但是代码优化总有一个极限，很多时候我们必须指定合适的硬件资源才能更有效率地完成各项任务。在云计算中，调整分配给不同工作/任务/服务的资源的过程称为 scaling。</p>
<p>Scaling 具体来说，可以分成两类</p>
<h3 id="Scaling__u7684_u5206_u7C7B"><a href="#Scaling__u7684_u5206_u7C7B" class="headerlink" title="Scaling 的分类"></a>Scaling 的分类</h3><p><strong>Vertical Scaling</strong></p>
<p>这是最简单的方法，也就是提高系统中资源的容量。例如，改变核心的数量，内存的大小或者处理器的计算速度。我们在之前的课程中也进行过测试。</p>
<p><strong>Horizontal Scaling</strong></p>
<p>Horizontal scaling 就复杂很多，因为需要把任务进行切分，然后分配到不同的资源上。一个比较简单的机制就是不断增加相同的资源（实例），这次我们主要以这种方式来完成 horizontal scaling</p>
<p>在没有云之前，要对资源进行 scaling 是一个很复杂的任务，云的其中一个突出好处就是可以动态添加资源，也就是这节课着重要强调的内容。</p>
<p>这里我们要做的就是写代码来和云上的资源进行交互，简单来说，就是把各种 API 连起来用正确的顺序进行调用，但是需要注意代码的可靠性和容错性。因为实际上是发送过去一个请求，然后得到一个返回结果，所以需要做好各种可能的预防措施，比如失败的话，可能需要重新申请。</p>
<h2 id="u5267_u60C5_u6897_u6982"><a href="#u5267_u60C5_u6897_u6982" class="headerlink" title="剧情梗概"></a>剧情梗概</h2><p>设定很有意思，居然强行扯上了<a href="http://www.wikiwand.com/en/Orwellian" target="_blank" rel="external">奥威尔的世界观</a>，简单来说，这个世界观比这门课有意思多啦！《1984》+《动物农场》，你值得拥有。大概是这样的：</p>
<p><img src="/images/14543608717887.jpg" alt=""></p>
<h2 id="Azure_Horizontal_Scaling"><a href="#Azure_Horizontal_Scaling" class="headerlink" title="Azure Horizontal Scaling"></a>Azure Horizontal Scaling</h2><ul>
<li>Scaling out: 从一个 <code>Standard_A1</code> 虚拟机扩展到很多个 <code>Standard_A1</code> 虚拟机</li>
<li>Scaling in: 减少虚拟机的数量</li>
</ul>
<p>这里我们会用到两种不同的实例：</p>
<ul>
<li>Load Generator: 产生请求 </li>
<li>Data Center: 处理和响应请求</li>
</ul>
<p>目标也很简单，不断开启实例，直到最终满足能够处理每秒 3000 次的请求(3000 RPS)</p>
<p><strong>第一步</strong></p>
<p>因为 Azure 的限制，所以需要把镜像先拷贝到自己的账户中：</p>
<ul>
<li>Data Center, <code>Standard_A1</code>, <code>https://cmucc.blob.core.windows.net/public/Microsoft.Compute/Images/vhds/cc15619p21dcv5-osDisk.e27faca3-f177-40ea-a740-9a1838326ae6.vhd</code></li>
<li>Load Generator, <code>Standard_D1</code>, <code>https://cmucc.blob.core.windows.net/public/Microsoft.Compute/Images/vhds/cc15619p21lgv10-osDisk.f6be8828-8cab-45ae-a611-904aeeef3c9e.vhd</code></li>
</ul>
<p>命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 复制</span></span><br><span class="line">azure storage blob copy start https://cmucc.blob.core.windows.net/public/Microsoft.Compute/Images/vhds/cc15619p21dcv5-osDisk.e27faca3<span class="operator">-f</span>177-<span class="number">40</span>ea<span class="operator">-a</span>740-<span class="number">9</span>a1838326ae6.vhd --dest-account-name YOURNAME --dest-account-key YOURKEY --dest-container YOURCONTAINER</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">azure storage blob copy show --account-name YOURNAME --account-key YOURKEY --container system --blob Microsoft.Compute/Images/vhds/cc15619p21dcv5-osDisk.e27faca3<span class="operator">-f</span>177-<span class="number">40</span>ea<span class="operator">-a</span>740-<span class="number">9</span>a1838326ae6.vhd</span><br></pre></td></tr></table></figure>
<p>大概要等一阵子，可以先来看看具体的测试规则：</p>
<ol>
<li>Data Center 必须用 <code>Standard_A1</code>，Load Generator 必须用 <code>Standard_D1</code></li>
<li>所有的虚拟机都必须通过代码启动，所有的 data center（除了第一个）都必须要在测试开始之后创建</li>
<li>代码需要完成处理当前每秒的请求并决定是否需要启动另一台虚拟机</li>
<li>不要 hardcode 虚拟机的数量</li>
<li>代码不应该连续开启多个 data center 虚拟机</li>
<li>每开启一个虚拟机，需要等待 100 秒才可以开启下一个虚拟机</li>
<li>测试一旦开始，除了关机没有其他办法可以停止，所以确定准备好了再开始</li>
<li>除了复制镜像的部分，程序必须是全自动并且可以容忍错误的。也就是说，从开启虚拟机到提交密码和 andrewid 再到开始测试再到添加需要的虚拟机最后测试完成退出都必须是自动的。</li>
<li>代码中不需要关闭 load generator，之后还会用到。不过 data center 可以删除（不一定需要在代码中完成）</li>
</ol>
<p>再来是给出的一些提示：</p>
<ol>
<li>可以利用之前给出的 Azure API 代码来从镜像创建虚拟机</li>
<li>使用 DNS 而不是 IP 地址</li>
<li>如果不大清楚程序在做什么，可以用浏览器体验一下整个过程</li>
<li>如果不熟悉如何通过代码提交请求，看看浏览器是怎么做的</li>
<li>使用 GET 和 POST 来完成请求</li>
<li>Horizontal Scaling Test 在达到指定的 RPS 后会结束，可以通过检查 log 来判断测试的状况</li>
<li>测试文件是 ini 格式的，可能需要用 <code>ConfigParser</code>(Python) 或 <code>ini4j</code>(Java) 来进行解析</li>
</ol>
<p>经过漫长的等待，复制完成，我们可以开始这次的任务了。首先是把之前的 Azure Demo 的代码导入到 Eclipse 里面。（代码在<a href="http://wdxtub.com/2016/01/15/cc-5/">第 5 课 Azure API</a>中，感谢 @jiexing 提供的具体步骤）</p>
<ol>
<li>eclipse-&gt;help-&gt;install new software-&gt;<a href="http://download.eclipse.org/technology/m2e/releases/" target="_blank" rel="external">http://download.eclipse.org/technology/m2e/releases/</a></li>
<li>eclipse-&gt;file-&gt;import-&gt;existing maven projects</li>
<li>在运行设置中，设置命令行参数：<code>RESOURCEGROUP STORAGEACCOUNT VHDNAME SUBSCRIPTIONID TENANTID APPLICATIONID APPLICATIONKEY</code>（和之前启动的一样）</li>
</ol>
<p><strong>第二步</strong></p>
<p>修改样例代码，让它能够启动一个 Load Generator 和一个 Data Center 的虚拟机。然后要去 load generator 那里注册一下 andrewid 和提交密码。地址是</p>
<p><code>http://[your-load-generator-instance-dns-name]/password?passwd=[your submission password]&amp;andrewid=[your andrew id]</code></p>
<p>这里我遇到了个问题，就是创建了虚拟机之后却没办法访问页面，好的暂时没办法继续了。</p>
<p>原因找到了，因为少了一段设置 DNS 的代码（后来更新的，在<a href="https://s3.amazonaws.com/15619public/webcontent/azureDemo.tar.gz" target="_blank" rel="external">这里</a>）</p>
<p><strong>第三步</strong></p>
<p>就是按部就班来完成任务了，不停测试是少不了的，说一些需要注意的地方：</p>
<ul>
<li>注意每一步操作之后均需要等待一段时间，这样一来更准确，二来不用反复重试</li>
<li>整体的逻辑最好先想好，不然写着写着容易乱</li>
<li>把访问网络的部分封装好，自动处理连接失败的问题，这样就可以避免很多麻烦</li>
<li>解析 RPS 数值可以使用 ini 解析器，也可以直接处理纯文本，我觉得纯文本比较好处理，就没用 ini 来解析了</li>
<li>访问 log 需要利用之前开始测试时返回的 log id，需要解析出来之后进行使用。</li>
<li>确保这一步没错才开始下一步，这样比较保险。</li>
</ul>
<h2 id="Azure_Autoscaling"><a href="#Azure_Autoscaling" class="headerlink" title="Azure Autoscaling"></a>Azure Autoscaling</h2><p>Azure 暂时还是不做了</p>
<h2 id="AWS_Horizontal_Scaling"><a href="#AWS_Horizontal_Scaling" class="headerlink" title="AWS Horizontal Scaling"></a>AWS Horizontal Scaling</h2><p>AWS 的这个部分需要完成的和 Azure 类似，需要注意以下几点：</p>
<ol>
<li>使用 <code>m3.medium</code> 用 <code>ami-8ac4e9e0</code> 来作为 load generator</li>
<li>使用 <code>m3.medium</code> 用 <code>ami-349fbb5e</code> 来作为 data center</li>
<li>用下面的 URL 来提交密码和 andrew id：<code>http://[your-load-generator-instance-dns-name]/password?passwd=[your submission password]&amp;andrewId=[your andrewId]</code></li>
<li>用下面的 URL 来提交 data center 的 dns 来开始测试：<code>http://[your-load-generator-instance-dns-name]/test/horizontal?dns=[your-instance-dns-name]</code></li>
<li>打标签需要在代码中完成，要确保 security group 设置所有的端口都打开</li>
<li>可以通过下面的 URL 来查看 log：<code>http://[your-load-generator-instance-dns-name]/log?name=test.[test-number].log</code></li>
<li>为了通过测试，需要保证 RPS 达到 4000，测试开始之后可以通过发送请求来添加实例：<code>http://[your-load-generator-instance-dns-name]/test/horizontal/add?dns=[your-instance-dns-name]</code></li>
<li>所有 data center 的规格应该是一样的</li>
</ol>
<p>就是按部就班来完成任务了，不停测试是少不了的，说一些需要注意的地方：</p>
<ul>
<li>注意每一步操作之后均需要等待一段时间，这样一来更准确，二来不用反复重试</li>
<li>整体的逻辑最好先想好，不然写着写着容易乱</li>
<li>把访问网络的部分封装好，自动处理连接失败的问题，这样就可以避免很多麻烦</li>
<li>解析 RPS 数值可以使用 ini 解析器，也可以直接处理纯文本，我觉得纯文本比较好处理，就没用 ini 来解析了</li>
<li>访问 log 需要利用之前开始测试时返回的 log id，需要解析出来之后进行使用。</li>
<li>确保这一步没错才开始下一步，这样比较保险。</li>
</ul>
<p>完成之后，就可以发现现在这种方法的局限：</p>
<p>我们有一个 Load Generator，若干个 data center 会试着从中获取数据。每次添加实例，都需要通知 load generator，然后需要进行一些计算使得各个 data center 获得相同的流量。但是如果不想要这么多 data center，或者忽然有一个实例挂掉了呢？怎么去监控这个事情呢？怎么保证每个 data center 的负载均衡呢？</p>
<p>所以 AWS 提供一个叫做 Elastic Load Balancing 的服务，可以自动把流量均分给连接的实例，也能处理好实例挂掉的情况。接下来我们会做一些这个方面的尝试。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>经过上一节课的『锻炼』，这一次我们要迎来更大的挑战。前面很多时候都是通过 Web 界面来进行云资源的管理，这里我们需要学会如何用代码来申请和控制各种资源。</p>]]>
    
    </summary>
    
      <category term="AWS" scheme="http://wdxtub.com/tags/AWS/"/>
    
      <category term="Azure" scheme="http://wdxtub.com/tags/Azure/"/>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="云计算" scheme="http://wdxtub.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to Write Fast Code 第 2 课 Multicore 编程]]></title>
    <link href="http://wdxtub.com/2016/02/01/fastcode-2/"/>
    <id>http://wdxtub.com/2016/02/01/fastcode-2/</id>
    <published>2016-02-01T14:51:26.000Z</published>
    <updated>2016-02-01T18:18:21.000Z</updated>
    <content type="html"><![CDATA[<p>这一课主要是介绍 Multicore 编程以及 OpenMP 的相关内容，OpenMP 会另外专门做一个配套的教程，稍后共享给大家。</p>
<a id="more"></a>
<hr>
<p>先要了解几个不同的并行层级，如下图所示：</p>
<p><img src="/images/14543461995158.jpg" alt=""></p>
<p>OpenMP 实际上就是在代码中标记出可以并行执行的部分，由编译器来完成最终并行化处理的过程。具体的怎么做到的呢？参考下图：</p>
<p><img src="/images/14543462820858.jpg" alt=""></p>
<p>OpenMP 这部分会专门写一次课来具体进行讲解，所以这里主要把理论上的东西提一下。</p>
<p>课程作业中另一个问题就是矩阵相乘，矩阵相乘是非常经典的问题，为了降低计算复杂度提高效率，这么多年来出现了各种各样的方法（不过基本也到极限了）。比方说利用分而治之的方式，利用内存排列的方式等等，具体来说可以考虑下面的方法:</p>
<ul>
<li>Block size adaptation for appropriate caches</li>
<li>Register-level blocking</li>
<li>Copy optimization(data layout)</li>
<li>Optimizing the mini-matrix-multiply (base case)</li>
<li>Multi-level blocking</li>
<li>Multi-level copying</li>
</ul>
<p>这部分也会专门写一课来进行讲解。</p>
<p>最后是很重要的一个用来分析性能的模型：Roofline Model。主要是理解下面几个图：</p>
<p><img src="/images/14543502445260.jpg" alt=""></p>
<p><img src="/images/14543502605039.jpg" alt=""></p>
<p><img src="/images/14543502758805.jpg" alt=""></p>
<p><img src="/images/14543502946889.jpg" alt=""></p>
<p><img src="/images/14543503147538.jpg" alt=""></p>
<p>尤其是最后一张，超级重要：</p>
<p><img src="/images/14543503391932.jpg" alt=""></p>
<p>具体的优化分类如下，大家在实践的时候可以思考下具体是在哪个类别进行优化，有没有其他类别的方法可以尝试：</p>
<p><img src="/images/14543505552239.jpg" alt=""></p>
<p>最后再说一个概念：</p>
<p><img src="/images/14543506076660.jpg" alt=""></p>
<p>可以通过汇编指令来进行查看</p>
<p><img src="/images/14543506249554.jpg" alt=""></p>
<p>接下的两课就不会这么泛泛了，主要来聊聊 Kmeans 和 矩阵相乘。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一课主要是介绍 Multicore 编程以及 OpenMP 的相关内容，OpenMP 会另外专门做一个配套的教程，稍后共享给大家。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="Multicore" scheme="http://wdxtub.com/tags/Multicore/"/>
    
      <category term="OpenMP" scheme="http://wdxtub.com/tags/OpenMP/"/>
    
      <category term="并行" scheme="http://wdxtub.com/tags/%E5%B9%B6%E8%A1%8C/"/>
    
      <category term="编程" scheme="http://wdxtub.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to Write Fast Code 第 1 课 背景知识]]></title>
    <link href="http://wdxtub.com/2016/02/01/fastcode-1/"/>
    <id>http://wdxtub.com/2016/02/01/fastcode-1/</id>
    <published>2016-02-01T14:51:22.000Z</published>
    <updated>2016-02-01T17:00:07.000Z</updated>
    <content type="html"><![CDATA[<p>这一课主要介绍并行编程的背景知识和一些基本的技巧，给大家一个整体的认知。</p>
<a id="more"></a>
<hr>
<p>简单来说，提高程序运行速度的方式有很多种，除了算法优化，还有其他许多软件硬件相结合的技巧。不同层级上的优化，带来的收益也会不一样，比方说在软件架构上的优化，可能可以带来 20-100 倍的收益，算法层面上的优化是 10-40 倍，而数据结构上的优化是 1.5-8 倍（当然这些数字都不是绝对的）</p>
<p>这门课主要涉及 OpenMP，CUDA 和 Hadoop（也会有一些 Spark 的内容，机器学习的部分还在商量中）。我主要负责 OpenMP 和 Hadoop 的部分。</p>
<p>具体需要理解的概念，基本上在第 0 课中我的笔记都有涉及，课件里的例子一定要重点掌握，比如：</p>
<ul>
<li>Instruction level parallelism 的原理和机制</li>
<li>SIMD 的原理和机制（SSE 的用法）</li>
<li>Simultaneous Multithreading(SMT)的概念</li>
<li>Memory Hierarchy 的原理及如何进行利用（矩阵相乘的例子）</li>
<li>Compulsory miss / Capacity / Conflict</li>
</ul>
<p>接着是两幅图：Platform + Technique</p>
<p><img src="/images/14543452357180.jpg" alt=""></p>
<p><img src="/images/14543452584935.jpg" alt=""></p>
<p>最后说一下 Kmeans 这个算法，具体的算法过程这里不赘述了，基本的过程参见下图：</p>
<p><img src="/images/14543458160793.jpg" alt=""></p>
<p>如果想要理解更清楚一些，还需要去看看 EM 算法（这里同样不写）。然后对应到具体的代码，看看有哪些地方可以并行，哪些地方不行，如何根据不同的策略来优化代码。这些会在之后的习题课进行详细一点的讲解。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一课主要介绍并行编程的背景知识和一些基本的技巧，给大家一个整体的认知。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="并行" scheme="http://wdxtub.com/tags/%E5%B9%B6%E8%A1%8C/"/>
    
      <category term="架构" scheme="http://wdxtub.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="编程" scheme="http://wdxtub.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to Write Fast Code 第 0 课 往年笔记与问题集]]></title>
    <link href="http://wdxtub.com/2016/02/01/fastcode-0/"/>
    <id>http://wdxtub.com/2016/02/01/fastcode-0/</id>
    <published>2016-02-01T14:51:17.000Z</published>
    <updated>2016-02-01T15:19:50.000Z</updated>
    <content type="html"><![CDATA[<p>本来打算借着当助教，看看这门课有没有什么变化。事实上，没啥变化，所以这里先把当时我的笔记放出来，之后的课程可能会主要集中于代码和项目的思路分析，具体理论的东西不会再重复太多。</p>
<a id="more"></a>
<hr>
<h1 id="Lecture_Note"><a href="#Lecture_Note" class="headerlink" title="Lecture Note"></a>Lecture Note</h1><ul>
<li>Fast Platforms (Multicore platforms, Manycore platforms, Cloud platform) + Good Techniques (Data structure, Algorithm, Software Architecture)</li>
<li>Need is driven by the applications, NOT by the availability of the platform.</li>
<li>Background -&gt; Multicore(openmp) -&gt; Manycore(CUDA) -&gt; cluster(Hadoop) -&gt; Special Topics</li>
</ul>
<h2 id="Multicore_vs_Manycore"><a href="#Multicore_vs_Manycore" class="headerlink" title="Multicore vs Manycore"></a>Multicore vs Manycore</h2><ul>
<li>Multicore: yoke of oxen. Each core optimized for executing a single thread.</li>
<li>Manycore: flock of chickens. Cores optimized for aggregate throughput, deemphasizing individual performance.</li>
</ul>
<h2 id="Instruction_Level_Parallelism__28ILP_29"><a href="#Instruction_Level_Parallelism__28ILP_29" class="headerlink" title="Instruction Level Parallelism (ILP)"></a>Instruction Level Parallelism (ILP)</h2><p>Instructions in a sequence that can be computed at the same time.</p>
<ul>
<li>Advantages<ul>
<li>No changes in sequential software necessary</li>
</ul>
</li>
<li>Disadvantages<ul>
<li>Significantly more complex processor architecture</li>
<li>Longer to design the processor</li>
<li>Longer to verify the correctness of the processor design</li>
<li>Consumes more energy than simple in-order processor</li>
</ul>
</li>
</ul>
<h2 id="Out-of-order_Pipelines"><a href="#Out-of-order_Pipelines" class="headerlink" title="Out-of-order Pipelines"></a>Out-of-order Pipelines</h2><p>Allows instruction re-ordering, register-renaming</p>
<h2 id="SIMD"><a href="#SIMD" class="headerlink" title="SIMD"></a>SIMD</h2><ul>
<li>can be area and power efficient</li>
<li>parallelism exposed to programmer &amp; compiler</li>
</ul>
<p>Locality, Temporal Locality, Spatial Locality</p>
<p>Compulsory misses, Capacity misses, Conflict misses</p>
<ul>
<li>Advantages<ul>
<li>Power-efficient wya to improve instruction throughput</li>
<li>Exploitable in many compute-intensive applications</li>
</ul>
</li>
<li>Disadvantages<ul>
<li>Explicit representation in vector instructions</li>
<li>Software requires re-compilation to take advantage of new SIMD capabilites.</li>
<li>May require hand-tuning to expoit full benefit</li>
</ul>
</li>
</ul>
<h2 id="Simultaneous_multithreading"><a href="#Simultaneous_multithreading" class="headerlink" title="Simultaneous multithreading"></a>Simultaneous multithreading</h2><p>Capturing the opportunity to run faster when more than one thread of instructions are available.</p>
<ul>
<li>Advantages<ul>
<li>Gain power-efficiency by increase processor pipeline utilization</li>
</ul>
</li>
<li>Disadvantages<ul>
<li>Requires multiple threads available</li>
<li>May trigger confilicts in shared cache during execution</li>
<li>Does not improve latency of each thread</li>
</ul>
</li>
</ul>
<h2 id="Concurrency_vs_Parallelism"><a href="#Concurrency_vs_Parallelism" class="headerlink" title="Concurrency vs Parallelism"></a>Concurrency vs Parallelism</h2><ul>
<li>Concurrency: We expose concurrency in our application</li>
<li>Parallelism: We exploit parallelism in our platform</li>
</ul>
<p>Concurrency: A sequence of instructions executes concurrently if they execute independent of each other as if they were executed at the same time.</p>
<ul>
<li>They do not need to be executed truly at the same time though.</li>
<li>On a single processor computer, multi-tasking systems execute programs concurrently by interleaving their operations such that they appear to execute at the same time.</li>
</ul>
<p>Parallelism: Instruction streams that execute in parallel actually execute at the same time</p>
<ul>
<li>Parallelism allows multiple instructions to be executed at the exact same time</li>
<li>Parallelism requires multiple processing units, ranging from small pipeline stages up through multithreaded architectures and multicore and multiprocessing systems</li>
</ul>
<p>Difference</p>
<ul>
<li>Time</li>
<li>In concurrency, at any given time, a single operation is occurring.<ul>
<li>High clock rates and clever interleaving can give the illusion of parallelism</li>
<li>All modern desktop/server OS give you this. Embedded, maybe not.</li>
</ul>
</li>
<li>In parallelism, at a given point in time, multiple operations are occurring.<ul>
<li>This is important to distinguish. Parallelism means it is extremely difficult (often impossible) to predict the interleaving of instructions.</li>
</ul>
</li>
</ul>
<h2 id="The_process_of_problem_solving_3A"><a href="#The_process_of_problem_solving_3A" class="headerlink" title="The process of problem solving:"></a>The process of problem solving:</h2><ul>
<li>Understand the current state<ul>
<li>Running on a platform</li>
<li>Using a specific set of resources</li>
<li>Achieving a specific performance</li>
<li>Meeting a specific criteria/requirement</li>
</ul>
</li>
<li>Observe the internal representation<ul>
<li>Application structure</li>
<li>Implementation concerns<ul>
<li>Task considerations</li>
<li>Data representations</li>
<li>concurrency opportunities</li>
</ul>
</li>
</ul>
</li>
<li>Search among alternatives</li>
<li>Select from a set of choices</li>
</ul>
<h2 id="Kmeans_Problem"><a href="#Kmeans_Problem" class="headerlink" title="Kmeans Problem"></a>Kmeans Problem</h2><ul>
<li>Find K cluster centers that minimize the distance from each data point to a cluster center (centroid)</li>
<li>Important algorithm in machine learning</li>
<li>NP-hard for arbitrary input</li>
<li>Issues<ul>
<li>Worst case running time is super-polynomial</li>
<li>Approximation can be arbitrarily bad</li>
</ul>
</li>
</ul>
<h2 id="How_to_write_fast_code"><a href="#How_to_write_fast_code" class="headerlink" title="How to write fast code"></a>How to write fast code</h2><ul>
<li><strong>Expose</strong> concurrencies in applications and algorithms</li>
<li><strong>Exploit</strong> parallelisms on application platform</li>
<li><strong>Explore</strong> mapping between concurrency and parallelism</li>
</ul>
<h2 id="The_phases_28kmeans_29"><a href="#The_phases_28kmeans_29" class="headerlink" title="The phases(kmeans)"></a>The phases(kmeans)</h2><ul>
<li>Initialization: Randomly select k cluster centers<ul>
<li>Select k samples from data as initial centers [Forgy Partition]</li>
</ul>
</li>
<li>Expectation: Assign each data point go closest center<ul>
<li>Compare each data point (N) to each cluster center (K)</li>
<li>Distance Metric: Euclidean distance (D dimensions)</li>
</ul>
</li>
<li>Maximization: Update centers based on assignments</li>
<li>Evaluate: Re-iterate steps 2-3 until convergence or stopping criteria.</li>
</ul>
<h2 id="Performance_Analysis_3A_Roofline_Model"><a href="#Performance_Analysis_3A_Roofline_Model" class="headerlink" title="Performance Analysis: Roofline Model"></a>Performance Analysis: Roofline Model</h2><ul>
<li>Observe the phases of execution</li>
<li>Characterize the execution time break downs</li>
<li>Reason about why a piece of code is slow</li>
<li>Identify performance bottleneck</li>
</ul>
<h2 id="How_to_evaluate_a_mapping"><a href="#How_to_evaluate_a_mapping" class="headerlink" title="How to evaluate a mapping"></a>How to evaluate a mapping</h2><ul>
<li>Efficiency: Runs quickly, makes good use of computational resources</li>
<li>Simplicity: Easy to understand code is easier to develop, debug, verify and modify</li>
<li>Portability: Should run on widest range of parallel computers</li>
<li>Scalability: Should be effective on a wide range of processing elements</li>
</ul>
<h2 id="Exploiting_Different_Levels_of_Parallelism"><a href="#Exploiting_Different_Levels_of_Parallelism" class="headerlink" title="Exploiting Different Levels of Parallelism"></a>Exploiting Different Levels of Parallelism</h2><ul>
<li>SIMD-Level: using vectorizing compiler and hand-code intrinsics</li>
<li>SMT-Level: OS abstract it to core-level parallelism</li>
<li>Core-Level: Using threads to describe work done on different cores</li>
</ul>
<h2 id="False_Sharing"><a href="#False_Sharing" class="headerlink" title="False Sharing"></a>False Sharing</h2><ul>
<li>Cache loads and stores work with 4-16 word long cache lines(64B for Intel)<ul>
<li>If two threads are wrting to the same cache line, conflicts occurs</li>
</ul>
</li>
<li>Even if the address differs, one will still suffer performance penalty</li>
</ul>
<h2 id="Optimization_Categorization"><a href="#Optimization_Categorization" class="headerlink" title="Optimization Categorization"></a>Optimization Categorization</h2><ul>
<li>Maximizing In-core Performance<ul>
<li>Exploit in-core parallelism (reorder, unroll, SIMD, eliminate branch)</li>
</ul>
</li>
<li>Maximizing Memory Bandwidth<ul>
<li>Exploit NUMA, Hide memory latency (unit-stride streams, memory affinity, sw prefetch, DMA Lists, TLB Blocking)</li>
</ul>
</li>
<li>Minimizing Memory Traffic<ul>
<li>Eliminate Capacity/Conflict/Compulsory misses (cache blocking, array padding, compress data, streaming stores)</li>
</ul>
</li>
</ul>
<h2 id="Measuring_Arithmetic_Intensity"><a href="#Measuring_Arithmetic_Intensity" class="headerlink" title="Measuring Arithmetic Intensity"></a>Measuring Arithmetic Intensity</h2><p>Arithmetic Intensity = (# of FP Operations to run the program) / (# of Bytes Accessed in the Main Memory)</p>
<p>Arithmetic Intensity = FLOPs / (Allocations + Compulsory + Conflict + Capacity)</p>
<h2 id="Roofline_Model"><a href="#Roofline_Model" class="headerlink" title="Roofline Model"></a>Roofline Model</h2><p>Attainable Performance(ij) = min(FLOP/s with Optimization(1-i), AI*Bandwidth with Optimization(1-j)</p>
<p>Plot on log-log scale</p>
<p>Lantency -&gt; Runtime</p>
<p>Throughput -&gt; Performance</p>
<ul>
<li>Throughput<ul>
<li>Usually measured in floating point operations per second(FLOPS)</li>
<li>Floating point operations = addition + multiplication</li>
</ul>
</li>
</ul>
<p>Higher Performance != Shorter Runtime</p>
<p>True Arithmetic Intensity (AI) ~ Total Flops / Total DRAM Bytes</p>
<ul>
<li>Arithmetic intensity is ultimately limited by compulsory traffic</li>
<li>Arithmetic intensity is diminished by conflict or capacity misses</li>
</ul>
<h2 id="Data_3A_Three_Classes_of_Locality"><a href="#Data_3A_Three_Classes_of_Locality" class="headerlink" title="Data: Three Classes of Locality"></a>Data: Three Classes of Locality</h2><ul>
<li>Spatial Locality<ul>
<li>data is transferred from cache to registers in words</li>
<li>However, data is transferred to the cache in 64-128 Byte lines</li>
<li>using every word in a line maximizes spatial locality</li>
<li>transform data structures into struct of arrays(SoA) layout</li>
</ul>
</li>
<li>Temporal Locality<ul>
<li>reusing data(either registers or cachelines) multiple times</li>
<li>amortizes the impact of limited bandwidth</li>
<li>transform loop s or algorithms to maximize reuese.</li>
</ul>
</li>
<li>Sequential Locality<ul>
<li>Many memory address patterns access cache lines sequentially</li>
<li>CPU’s hardware stream prefetchers exploit this observation to hide speculatively load data to memory lantency</li>
<li>Tansform loops to generate long, unit-stride accesses</li>
</ul>
</li>
</ul>
<h2 id="GPU_is_an_Accelerator"><a href="#GPU_is_an_Accelerator" class="headerlink" title="GPU is an Accelerator"></a>GPU is an Accelerator</h2><ul>
<li>Host System (CPU) &lt;—&gt; Device System (GPU)</li>
<li>When Does Using GPU Make Sense?<ul>
<li>Application with a lot of concurrency (1000-way, fine-grained concurrency)</li>
<li>Some memory intensive applications (Aggregate memory bandwidth is higher)</li>
<li>Advantage diminishes when task granularity becomes too large to fit in shared memory</li>
</ul>
</li>
</ul>
<h2 id="GPU_Programming_Model_3A_Stream"><a href="#GPU_Programming_Model_3A_Stream" class="headerlink" title="GPU Programming Model: Stream"></a>GPU Programming Model: Stream</h2><ul>
<li>Stream -&gt; kernel -&gt; stream</li>
<li>Streams: An array of data units</li>
<li>Kernels<ul>
<li>Take streams as input, produce streams at output</li>
<li>Perform computation on streams</li>
<li>Kernels can be linked together</li>
</ul>
</li>
</ul>
<h2 id="CUDA_3A_Compute_Unified_Device_Architecture"><a href="#CUDA_3A_Compute_Unified_Device_Architecture" class="headerlink" title="CUDA: Compute Unified Device Architecture"></a>CUDA: Compute Unified Device Architecture</h2><ul>
<li>Integrated host + device app C program</li>
<li>Serial or modestly parallel parts in host C code</li>
<li>Highly Parallel parts in device SPMP kernel C code</li>
</ul>
<h2 id="CUDA_Programming_Model"><a href="#CUDA_Programming_Model" class="headerlink" title="CUDA Programming Model"></a>CUDA Programming Model</h2><ul>
<li>Executing kernel functions within threads</li>
<li>Threads organization<ul>
<li>Blocks and Grids</li>
</ul>
</li>
<li>Hardware mapping of threads<ul>
<li>Computation-to-core mapping<ul>
<li>Thread -&gt; Core</li>
<li>Thread blocks -&gt; Multi-processors</li>
</ul>
</li>
</ul>
</li>
<li>Thread organization<ul>
<li>an array of threads -&gt; block</li>
<li>an array of blocks -&gt; grid</li>
</ul>
</li>
<li>All threads in one grid execute the same kernel</li>
<li>Grids are executed sequentially</li>
<li>Thread Cooperation<ul>
<li>Threads within a block<ul>
<li>Shared memory</li>
<li>Atomic operation on Share memory &amp; global memory</li>
<li>Barrier</li>
</ul>
</li>
<li>Threads between blocks<ul>
<li>Atomic operation on global memory</li>
</ul>
</li>
<li>Threads between grids<ul>
<li>NO WAY!</li>
</ul>
</li>
</ul>
</li>
<li>Thread Mapping and Scheduling<ul>
<li>A grid of threads takes over the whole device</li>
<li>A block of threads is mapped on one multi-processor<ul>
<li>A multi-processor can take more than one blocks.(Occupancy)</li>
<li>A block can not be preempted until finish</li>
</ul>
</li>
<li>Threads within a blocks are shceduled to run on multi-processors</li>
<li>Threads are grouped into warps(32) as scheduling units</li>
</ul>
</li>
<li>Parallel Memory Sharing<ul>
<li>Local Memory: per-thread</li>
<li>Shared Memory: per-Block</li>
<li>Global Memory: per-application</li>
</ul>
</li>
<li>Shared Memory<ul>
<li>Each Multi-processor has 32KB of Shared Memory - 32 banks of 32bit words</li>
<li>Visible to all threads in a thread block</li>
</ul>
</li>
</ul>
<h2 id="Why_Warps"><a href="#Why_Warps" class="headerlink" title="Why Warps"></a>Why Warps</h2><p>Each Fermi core can maintain 48 warps of architecural context.</p>
<p>Each warp manages a 32-wide SIMD vector worth of computation</p>
<p>With ~20 registers for each trhead:</p>
<p>4(Bytes/register) x 20(Registers) x 32(SIMD lanes) x 48 (Warps) = 128KB per core x 16 (core) = 2MB total of register files</p>
<ul>
<li>Software abstract info hid an extra level of architecture complexity</li>
<li>A 128KB register file is a large memory (takes more than one cycle)</li>
<li>Hardware provide 160wide physical SIMD units, half-pump register files</li>
<li>To simplify the programming model</li>
</ul>
<h2 id="How_to_Deal_with_GPUs_of_Different_Sizes_3F"><a href="#How_to_Deal_with_GPUs_of_Different_Sizes_3F" class="headerlink" title="How to Deal with GPUs of Different Sizes?"></a>How to Deal with GPUs of Different Sizes?</h2><ul>
<li>CUDA provides an abstract infor concurrency to be fully exposed</li>
<li>HW/Runtime provides capability to schedule the computation</li>
</ul>
<h2 id="Thread_Blocks"><a href="#Thread_Blocks" class="headerlink" title="Thread Blocks"></a>Thread Blocks</h2><ul>
<li>Computation is grouped into blocks of independent concurrently execrable work</li>
<li>Fully exposed the concurrency in the application</li>
<li>The HW/Runtime makes the decision to selectively sequentialize the execution as necessary</li>
</ul>
<h2 id="21_21_Threads"><a href="#21_21_Threads" class="headerlink" title="!! Threads"></a>!! Threads</h2><ul>
<li>Threads are the computation performed in each SIMD lane in a core<ul>
<li>CUDA provides a SIMT programming abstraction to assist users</li>
</ul>
</li>
<li>SIMT: Single Instruction Multiple Threads<ul>
<li>A single instruction multiple processing elements</li>
<li>Different from SIMD</li>
<li>SIMT abstract the # threads in a thread block as a user-specified parameter</li>
</ul>
</li>
<li>SIMT enables programmers to write thread-level parallel code for<ul>
<li>Independent, Scalar threads</li>
<li>Data-parallel code fro coordinated threads</li>
</ul>
</li>
<li>For function correctness, programmers can ignore SIMT behavior</li>
<li>For performance, programmer can tune applications with SIMT in mind</li>
</ul>
<h2 id="About_Data"><a href="#About_Data" class="headerlink" title="About Data"></a>About Data</h2><ul>
<li>SIMD style programming can be very restrictive for communication between SIMD lanes.</li>
<li>On the same chip, in the same core, computations in SMD lanes (physically) takes places very close to each other</li>
</ul>
<h2 id="Shared_Memory/L1_cache"><a href="#Shared_Memory/L1_cache" class="headerlink" title="Shared Memory/L1 cache"></a>Shared Memory/L1 cache</h2><ul>
<li>Manycore processors provide memory local to each core</li>
<li>Computations in SIMD-lanes in the same core can communicate via memory read / write</li>
<li>Two types of memory:<ul>
<li>Programmer-managed scratch pad memory</li>
<li>HW-managed L1 cache</li>
</ul>
</li>
<li>For NVIDIA Fermi architecture, you get 64KB per core with 2 configurations:<ul>
<li>48KB scratch pad (Shared Memory), 16KB L1 cache</li>
<li>16KB scratch pad (Shared Memory), 48KB L1 cache</li>
</ul>
</li>
<li>How many Threads per Thread Block<ul>
<li>In Fermi, 48 warps of context are maintained per core</li>
<li>In Fermi, each thread block can have up to 1024 threads</li>
</ul>
</li>
</ul>
<h2 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h2><ul>
<li><code>__syncthreads()</code><ul>
<li>waits until all threads in the thread block have reached this point and all global and shared memory accesses made by these threads prior to <code>__syncthreads()</code> are visible to all threads in the block</li>
<li>used to coordinate communication between the threads of the same block</li>
</ul>
</li>
</ul>
<h2 id="Compilation"><a href="#Compilation" class="headerlink" title="Compilation"></a>Compilation</h2><ul>
<li>Any source file containing CUDA language extensions must be compiled with NVCC<ul>
<li>NVCC is a compiler driver</li>
<li>Works by invoking all the necessary tools and compilers like cudacc, g++, …</li>
</ul>
</li>
<li>NVCC outputs<ul>
<li>C code (host CPU code)<ul>
<li>Must be compiled with the rest of the application using another tool</li>
</ul>
</li>
<li>PTX<ul>
<li>object code directly</li>
<li>or, PTX source, interpreted at runtime</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="SOA_vs_AOS"><a href="#SOA_vs_AOS" class="headerlink" title="SOA vs AOS"></a>SOA vs AOS</h2><p>Struct of Arrays: 一共只有一个 struct</p>
<pre><code>typedef struct
{
    float* x;
    float* y;
    float* z;
} Constraints;
</code></pre><p>x | x | x | y | y | y | z | z | z</p>
<p>Array of Struct</p>
<pre><code>typedef struct __align__(16)
{
    float3 position;
} Constraint;
</code></pre><p>x | y | z | x | y | z | x | y | z</p>
<p>It depends on the usage of the data.</p>
<p>Note that AoS pads within each struct. While SoA pads between the arrays.</p>
<p>These have the following trade-offs:</p>
<ol>
<li>AoS tends to be more readable to the programmer as each “object” is kept together.</li>
<li>AoS may have better cache locality if all the members of the struct are accessed together.</li>
<li>SoA could potentially be more efficient since grouping same datatypes together sometimes exposes vectorization.</li>
<li>In many cases SoA uses less memory because padding is only between arrays rather than between every struct.</li>
</ol>
<h2 id="Optimization_Strategies"><a href="#Optimization_Strategies" class="headerlink" title="Optimization Strategies"></a>Optimization Strategies</h2><ul>
<li>Global Memory Access Pattern -&gt; Coalescing</li>
<li>Control Flow -&gt; Divergent branch</li>
</ul>
<h2 id="Memory_Coalescing"><a href="#Memory_Coalescing" class="headerlink" title="Memory Coalescing"></a>Memory Coalescing</h2><ul>
<li>Hardware Constraint: DRAM is accessed in ‘segments’ of 32B/64B/128B</li>
<li>Goal: combine multiple memory accesses generated from multiple threads into a single physical transaction</li>
<li>Rules for maximizing DRAM memory bandwidth:<ul>
<li>Possible bus transaction sizes: 32B, 64B, or 128B</li>
<li>Memory segment must be aligned: First address = multiple of segment</li>
<li>Hardware coalescing fro each half-warp: 16-word wide</li>
</ul>
</li>
</ul>
<p>Threads can access any words in any order, including the same words, and a single memory transaction for each segment addressed by a half-warp.</p>
<p>核心想法就是一次载入，尽量多次使用，减少访问次数。</p>
<h2 id="Use_of_Shared_Memory"><a href="#Use_of_Shared_Memory" class="headerlink" title="Use of Shared Memory"></a>Use of Shared Memory</h2><ul>
<li>Process:<ul>
<li>Load from DRAM to shared memory</li>
<li>Synchronize</li>
<li>Perform work on data in shared memory</li>
<li>Synchronize</li>
<li>Write out results to DRAM</li>
</ul>
</li>
</ul>
<p>Trick: Double Buffering</p>
<p>先载入到 global memory 再折腾到 shared memory</p>
<p>Declared a fixed sized variable at compile time</p>
<pre><code>__shared__ float As[BLOCK_SIZE][BLOCK_SIZE];
</code></pre><p>Define a size to be used at run time</p>
<pre><code>mykernel &lt;&lt;&lt;nBloks, nThds, shmemByteSize&gt;&gt;&gt;(a, objects);
在 kernel 函数中也需要进一步处理
</code></pre><h2 id="Memory_Bank_Conflicts"><a href="#Memory_Bank_Conflicts" class="headerlink" title="Memory Bank Conflicts"></a>Memory Bank Conflicts</h2><ul>
<li>Shared memory has 32 banks<ul>
<li>Organized such that successive 32-bit words are assigned to successive banks</li>
<li>Each bank has a bandwidth of 32 bits per two clock cycles (2 cycle latency)</li>
</ul>
</li>
</ul>
<p>A bank conflict occurs if two or more threads access any bytes within different 32-bit words belonging to the same bank.</p>
<p>如果访问的是同一个 bank 的同一个数据，那么多少个线程一起访问也不 conflict</p>
<h2 id="Padding_Technique"><a href="#Padding_Technique" class="headerlink" title="Padding Technique"></a>Padding Technique</h2><p>矩阵的那个如果不是整数可以考虑 padding</p>
<h2 id="Branch_divergence"><a href="#Branch_divergence" class="headerlink" title="Branch divergence"></a>Branch divergence</h2><p>Optimization: Factor out decision variables to have shorter sequence of divergent code</p>
<p>Branch divergence occurs only within a warp</p>
<h2 id="Optimizing_Instruction_Mix"><a href="#Optimizing_Instruction_Mix" class="headerlink" title="Optimizing Instruction Mix"></a>Optimizing Instruction Mix</h2><ul>
<li>Compiler Assisted Loop Unrolling<ul>
<li>Provides more instruction level parallelism for the compiler to use</li>
<li>Improves the ability for the compiler to find the instruction mix that instructions executed per cycle(IPC)</li>
</ul>
</li>
<li>By default, the compiler unrolls small loops with a know trip count</li>
<li>In CUDA, <code>#pragma unroll</code> directive can control unrolling of any given loop<ul>
<li>Must be placed immediately before the loop and only applies to that loop</li>
<li>Optionally followed by a number</li>
</ul>
</li>
</ul>
<h3 id="Device-only_CUDA_intrinsic_function"><a href="#Device-only_CUDA_intrinsic_function" class="headerlink" title="Device-only CUDA intrinsic function"></a>Device-only CUDA intrinsic function</h3><p>常用的数学计算有 gpu 版本替代</p>
<h2 id="Data_Parallel_Algorithms_-_Map"><a href="#Data_Parallel_Algorithms_-_Map" class="headerlink" title="Data Parallel Algorithms - Map"></a>Data Parallel Algorithms - Map</h2><p>Map: A fucntion that applies a given function to each element of a list , and returning a list of results</p>
<p>Two important properties:</p>
<ul>
<li>Side-effect free: Only returning a value, no modifications of state with the rest of the application</li>
<li>Independent: Has an independent piece of work, where its input does not depend on another function</li>
</ul>
<h2 id="Data_Parallel_Algorithm_-_Reduce"><a href="#Data_Parallel_Algorithm_-_Reduce" class="headerlink" title="Data Parallel Algorithm - Reduce"></a>Data Parallel Algorithm - Reduce</h2><p>Reduce: A function that takes in a list of objects and builds up a return value.</p>
<p>Important properties for parallel reduction:</p>
<ul>
<li>Associativity: a+(b+c) == (a+b)+c</li>
<li>Allows elements to be reduced in prarallel in a ‘tree’</li>
</ul>
<h2 id="Data_Parallel_Algorithms_-_Scan"><a href="#Data_Parallel_Algorithms_-_Scan" class="headerlink" title="Data Parallel Algorithms - Scan"></a>Data Parallel Algorithms - Scan</h2><p>Scan(prefix-sum): Takes a binary associative operator ⊕ with identity I, and an array of n elements [a0, a1, …, an-1] and returns the ordered set [I, a0, (a0⊕a1),…, (a0⊕a1⊕…⊕an-2)]</p>
<p>Example:</p>
<p>if ⊕ is addition, than scan on the set [3 1 7 0 4 1 6 3 ] returns the set [0 3 4 11 11 15 16 22]</p>
<p>Scan Algorithm in CUDA 4.0</p>
<h2 id="Data_Parallel_Algorithms_-_Compact"><a href="#Data_Parallel_Algorithms_-_Compact" class="headerlink" title="Data Parallel Algorithms - Compact"></a>Data Parallel Algorithms - Compact</h2><p>Compaction: Removing elements from an array - take in an array and produce an shorter array.</p>
<p>How do we perform removal in parallel?</p>
<ul>
<li>Map - create flags (1 keep, 0 remove)</li>
<li>Scan - compute index</li>
<li>Map - copy to new array</li>
</ul>
<p><img src="/images/14543391583932.jpg" alt=""></p>
<h2 id="Data_Parallel_Algorithms_-_FindUniq"><a href="#Data_Parallel_Algorithms_-_FindUniq" class="headerlink" title="Data Parallel Algorithms - FindUniq"></a>Data Parallel Algorithms - FindUniq</h2><p>FindUniq: Removing duplicates from an array - take in an set, produces an equal or smaller set of unique values</p>
<p><img src="/images/14543391502961.jpg" alt=""></p>
<p>在某些特殊情况可以利用 hash insertion 去掉 sort 的步骤, hash table 已经是有序的，就是打表的方法。</p>
<h2 id="Parallel_Software_Patterns"><a href="#Parallel_Software_Patterns" class="headerlink" title="Parallel Software Patterns"></a>Parallel Software Patterns</h2><p>A parallel software pattern is a generalizable solution to a class of recurring problems that occurs in the design of parallel software.</p>
<p>Attaches names to well-analyzed solutions that encapsulate the way an expert in the field solves problems.</p>
<p>Aims to achieve three goals:</p>
<ul>
<li>Define a set of vocabularies to communicate</li>
<li>Present a set of expert techniques for beginners to learn</li>
<li>Allows experts to more quickly design complex systems</li>
</ul>
<p><a href="http://parlab.eecs.berkely.edu/wiki/patterns/patterns" target="_blank" rel="external">Our Pattern Language</a></p>
<p>OPL: The Organization</p>
<p><img src="/images/14543391400653.jpg" alt=""></p>
<p>Structural Patterns:</p>
<ul>
<li>!Pipe-and-Filter</li>
<li>Agent-and-Repository</li>
<li>Event-based</li>
<li>Layered Systems</li>
<li>Model-view-constroller</li>
<li>Arbitrary Task Graphs</li>
<li>Puppeteer</li>
<li>Iterator/BSP</li>
<li>!MapReduce</li>
</ul>
<p>Monte Carlo Methods</p>
<h3 id="Applications_to_Your_Term_Projects"><a href="#Applications_to_Your_Term_Projects" class="headerlink" title="Applications to Your Term Projects"></a>Applications to Your Term Projects</h3><p><img src="/images/14543391286447.jpg" alt=""></p>
<h2 id="Distributed_Computing"><a href="#Distributed_Computing" class="headerlink" title="Distributed Computing"></a>Distributed Computing</h2><ul>
<li>Speedup not necessarily from better algorithm, but from scale</li>
<li>When an algorithms is converted to MapReduce it may operate significantly slower than sequential code on a single node</li>
<li>Mapping algorithms to a MapReduce framework is the challenge</li>
</ul>
<h2 id="Big_Data"><a href="#Big_Data" class="headerlink" title="Big Data"></a>Big Data</h2><ul>
<li>Web Data: Search, Advertisements, Behavioral data, Social graphs</li>
<li>Computational Physics Experiments<ul>
<li>Atomic Energy Research</li>
<li>Numerical Wind Tunnels</li>
</ul>
</li>
<li>The Earth Simulator<ul>
<li>Global Climate Change Research</li>
</ul>
</li>
<li>Weather Forecasting</li>
<li>The Human Genome Project, AIDS Research</li>
</ul>
<h2 id="Distributed_and_Cloud_Computing"><a href="#Distributed_and_Cloud_Computing" class="headerlink" title="Distributed and Cloud Computing"></a>Distributed and Cloud Computing</h2><ul>
<li>Distributed Computing<ul>
<li>Using distributed systems to solve computational problems.</li>
<li>Problem is divided in to many tasks, each of which is solved by one or more computers.</li>
</ul>
</li>
<li>Cloud Computing<ul>
<li>Distributed Computing on Cloud Resources</li>
</ul>
</li>
</ul>
<p>Distributed Computing on Cloud Computing Infrastructure = Scalable Computing</p>
<h2 id="Scalabel_Computing"><a href="#Scalabel_Computing" class="headerlink" title="Scalabel Computing"></a>Scalabel Computing</h2><ul>
<li>Embarrassingly parallel problems<ul>
<li>Shared Nothing Architecture</li>
</ul>
</li>
<li>Two dimensions of scalability<ul>
<li>Data: Given twice the amount of data, the same algorithm should take no more than twice as long to run</li>
<li>Resources: Given a cluster of twice the size, the same algorithm should take no more than half as long to run</li>
</ul>
</li>
</ul>
<h2 id="Big_Data-1"><a href="#Big_Data-1" class="headerlink" title="Big Data"></a>Big Data</h2><ul>
<li>Decompose the original problem in smaller, parallel tasks</li>
<li>Schedule tasks on workers distributed in a cluster<ul>
<li>Data locality</li>
<li>Resource availability</li>
</ul>
</li>
<li>Ensure Workers get the data they need</li>
<li>Coordinate synchronization among workers</li>
<li>Share partial results</li>
<li>Handle failures</li>
<li>Implementation details are complex</li>
<li>Shared memory approach(OpenMP)<ul>
<li>Developer needs to take case of almost everything</li>
<li>Synchronization, Concurrency</li>
<li>Resource Allocation</li>
</ul>
</li>
<li>MapReduce: a shared nothing approach<ul>
<li>Most of the above issures are taken care of</li>
<li>Problem decomposition and sharing partial results need particular attention</li>
<li>Optimization(memory and network consumption) are tricky</li>
</ul>
</li>
</ul>
<h2 id="Failures_in_Distributed_Computing"><a href="#Failures_in_Distributed_Computing" class="headerlink" title="Failures in Distributed Computing"></a>Failures in Distributed Computing</h2><ul>
<li>In large-scale distriuted computing, failure is ensured</li>
<li>Without fail-safe mechanisms distributed computing cannot work</li>
<li>HADOOP: MapReduce + HDFS(Hadoop Distributed Filesystem)<ul>
<li>Fail-safe Storage: By default stores 3 separate copies of each block</li>
<li>Fail-safe Task Management: Failed tasks re-scheduled up to 4 times</li>
</ul>
</li>
</ul>
<p>-&gt; Reliable and scalable computing</p>
<h2 id="HADOOP_-_26gt_3B_MapReduce"><a href="#HADOOP_-_26gt_3B_MapReduce" class="headerlink" title="HADOOP -&gt; MapReduce"></a>HADOOP -&gt; MapReduce</h2><ul>
<li>What is MapReduce?<ul>
<li>A programming model<ul>
<li>Inspired by function programming</li>
<li>Model to express distributed computations on massive amounts of data</li>
</ul>
</li>
<li>An execution framework<ul>
<li>Designed for large-scale data processing</li>
<li>Designed to run on clusters of commodity hardware</li>
</ul>
</li>
</ul>
</li>
<li>Separate the what from how<ul>
<li>Abstract away the “distributed” part of the system -&gt; handled by framework</li>
</ul>
</li>
<li>For optimal performance knowledge of framework is key<ul>
<li>Custom data reader/writer</li>
<li>Custom data partitioning</li>
<li>Memory utilization</li>
</ul>
</li>
</ul>
<h3 id="Map__26amp_3B_Reduce"><a href="#Map__26amp_3B_Reduce" class="headerlink" title="Map &amp; Reduce"></a>Map &amp; Reduce</h3><ul>
<li>Map: (map operation in functional programming)<ul>
<li>Transformation over a dataset</li>
<li>Apply a function f(x) to all elements in isolation</li>
<li>The application of f(x) to each element of a dataset can be parallelized in a straightforward manner</li>
</ul>
</li>
<li>Reduce: (fold operation in functional programming)<ul>
<li>Aggregation operation defined by a function g(x)</li>
<li>Data locality: elements in the list brought together</li>
<li>If we can group elements of the list, then reduce phase can proceed in parallel</li>
</ul>
</li>
<li>The framework coordinates the map and reduce phases<ul>
<li>How intermediate results are grouped for the reduce to happen in parallel</li>
</ul>
</li>
</ul>
<h3 id="Designing_a_MapReduce_algorithm"><a href="#Designing_a_MapReduce_algorithm" class="headerlink" title="Designing a MapReduce algorithm"></a>Designing a MapReduce algorithm</h3><ul>
<li>Key-value pairs are the basic data structures in MapReduce<ul>
<li>Keys and values can be: integers, strings, arbitrary data structures</li>
</ul>
</li>
<li>The design of a MapReduce algorithm involves:<ul>
<li>Define a key-value structures for application</li>
<li>Define mapper and reducer functions<ul>
<li>map: (k1,v1)-&gt;[(k2,v2)]</li>
<li>reduce: (k2,[v2]) -&gt; [(k3,v3)]</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="A_MapReduce_Job"><a href="#A_MapReduce_Job" class="headerlink" title="A MapReduce Job"></a>A MapReduce Job</h3><ul>
<li>Dataset: stored on the underlying distributed filesystem<ul>
<li>Split across files and across machines</li>
</ul>
</li>
<li>Mapper: The mapper is applied to every input key-value pair to generate intermediate key-value pairs</li>
<li>Reducer: The reducer is applied to all values associated with the same intermediate key to generate output key-value pairs</li>
<li>A distributed “group by” operation is implicitly performed between the map and reduce phases<ul>
<li>Intermediate data arrives at each reducer in order, sorted by the key</li>
<li>No ordering is guaranteed across reducers</li>
</ul>
</li>
<li>Output Keys from reducers are written to distributed filesystem</li>
<li>Intermediate keys are transient</li>
</ul>
<h3 id="Simplified_View_of_MapReduce"><a href="#Simplified_View_of_MapReduce" class="headerlink" title="Simplified View of MapReduce"></a>Simplified View of MapReduce</h3><ul>
<li>Mappers applied to all input key-value pairs -&gt; generate intermediate pairs</li>
<li>Reducers applied to all intermediate values associated with the same intermediate key</li>
<li>Between map and reduce lies a barrier that involves a large distributed sort and group by</li>
</ul>
<h3 id="Word_Count_in_MapReduce"><a href="#Word_Count_in_MapReduce" class="headerlink" title="Word Count in MapReduce"></a>Word Count in MapReduce</h3><ul>
<li>Define the appropriate key-value structures?<ul>
<li>Input (docid, doc)</li>
<li>Mapper (word, 1)</li>
<li>Output (word, C(word))</li>
</ul>
</li>
<li>Define Mapper and Reducer functions<ul>
<li>Mapper: tokenize the document, outputs key-value (word, 1)</li>
<li>The framework guarantees all values associated with the same key(word) are brought to the same reducer</li>
<li>Reducer: receives all values associated to some key (word)</li>
<li>Sums the values and writes output key-value pairs(word, C(word))</li>
</ul>
</li>
</ul>
<h3 id="Implementation_Details"><a href="#Implementation_Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><ul>
<li>A partitioned is in charge of assigning intermediate keys(words) to reducers<ul>
<li>Partitioner can be customized</li>
</ul>
</li>
<li>How many map and reduce tasks?<ul>
<li>The framework essentially takes care of map tasks</li>
<li>The designer/developer takes care of reduce tasks</li>
</ul>
</li>
</ul>
<h3 id="A_MapReduce_Job_on_Hadoop"><a href="#A_MapReduce_Job_on_Hadoop" class="headerlink" title="A MapReduce Job on Hadoop"></a>A MapReduce Job on Hadoop</h3><p>Master-slave architecture</p>
<ul>
<li>JobTrackerNode creating object for the job, determines number of mappers/reduces, schedules jobs, bookkeeping tasks’ status and progress</li>
<li>TaskTrackerNode: slaves manages individual tasks</li>
</ul>
<h2 id="HADOOP_-_26gt_3B_HDFS"><a href="#HADOOP_-_26gt_3B_HDFS" class="headerlink" title="HADOOP -&gt; HDFS"></a>HADOOP -&gt; HDFS</h2><ul>
<li>Improve computing throughput by co-locating data and computation</li>
<li>Abandon the separation between compute and storage nodes<ul>
<li>Not mandatory but highly desirable for MapReduce computing</li>
</ul>
</li>
<li>Distributed filesystems:<ul>
<li>Write once, read many workloads</li>
<li>Does not handle concurrency, but allows replication</li>
<li>Optimized for throughput not latency</li>
</ul>
</li>
<li>HDFS(Hadoop Distributed FileSystem)<ul>
<li>Tailored to the specific requirements of MapReduce</li>
</ul>
</li>
</ul>
<h3 id="HDFS_I/O"><a href="#HDFS_I/O" class="headerlink" title="HDFS I/O"></a>HDFS I/O</h3><ul>
<li>A typical read from a client involves:<ul>
<li>Contact the NameNode to determine where the actual data is stored</li>
<li>NameNode replies with block identifiers and locations(which DataNode)</li>
<li>Contact the DataNode to fetch data</li>
</ul>
</li>
<li>A typical write from a client invovles:<ul>
<li>Contact the NameNode to update the namespace and verify permissions</li>
<li>NameNode allocates a new block on a suitable DataNode</li>
<li>The client directly streams to the selected DataNode</li>
<li>HDFS files are immutable</li>
</ul>
</li>
<li>Data is never moved through the NameNode -&gt; no bottleneck</li>
</ul>
<h3 id="HDFS_Replication"><a href="#HDFS_Replication" class="headerlink" title="HDFS Replication"></a>HDFS Replication</h3><ul>
<li>By default, HDFS stores 3 separate copies of each block<ul>
<li>Ensures reliability, availability and performance</li>
</ul>
</li>
<li>Replication policy<ul>
<li>Spread replicas across different racks -&gt; Robust against cluster node and rack failures</li>
</ul>
</li>
<li>Block replication benefits MapReduce<ul>
<li>Scheduling decisions can take replicas into account</li>
<li>Exploit better data locality</li>
</ul>
</li>
<li>HDFS also transparently checksums all data during I/O</li>
</ul>
<h3 id="HDFS_Constraints"><a href="#HDFS_Constraints" class="headerlink" title="HDFS Constraints"></a>HDFS Constraints</h3><ul>
<li>Input splits for MapReduce based on individual files<ul>
<li>Mappers are launched for every file</li>
<li>High startup correctness</li>
<li>Inefficient “shuffle and sort”</li>
</ul>
</li>
</ul>
<p>Small number of large files preferred over a large number of small files</p>
<h2 id="Cloud_Computing_-_Advantages"><a href="#Cloud_Computing_-_Advantages" class="headerlink" title="Cloud Computing - Advantages"></a>Cloud Computing - Advantages</h2><ul>
<li>Illusion of infinite computing resources on demand</li>
<li>Elimination of an up-front commitment by user</li>
<li>Ability to pay for use of computing resources on a short-term basis as needed</li>
<li>Lowering entry barrier for large scale computing<ul>
<li>Removing equipment fixed cost</li>
</ul>
</li>
<li>Making available economy-of-scale<ul>
<li>Reducing operating variable cost</li>
</ul>
</li>
</ul>
<h2 id="Developing_Algorithms_in_Hadoop"><a href="#Developing_Algorithms_in_Hadoop" class="headerlink" title="Developing Algorithms in Hadoop"></a>Developing Algorithms in Hadoop</h2><ul>
<li>Algorithm development involves:<ul>
<li>preparing the input data</li>
<li>Implement the mapper and the reducer</li>
<li>Optionally, design the combiner and the partitioner</li>
</ul>
</li>
<li>How to recast existing algorithms in MapReduce?<ul>
<li>It is not always obvious how to express algorithms</li>
<li>Data structures play an important role</li>
<li>Optimization is hard</li>
</ul>
</li>
<li>Developer needs to understand the framework</li>
<li>Learn by examples<ul>
<li>Design Patterns</li>
<li>Synchronization is most trick aspect</li>
</ul>
</li>
</ul>
<h2 id="Efficiency_2C_Bottlenecks__26amp_3B_Precautions"><a href="#Efficiency_2C_Bottlenecks__26amp_3B_Precautions" class="headerlink" title="Efficiency, Bottlenecks &amp; Precautions"></a>Efficiency, Bottlenecks &amp; Precautions</h2><ul>
<li>Efficiency<ul>
<li>Reduces I/O bandwidth(number of intermediate key-value pairs)</li>
<li>Un-necessary object creation and destruction(garbage collection)</li>
</ul>
</li>
<li>Bottlenecks<ul>
<li>In-mapper combining depends on having sufficient memory</li>
<li>Multiple threads compete for same resources</li>
</ul>
</li>
<li>Precautions<ul>
<li>Breaks functional programming paradigm due to state preservation</li>
<li>Preserving state -&gt; algorithm behavior might depend on execution order</li>
</ul>
</li>
</ul>
<h2 id="How_do_you_interpret_speedup_results_3F"><a href="#How_do_you_interpret_speedup_results_3F" class="headerlink" title="How do you interpret speedup results?"></a>How do you interpret speedup results?</h2><p>Based on the PALLAS paper from UC Berkeley</p>
<ul>
<li>(SW) Application Developers<ul>
<li>Provide end-user with new capabilites within cost constraints</li>
<li>Concerned about a specific subset of applications at a time</li>
<li>Pragmatic towards processor platform choices</li>
<li>Gains no value from documenting multiple implementation platforms</li>
<li><strong>Platform as a black box</strong></li>
</ul>
</li>
<li>(HW) Architecture Researchers<ul>
<li>Develop new micro-architectures features for next-gen processors</li>
<li>Understand the pros and cons of architectural features of a <strong>broad range</strong> of platform for a <strong>broad range</strong> of applications</li>
<li>Use <strong>toy problems</strong> to exercise all features</li>
<li><strong>Application as a black box</strong></li>
</ul>
</li>
</ul>
<h2 id="Computational_Finance"><a href="#Computational_Finance" class="headerlink" title="Computational Finance"></a>Computational Finance</h2><p>Use Value-at-Risk(VaR) estimates - based on Monte Carlo methods Pattern.</p>
<ul>
<li><p>VaR</p>
<ul>
<li>Maximum expected loss that will not be exceeded</li>
<li>under normal market considerations</li>
<li>over a predetermined period</li>
<li>at a given confidence level</li>
</ul>
</li>
<li><p>Different Optimization Across Platforms</p>
<ul>
<li>Oganization &amp; Structure: Reduce Computation</li>
<li>Algorithm Strategies: Fast Convergence</li>
<li>Implementation Strategies: Saving Memory BW / Kernel Merge Vectorization</li>
</ul>
</li>
</ul>
<h2 id="Speedup"><a href="#Speedup" class="headerlink" title="Speedup"></a>Speedup</h2><p>Before: Performance x  – After: Performance y – ROI(speedup): y/x</p>
<h2 id="Term_Project_Report"><a href="#Term_Project_Report" class="headerlink" title="Term Project Report"></a>Term Project Report</h2><ul>
<li>Clearly describe what is the <strong>baseline</strong> you are comparing to, in terms of:<ul>
<li>Platform used</li>
<li>Software architecture</li>
<li>Algorithm strategies</li>
<li>Implementation strategies</li>
</ul>
</li>
<li>Present your speed ups, which is often <strong>NOT</strong> only the result of differences in the processor or the platform, but also include:<ul>
<li>Differences in application architecture</li>
<li>Differences in algorithm strategy</li>
<li>Differences in implementation strategy techniques</li>
<li>Differences in the fine-tuning of parameters</li>
</ul>
</li>
</ul>
<hr>
<h1 id="Question_Set"><a href="#Question_Set" class="headerlink" title="Question Set"></a>Question Set</h1><h2 id="Module_1-2"><a href="#Module_1-2" class="headerlink" title="Module 1.2"></a>Module 1.2</h2><ul>
<li>What are the differences between multicore and manycore processors?<ul>
<li>Multicore: yoke of oxen. Each core optimized for executing a single thread.</li>
<li>Manycore: flock of chickens. Cores optimized for aggregate throughput, deemphasizing individual performance.</li>
</ul>
</li>
<li>What is instruction level parallelism? What is SIMD?<ul>
<li>ILP: Instructions in a sequence that can be computed at the same time.</li>
<li>ILP(wiki): a measure of how many of the operations in a computer program can be performed simultaneously</li>
<li>SIMD(wiki): computers with multiple processing elements that perform the same operation on multiple data points simultaneously. data level parallelism. </li>
</ul>
</li>
<li>What is simultaneous multithreading?<ul>
<li>a technique for improving the overall efficiency of superscalar CPUs with hardware multithreading. SMT permits multiple independent threads of execution to better utilize the resources provided by modern processor architectures.</li>
</ul>
</li>
<li>What are the three metrics for a memory hierarchy?<ul>
<li>Capacity: Size, e.g. number of bytes of data</li>
<li>Latency: From start to finish, in units of time, e.g. CPU clock cycles</li>
<li>Throughput: Tasks accomplished per unit time, e.g. GB/s</li>
</ul>
</li>
<li>What are the different system granularity?<ul>
<li>Remote Procedure Call based Implementations</li>
<li>MPI-based Implementations</li>
<li>Pthread-based Implementations</li>
<li>Multicore Task Queue-based Implementations</li>
<li>Manycore Throughput Optimized Implementations</li>
</ul>
</li>
</ul>
<h2 id="Module_1-3"><a href="#Module_1-3" class="headerlink" title="Module 1.3"></a>Module 1.3</h2><ul>
<li>What is the different between concurrency and parallelism?<ul>
<li>Concurrency: We expose concurrency in our application</li>
<li>Parallelism: We exploit parallelism in our platform</li>
</ul>
</li>
<li>What are the four key elements of the human problem solving process?<ul>
<li>Understand the current state</li>
<li>Observe the internal representation</li>
<li>Search among alternatives</li>
<li>Select from a set of choices</li>
</ul>
</li>
<li>What are the characteristics of a current algorithm implementation?<ul>
<li>Efficiency</li>
<li>Simplicity</li>
<li>Portablility</li>
<li>Scalability</li>
</ul>
</li>
<li>What levels of concurrency can be exposed in the kmeans algorithm?<ul>
<li>Expectation: N(independent) k(min reduction) D(sum reduction)</li>
<li>Maximization: D(independent) N(Histogram computation into k bins)</li>
</ul>
</li>
<li>What levels of parallelism are available to be exploited?<ul>
<li>Core level Parallelism</li>
<li>SIMD level parallelism</li>
</ul>
</li>
<li>What mapping between concurrency and parallelism can be explored?<ul>
<li>One level of concurrency could map to multiple levels of parallelism</li>
<li>SIMD &amp; core-level parallelism across data-points<ul>
<li>Update membership for each data point sequentially</li>
<li>Histogram computation</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Module_2-1"><a href="#Module_2-1" class="headerlink" title="Module 2.1"></a>Module 2.1</h2><ul>
<li>What are the exploitable levels of parallelism in a multicore processor?<ul>
<li>SIMD-Level: using vectorizing compiler and hand-code intrinsics</li>
<li>SMT-Level: OS abstract it to core-level parallelism</li>
<li>Core-Level: Using threads to describe work done on different cores</li>
</ul>
</li>
<li>What is SPMD? And how to use OpenMP to do SPMD?<ul>
<li>OpenMP - Pthread-based Implementations(granularity)</li>
<li>SPMD(wiki): SPMD (single program, multiple data) is a technique employed to achieve parallelism; it is a subcategory of MIMD. Tasks are split up and run simultaneously on multiple processors with different input in order to obtain results faster.</li>
<li>OpenMP managed <strong>Fork-Join</strong> Parallelism to do SPMD</li>
</ul>
</li>
<li>What is the difference between critical and atomic?<ul>
<li>critical: 并行程序块，同时只能有一个线程能访问该并行程序块</li>
<li>atomic: 只适用于两种情况：自加减操作以及基本的操作符</li>
<li>critical 与 atomic 的区别在于，atomic 仅适用于两种基本类型操作，而且 atomic 所防护的仅为一句代码。critical 可以对某个并行程序块进行防护。</li>
</ul>
</li>
<li>How to reduce synchronization cost and avoid false sharing?<ul>
<li>Be aware of the cache line sizes for a platform</li>
<li>Avoid accessing the same cache line from different threads</li>
</ul>
</li>
<li>What are the scheduling, reduction, data sharing, and synchronization options for OpenMP?<ul>
<li>scheduling<ul>
<li>static</li>
<li>dynamic</li>
<li>guided</li>
</ul>
</li>
<li>data sharing<ul>
<li>shared</li>
<li>private</li>
<li>firstprivate</li>
<li>lastprivate</li>
</ul>
</li>
<li>synchronization<ul>
<li>ordered</li>
<li>barrier</li>
<li>single</li>
<li>nowait</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="21_21_Module_2-2"><a href="#21_21_Module_2-2" class="headerlink" title="!! Module 2.2"></a>!! Module 2.2</h2><ul>
<li>Why naive matrix-multiply does not achieve peak performance on the CPU?<ul>
<li>Deep memory hierarchy</li>
<li>Pipeline, ILP</li>
<li>Free operations are not free</li>
</ul>
</li>
<li>What are the different data layouts for matrices?<ul>
<li>Column major</li>
<li>Row major</li>
</ul>
</li>
<li>What is cache blocking? Why do we need it?</li>
<li>Is blocking sufficient? What more can we do?<ul>
<li>Strength reduction</li>
<li>Function inlining</li>
<li>Loop unrolling</li>
<li>Common subexpression elimination</li>
<li>Load/Store elimination</li>
<li>Table lookups</li>
<li>Branch elimination</li>
</ul>
</li>
</ul>
<h2 id="Module_2-3"><a href="#Module_2-3" class="headerlink" title="Module 2.3"></a>Module 2.3</h2><ul>
<li>What is the roofline model? What are the metrics and axis used?<ul>
<li>Roofline model: a pedagogical tool for program analysis and optimization</li>
<li>Metric of interest: DRAM bandwidth(GB/s)</li>
<li>y-axis: FLOPs; x-axis: AI</li>
</ul>
</li>
<li>What is the difference between “flop’s per memory instruction” from “flop’s per DRAM byte”?<ul>
<li>?</li>
</ul>
</li>
<li>Consider an image <code>Image[height][width]</code>. If one were to stride through the columns of values, what would be the effects? How would they be mapped to the roofline?<ul>
<li>?</li>
</ul>
</li>
<li>How does one model incomplete SIMDization (e.g. half the flop’s can be SIMDized). insufficient ILP(some dependent flop’s), or an imbalance between FDMUL’s and FPADD’s on the roofline?<ul>
<li>See the complete graph below</li>
</ul>
</li>
<li>How would one model {branch mispredicts, TLB misses, or too many streams for the prefetchers} on the roofline.<ul>
<li>See the complete graph below</li>
</ul>
</li>
</ul>
<p><img src="/images/14543392317490.jpg" alt=""></p>
<h2 id="Module_3-1"><a href="#Module_3-1" class="headerlink" title="Module 3.1"></a>Module 3.1</h2><ul>
<li>What’s the Difference between Multicore and Manycore?<ul>
<li>Multicore: yoke of oxen. Each core optimized for executing a single thread.</li>
<li>Manycore: flock of chickens. Cores optimized for aggregate throughput, deemphasizing individual performance.</li>
</ul>
</li>
<li>When does using a GPU make sense?<ul>
<li>Application with a lot of concurrency (1000-way, fine-grained concurrency)</li>
<li>Some memory intensive applications (Aggregate memory bandwidth is higher)</li>
<li>Advantage diminishes when task granularity becomes too large to fit in shared memory</li>
</ul>
</li>
<li>What is the memory hierarchy inversion? And why is it there?<ul>
<li>Memory hierarchy inversion: more registers than shared memory</li>
<li>Single thread won’t see inverse hierarchy</li>
<li>Inversion comes from parallelism</li>
<li>Registers scale with SIMD and multithreading (Shared memory/L1 cache don’t have to)</li>
</ul>
</li>
<li>What is the memory wall? How to get around it?<ul>
<li>Memory wall: Increasing gap between Processor and DRAM performance</li>
<li>Many core Processors utilize application concurrency to hide memory latency (aka get around the memory wall)</li>
</ul>
</li>
<li>Why warps?<ul>
<li>Software abstract info hid an extra level of architecture complexity</li>
<li>A 128KB register file is a large memory (takes more than one cycle)</li>
<li>Hardware provide 160wide physical SIMD units, half-pump register files</li>
<li>To simplify the programming model</li>
</ul>
</li>
<li>How do we deal with GPUs of different sizes?<ul>
<li>CUDA provides an abstract infor concurrency to be fully exposed</li>
<li>HW/Runtime provides capability to schedule the computation</li>
</ul>
</li>
<li>What are the implications of the thread block abstraction?<ul>
<li>Computation is grouped into blocks of independent concurrently execrable work</li>
<li>Fully exposed the concurrency in the application</li>
<li>The HW/Runtime makes the decision to selectively sequentialize the execution as necessary</li>
</ul>
</li>
<li>How do threads communicate with each other?<ul>
<li>Shared Memory</li>
<li>Manycore processors provide memory local to each core</li>
<li>Computations in SIMD-lanes in the same core can communicate via memory read / write</li>
</ul>
</li>
<li>What is the caveat in synchronizing threads in a thread block?<ul>
<li><code>__syncthreads()</code> 必须在每个线程中都能执行到，而不能有的有有的没有</li>
</ul>
</li>
</ul>
<h2 id="Module_3-2"><a href="#Module_3-2" class="headerlink" title="Module 3.2"></a>Module 3.2</h2><ul>
<li>What are the three ways to improve execution throughput?<ul>
<li>Maximizing Memory Throughput<ul>
<li>SoA vs AoS</li>
<li>Memory coalescing</li>
<li>Use of shared memory</li>
<li>Memory bank conflict</li>
<li>Padding</li>
</ul>
</li>
<li>Maximizing Instruction Throughput<ul>
<li>Branch divergence</li>
<li>Optimize instruction mix</li>
</ul>
</li>
<li>Maximizing Scheduling Throughput</li>
</ul>
</li>
<li>When to use SOA vs AOS?<ul>
<li>Unfortunately, the SoA form is not ideal in all circumstances. For random or incoherent circumstances, gathers are used to access the data and the SoA form can result in extra unneeded data being read into cache, thus reducing performance. In this case, use of the AoS form instead will result in a smaller working set and improved performance. Generally, though, if the computation is to be vectorized, the SoA form is preferred.</li>
</ul>
</li>
<li>What is memory coalescing? When to use it? Why is it important?<ul>
<li>Memory coalescing: combine multiple memory accesses generated from multiple threads into a single physical transaction</li>
<li>Hardware Constraint: DRAM is accessed in ‘segments’ of 32B/64B/128B</li>
</ul>
</li>
<li>What is shared memory? How to use it?<ul>
<li>Manycore processors provide memory local to each core</li>
<li><code>__share__</code></li>
</ul>
</li>
<li>What is memory bank conflict? How to work around it?<ul>
<li>A bank conflict occurs if two or more threads access any bytes within different 32-bit words belonging to the same bank.</li>
<li>If each thread in a halfwarp accesses successive 32bit values there are no bank conflicts.</li>
</ul>
</li>
<li>What is branch divergence?<ul>
<li>threads of a warp diverge via a data-dependent conditional branch</li>
</ul>
</li>
<li>How to optimize for instruction mix?<ul>
<li>Compiler Assisted Loop Unrolling</li>
<li>#pragma unroll</li>
</ul>
</li>
<li>What is occupancy? How to model/measure it?<ul>
<li>Occupancy: Ability of a CUDA kernel to occupy concurrent contexts in a SM</li>
<li>CUDA Occupancy Calculator</li>
<li><code>--ptxas-options=-v</code></li>
</ul>
</li>
<li>How to use the code profiler with CUDA?<ul>
<li>CUDA Profiler Tutorial by Erik Reed</li>
</ul>
</li>
</ul>
<h2 id="Module_3-3"><a href="#Module_3-3" class="headerlink" title="Module 3.3"></a>Module 3.3</h2><ul>
<li>What are the important properties of a Map function?<ul>
<li>Side-effect free: Only returning a value, no modifications of state with the rest of the application</li>
<li>Independent: Has an independent piece of work, where its input does not depend on another function</li>
</ul>
</li>
<li>What are the important properties of a Reduce function?<ul>
<li>Associativity: a+(b+c) == (a+b)+c</li>
<li>Allows elements to be reduced in prarallel in a ‘tree’</li>
</ul>
</li>
<li>What are the important properties of s Scan function?<ul>
<li>return a ordered set</li>
</ul>
</li>
<li>How to compact an array in a data-parallel way?<ul>
<li>Map - create flags (1 keep, 0 remove)</li>
<li>Scan - compute index</li>
<li>Map - copy to new array</li>
</ul>
</li>
<li>How to find unique elements in an array in a data-parallel way?<ul>
<li>Sort</li>
<li>Map - create flags (1 keep, 0 remove)</li>
<li>Scan - compute index</li>
<li>Map - copy to new array</li>
</ul>
</li>
</ul>
<h2 id="Module_3-4"><a href="#Module_3-4" class="headerlink" title="Module 3.4"></a>Module 3.4</h2><ul>
<li>What are parallel software patterns?</li>
<li>What are the three goals the software patterns aim to achieve?</li>
<li>What is a software architecture?</li>
<li>How is it important for writing fast code?</li>
<li>What the the five categories of patterns in OPL?</li>
<li>What are the nine sections in an OPL pattern?</li>
<li>What are the areas of consideration for your Term Project?</li>
</ul>
<h2 id="Module_4-1"><a href="#Module_4-1" class="headerlink" title="Module 4.1"></a>Module 4.1</h2><ul>
<li>Why Distributed Computing?</li>
<li>How common are failures in Large Scale Distributed Computing?</li>
<li>How are failures handled in HADOOP?</li>
<li>What is MapReduce?</li>
<li>When developing a MapReduce application what components and functions need to be defined?</li>
<li>How are data bottlenecks reduced in HDFS?</li>
<li>What are the advantages of Cloud Computing?</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>本来打算借着当助教，看看这门课有没有什么变化。事实上，没啥变化，所以这里先把当时我的笔记放出来，之后的课程可能会主要集中于代码和项目的思路分析，具体理论的东西不会再重复太多。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="思考题" scheme="http://wdxtub.com/tags/%E6%80%9D%E8%80%83%E9%A2%98/"/>
    
      <category term="笔记" scheme="http://wdxtub.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="编程" scheme="http://wdxtub.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[游戏引进评估的一些思考]]></title>
    <link href="http://wdxtub.com/2016/02/01/game-import/"/>
    <id>http://wdxtub.com/2016/02/01/game-import/</id>
    <published>2016-02-01T11:57:08.000Z</published>
    <updated>2016-02-01T14:23:15.000Z</updated>
    <content type="html"><![CDATA[<p>最近要面一个游戏引进评估的职位，因为网上的资料实在很少，所以自己总结思考了三个方面。虽然难免流于纸上谈兵，但也比什么都不准备想当然要好得多。</p>
<a id="more"></a>
<hr>
<p>游戏评估算是非技术类职位，因为面试内容不是算法题，所以前期准备的空间很大。这也就意味着，首先需要确定一个整体的思路，不然很容易迷失在繁杂的细节当中。对于任何一场面试，面任何一个职位，从公司发布的职位描述开始，往往不会错。虽然职位描述大多比较宽泛抽象，但至少可以给我们一个大方向。</p>
<p>例如，我大致浏览了一下不同公司对游戏评估类似职位的描述，主要强调的工作内容和能力有以下几点：</p>
<ul>
<li>寻找、评估、谈判，完善甄别评估体系</li>
<li>了解市面上的游戏，对行业有基本了解</li>
<li>市场和竞争产品的关注与分析</li>
</ul>
<p>游戏评估其实和其他的可行性分析工作一样，需要在确定的大方向下，可以切分出不同的维度，在各个维度上进行调查、研究和分析，对于是否要引进一个游戏来说，主要可以分成这三个维度：</p>
<ol>
<li>游戏质量评估：游戏本身的质量如何，涉及到许多关于游戏设计的概念，也是本文着力想要说明的</li>
<li>游戏运营评估：游戏是否适合本地化运营，包括对应的改动及处理好文化差异</li>
<li>具体事务评估：这一部分比较杂，是除了质量和运营外的诸多因素的综合考虑，比方说研发团队的从业经历，是否是经典题材，投资方等等</li>
</ol>
<p>因为不确定面试时具体要讨论哪方面（当然也可能我想得全 miss），所以这三个方面都会写一下，算是一个思考和总结</p>
<h2 id="u6E38_u620F_u8D28_u91CF_u8BC4_u4F30"><a href="#u6E38_u620F_u8D28_u91CF_u8BC4_u4F30" class="headerlink" title="游戏质量评估"></a>游戏质量评估</h2><p>对一个游戏进行评估，主要可以从以下五个维度来进行（这些同时也与营销策略的制定密切相关）：</p>
<ul>
<li>核心体验：游戏类型，游戏乐趣的主要来源，玩家进行游戏的主要动机</li>
<li>基础机制：长中短期目标是否明确，规则是否清晰，策略与运气（其实就是数值）是否平衡</li>
<li>奖惩系统：玩家在胜利和失败时会得到什么，是用什么方式来处理可能产生的挫败感</li>
<li>长期激励：游戏通过什么方式让玩家愿意持续去进行游戏，荣誉/惊喜/等级/任务/社交/玩法/奖励/活动等等</li>
<li>美学布局：剧情，画面，界面设计，音乐音效，动画效果，色彩色调及它们对玩家心理的影响</li>
</ul>
<p>这里面每一点如果展开，都是几天几夜说不完的，所以简单挑一些比较清晰直白的来进行描述。比方说，如果要分析游戏乐趣从哪里来，那么基本就逃不开下面八种模式：</p>
<ol>
<li>竞争：竞速，占领版图等等</li>
<li>达到目标：比方说达到一定等级或者是拥有某些装备</li>
<li>战胜：可以是 PVP，PVE，也可以是完成设定好的挑战</li>
<li>合作：多人副本，公会，社交</li>
<li>角色扮演：属性成长，剧情带入</li>
<li>探索和建设：开放世界沙盒类游戏</li>
<li>收集：一些需要积累的任务，或者是类似偷菜这种以收集为主体的游戏</li>
<li>解决问题或制定策略：即时战略与益智游戏等等</li>
</ol>
<p>我们发现，其实目前许多游戏早已涵盖了几个甚至全部的游戏模式。通过这种大而全的策略来笼络各类玩家。而这些乐趣的来源，实际上是玩家进行游戏的动机的具象化，玩家的动机主要是以下这些：权力、好奇心、独立性、地位、社会联系、复仇、荣誉、理想主义、锻炼身体、浪漫、嫁人、整理、饮食、接受、宁静、存储等等。</p>
<p>玩家的类型也是多种多样的，评估的时候也需要考虑到游戏的主要受众，比方说：社交家，自由者，成就者，慈善家，玩家（这里指研究游戏系统），破坏者等等。最好根据不同的特点来进行对应的评估。</p>
<p>最重要的一个部分，可能是文化层面的契合度分析。日韩游戏和我们的理念比较接近，但是欧美的可能就差别比较大了。经济、文化、信息渠道和用户习惯的巨大差异，使得游戏引进需要更加细致的评估。比方说，欧美玩家更加崇尚通过长时间的努力来磨练技艺，而中国玩家则更愿意直接砸钱甩出优越感，这可能就需要对游戏本身的玩法和逻辑进行一定调整了。</p>
<p>而文化层面的评估，还可以更加细化，如：</p>
<ul>
<li>人文：背景、故事、历史、神话、宗教、民俗、语言（不同文化间可能差异巨大）</li>
<li>视听：画面、布局、声乐、美术、色彩、动画</li>
<li>资源管理：人口、管理、经济、数值、统计</li>
<li>空间：建筑、地理、气候、农业、畜牧业、化学</li>
<li>用户行为：玩家类型、社交、心理、战略</li>
</ul>
<p>这里就不展开了。</p>
<h2 id="u6E38_u620F_u8FD0_u8425_u8BC4_u4F30"><a href="#u6E38_u620F_u8FD0_u8425_u8BC4_u4F30" class="headerlink" title="游戏运营评估"></a>游戏运营评估</h2><p>如果游戏的质量过硬，还需要考虑具体运营的时候，能否顺利进行本土化处理，比方说，处理好文本，表达方式，接受习惯的差异，添加本地化支付方式等。还需要考虑的问题有；</p>
<ul>
<li>依赖鲸鱼玩家 vs 依赖众多小额付费玩家（微交易-比方说花一块钱复活）</li>
<li>性能数据、过程数据、用户数据</li>
<li>消费者指标、社区指标、玩法指标（可以通过观察不同地区 App Store 排行榜，百度指数，贴吧论坛等的人气变化来进行评估）</li>
<li>能够让玩家维持多久的游戏时间，这种玩法的接受度有多高</li>
<li>目标群体（人数，人口特征，消费能力）以及游戏地点（居家休闲，旅途，工作间隙，还是需要专门拿出一段时间来游戏）</li>
</ul>
<h2 id="u5177_u4F53_u4E8B_u52A1_u8BC4_u4F30"><a href="#u5177_u4F53_u4E8B_u52A1_u8BC4_u4F30" class="headerlink" title="具体事务评估"></a>具体事务评估</h2><p>这里简单提一些需要注意的问题：</p>
<ul>
<li>研发团队的从业经历</li>
<li>是否源自经典题材的拓展（横向、纵向）</li>
<li>游戏数据表现</li>
<li>投资方与并购方</li>
<li>游戏题材的情怀与玩家共鸣</li>
<li>与当红游戏进行对比</li>
<li>是否有明星等进行广泛影响（比方说 Guitar Hero 在北美就有很多大牌明星代言）</li>
<li>行业竞赛及所得奖项</li>
</ul>
<p>具体工作中肯定还会遇到比这个详尽繁杂得多的问题，这里就算是梳理下思路了。</p>
<h2 id="u9644_u5F55_uFF1A_u817E_u8BAF_u5F15_u8FDB/_u4EE3_u7406_u6E38_u620F_u5217_u8868"><a href="#u9644_u5F55_uFF1A_u817E_u8BAF_u5F15_u8FDB/_u4EE3_u7406_u6E38_u620F_u5217_u8868" class="headerlink" title="附录：腾讯引进/代理游戏列表"></a>附录：腾讯引进/代理游戏列表</h2><p>手游：</p>
<p>火影忍者 / 奇迹暖暖 / 糖果传奇 / 我叫 MT 2 / 仙剑 / 宫爆老奶奶 / Two Dots / 全民切水果 / 胜利足球 / FIFA ONLINE 3 M / 复仇者联盟</p>
<p>端游</p>
<p>剑灵（NCSoft）/ 地下城与勇士 / 寻仙 / 天堂（NCSoft）/ 英雄联盟 / 穿越火线 / NBA 2K OL（Take-Two）/ Call of Duty Online（动视暴雪）/ 自由足球 / 战争前线（Crytek）/ 战地之王（Redduck）/ 超神英雄HON（S2 Games）/ 上古世纪 / 怪物猎人（Capcom）/ 疾风之刃（Allm）/ 兽人必须死（Robot）/ 全职大师（NCSoft）/</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>最近要面一个游戏引进评估的职位，因为网上的资料实在很少，所以自己总结思考了三个方面。虽然难免流于纸上谈兵，但也比什么都不准备想当然要好得多。</p>]]>
    
    </summary>
    
      <category term="引进" scheme="http://wdxtub.com/tags/%E5%BC%95%E8%BF%9B/"/>
    
      <category term="游戏" scheme="http://wdxtub.com/tags/%E6%B8%B8%E6%88%8F/"/>
    
      <category term="评估" scheme="http://wdxtub.com/tags/%E8%AF%84%E4%BC%B0/"/>
    
      <category term="面试" scheme="http://wdxtub.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Game" scheme="http://wdxtub.com/categories/Game/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Deadline 与不插电]]></title>
    <link href="http://wdxtub.com/2016/01/31/deadline-and-unplug/"/>
    <id>http://wdxtub.com/2016/01/31/deadline-and-unplug/</id>
    <published>2016-02-01T02:36:38.000Z</published>
    <updated>2016-02-01T03:19:54.000Z</updated>
    <content type="html"><![CDATA[<p>这是一篇很早就想写的文章，在回家的路上捋清了思路。想要说的是：焦虑其实是一种生活方式。但是可能只需要一个简单的动作，就能让一切焕然一新。</p>
<a id="more"></a>
<hr>
<p>这个世界上有两种焦虑，大部分人属于第一种：嘴上的焦虑。另一种属于生理上的『焦虑症』，不懂，所以不妄议，接下来提到的焦虑，都指的是『嘴上的焦虑』。</p>
<p>在 CMU 听到最多的一句话，就是『我这周有 X 个 Deadline，怎么办要死了』。我很能理解他们的心情，潜台词就是说『但是老子还是顽强活下来了，是不是超级厉害』。所以常常能看到『嘴上焦虑症』患者平日里大把大把浪费时间然后熬几个夜感动一下自己，即使真的没做好也有个退路，『At least I try』。我想说的是，如果没有去想办法提高自己的效率反而是用时间的堆积来告诉自己已经很努力，也就比不做作业稍微好一点点。所谓作业，是让我们在一次次挑战中找到并看清自己，如果一直走的是堆时间而不是增效率的路，那这个学，不能说是白上，只能说『您辛苦了』。</p>
<p>Deadline 的逻辑，其实和贫穷很像，『贫穷』是经济的『稀缺』，而 Deadline 是时间的『稀缺』，它们带来的问题都是『判断力剥夺』。判断力实际上是一个很玄学的概念，比方说直觉或者是一念之间。但是生活中大部分情况需要的是理性分析判断，这里主要强调的也是这个方面。</p>
<p>拥有判断力是一个过程，漫长的过程。笨办法，自己一个个坑躺过去；稍微聪明一点的办法，找过来人取经；最有效率的办法，看书。可是，判断对错好坏其实是第二件事，第一件事是，拥有判断（不是想当然的那种判断）。怎么拥有判断又是一个很大的话题，这里就先不展开，姑且假设大家都已经有了一定的判断能力。</p>
<p>那么这个时候，『稀缺』在某种程度上来说，就是判断力的决定因素了。因为贫穷，所以在判断的时候只去关注短期经济利益，即使每一步都不犯错，最多也只能落入局部最优。因为时间紧，所以在判断的时候，基本就没有了判断（基本就按照 Deadline 的时间顺序来了）。</p>
<p>乍看起来没有什么问题，但是知识本身有其组织架构，也就是说不同的内容可能之间有路径依赖，那么如果只按照时间顺序来学习，肯定很多时候会因为知识储备不充分的缘故，在很简单的问题上浪费大量的时间。一来没有机会检验调整自己的知识体系，二来分不清轻重缓急，那时间管理注定是一场灾难。</p>
<p>但 Deadline 的用意绝非如此，反而更应该是一个帮助我们提高效率的工具。举个例子，拔掉笔记本的电源，也就是不插电，只给你一段有限的时间去完成工作，那么在开始之前，是不是会想办法去尽可能利用好这段时间呢？</p>
<p>在开动之前，知道自己需要什么，有目的；知道自己要怎么做，有步骤；其实就是『谋定而后动』的题中之义。</p>
<p>所以当我看到插着电坐在桌子前却不知道在做什么的同学，往往都会想：如果把他们的电源拔掉，是不是就能让他们真正开始思考，究竟做什么，才能最有效率地完成手头上的任务。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这是一篇很早就想写的文章，在回家的路上捋清了思路。想要说的是：焦虑其实是一种生活方式。但是可能只需要一个简单的动作，就能让一切焕然一新。</p>]]>
    
    </summary>
    
      <category term="判断" scheme="http://wdxtub.com/tags/%E5%88%A4%E6%96%AD/"/>
    
      <category term="思考" scheme="http://wdxtub.com/tags/%E6%80%9D%E8%80%83/"/>
    
      <category term="生活" scheme="http://wdxtub.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
      <category term="稀缺" scheme="http://wdxtub.com/tags/%E7%A8%80%E7%BC%BA/"/>
    
      <category term="Thinking" scheme="http://wdxtub.com/categories/Thinking/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[软件架构与设计 习题课 3 从不同视角描述系统]]></title>
    <link href="http://wdxtub.com/2016/01/31/sad-r3/"/>
    <id>http://wdxtub.com/2016/01/31/sad-r3/</id>
    <published>2016-01-31T19:18:09.000Z</published>
    <updated>2016-02-01T02:08:05.000Z</updated>
    <content type="html"><![CDATA[<p>这一次的作业，会在之前的基础上，通过不同的观察角度，更加科学系统来展示整个软件的架构和各个部分的关系。老师给出了一篇论文，这里也会简单总结下。</p>
<a id="more"></a>
<hr>
<p>老师给出的论文叫做 <a href="http://www.cs.ubc.ca/~gregor/teaching/papers/4+1view-architecture.pdf" target="_blank" rel="external">Architectural Blueprints—The “4+1” View Model of Software Architecture</a>，实话说，没啥用。作者用若干个例子来说明了我们需要从多个角度来审视和描述系统，整个思路基本上用下面这张图就可以概括：</p>
<p><img src="/images/Screen%20Shot%202016-01-31%20at%202.16.18%20PM.jpg" alt="总体设计"></p>
<p>因为论文是20多年前的，所以很多当时比较『新』的概念，其实在现在的软件开发中早已成为平常，甚至也已经过时了。至少在目前风口浪尖的移动互联网，等这些乱七八糟的文档画完，项目估计都黄了。更有意思的是，这篇论文和我们的作业并没有太大关系（你™是在逗我？）</p>
<p>这里补充一段自己在飞机上看时写的批注：20 年前的方法论，在很多尚未成熟的领域（比如移动互联网）不适用，因为需求本身不是明确的，而是要靠试错和挖掘的。而且需要撰写的文档太多，会导致启动/转向缓慢，并且保证文档实时更新也是难题，而不更新的文档，其实是毫无意义的。文档应当是开发的产出，反过来，开发不应是文档的产出。但是这种分层和切片的思想，是很有用的。不过在这个具体的场景中，对于已经理解了整个系统的人，这样写会更清晰，但是对于不理解的人来说，还是难以有全局概念（但是比传统的仍旧好一些）。就我个人的感觉，还是快速原型+迭代更新更有效。</p>
<p>那么现在我们来看看，这次的作业是要干嘛。简单来说，就是利用这种多个视角的方式来继续完成之前的设计，有以下角度：</p>
<ul>
<li>功能视图：各个模块图，包括接口和依赖<ul>
<li>系统中主要的功能模块是哪些</li>
<li>使用简化版的 UML 2.0 来描述</li>
</ul>
</li>
<li>信息视图：展示 schema，数据模型和数据流，用状态机图来描述系统的信息模型</li>
<li>部署视图：软件的组件需要在哪里部署和运行</li>
<li>开发视图：主要的软件包是什么</li>
<li>并行视图：在不同地方运行时，系统是如何运行的。你会如何保证数据一致性？</li>
</ul>
<p>以上是作业的第一部分（这句话的意思是，还有另外一部分，不过先从这里开始），下面是我的设计，但是用来描述的文字就不翻译了，就算是抛砖引玉，大家自己思考下。</p>
<h2 id="Function_View"><a href="#Function_View" class="headerlink" title="Function View"></a>Function View</h2><p><img src="/images/3.1functionview.png" alt="3.1functionvie"></p>
<h2 id="Information_View"><a href="#Information_View" class="headerlink" title="Information View"></a>Information View</h2><p><img src="/images/3.1informationview.png" alt="3.1informationvie"></p>
<h2 id="Concurrency_View"><a href="#Concurrency_View" class="headerlink" title="Concurrency View"></a>Concurrency View</h2><p><img src="/images/3.1concurrencyview.png" alt="3.1concurrencyvie"></p>
<h2 id="Deployment_View"><a href="#Deployment_View" class="headerlink" title="Deployment View"></a>Deployment View</h2><p><img src="/images/3.1deploymentview.png" alt="3.1deploymentvie"></p>
<h2 id="Development_View"><a href="#Development_View" class="headerlink" title="Development View"></a>Development View</h2><p><img src="/images/3.1developmentview.png" alt="3.1developmentvie"></p>
<p>接下来的一部分是根据之前的设计，把每个架构风格的各个部件列举出来，如：</p>
<ul>
<li>组件</li>
<li>连接器</li>
<li>数据元素</li>
<li>行为</li>
<li>需要注意的事项</li>
</ul>
<p>基本上对着 PPT 改一下就好，这里也就不赘述了。</p>
<p>说了这么多，就是想要表达，在一门以实践为重的学科里，天天学理论，是有多™蛋疼。</p>
<p>本课完。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一次的作业，会在之前的基础上，通过不同的观察角度，更加科学系统来展示整个软件的架构和各个部分的关系。老师给出了一篇论文，这里也会简单总结下。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="习题" scheme="http://wdxtub.com/tags/%E4%B9%A0%E9%A2%98/"/>
    
      <category term="架构" scheme="http://wdxtub.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="视角" scheme="http://wdxtub.com/tags/%E8%A7%86%E8%A7%92/"/>
    
      <category term="设计" scheme="http://wdxtub.com/tags/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="风格" scheme="http://wdxtub.com/tags/%E9%A3%8E%E6%A0%BC/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[第三周 - Die Internationale]]></title>
    <link href="http://wdxtub.com/2016/01/29/die-internationale/"/>
    <id>http://wdxtub.com/2016/01/29/die-internationale/</id>
    <published>2016-01-30T02:17:10.000Z</published>
    <updated>2016-01-30T06:18:29.000Z</updated>
    <content type="html"><![CDATA[<p>So comrades come rally. For this is the time and place. </p>
<a id="more"></a>
<hr>
<p>这周相当精彩，或者说，一直没机会停下来歇歇。周末大暴雪，跑出去堆了个雪人，时隔这么多年在大洋彼岸回到小时候，反而有那么一点心酸。想到前几天广州特别冷我却没办法为爸妈做点什么，游子的苦也只有往肚里吞。</p>
<p>周一去 Google Pittsburgh 面试，整一天下来，甚至动摇了我回国的决心，和聪明人一起真的能够最大程度激发自己的潜力，加上浮夸走心的装修和各种娱乐设施，真的是背靠大树好乘凉。相比之下，亚马逊就磕碜了许多，毫无诚意的 group interview 我们和面试官互相应付下匆匆完事儿，我讲完代码从面试官一脸迷茫就知道我精心设计的绝妙解决方案白瞎了，满满对牛弹琴的感觉。我还特地挑了最难的那道题目，就不能找点聪明人或者更有激情的人来面试嘛，面了这么多家，这次真心感觉到了不走心，但是看在报销各种费用的情况下，我就忍了。</p>
<p>接着面试的机会又来到的西海岸，这次是西雅图。美国的安检还是相当严格的，安检大叔估计见我是中国人，还跟我说『你好』，让颇为繁琐的安检没那么令人生厌。中间在明尼苏达州的明尼阿波利斯转机，还遇到了一对要去夏威夷度假的老爷爷老奶奶。我说匹兹堡好冷呀，他们表示你们南方人根本不知道暴风雪的力量。</p>
<p>第一趟飞机特别小，窄得跟公交车似的；第二趟好很多，至少能看电影。时间关系看了两部：火星救援（再一次）和拳王阿里。火星救援不必多说，硬科幻一直是我的最爱，拳王阿里倒是让我印象深刻，就是因为穿插其中的 soul music。当年的 Will Smith 还是小鲜肉，现在都带着儿子出来骗钱了，岁月呀。</p>
<p>机缘巧合的是，在西雅图见到了妈妈的高中同学，在热腾腾的火锅边真有点找到温暖的感觉。这恐怕是在匹兹堡很难有的体验吧。聊到爸爸妈妈，聊到发小朋友。真的是『感时花溅泪，恨别鸟惊心』。</p>
<p>爸爸妈妈一直以来对我的教育和背后的默默支持，让我有机会成为我自己，越长大越明白他们为我付出了太多太多，可是很多时候在他们最需要我的时候我却不能在身边，有那么些时刻，那种无力感真的让人绝望。又聊到朋友，想起周对我说过『你去美国后，你爸妈就是我爸妈』，又或者『才一两个月没见，还真的有点想你』，何德何能，竟有这样伟大的父母与情同手足的朋友。</p>
<p>另外，第一次当上了研究生课的助教，还是 CMU 的课，感觉自己还是萌萌哒，不过这周基本还在熟悉各种工作，其他杂事也比较多，下周要好好肩负起自己应该担起的责任。</p>
<p>When we fight, provoked by their aggression. Let us be inspired by like and love. For though they offer us concessions. Change will not come from above</p>
<p>（时差还没倒过来，夜，于西雅图）</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>So comrades come rally. For this is the time and place. </p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="周记" scheme="http://wdxtub.com/tags/%E5%91%A8%E8%AE%B0/"/>
    
      <category term="西雅图" scheme="http://wdxtub.com/tags/%E8%A5%BF%E9%9B%85%E5%9B%BE/"/>
    
      <category term="面试" scheme="http://wdxtub.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="Gossip" scheme="http://wdxtub.com/categories/Gossip/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[云计算 第 10 课 Parallel Programming using EMR]]></title>
    <link href="http://wdxtub.com/2016/01/25/cc-10/"/>
    <id>http://wdxtub.com/2016/01/25/cc-10/</id>
    <published>2016-01-26T00:42:38.000Z</published>
    <updated>2016-01-29T15:06:47.000Z</updated>
    <content type="html"><![CDATA[<p>这节课我们来看看，如何利用 AWS 来进行并行处理，完成与上节课类似的文本处理任务。</p>
<a id="more"></a>
<hr>
<p>这周的主要任务有下面四个：</p>
<ol>
<li>探索一个大数据集</li>
<li>利用 MapReduce 来处理一个大数据集</li>
<li>使用 EMR(Elastic MapReduce) 在云上运行一个 MapReduce 工作</li>
<li>理解使用诸如 MapReduce 这样的框架来处理大数据的优势</li>
</ol>
<p>注意！EMR 非常贵！所以从小的数据集开始。有两个部分要收钱：per-instance EMR 费用和实际的  EC2 实例费用。使用竞价实例来减小第二部分的花费。</p>
<blockquote>
<p>先使用 WordCount 的例子来熟悉如何设置 cluster。</p>
</blockquote>
<p>这次的的限额是 <code>$15</code>，大概就是有 2 次跑全数据的测试。</p>
<p>任务和上一周的类似，用上个月的维基百科页面访问的数据来进行分析。我们先从上个 project 所做的 filtering 开始，然后把所有的 2015 年 12 月的页面访问数据聚合起来。取出那些最重要的记录并输出到一个小的输出文件中，然后做一些处理来得到真正有用的信息。</p>
<p>上一次我们顺序处理了一个单一文件，但是没办法回答以下这些问题：</p>
<ul>
<li>2015 年 12 月最受欢迎的页面是哪个</li>
<li>某个页面在某一天得到了多少点击</li>
</ul>
<p>如果想要回答这两个问题，我们必须：</p>
<ul>
<li>把所有的访问次数聚合起来，并且</li>
<li>对每个我们感兴趣的文章，生成每天的页面访问时间轴</li>
</ul>
<p>为了处理这么大的一个数据集（压缩后 65 GB），我们会设置一个 Elastic MapReduce 工作来完成。需要写简单的 Map 和 Reduce 函数/程序。</p>
<p>开始之前，最好先弄明白 <a href="https://aws.amazon.com/elasticmapreduce/pricing/" target="_blank" rel="external">EMR 怎么收费</a>。</p>
<blockquote>
<p>别忘了打上 Project: 1.2 的标签</p>
</blockquote>
<h2 id="Introduction_to_MapReduce"><a href="#Introduction_to_MapReduce" class="headerlink" title="Introduction to MapReduce"></a>Introduction to MapReduce</h2><p>MapReduce 是用许多机器来进行大数据处理的编程模型。Hadoop 是开源版本的 MapReduce 实现。Hadoop 把 MapReduce 当做一个分析引擎，并使用 Hadoop Distributed File System(HDFS) 来进行存储。HDFS 把数据集分成固定大小的块，分布式存放在不同的节点上。具体要执行的任务可以在不同的机器上并行处理。MapReduce 会把整个大任务分成不同的小的 map 和 reduce 任务。所有的 map 任务都在 map 阶段进行，所有的 reduce 任务都在 reduce 阶段进行。map 阶段可能有 1 个或多个任务，reduce 阶段可以有 0 个或多个 reduce 任务。</p>
<p><img src="/images/14537775895092.jpg" alt="MapReduce 概览"></p>
<p>上图描述了一个简化的，但是完整的 MapReduce 分析引擎。Map 任务在分布式 HDFS 块上执行，reduce 任务在 map 任务的输出上执行（标记为 intermediate output 或 partitions）。每个 map 任务处理一个或多个不同的 HDFS 块，每个 reduce 任务处理一个或多个 partitions。在一个典型的 MapReduce 程序中，在所有 HDFS 块上执行的 map 任务都是一样的，在所有的 partitions 上执行的 reduce 任务也是一样的。</p>
<p><a href="https://youtu.be/1gBLqlMUQQk" target="_blank" rel="external">MapReduce 视频介绍</a></p>
<p>要使用集群来进行计算，需要考虑以下问题：</p>
<ul>
<li>怎么样切分输入数据？</li>
<li>怎么样分配不同的工作？</li>
<li>怎么样协调所有的机器？</li>
<li>怎么样汇总结果？</li>
</ul>
<p>有一些模型可以给我们一些帮助，如 MPI，但是只在消息传递阶段可以给我们帮助。这个时候，就要 MapReduce 出场了。先来看定义：</p>
<blockquote>
<p>MapReduce (Definition):<br>Programming model for processing large data sets with a parallel, distributed algorithm on a cluster.</p>
</blockquote>
<p>分步骤来描述的话就是：</p>
<ul>
<li>Map：提取出关注的数据</li>
<li>Group by key：对这些数据排序和重组(sort and shuffle)</li>
<li>Reduce：聚合，汇总，过滤或者转变(Aggregate, summarize, filter or transform)</li>
<li>最后输出结果</li>
</ul>
<p>具体来看看每个阶段的细节。</p>
<p>在 Map 阶段，需要为 mapper 准备好输入数据，也就是把大数据分割成小块并指派给各个 mapper。然后每个 mapper 就会在分到的数据块上完成指定的工作，之后输出键值对(key-value pair)。这里的键会用于之后的 shuffle 与 merge。Value 是从 mapper 发送到 reducer 的信息。</p>
<p>在 Shuffle 阶段，会把 mapper 阶段得到的结果根据 key 来进行排序和分组。利用哈希的方式把 key 进行分隔然后指派到不同的 reducers 中，每个 key 只会被指派给 1 个 reducer。</p>
<p>在 Reduce 阶段，每个 reducer 会处理 1 个或多个 key。这里的输入就是 mapper 的输出，也就是键值对，这里的输出就是我们需要的结果（可以编写不同的聚合逻辑）</p>
<p>对于程序员来说，使用 MapReduce 这个编程模型，需要提供：</p>
<ul>
<li>Map 函数</li>
<li>Reduce 函数</li>
<li>输入和输出的位置</li>
</ul>
<p>而 MapReduce 框架会处理好：</p>
<ul>
<li>分隔输入数据</li>
<li>在一组机器上运行程序</li>
<li>执行 Group by key</li>
<li>处理机器执行失败的情况</li>
<li>管理必需的机器间交互</li>
</ul>
<p>那么所谓的『并行』，体现在哪里呢？首先，mapper 是并行执行的，同时 reducer 也是并行执行的。但是。reducer 必须在 mapper 执行完成之后才可以开始。</p>
<p>MapReduce 的发展历程大概如下：</p>
<ul>
<li>1958: LISP and Lambda Functions in Functional Programming</li>
<li>1995: Message Passing Interface(MPI) has Gather/Scatter functions</li>
<li>2004: Google’s MapReduce Paper</li>
<li>2006-2008: Apache Hadoop v1.0</li>
<li>2013: YARN (Hadoop 2.0)</li>
</ul>
<p>那么要如何使用 Hadoop 的 MapReduce 呢？可以有以下几种方式：</p>
<ul>
<li>用 Java 写原生 MapReduce 程序：自定义 mapper 和 reducer</li>
<li>Streaming  MapReduce 工作：使用任何可执行的程序来作为 mapper 和 reducer</li>
<li>高层抽象：Pig, Hive 等</li>
</ul>
<p>Amazon 的 Elastic MapReduce 是一个 Hadoop 的 PaaS 实现，为的是快速申请 Hadoop 集群并利用 S3 来导入/导出数据。接下来通过一个简单的例子来感受一下 Elastic MapReduce 是怎么回事。</p>
<h2 id="Example_EMR_Job_Flow_3A_Wordcount"><a href="#Example_EMR_Job_Flow_3A_Wordcount" class="headerlink" title="Example EMR Job Flow: Wordcount"></a>Example EMR Job Flow: Wordcount</h2><p>这里我们用 Java 来进行实现（Python 的就只提供视频地址）：<a href="https://youtu.be/fQAZoZCRqX0" target="_blank" rel="external">Java 版本视频教程</a> / <a href="https://youtu.be/htr6JH7UWNg" target="_blank" rel="external">Python 版本视频教程</a></p>
<p>整个过程可以用如下的命令来大致描述：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat input | mapper_program | sort | reducer_program &gt; output</span><br></pre></td></tr></table></figure>
<p>我们的输入是一个文本文件，里面是一篇英文的文章，我们的 mapper 程序如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">wordcountMapper</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(System.in));</span><br><span class="line">            String input;</span><br><span class="line">            <span class="comment">// While we have input on stdin</span></span><br><span class="line">            <span class="keyword">while</span>((input = br.readline()) != <span class="keyword">null</span>)&#123;</span><br><span class="line">                StringTokenizer tokenizer = <span class="keyword">new</span> StringTokenizer(input);</span><br><span class="line">                <span class="keyword">while</span> (tokenizer.hasMoreTokens())&#123;</span><br><span class="line">                    String word = tokenizer.nextToken();</span><br><span class="line">                    System.out.println(word + <span class="string">"\t"</span> + <span class="string">"1"</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span>(IOException io)&#123;</span><br><span class="line">                io.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们来看看 reducer 程序，这个比 mapper 稍微复杂一点：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">wordcountReducer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(System.in));</span><br><span class="line">            String input;</span><br><span class="line">            String word = <span class="keyword">null</span>;</span><br><span class="line">            String currentWord = <span class="keyword">null</span></span><br><span class="line">            <span class="keyword">int</span> currentCount = <span class="number">0</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">while</span> ((input = br.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    String[] parts = input.split(<span class="string">"\t"</span>);</span><br><span class="line">                    word = parts[<span class="number">0</span>];</span><br><span class="line">                    <span class="keyword">int</span> count = Integer.parseInt(parts[<span class="number">1</span>]);</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">// We have sorted input, so check if we have the same word</span></span><br><span class="line">                    <span class="keyword">if</span> (currentWord != <span class="keyword">null</span> &amp;&amp; currentWord.equals(word))&#123;</span><br><span class="line">                        currentCount++;</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123; <span class="comment">// the word has changed</span></span><br><span class="line">                        <span class="keyword">if</span> (currentWord != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            System.out.println(currentWord + <span class="string">"\t"</span> + currentCount);</span><br><span class="line">                        &#125;</span><br><span class="line">                        currentWord = word;</span><br><span class="line">                        currentCount = count;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (NumberFormatException e) &#123;</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> (currentWord != <span class="keyword">null</span> &amp;&amp; currentWord.equals(word)) &#123;</span><br><span class="line">                System.out.println(currentWord + <span class="string">"\t"</span> + currentCount);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span>(IOException io) &#123;</span><br><span class="line">            io.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>查看结果的话命令为（注意需要先编译，上面给出的代码不包含头文件）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat input.txt | java wordcoutnMapper | sort | java wordcountReducer &gt; output</span><br></pre></td></tr></table></figure>
<p>如果代码都准备好了，可以参考下面的视频，<a href="https://youtu.be/qbHs1HXuE1M" target="_blank" rel="external">在 EMR 上运行 Java Streaming Program</a></p>
<p>从 S3 的 Bucket 获取数据，把 mapper 和 reducer 打包生成 jar 包并上传到 S3。然后到 Analytic 类别下的 EMR 选项。注意，运行 EMR 之前一定要在本地先测试！</p>
<p>命令行生成 jar 包的过程（假设我们有 <code>wordcountMapper.java</code> 和 <code>wordcountReducer.java</code> 两个文件）：</p>
<ol>
<li>先编译 <code>javac wordcountMapper.java</code> 和 <code>javac wordcountReducer.java</code>，然后我们就有了对应的 <code>.class</code> 文件</li>
<li>然后就可以打包了 <code>jar -cvf wordcount.jar *.class</code>，如果不是这么简单的情况，还是用 IDE 来打包比较方便</li>
</ol>
<p>用具体的步骤来描述就是（前面是英文这里参考中文界面）：</p>
<ol>
<li>在 AWS 管理控制台选择 <strong>分析</strong> 下的 <strong>EMR(Hadoop 托管框架)</strong></li>
<li>然后选择 <strong>创建集群</strong>，这里我们不使用快速选项，而是『转到高级选项』</li>
<li>配置页面要注意以下内容<ul>
<li>起个名字</li>
<li>输入 S3 地址，用来存储 log</li>
<li>开启 logging 和 debugging</li>
<li>bucket 名字最好值包含小写字母和数字，不要用 <code>.</code>，<code>-</code> 和大写字母</li>
<li>软件配置中，选择 <code>emr-4.0.0</code>，除了 Hadoop 的那一项其他都可以不选</li>
<li>硬件配置中，选择 <code>m3.xlarge</code>，1 个 master，2 个 core，不需要 task 节点</li>
<li>选择一个之前已经创建过的安全组</li>
<li>没有提到的一般不需要修改</li>
</ul>
</li>
<li>注意要打好对应的标签。竞价实例可能没办法保证 tag，所以需要检查并添加上（当实例真正启动时）</li>
<li>在添加步骤中，选择流程序，然后进行配置。输入 mapper 和 reducer 的执行命令 <code>java -cp wordcount.jav wordcountMapper</code> 和 <code>java -cp wordcount.jar wordcountReducer</code>。然后配置输入输出的地址（也可以在界面上选），这里注意输出的文件夹最好不存在，不然覆盖的时候可能会失败，在参数里设置 <code>-files s3://address for jar file</code>。最后选择失败时要执行的操作，这里选择 <code>terminate cluster</code> 比较好（省钱）。</li>
<li>不要选择完成后自动终止，这样我们可以登录到机器上来查看任务详情，但是用完之后务必要手动关闭。</li>
<li>检查无误后，点击创建实例之后就可以开始等待了。完成之后可以在 S3 里看到对应的输出，多个 reduce 会有多个结果，可能需要下载下来进行合并。</li>
</ol>
<h2 id="Writing_your_own_Mappers_and_Reducers"><a href="#Writing_your_own_Mappers_and_Reducers" class="headerlink" title="Writing your own Mappers and Reducers"></a>Writing your own Mappers and Reducers</h2><p>现在我们就来处理维基百科的数据集了，这里需要写自己的 mapper 和 reducer，在整整一个月的输入数据中，完成下面的任务：</p>
<ol>
<li>设计一个 MapReduce 的工作流，需要完成<ul>
<li>根据上一个 project 的规则来过滤元素</li>
<li>从 mapper 中读取输入的文件名。因为 日期/时间 的信息在文件名当中，所以 Hadoop 流会把文件名放在名为 <code>mapreduce_map_input_file</code> 这个环境变量中，每个 map 任务都可以访问。举个例子，python 中用 <code>os.environ[&quot;mapreduce_map_input_file&quot;]</code>，Java 中用 <code>System.getenv(&quot;mapreduce_map_input_file&quot;)</code></li>
<li>把每小时的页面浏览记录聚合成每天的页面浏览记录</li>
<li>计算每篇文章的总浏览记录</li>
<li>对于浏览次数超过 100,000 的页面，用以下的格式进行输出 <code>[月总浏览量]\t[文章名称]\t[第一个日期的浏览量]\t[第二个日期的浏览量]......</code></li>
</ul>
</li>
<li>设计并测试好了 MapReduce 工作流后，使用 EMR 跑 2015 年 12 月的全部数据<ul>
<li>数据集可以在 <code>s3://cmucc-datasets/wikipediatraf/201512/</code> 找到</li>
<li>记录下集群的配置以及运行时间（分钟位单位）</li>
<li>在 S3 中只使用小写字母和数字，不然会失败</li>
</ul>
</li>
<li>结果处理好之后，启动一个 <code>t1.micro</code> 实例 <code>ami-bcd8f8d6</code> 来提交成绩<ul>
<li>把结果从 S3 下载到 这个实例中</li>
<li>把输出融合成一个 output 文件</li>
<li>用 <code>submitter</code> 来测试 mapper 和 reducer</li>
</ul>
</li>
<li>完成 <code>runner.sh</code> 中的问题</li>
<li>使用 <code>submitter</code> 来提交最终的答案 </li>
</ol>
<p>一些建议：</p>
<ul>
<li>用竞价实例很省钱</li>
<li>只支持 Python 2.7 和 Java 1.7</li>
<li>输出格式：<ul>
<li>日期用 <code>yyyymmdd</code> 格式</li>
<li>日期要按照时间顺序来 <code>20151201</code> 应该在 <code>20151202</code> 之前</li>
<li>所有的页面浏览数据应该输出到一个文件中</li>
</ul>
</li>
</ul>
<p>一个简单的例子，每一行都必须有 31 天，即使那一天的访问量是 0：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">10</span>   Dopamine    <span class="number">20151201</span>:<span class="number">1</span>    <span class="number">20151202</span>:<span class="number">2</span>    <span class="number">20151203</span>:<span class="number">0</span>    <span class="number">20151204</span>:<span class="number">0</span>    <span class="number">20151205</span>:<span class="number">1</span>    <span class="number">20151206</span>:<span class="number">0</span>    <span class="number">20151207</span>:<span class="number">0</span>    <span class="number">20151208</span>:<span class="number">0</span>    <span class="number">20151209</span>:<span class="number">0</span>    <span class="number">20151210</span>:<span class="number">6</span>    <span class="number">20151211</span>:<span class="number">0</span>    <span class="number">20151212</span>:<span class="number">0</span>    <span class="number">20151213</span>:<span class="number">0</span>    <span class="number">20151214</span>:<span class="number">0</span>	<span class="number">20151215</span>:<span class="number">0</span>    <span class="number">20151216</span>:<span class="number">0</span>    <span class="number">20151217</span>:<span class="number">0</span>    <span class="number">20151218</span>:<span class="number">0</span>    <span class="number">20151219</span>:<span class="number">0</span>    <span class="number">20151220</span>:<span class="number">0</span>    <span class="number">20151221</span>:<span class="number">0</span>    <span class="number">20151222</span>:<span class="number">0</span>    <span class="number">20151223</span>:<span class="number">0</span>    <span class="number">20151224</span>:<span class="number">0</span>    <span class="number">20151225</span>:<span class="number">0</span>    <span class="number">20151226</span>:<span class="number">0</span>    <span class="number">20151227</span>:<span class="number">0</span>    <span class="number">20151228</span>:<span class="number">0</span>    <span class="number">20151229</span>:<span class="number">0</span>    <span class="number">20151230</span>:<span class="number">0</span>    <span class="number">20151231</span>:<span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>最后是 <a href="https://youtu.be/H0q5V4ApuU4" target="_blank" rel="external">EMR Troubleshooting</a></p>
<ul>
<li>访问 master public DNS:9100 可以访问日志</li>
</ul>
<h2 id="Grading"><a href="#Grading" class="headerlink" title="Grading"></a>Grading</h2><p>一些提交步骤的记录：</p>
<ol>
<li>文件夹位于 <code>/home/ubuntu/Project1_2</code>，有三个文件，可以编辑 <code>runner.sh</code> 和 <code>references</code></li>
<li>如果完成了 mapper 和 reducer，可以通过 <code>submitter</code> 提交来测试<ul>
<li><code>./submitter -a andrewid -l java</code> 或者 java 换成 python </li>
</ul>
</li>
<li>结果中的第一行表示正确的 mapper 和 reducer</li>
<li>得到结果后聚合成一个文件，名字是 output，然后需要完成 <code>runner.sh</code> 中的题目</li>
<li>其他的要求和之前一样</li>
</ol>
<h2 id="u9879_u76EE_u65E5_u5FD7"><a href="#u9879_u76EE_u65E5_u5FD7" class="headerlink" title="项目日志"></a>项目日志</h2><h3 id="Mapper"><a href="#Mapper" class="headerlink" title="Mapper"></a>Mapper</h3><p>首先我们要理解清楚这次的任务是什么，说起来很简单，就是用 MapReduce 把上个项目的工作大概再做一次，借此理解 MapReduce 的编程模型。</p>
<p>实话说，MapReduce 的模型是比较容易理解的，尤其是我们这个项目所用的流程序，唯一需要弄清楚的就是三个步骤：怎么输入，中间怎么处理，怎么输出。</p>
<p>输入输出部分之前的 wordcount 的例子都有讲解，看一下代码应该就能弄明白，这里主要说说中间要怎么处理。</p>
<p>在 MapReduce 中，一切的内容都要转换为键值对，那么我们就需要考虑，键值对的格式是什么，怎么样设计会方便我们处理。</p>
<p>但是在设计之前，我们先大概想一下，具体需要些什么内容。我们需要：</p>
<ul>
<li>文章的日期</li>
<li>文章的标题</li>
<li>文章的访问量</li>
</ul>
<p>文章的标题和访问量就在传入的每一行数据中，这个方便处理，但是日期这里，因为是跟输入文件的文件名有关，所以我们得想个办法获取到。对，就是利用环境变量（前面有提到）：<code>String env = System.getenv(&quot;mapreduce_map_input_file&quot;);</code></p>
<p>可以通过以下命令查看所有文件（如果配置了 aws cli tool ）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws s3 ls s3://cmucc-datasets/wikipediatraf/<span class="number">201512</span>/</span><br></pre></td></tr></table></figure>
<p>然后获取到的路径大概是这样的格式：<code>s3://cmucc-datasets/wikipediatraf/201512/pagecounts-20151231-230000.gz</code>，所以需要做一些解析，取出我们需要的 <code>20151231</code> 这样的日期。然后结合之前的项目，过滤后输出即可。我得到的结果大概是这样的（我只用了很小很小的测试集），可以通过下面的命令在裁剪数据集：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">head -<span class="number">1000000</span> testdata &gt; smalltestdata</span><br></pre></td></tr></table></figure>
<h3 id="Reducer"><a href="#Reducer" class="headerlink" title="Reducer"></a>Reducer</h3><p>Reducer 要做的工作稍微多一点，比方说要按照规定的格式进行输出，但是本质上和 example 中的逻辑是差不多多少的，毕竟 mapper 中已经把数据过滤得差不多了。这里要注意的就是数值累加即可。得到的数据差不多是这样（这里我修改了阈值来查看输出，如果你也是这样做的，请记得测试完改回去）</p>
<p><img src="/images/14538337031959.jpg" alt=""></p>
<h3 id="u4EE3_u7801_u6D4B_u8BD5"><a href="#u4EE3_u7801_u6D4B_u8BD5" class="headerlink" title="代码测试"></a>代码测试</h3><p>然后我们可以提交自己的 Mapper.java 和 Reducer.java，测试一下功能正确与否。（注意要把为了本地跑的部分测试代码注释掉，不然就过不了测试，感谢 @jiexing）</p>
<p>启动一个 <code>t1.micro</code> 实例 <code>ami-bcd8f8d6</code>。记得打标签。</p>
<p>先登录：<code>ssh -i demo.pem ubuntu@ec2-54-152-44-36.compute-1.amazonaws.com</code></p>
<p>用下面的命令把文件复制到机器里：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -i demo.pem ./Mapper.java ubuntu@ec2-<span class="number">54</span>-<span class="number">152</span>-<span class="number">44</span>-<span class="number">36</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/</span><br><span class="line"></span><br><span class="line">scp -i demo.pem ./Reducer.java ubuntu@ec2-<span class="number">54</span>-<span class="number">152</span>-<span class="number">44</span>-<span class="number">36</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/</span><br></pre></td></tr></table></figure>
<p>然后可以用下面的代码提交：<code>./submitter -a dawang -l java</code>。如果成功的话，应该可以看到第一栏得到 20 分，那么就可以进行下一步了。</p>
<h3 id="EMR__u6D4B_u8BD5"><a href="#EMR__u6D4B_u8BD5" class="headerlink" title="EMR 测试"></a>EMR 测试</h3><p>首先是把对应的内容上传到 S3 中。当然这之前需要打包一下：<code>jar -cvf dawang.jar Mapper.java Reducer.java *.class</code>，然后准备创建 EMR 集群。如下</p>
<p><img src="/images/14538412976569.jpg" alt=""></p>
<p>然后我们多选择一点机器，然后设置一个竞价，如下图：</p>
<p><img src="/images/14538416282891.jpg" alt=""></p>
<p>然后设置一下日志和其他设定：</p>
<p><img src="/images/14538417094574.jpg" alt=""></p>
<p>然后就可以创建集群来跑一跑看了。这里记得在竞价实例创建之后，要手动给不同的机器打上标签（如果没有自动生成的话）。</p>
<p>等待竞价实例启动，就可以监控了，如下图：</p>
<p><img src="/images/14538425422610.jpg" alt=""></p>
<p>然后果断失败了，因为我的 Java 版本是 1.8，需要切换到 1.7，具体参考<a href="http://chessman-126-com.iteye.com/blog/2162466" target="_blank" rel="external">这里</a></p>
<p>简单来说就是：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bash_profile <span class="comment"># 输入以下内容  </span></span><br><span class="line"><span class="built_in">source</span> .bash_profile <span class="comment"># 生效新配置</span></span><br></pre></td></tr></table></figure>
<p>内容是</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Mac默认 JDK 6（Mac默认自带了一个jdk6版本）</span></span><br><span class="line"><span class="built_in">export</span> JAVA_6_HOME=`/usr/libexec/java_home -v <span class="number">1.6</span>`</span><br><span class="line"><span class="comment"># 设置 JDK 7</span></span><br><span class="line"><span class="built_in">export</span> JAVA_7_HOME=`/usr/libexec/java_home -v <span class="number">1.7</span>`</span><br><span class="line"><span class="comment"># 设置 JDK 8</span></span><br><span class="line"><span class="built_in">export</span> JAVA_8_HOME=`/usr/libexec/java_home -v <span class="number">1.8</span>`</span><br><span class="line"></span><br><span class="line"><span class="comment">#默认JDK 6</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="variable">$JAVA_6_HOME</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#alias命令动态切换JDK版本</span></span><br><span class="line"><span class="built_in">alias</span> jdk6=<span class="string">"export JAVA_HOME=<span class="variable">$JAVA_6_HOME</span>"</span></span><br><span class="line"><span class="built_in">alias</span> jdk7=<span class="string">"export JAVA_HOME=<span class="variable">$JAVA_7_HOME</span>"</span></span><br><span class="line"><span class="built_in">alias</span> jdk8=<span class="string">"export JAVA_HOME=<span class="variable">$JAVA_8_HOME</span>"</span></span><br></pre></td></tr></table></figure>
<p>直接直接可以用 <code>jdk6</code>, <code>jdk7</code>, <code>jdk8</code> 来切换。</p>
<p>经过漫长的等待（约 73 分钟），就可以在 S3 中拿到结果，可以用 <code>aws s3 cp s3://project1dawang/output/ ./output/ --recursive</code>，然后用 <code>cat part-* &gt; output</code> 来进行合并。然后就可以来做最后的计算和分析了。</p>
<p>这里把 instance 上的文件都拷贝到本地来进行测试：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -i demo.pem ubuntu@ec2-<span class="number">54</span>-<span class="number">84</span>-<span class="number">88</span>-<span class="number">191</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/* ./server/</span><br></pre></td></tr></table></figure>
<p>然后在下一个阶段完成所有的工作</p>
<h3 id="Runner"><a href="#Runner" class="headerlink" title="Runner"></a>Runner</h3><p>先把 runner 复制到本地，用以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -i demo.pem ubuntu@ec2-<span class="number">54</span>-<span class="number">164</span>-<span class="number">94</span>-<span class="number">23</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/runner.sh ./</span><br></pre></td></tr></table></figure>
<p>需要回答的问题是：</p>
<ol>
<li>output 文件中有多少行，可以用这个命令 <code>wc -l output | awk {&#39;print $1&#39;}</code></li>
<li>过滤后的输出中最不热门的文章是哪个，获得了多少次访问</li>
<li>12 月 18 日最热门的文章是哪篇，对应那一天的点击量是多少</li>
<li>2015 年 12 月最受欢迎的且在 12 月 1 日没有人访问的页面是那个(实在想不明白为什么会出现顺序影响结果的问题)</li>
<li>这个月有多少天，标题是 <code>Twitter</code> 的页面的访问次数比标题是 <code>Apple_Inc.</code> 的页面的访问次数多。</li>
<li>给在文件 q6 中出现的电影排序，根据单天最高的浏览量来排（高的在前面），用逗号分隔，没有空格</li>
<li>给在文件 q7 中出现的操作系统排序，根据月份最高的浏览量来排（高的在前面），用逗号分隔，没有空格，数量相同需要用字母降序排序</li>
<li>有多少数据集中的电影也有对应的电视剧？电影名称 <code>&lt;article_name&gt;_([year_]film)</code>，电视剧名称 <code>&lt;article_name&gt;_([year]_TV_series)</code>，也就是说，<code>article_name</code> 必须完全相同，电影和电视剧系列可能跟着一个 4 位数的年份（也就是说可能没有）</li>
<li>Find out the number of articles with longest number of strictly decreasing sequence of views 最长递减子序列的个数，可以一次做完</li>
</ol>
<p>后面四个问题是不评分的，按照实际情况填写就好。我用的都是 <code>m3.xlarge</code> 类型的 instance，然后一共 4 个 core，时间是：73 min</p>
<p>因为之前终止了实例，所以需要把之前的工作重新上传：</p>
<p>先登录：<code>ssh -i demo.pem ubuntu@ec2-54-84-88-191.compute-1.amazonaws.com</code></p>
<p>用下面的命令把文件复制到机器里：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scp -i demo.pem ./Mapper.java ubuntu@ec2-<span class="number">54</span>-<span class="number">175</span>-<span class="number">116</span>-<span class="number">84</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/</span><br><span class="line"></span><br><span class="line">scp -i demo.pem ./Reducer.java ubuntu@ec2-<span class="number">54</span>-<span class="number">175</span>-<span class="number">116</span>-<span class="number">84</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/</span><br><span class="line"></span><br><span class="line">scp -i demo.pem ./runner.sh ubuntu@ec2-<span class="number">54</span>-<span class="number">84</span>-<span class="number">88</span>-<span class="number">191</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/</span><br><span class="line"></span><br><span class="line">scp -i demo.pem ./Q4.java ubuntu@ec2-<span class="number">54</span>-<span class="number">84</span>-<span class="number">88</span>-<span class="number">191</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/</span><br><span class="line"></span><br><span class="line">scp -i demo.pem ./Q7.java ubuntu@ec2-<span class="number">54</span>-<span class="number">164</span>-<span class="number">94</span>-<span class="number">23</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复上次的工作</span></span><br><span class="line">scp -i demo.pem ./server/* ubuntu@ec2-<span class="number">54</span>-<span class="number">84</span>-<span class="number">88</span>-<span class="number">191</span>.compute-<span class="number">1</span>.amazonaws.com:~/Project1_2/</span><br></pre></td></tr></table></figure>
<p>然后可以用下面的代码提交：<code>./submitter -a dawang -l java</code>。</p>
<p>大部分的时间都在为奇奇怪怪又不说清楚的测试集耽误时间，真心觉得这样浪费大家时间没多少意义。差评。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这节课我们来看看，如何利用 AWS 来进行并行处理，完成与上节课类似的文本处理任务。</p>]]>
    
    </summary>
    
      <category term="AWS" scheme="http://wdxtub.com/tags/AWS/"/>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="EMR" scheme="http://wdxtub.com/tags/EMR/"/>
    
      <category term="云计算" scheme="http://wdxtub.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
      <category term="文本处理" scheme="http://wdxtub.com/tags/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[软件架构与设计 习题课 2 不同架构风格应用]]></title>
    <link href="http://wdxtub.com/2016/01/24/sad-r2/"/>
    <id>http://wdxtub.com/2016/01/24/sad-r2/</id>
    <published>2016-01-24T14:16:36.000Z</published>
    <updated>2016-01-24T16:38:24.000Z</updated>
    <content type="html"><![CDATA[<p>这次的作业主要是利用课上所学过的各种架构风格来对之前设计的 ATM 来进行不同的理念尝试。</p>
<a id="more"></a>
<hr>
<h2 id="Main_program_and_sub_routines"><a href="#Main_program_and_sub_routines" class="headerlink" title="Main program and sub routines"></a>Main program and sub routines</h2><p>这个风格实际上跟程序设计的思路很像，就是利用顺序、分支和循环来构建整个系统的逻辑，具体的设计主要就是根据 ATM 所需要执行的事务，合并公共部分，再利用分发机制由主程序切换到子任务，完成后再返回后续处理，设计如下：</p>
<p><img src="/images/14536454405819.jpg" alt=""></p>
<h2 id="Object_Oriented"><a href="#Object_Oriented" class="headerlink" title="Object Oriented"></a>Object Oriented</h2><p>面向对象的设计就和上周的作业差不多了，实际上就是每个组件能够独立完成需要这个组件参与的行动，然后组件之间通过过程调用来进行联系，具体如下：</p>
<p><img src="/images/14536455334542.jpg" alt=""></p>
<h2 id="Virtual_machines"><a href="#Virtual_machines" class="headerlink" title="Virtual machines"></a>Virtual machines</h2><p>虚拟机实际上就是分层风格，不同层次之间通过 API 进行通信。那么对于 ATM 来说，一个可能的分层模型就是每一层暴露给下一层的都是一个统一的标准化的操作，具体如下：</p>
<p><img src="/images/14536462486833.jpg" alt=""></p>
<h2 id="Client_Server"><a href="#Client_Server" class="headerlink" title="Client Server"></a>Client Server</h2><p>设计的逻辑其实和上面的虚拟机比较类似，只是把整个具体操作分离成了服务端与客户端。其中客户端负责做一些简单的验证和计算，服务端通过更加强大的硬件系统保证一致性。ATM 机的设计其实天然符合这种架构，如下：</p>
<p><img src="/images/14536470725789.jpg" alt=""></p>
<h2 id="MVC"><a href="#MVC" class="headerlink" title="MVC"></a>MVC</h2><p>MVC 模型其实不算特别适合 ATM 机，因为本身来说，显示的状态和内容有限，而且由于数据和逻辑紧密联系，分开来其实会带来一些不安全的因素，但是也是可以来尝试用这种架构来设计的，如下：</p>
<p><img src="/images/14536475501848.jpg" alt=""></p>
<h2 id="Batch_Sequence"><a href="#Batch_Sequence" class="headerlink" title="Batch Sequence"></a>Batch Sequence</h2><p>这个架构风格和一开始根据事务流程，有些类似，差别在于这个的设计重点在于数据的流动，然后根据数据的流动方向来设计对应的逻辑和步骤，具体如下：</p>
<p><img src="/images/14536477765273.jpg" alt=""></p>
<h2 id="Pipe_and_filter"><a href="#Pipe_and_filter" class="headerlink" title="Pipe and filter"></a>Pipe and filter</h2><p>这种模式实际上不大适合 ATM 机的交互，因为 ATM 需要在每个步骤都由用户确定来保证安全性，如果硬要用这种模式，就是用户一开始输入所有的内容，然后进行自动流程处理，如下：</p>
<p><img src="/images/14536483943938.jpg" alt=""></p>
<h2 id="Blackboard"><a href="#Blackboard" class="headerlink" title="Blackboard"></a>Blackboard</h2><p>Blackboard 的模式实际上跟 Client Server 有点类似，通过统一的数据访问接口，由 Blackboard 进行中心管理和流程控制，实话说不是特别适合 ATM，一个可能的设计如下：</p>
<p><img src="/images/14536489292256.jpg" alt=""></p>
<h2 id="Rule_Based__26amp_3B_MapReduce"><a href="#Rule_Based__26amp_3B_MapReduce" class="headerlink" title="Rule Based &amp; MapReduce"></a>Rule Based &amp; MapReduce</h2><p>这两种都不太适合 ATM 的设计，原因如下：</p>
<ul>
<li>基于规则的需要逻辑推理引擎，既然是推理，就有出错的可能，对于银行业务来说这是不允许的</li>
<li>MapReduce 是一个分布式计算框架，我没有特别想明白这个和 ATM 架构有什么太大的联系</li>
</ul>
<h2 id="Interpreter__26amp_3B_Mobile_Code"><a href="#Interpreter__26amp_3B_Mobile_Code" class="headerlink" title="Interpreter &amp; Mobile Code"></a>Interpreter &amp; Mobile Code</h2><p>这两种同样不算特别适合 ATM，主要是设计思想的问题，无论是 interpreter 还是 mobile code，强调的都是灵活性。那么对于 ATM 来说，如果要排序的话，灵活性可能是最后一位的。因为灵活的同时不可避免就不太安全。</p>
<p>至于 Mobile Code，如果 mobile 一段恶意代码，显然要出大事，所以几乎不会被考虑。</p>
<h2 id="Peer_to_peer"><a href="#Peer_to_peer" class="headerlink" title="Peer to peer"></a>Peer to peer</h2><p>这个模式在 ATM 的架构中也不算太合适，因为如果按照点对点的设计，那么一端是 ATM，另一端是银行，但是对于很多 ATM 来说，因为一端必须是银行，所以就变成了类似 Client Server 架构了。</p>
<h2 id="C2"><a href="#C2" class="headerlink" title="C2"></a>C2</h2><p>基本的思路是通过事件来进行各个组件的连接和交互，简单来说如下：</p>
<p><img src="/images/14536519165284.jpg" alt=""></p>
<h2 id="CORBA"><a href="#CORBA" class="headerlink" title="CORBA"></a>CORBA</h2><p>这个架构的目标主要是兼容各种平台各种平台，因此也带来了很多复杂性。ATM 还是一个比较需要稳定，也不会有太多变化，所以不是特别适合。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这一课的主要目的是自己动手尝试设计不同的架构风格，学习就是先不要管对错，试试再说，可以慢慢修正嘛。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这次的作业主要是利用课上所学过的各种架构风格来对之前设计的 ATM 来进行不同的理念尝试。</p>]]>
    
    </summary>
    
      <category term="CMU" scheme="http://wdxtub.com/tags/CMU/"/>
    
      <category term="习题" scheme="http://wdxtub.com/tags/%E4%B9%A0%E9%A2%98/"/>
    
      <category term="架构" scheme="http://wdxtub.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="设计" scheme="http://wdxtub.com/tags/%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="风格" scheme="http://wdxtub.com/tags/%E9%A3%8E%E6%A0%BC/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 13 课 总结]]></title>
    <link href="http://wdxtub.com/2016/01/23/programmer-startline-13/"/>
    <id>http://wdxtub.com/2016/01/23/programmer-startline-13/</id>
    <published>2016-01-23T22:48:13.000Z</published>
    <updated>2016-01-24T14:17:59.000Z</updated>
    <content type="html"><![CDATA[<p>最后一节课写点感想，除了鸡汤就是情怀。</p>
<a id="more"></a>
<hr>
<p>今天暴雪，在雪中跑了几步，满是有劲没地方使的感觉，相信这也是从学校到社会转变的必经之路。一味用蛮力，哪怕脚步再快，进两步退一步，也是事倍功半。</p>
<p>比较好的做法是，先撒盐，看清路了，再一路向前。</p>
<p>所以这个系列，虽然列出了很多题目，但是题目本身并不重要，重要的是启发思路，而不是把答案背下来，毕竟真正有用的，是解决问题的能力。</p>
<p>去弄懂问题背后的原因，或者说组成问题本身的概念，往往有助于去真正理解问题，进而去解决问题。</p>
<p>有一类问题，比如说这个和那个哪个比较好。这类问题其实我是不愿意回答的。一来，怎么样才是『好』，不同人不同的立场，自然有不同的看法，二来，我的判断是基于自己的实际情况做出的，即使客观，程度也有限，我能做的可能是给出几个思考的角度，具体的思考过程，是谁也不能代替的。</p>
<p>遇到不懂的问题，一定要弄明白自己到底是哪里不懂，这个可能比问题本身更重要，因为这些『卡壳』的地方，往往是自己思维的误区盲区，只有看见，才能跨过去，进而解决许多甚至都还没有遇到的问题。</p>
<p>行文匆忙，定有不少疏漏重复之处，还请大家睁大双眼仔细分辨。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>最后一节课写点感想，除了鸡汤就是情怀。</p>]]>
    
    </summary>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="总结" scheme="http://wdxtub.com/tags/%E6%80%BB%E7%BB%93/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 12 课 其他知识]]></title>
    <link href="http://wdxtub.com/2016/01/23/programmer-startline-12/"/>
    <id>http://wdxtub.com/2016/01/23/programmer-startline-12/</id>
    <published>2016-01-23T22:48:09.000Z</published>
    <updated>2016-01-24T02:26:19.000Z</updated>
    <content type="html"><![CDATA[<p>这一章包括剩余一些比较基本的常识性知识，具体可能是以聊天的形式来进行交流，关键就在于理解，不要死记硬背。其实计算机学科的各种概念联系都比较紧密，梳理清晰自然就记住了。</p>
<a id="more"></a>
<hr>
<h2 id="u7F51_u7EDC"><a href="#u7F51_u7EDC" class="headerlink" title="网络"></a>网络</h2><p>计算机之间的交互模型通常是指Open Systems Interconnection model (OSI)，该模型将网络通信系统抽象成了七层</p>
<h3 id="u8DEF_u7531"><a href="#u8DEF_u7531" class="headerlink" title="路由"></a>路由</h3><p>从用户角度来看，路由(Routing)是指将数据从一个用户终端，通过网络节点(例如路由器，交换机等)，发送到另一个用户节点的过程。理论上说，对于一个拥有多个节点的拓扑网络而言，路由是指在Network Layer(OSI model的第三层)，将数据包(data packet)从一个节点以最优路径发送到目标节点的实现方法。其核心包括：如何获得邻近节点的信息，如何估计链路质量，如何寻址，如何构建网络拓扑结构“等等。 通过路由器之间的路由协议(routing protocol)，可以实现两个网络节点之间信息(包括网络域名，邻近节点，链路质量等)的交换和散布，通过不断重复该过程，每个节点都会获得足够多关于所在网络的拓扑信息。当有数据包需要传送时，路由器再通过路由算法(routing algorithm)计算传递当前数据包的最优路径，并把数据包发送给下一个邻近节点。许多路由算法基于图理论，实现了最小生成树，最短路径等等经典的拓扑算法。关于路由算法的进一步讨论，请参考“工具箱”中提到的参考教材。</p>
<p>网络中，所谓的地址是指IP地址，IPv4规定利用32bits作为IP地址。但随着网络设备的增多，IPv4已经不能满足人们的需求，故互联网逐渐向IPv6进行演进，IPv6利用128bits作为IP地址。</p>
<p>事实上，直观而言，network routing的过程就相当于传统意义上的邮包寄送，IP地址可以类比于邮政编码，路由器就相当于邮局，通过目的地邮政编码与邮局系统中的递送路径进行比较，由此确定下一步应该把当前包裹传递到哪里。</p>
<h3 id="u5E38_u7528_u7F51_u7EDC_u7EDF_u8BA1_u6307_u6807"><a href="#u5E38_u7528_u7F51_u7EDC_u7EDF_u8BA1_u6307_u6807" class="headerlink" title="常用网络统计指标"></a>常用网络统计指标</h3><p>衡量网络质量通常有下面两个指标：</p>
<p>1) 带宽/速率(Bandwidth/Rate)</p>
<p>所谓的带宽是指一个网络节点能以多快的速度将数据接收／发送出去，单位是bits per second(bps)。对于对实时性要求不高的数据，例如下载等，带宽是影响用户体验的主要因素。两个终端节点之间的带宽由路径中所有节点的最小带宽决定。同时，终端的数据发送速度不应该超过当前的上载带宽，否则会对网络造成压力导致拥堵(congestion)。</p>
<p>2) One-way Delay / Round Trip Time (RTT)</p>
<p>One-way Delay用以衡量网络的延迟。假设在时间点A从一个节点发送数据到另一个节点，目的地节点在时间点B收到数据，则两个时间点之差即为One-way Delay。类似地，RTT则是数据完成一个Round Trip回到始发节点的时间差，一般RTT可以近似估计为One-way Delay的两倍。对于网络会议，IP电话等等，延迟是影响用户体验的主要因素。延迟可能是由网络中某个节点处理数据速度慢，突然有大规模数据需要传输，或者某条链路不断重传数据造成的。延迟与带宽有一定的相关性，但没有必然联系：可以类比某个路口，假设每秒可以有一辆车通过该路口，但现在突然来了100辆车，路口的通过效率并没有变化(即带宽不变)，但每辆车通过路口的等待时间却变长了(延迟增加)。</p>
<h3 id="Transmission_Control_Protocol_uFF0CTCP"><a href="#Transmission_Control_Protocol_uFF0CTCP" class="headerlink" title="Transmission Control Protocol，TCP"></a>Transmission Control Protocol，TCP</h3><p><strong>Reliable Protocol</strong></p>
<p>TCP是一种可靠的传输协议，即在网络条件正常的情况下，TCP协议能够保证接收端收到所有数据，并且接收到的数据顺序与发送端一致。TCP通过在发送端给每个数据包分配单调递增的sequence number，以及在接受端发送ACK(acknowledgement)实现可靠传输。每个发送的数据包都包含序列号，当接收端收到数据包时，会发送ACK告诉发送端当前自己期待的下一个序列号是多少。例如，发送端分别发送了序列号为99，100，101，102的四个数据包，接收端收到数据包99后，会发送ACK100，意味着接收端期待下一个数据包编号100。如果由于某些原因，数据包100没有到达接收端，但数据包101，102到达了，那么接收端会继续发送ACK100。当发送端发现当前发送的数据包编号超过了100，但接收端仍然期望收到100，那么发送端就会重新发送数据包100。“如果接收端收到了重新发送的数据包100，那么接收端会回复ACK103，继续进行剩下的数据传输，并且把数据包99，100，101，102按顺序传递给上一层。</p>
<p><strong>Flow Control</strong></p>
<p>TCP使用了end-to-end flow control以避免发送端发送数据过快导致接收端无法处理。TCP采用了滑动窗口(sliding window)实现流量控制。接收端通过ACK告诉发送端自己还能够接收多少数据，发送端不能发送超过该值的数据量。当接收端返回的窗口大小为0时，发送端停止发送数据，直到窗口大小被更新。由于ACK是由发送端发送的数据触发，可能接收端窗口已经打开，但是由于发送端已经停止发送，故接收端没有机会通过ACK告知发送端新的窗口大小，在这种情况下会造成死锁。在实际实现中，发送端会设置一个timer，如果timer到期，发送端会尝试发送小数据包，以触发接收端的ACK。</p>
<p><strong>Congestion Control</strong></p>
<p>为了控制传输速度防止堵塞网络，并且在网络容量允许的范围内尽可能多地传输数据，TCP引入congestion control，用以判断当前的网络负荷，并且调整传输速率。TCP通常采用additive increase，multiplicative decrease的算法，即如果按时收到对应的ACK，则下一次传输速率线性增加，否则则视为发生了网络堵塞，下一次传输的比特数折半。所谓的“按时”基于RTT：发送端会估计RTT，并且期望当数据包发送以后，在RTT时间内收到对应的ACK。“现代TCP需要分别实现Slow-start，congestion avoidance，fast retransmit和fast recovery，以达到最高的效率。具体请参考“工具箱”给出的资料。</p>
<h3 id="User_Datagram_Protocol_uFF0CUDP"><a href="#User_Datagram_Protocol_uFF0CUDP" class="headerlink" title="User Datagram Protocol，UDP"></a>User Datagram Protocol，UDP</h3><p>相比于TCP，UDP简单许多：连接建立时不需要经过类似于TCP的三次握手，只需要知道接收端的IP和端口，发送端就可以直接发送数据。同时，UDP也没有ACK，flow control和congestion control，故UDP本身不能保证传输是可靠的。由于UDP本身只负责把数据传输到目的地，故可扩展性比较强。有些应用可以实现基于UDP 的特定算法，使得传输效率高于TCP。例如，当发生丢包时，TCP会重传该数据包，但该操作增加了传输延时。对于某些实时性要求较高的应用，可能继续传输新的数据更为重要，故基于UDP的传输方式可以更好地满足该要求。</p>
<p>通常而言，如果需要满足可靠性，有序接收，自适应带宽等要求，应该优先考虑TCP，因为其协议本身确保了这点。如果对实时性要求较高，或者应用需要特定的网络传输特性，则可以实现基于UDP的传输协议。往往，这样的协议需要实现congestion control，flow control，retransmission等机制，故通常情况下都可以直接采用TCP以减小开发成本。</p>
<h2 id="u6570_u636E_u5E93"><a href="#u6570_u636E_u5E93" class="headerlink" title="数据库"></a>数据库</h2><p>事务的概念来自于两个独立的需求：并发数据库访问，系统错误恢复。</p>
<p>一个事务是可以被看作一个单元的一系列SQL语句的集合。</p>
<h3 id="u4E8B_u52A1_u7684_u7279_u6027_uFF08ACID_uFF09"><a href="#u4E8B_u52A1_u7684_u7279_u6027_uFF08ACID_uFF09" class="headerlink" title="事务的特性（ACID）"></a>事务的特性（ACID）</h3><ul>
<li>A, atomacity 原子性 事务必须是原子工作单元；对于其数据修改，要么全都执行，要么全都不执行。通常，与某个事务关联的操作具有共同的目标，并且是相互依赖的。如果系统只执行这些操作的一个子集，则可能会破坏事务的总体目标。原子性消除了系统处理操作子集的可能性。</li>
<li>C, consistency 一致性。事务将数据库从一种一致状态转变为下一种一致状态。也就是说，事务在完成时，必须使所有的数据都保持一致状态（各种 constraint 不被破坏）。</li>
<li>I, isolation 隔离性 由并发事务所作的修改必须与任何其它并发事务所作的修改隔离。事务查看数据时数据所处的状态，要么是另一并发事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看中间状态的数据。换句话说，一个事务的影响在该事务提交前对其他事务都不可见。</li>
<li>D, durability 持久性。事务完成之后，它对于系统的影响是永久性的。该修改即使出现致命的系统故障也将一直保持。</li>
</ul>
<h3 id="u4E8B_u52A1_u7684_u9694_u79BB_u7EA7_u522B"><a href="#u4E8B_u52A1_u7684_u9694_u79BB_u7EA7_u522B" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><p>如果不对数据库进行并发控制，可能会产生异常情况：</p>
<ol>
<li>脏读(Dirty Read)<ul>
<li>当一个事务读取另一个事务尚未提交的修改时，产生脏读。</li>
<li>同一事务内不是脏读。 一个事务开始读取了某行数据，但是另外一个事务已经更新了此数据但没有能够及时提交。这是相当危险的，因为很可能所有的操作都被回滚，也就是说读取出的数据其实是错误的。</li>
</ul>
</li>
<li>非重复读(Nonrepeatable Read) 一个事务对同一行数据重复读取两次，但是却得到了不同的结果。同一查询在同一事务中多次进行，由于其他提交事务所做的修改或删除，每次返回不同的结果集，此时发生非重复读。</li>
<li>幻像读(Phantom Reads) 事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据（这里并不要求两次查询的SQL语句相同）。这是因为在两次查询过程中有另外一个事务插入数据造成的。<ul>
<li>当对某行执行插入或删除操作，而该行属于某个事务正在读取的行的范围时，会发生幻像读问题。</li>
</ul>
</li>
<li>丢失修改(Lost Update)<ul>
<li>第一类：当两个事务更新相同的数据源，如果第一个事务被提交，第二个却被撤销，那么连同第一个事务做的更新也被撤销。</li>
<li>第二类：有两个并发事务同时读取同一行数据，然后其中一个对它进行修改提交，而另一个也进行了修改提交。这就会造成第一次写操作失效。</li>
</ul>
</li>
</ol>
<p>为了兼顾并发效率和异常控制，在标准SQL规范中，定义了4个事务隔离级别，（ Oracle 和 SQL Server 对标准隔离级别有不同的实现 ）</p>
<ol>
<li>未提交读(Read Uncommitted)<ul>
<li>直译就是”读未提交”，意思就是即使一个更新语句没有提交，但是别的事务可以读到这个改变。</li>
<li>Read Uncommitted允许脏读。</li>
</ul>
</li>
<li>已提交读(Read Committed)<ul>
<li>直译就是”读提交”，意思就是语句提交以后，即执行了 Commit 以后别的事务就能读到这个改变，只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别。</li>
<li>Read Commited 不允许脏读，但会出现非重复读。</li>
</ul>
</li>
<li>可重复读(Repeatable Read)：<ul>
<li>直译就是”可以重复读”，这是说在同一个事务里面先后执行同一个查询语句的时候，得到的结果是一样的。</li>
<li>Repeatable Read 不允许脏读，不允许非重复读，但是会出现幻象读。</li>
</ul>
</li>
<li>串行读(Serializable)<ul>
<li>直译就是”序列化”，意思是说这个事务执行的时候不允许别的事务并发执行。完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。</li>
<li>Serializable 不允许不一致现象的出现。</li>
</ul>
</li>
</ol>
<h3 id="u4E8B_u52A1_u9694_u79BB_u7684_u5B9E_u73B0_u2014_u2014_u9501"><a href="#u4E8B_u52A1_u9694_u79BB_u7684_u5B9E_u73B0_u2014_u2014_u9501" class="headerlink" title="事务隔离的实现——锁"></a>事务隔离的实现——锁</h3><ol>
<li>共享锁(S锁)<ul>
<li>用于只读操作(SELECT)，锁定共享的资源。共享锁不会阻止其他用户读，但是阻止其他的用户写和修改。</li>
</ul>
</li>
<li>更新锁(U锁)<ul>
<li>用于可更新的资源中。防止当多个会话在读取、锁定以及随后可能进行的资源更新时发生常见形式的死锁。</li>
</ul>
</li>
<li>独占锁(X锁，也叫排他锁)<ul>
<li>一次只能有一个独占锁用在一个资源上，并且阻止其他所有的锁包括共享缩。写是独占锁，可以有效的防止“脏读”。</li>
</ul>
</li>
</ol>
<p>Read Uncommited 如果一个事务已经开始写数据，则另外一个数据则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。</p>
<p>Read Committed 读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。可以通过“瞬间共享读锁”和“排他写锁”实现。</p>
<p>Repeatable Read 读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。可以通过“共享读锁”和“排他写锁”实现。</p>
<p>Serializable 读加共享锁，写加排他锁，读写互斥。</p>
<h3 id="u7D22_u5F15"><a href="#u7D22_u5F15" class="headerlink" title="索引"></a>索引</h3><p>数据库创建索引能够大大提高系统的性能。</p>
<ol>
<li>通过创建唯一性的索引，可以保证数据库表中每一行数据的唯一性。</li>
<li>可以大大加快数据的检索速度，这也使创建索引的最主要的原因。</li>
<li>可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。</li>
<li>在使用分组和排序子句进行数据检索时，同样可以显著的减少查询中查询中分组和排序的时间。</li>
<li>通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。</li>
</ol>
<p>增加索引也有许多不利的方面。</p>
<ol>
<li>创建索引和维护索引需要消耗时间，这种时间随着数量的增加而增加。</li>
<li>索引需要占物理空间，除了数据表占据数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要额空间就会更大。</li>
<li>当对表中的数据进行增加，删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。</li>
</ol>
<p>应该对如下的列建立索引</p>
<ol>
<li>在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构。</li>
<li>在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度。</li>
<li>在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的。</li>
<li>在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。</li>
<li>在经常使用在where子句中的列上面创建索引，加快条件的判断速度。</li>
</ol>
<p>有些列不应该创建索引</p>
<ol>
<li>在查询中很少使用或者作为参考的列不应该创建索引。</li>
<li>对于那些只有很少数据值的列也不应该增加索引（比如性别，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度）。</li>
<li>对于那些定义为text，image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。</li>
<li>当修改性能远远大于检索性能时，不应该创建索引，因为修改性能和检索性能是矛盾的。</li>
</ol>
<p>创建索引的方法：直接创建和间接创建（在表中定义主键约束或者唯一性约束时，同时也创建了索引）。</p>
<p>索引的特征：</p>
<p>唯一性索引和复合索引。唯一性索引保证在索引列中的全部数据是唯一的，不会包含冗余数据。复合索引就是一个索引创建在两个列或者多个列上。可以减少一在一个表中所创建的索引数量。</p>
<h2 id="u6D4B_u8BD5"><a href="#u6D4B_u8BD5" class="headerlink" title="测试"></a>测试</h2><p>在面试软件开发的过程中，面试官可能也会询问关于软件开发流程以及测试方法相关的问题。在大多数互联网公司，许多部门不一定配有专门的QA(Quality Assurance)，在这种情况下，程序员本身需要对自己开发的模块和系统进行测试。另一方面，程序员在开发过程中测试自己的程序也是非常好的习惯，这样可以确保开发效率。基于上述原因，面试软件开发职位但遇到测试相关的问题并不少见。</p>
<h3 id="u6D4B_u8BD5_u73B0_u5B9E_u4E16_u754C_u7684_u7269_u4F53_u3001_u8F6F_u4EF6_u6216_u51FD_u6570"><a href="#u6D4B_u8BD5_u73B0_u5B9E_u4E16_u754C_u7684_u7269_u4F53_u3001_u8F6F_u4EF6_u6216_u51FD_u6570" class="headerlink" title="测试现实世界的物体、软件或函数"></a>测试现实世界的物体、软件或函数</h3><p>三者并无本质的差别，问题的核心均在于：测试对象在不同的输入下，能否实现预计的功能，提供恰当的输出。 一般情况下，总是需要考虑以下几个方面，以全面测试对象对于不同类型输入的效果：</p>
<p>(1) 常规情况(Normal cases)</p>
<p>输入不同类型的合法数据，主要用以判断对象的功能性：在给定输入的情况下能否给出期望的输出，由此判断功能的实现是否正确。比如，测试银行账户的转账功能：假设账户中有1000元，可以输入100，2000等并判断余额及转出钱数是否符合期望。</p>
<p>(2) 极端情况(Extreme cases)</p>
<p>测试一些边界条件或极端情况。所谓的极端情况包括多用户或多线程情况下频繁地访问／更新数据。比如，继续测试银行账户的转账功能：假设账户中有1000元，可以测试边界条件，取出1000元等。或者测试极端情况，假设用户开了多个页面，并在每个页面上几乎同时都尝试转出1000元，或者用户通过ATM机和手机APP同时进行转账操作等。</p>
<p>(3) 非法情况(Invalid case)</p>
<p>主要测试用户输入非法数据时系统不会崩溃，并且能够给出恰当的反馈。比如，测试银行账户的转账功能：当用户输入大于账户余额的数字时，或者当接收人账户错误时，系统能否给出错误提示等。</p>
<h3 id="u6545_u969C_u6392_u9664_28Troubleshooting_29"><a href="#u6545_u969C_u6392_u9664_28Troubleshooting_29" class="headerlink" title="故障排除(Troubleshooting)"></a>故障排除(Troubleshooting)</h3><p>另一大类的常见问题是给出一个有问题的测试现象，让面试者判断问题出现在哪里。对于这类问题，首先考虑测试对象由生成，到运行，到产生最终结果的完整流程，其次判断每一步执行了什么，需要依赖哪些参数，该步骤的异常是否会导致最终的测试现象，并且考虑如何验证自己的判断。 例如，测试用户无法访问你开发的网站。首先考虑主要流程，简述如下：用户连接到网络，发送HTTP请求到网站，网站发送数据包给用户，用户浏览器显示页面。在此例中，每一步都有可能导致无法访问网站的情况，具体描述如下：</p>
<p>(1) 用户连接到网络：这一步用户需要获得有效的IP，获取访问互联网的权限。需要依赖用户的网卡是否工作正常，是否能够被分配到有效的IP，是否能够从路由器或者服务器获得互联网访问权限等等。检验方式可以是：可以打开终端用ping命令，尝试建立与大型网站的连接。或者直接用浏览器尝试访问其他大型网站。如果不能建立与其他网站的连接，则网络接入有问题。</p>
<p>(2) 发送HTTP请求到网站：用户首先会通过DNS获取服务器地址，然后发送HTTP请求到对应的IP。需要依赖用户能否正确获取网站IP地址。检验方式可以是：在用户端利用抓包软件，例如WireShark，tcpdump等，观察是否有HTTP请求发送到网站服务器。如果没有发送HTTP请求或目的地IP有问题，则DNS可能有错。</p>
<p>(3) 网站发送数据包给用户：这一步需要网站接收到HTTP请求，并且将对应数据传回给用户。需要依赖网站能否收到HTTP请求以及对于HTTP请求的处理是否正确。检验方式可以是：在服务器端通过log判断是否有新用户接入，接入请求的处理是否正确，以及发送给用户的数据是什么。如果网站没有收到请求，则服务器端的网络可能有问题。如果服务器无法处理HTTP请求或抛出异常，则服务器的实现可能有问题。</p>
<p>(4) 用户浏览器显示页面： 这一步需要用户接收到网站发回的数据，浏览器解析数据并显示页面。需要依赖于用户能否收到数据，以及收到的数据是否能够被浏览器正确解析及显示。检验方式可以是：在用户端利用抓包软件，观察是否有来自服务器的数据。一般来说，如果用户用的是商用浏览器，即能够正确解析数据。故如果能收到服务器数据但是不能正常显示，我们可以认为服务器的数据有问题。</p>
<h3 id="u6D4B_u8BD5_u7684_u65B9_u6CD5"><a href="#u6D4B_u8BD5_u7684_u65B9_u6CD5" class="headerlink" title="测试的方法"></a>测试的方法</h3><p><strong>AB Testing</strong></p>
<p>AB测试是一种对比测试方案。测试人员对于不同用户随机生成两种方案，例如，某些用户看到的网页按钮是圆形的，其他用户看到的网页按钮是方形的。通过用户对于不同测试方案的反应，来决定最终部署哪种方案。具体请参考：<br><a href="http://en.wikipedia.org/wiki/A/B_testing" target="_blank" rel="external">http://en.wikipedia.org/wiki/A/B_testing</a></p>
<p><strong>Black Box Testing</strong></p>
<p>黑箱测试主要用于测试程序的功能，而不是内部结构或运作。测试者秩序知道输入以及对应的输出，就可以生成测试数据。黑箱测试的目的在于快速检测程序的功能性。特别地，黑箱测试还应该包括非法的输入数据，以确保程序不会崩溃。</p>
<p><strong>White Box Testing</strong></p>
<p>与黑箱测试相对，白箱测试主要用于测试程序的内部结构或运作。测试人员需要从程序设计的角度生成测试案例：输入测试数据并验证程序按照既定的流程执行。</p>
<h3 id="u5DE5_u4E1A_u754C_u6D4B_u8BD5_u6D41_u7A0B"><a href="#u5DE5_u4E1A_u754C_u6D4B_u8BD5_u6D41_u7A0B" class="headerlink" title="工业界测试流程"></a>工业界测试流程</h3><p><strong>Unit Test</strong></p>
<p>优良的软件设计强调模块化，即模块之间通过API进行交互，每个模块负责实现相对独立的功能。单元测试的目的在于对于每个模块设计相应的测试数据，用以检验模块的功能。通常，单元测试采用黑箱测试，通过运行脚本完成。测试人员将测试数据输入脚本，将输出结果与期望的输出数据进行比较。单元测试不仅仅可以用于新模块的开发，还可以用于对于已有模块的更新，维护。对于模块的每次更改都应该运行相应的单元测试以确保功能的完整性。</p>
<p><strong>Alpha Test</strong></p>
<p>Alpha测试通常是阶段性开发完成后开始进行。主要是面向内部开发人员，在模拟环境中输入模拟的数据进行测试，以验证系统符合使用者以及设计者的需求。</p>
<p><strong>Beta Test</strong></p>
<p>当Alpha阶段完成后，可以进入由公众参与的beta测试阶段。Beta测试通常使用真实的运行环境，并且使用实际数据进行测试，以确认系统效率。测试的主要目的在于进一步测试及完善功能。</p>
<h2 id="u64CD_u4F5C_u7CFB_u7EDF"><a href="#u64CD_u4F5C_u7CFB_u7EDF" class="headerlink" title="操作系统"></a>操作系统</h2><p>大部分互联网公司的软件开发职位面试可能不会直接涉及这一层面的知识，但并不意味着这部分知识不重要。对于计算机底层实现的深入理解，能帮助你了解计算机的运行原理，能够更好地设计高效的架构，并且有助于调试、判断错误。特别地，对于多线程的理解尤为重要：现今的程序架构都需要并发处理，如何协调不同线程之间的分工协作，避免死锁、同步出错等等问题，是程序员应当具备的技能。对于后端工程师而言，良好的操作系统知识基础更是深刻理解并实现复杂分布式系统的前提条件。</p>
<h3 id="u8FDB_u7A0B"><a href="#u8FDB_u7A0B" class="headerlink" title="进程"></a>进程</h3><p>进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。</p>
<p>进程的概念主要有两点：第一，进程是一个实体。每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。第二，进程是一个“执行中的程序”。程序是一个没有生命的实体，只有处理器赋予程序生命时，它才能成为一个活动的实体，我们称其为进程。</p>
<h4 id="u8FDB_u7A0B_u7684_u57FA_u672C_u72B6_u6001"><a href="#u8FDB_u7A0B_u7684_u57FA_u672C_u72B6_u6001" class="headerlink" title="进程的基本状态"></a>进程的基本状态</h4><ol>
<li>等待态：等待某个事件的完成；</li>
<li>就绪态：等待系统分配处理器以便运行；</li>
<li>运行态：占有处理器正在运行。</li>
<li>运行态→等待态 往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。</li>
</ol>
<p>等待态→就绪态 则是等待的条件已满足，只需分配到处理器后就能运行。</p>
<p>运行态→就绪态 不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。</p>
<p>就绪态→运行态 系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态</p>
<h3 id="u8FDB_u7A0B_u8C03_u5EA6"><a href="#u8FDB_u7A0B_u8C03_u5EA6" class="headerlink" title="进程调度"></a>进程调度</h3><h4 id="u8C03_u5EA6_u79CD_u7C7B"><a href="#u8C03_u5EA6_u79CD_u7C7B" class="headerlink" title="调度种类"></a>调度种类</h4><p>高级、中级和低级调度作业从提交开始直到完成，往往要经历下述三级调度：</p>
<ul>
<li>高级调度：(High-Level Scheduling)又称为作业调度，它决定把后备作业调入内存运行；</li>
<li>低级调度：(Low-Level Scheduling)又称为进程调度，它决定把就绪队列的某进程获得CPU；</li>
<li>中级调度：(Intermediate-Level Scheduling)又称为在虚拟存储器中引入，在内、外存对换区进行进程对换。</li>
</ul>
<h4 id="u975E_u62A2_u5360_u5F0F_u8C03_u5EA6_u4E0E_u62A2_u5360_u5F0F_u8C03_u5EA6"><a href="#u975E_u62A2_u5360_u5F0F_u8C03_u5EA6_u4E0E_u62A2_u5360_u5F0F_u8C03_u5EA6" class="headerlink" title="非抢占式调度与抢占式调度"></a>非抢占式调度与抢占式调度</h4><ul>
<li>非抢占式<ul>
<li>分派程序一旦把处理机分配给某进程后便让它一直运行下去，直到进程完成或发生进程调度进程调度某事件而阻塞时，才把处理机分配给另一个进程。</li>
</ul>
</li>
<li>抢占式<ul>
<li>操作系统将正在运行的进程强行暂停，由调度程序将CPU分配给其他就绪进程的调度方式。</li>
</ul>
</li>
</ul>
<h4 id="u8C03_u5EA6_u7B56_u7565_u7684_u8BBE_u8BA1"><a href="#u8C03_u5EA6_u7B56_u7565_u7684_u8BBE_u8BA1" class="headerlink" title="调度策略的设计"></a>调度策略的设计</h4><p>响应时间: 从用户输入到产生反应的时间</p>
<p>周转时间: 从任务开始到任务结束的时间</p>
<p>CPU任务可以分为交互式任务和批处理任务，调度最终的目标是合理的使用CPU，使得交互式任务的响应时间尽可能短，用户不至于感到延迟，同时使得批处理任务的周转时间尽可能短，减少用户等待的时间。</p>
<h4 id="u8C03_u5EA6_u7B97_u6CD5"><a href="#u8C03_u5EA6_u7B97_u6CD5" class="headerlink" title="调度算法"></a>调度算法</h4><ol>
<li>FIFO或First Come, First Served (FCFS)<ul>
<li>调度的顺序就是任务到达就绪队列的顺序。</li>
<li>公平、简单(FIFO队列)、非抢占、不适合交互式。未考虑任务特性，平均等待时间可以缩短</li>
</ul>
</li>
<li>Shortest Job First (SJF)<ul>
<li>最短的作业(CPU区间长度最小)最先调度。</li>
<li>可以证明，SJF可以保证最小的平均等待时间。</li>
<li>Shortest Remaining Job First (SRJF)</li>
<li>SJF的可抢占版本，比SJF更有优势。</li>
<li>SJF(SRJF): 如何知道下一CPU区间大小？根据历史进行预测: 指数平均法。</li>
</ul>
</li>
<li>优先权调度<ul>
<li>每个任务关联一个优先权，调度优先权最高的任务。</li>
<li>注意：优先权太低的任务一直就绪，得不到运行，出现“饥饿”现象。</li>
<li>FCFS是RR的特例，SJF是优先权调度的特例。这些调度算法都不适合于交互式系统。</li>
</ul>
</li>
<li>Round-Robin(RR)<ul>
<li>设置一个时间片，按时间片来轮转调度（“轮叫”算法）</li>
<li>优点: 定时有响应，等待时间较短；缺点: 上下文切换次数较多；</li>
<li>如何确定时间片？</li>
<li>时间片太大，响应时间太长；吞吐量变小，周转时间变长；当时间片过长时，退化为FCFS。</li>
</ul>
</li>
<li>多级队列调度<ul>
<li>按照一定的规则建立多个进程队列</li>
<li>不同的队列有固定的优先级（高优先级有抢占权）</li>
<li>不同的队列可以给不同的时间片和采用不同的调度方法</li>
<li>存在问题1：没法区分I/O bound和CPU bound；</li>
<li>存在问题2：也存在一定程度的“饥饿”现象；</li>
</ul>
</li>
<li>多级反馈队列<ul>
<li>在多级队列的基础上，任务可以在队列之间移动，更细致的区分任务。</li>
<li>可以根据“享用”CPU时间多少来移动队列，阻止“饥饿”。</li>
<li>最通用的调度算法，多数OS都使用该方法或其变形，如UNIX、Windows等。</li>
</ul>
</li>
</ol>
<h3 id="u8FDB_u7A0B_u540C_u6B65"><a href="#u8FDB_u7A0B_u540C_u6B65" class="headerlink" title="进程同步"></a>进程同步</h3><h4 id="u4E34_u754C_u8D44_u6E90_u4E0E_u4E34_u754C_u533A"><a href="#u4E34_u754C_u8D44_u6E90_u4E0E_u4E34_u754C_u533A" class="headerlink" title="临界资源与临界区"></a>临界资源与临界区</h4><p>在操作系统中，进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）。但对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。</p>
<p>对于临界资源的访问，必须是互斥进行。也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。而进程内访问临界资源的代码被成为临界区。</p>
<p>对于临界区的访问过程分为四个部分：</p>
<ol>
<li>进入区:查看临界区是否可访问，如果可以访问，则转到步骤二，否则进程会被阻塞</li>
<li>临界区:在临界区做操作</li>
<li>退出区:清除临界区被占用的标志</li>
<li>剩余区：进程与临界区不相关部分的代码</li>
</ol>
<p>解决临界区问题可能的方法：</p>
<ol>
<li>一般软件方法</li>
<li>关中断方法</li>
<li>硬件原子指令方法</li>
<li>信号量方法</li>
</ol>
<h3 id="u7EBF_u7A0B"><a href="#u7EBF_u7A0B" class="headerlink" title="线程"></a>线程</h3><p>线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。</p>
<p>线程具有以下属性：</p>
<ol>
<li>轻型实体 线程中的实体基本上不拥有系统资源，只是有一点必不可少的、能保证独立运行的资源。线程的实体包括程序、数据和TCB。线程是动态概念，它的动态特性由线程控制块TCB（Thread Control Block）描述。TCB包括以下信息：<ul>
<li>线程状态。</li>
<li>当线程不运行时，被保存的现场资源。</li>
<li>一组执行堆栈。</li>
<li>存放每个线程的局部变量主存区。</li>
<li>访问同一个进程中的主存和其它资源。</li>
<li>用于指示被执行指令序列的程序计数器、保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈。</li>
</ul>
</li>
<li>独立调度和分派的基本单位。<ul>
<li>在多线程OS中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位。由于线程很“轻”，故线程的切换非常迅速且开销小（在同一进程中的）。</li>
</ul>
</li>
<li>可并发执行。 在一个进程中的多个线程之间，可以并发执行，甚至允许在一个进程中所有线程都能并发执行；同样，不同进程中的线程也能并发执行，充分利用和发挥了处理机与外围设备并行工作的能力。</li>
<li>共享进程资源。 在同一进程中的各个线程，都可以共享该进程所拥有的资源，这首先表现在：所有线程都具有相同的地址空间（进程的地址空间），这意味着，线程可以访问该地址空间的每一个虚地址；此外，还可以访问进程所拥有的已打开文件、定时器、信号量机构等。由于同一个进程内的线程共享内存和文件，所以线程之间互相通信不必调用内核。 线程共享的环境包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。</li>
</ol>
<h3 id="u534F_u7A0B"><a href="#u534F_u7A0B" class="headerlink" title="协程"></a>协程</h3><p>协程，又称微线程，纤程。英文名Coroutine。</p>
<p>协程可以理解为用户级线程，协程和线程的区别是：线程是抢占式的调度，而协程是协同式的调度，协程避免了无意义的调度，由此可以提高性能，但也因此，程序员必须自己承担调度的责任，同时，协程也失去了标准线程使用多CPU的能力。</p>
<p>使用协程改写生产者-消费者问题：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">import <span class="tag">time</span></span><br><span class="line"></span><br><span class="line">def <span class="function"><span class="title">consumer</span><span class="params">()</span></span>:</span><br><span class="line">    r = <span class="string">''</span></span><br><span class="line">    while True:</span><br><span class="line">        n = yield r</span><br><span class="line">        <span class="keyword">if</span> not n:</span><br><span class="line">            return</span><br><span class="line">        <span class="function"><span class="title">print</span><span class="params">(<span class="string">'[CONSUMER] Consuming %s...'</span> % n)</span></span></span><br><span class="line">        <span class="tag">time</span>.<span class="function"><span class="title">sleep</span><span class="params">(<span class="number">1</span>)</span></span></span><br><span class="line">        r = <span class="string">'200 OK'</span></span><br><span class="line"></span><br><span class="line">def <span class="function"><span class="title">produce</span><span class="params">(c)</span></span>:</span><br><span class="line">    c.<span class="function"><span class="title">next</span><span class="params">()</span></span></span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    while n &lt; <span class="number">5</span>:</span><br><span class="line">        n = n + <span class="number">1</span></span><br><span class="line">        <span class="function"><span class="title">print</span><span class="params">(<span class="string">'[PRODUCER] Producing %s...'</span> % n)</span></span></span><br><span class="line">        r = c.<span class="function"><span class="title">send</span><span class="params">(n)</span></span></span><br><span class="line">        <span class="function"><span class="title">print</span><span class="params">(<span class="string">'[PRODUCER] Consumer return: %s'</span> % r)</span></span></span><br><span class="line">    c.<span class="function"><span class="title">close</span><span class="params">()</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    c = <span class="function"><span class="title">consumer</span><span class="params">()</span></span></span><br><span class="line">    <span class="function"><span class="title">produce</span><span class="params">(c)</span></span></span><br></pre></td></tr></table></figure>
<p>可以看到，使用协程不再需要显式地对锁进行操作</p>
<h3 id="u8FDB_u7A0B_vs-__u7EBF_u7A0B"><a href="#u8FDB_u7A0B_vs-__u7EBF_u7A0B" class="headerlink" title="进程 vs. 线程"></a>进程 vs. 线程</h3><p>进程(process)与线程(thread)最大的区别是进程拥有自己的地址空间，某进程内的线程对于其他进程不可见，即进程A不能通过传地址的方式直接读写进程B的存储区域。进程之间的通信需要通过进程间通信(Inter-process communication，IPC)。与之相对的，同一进程的各线程间之间可以直接通过传递地址或全局变量的方式传递信息。</p>
<p>此外，进程作为操作系统中拥有资源和独立调度的基本单位，可以拥有多个线程。通常操作系统中运行的一个程序就对应一个进程。在同一进程中，线程的切换不会引起进程切换。在不同进程中进行线程切换，如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。相比进程切换，线程切换的开销要小很多。线程于进程相互结合能够提高系统的运行效率。</p>
<p>线程可以分为两类：</p>
<p>一类是用户级线程(user level thread)。对于这类线程，有关线程管理的所有工作都由应用程序完成，内核意识不到线程的存在。在应用程序启动后，操作系统分配给该程序一个进程号，以及其对应的内存空间等资源。应用程序通常先在一个线程中运行，该线程被成为主线“程。在其运行的某个时刻，可以通过调用线程库中的函数创建一个在相同进程中运行的新线程。 用户级线程的好处是非常高效，不需要进入内核空间，但并发效率不高。</p>
<p>另一类是内核级线程(kernel level thread)。对于这类线程，有关线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只能调用内核线程的接口。内核维护进程及其内部的每个线程，调度也由内核基于线程架构完成。内核级线程的好处是，内核可以将不同线程更好地分配到不同的CPU，以实现真正的并行计算。</p>
<p>事实上，在现代操作系统中，往往使用组合方式实现多线程，即线程创建完全在用户空间中完成，并且一个应用程序中的多个用户级线程被映射到一些内核级线程上，相当于是一种折中方案。</p>
<h3 id="u4E0A_u4E0B_u6587_u5207_u6362"><a href="#u4E0A_u4E0B_u6587_u5207_u6362" class="headerlink" title="上下文切换"></a>上下文切换</h3><p>对于单核单线程CPU而言，在某一时刻只能执行一条CPU指令。上下文切换(Context Switch)是一种将CPU资源从一个进程分配给另一个进程的机制。从用户角度看，计算机能够并行运行多个进程，这恰恰是操作系统通过快速上下文切换造成的结果。在切换的过程中，操作系统需要先存储当前进程的状态(包括内存空间的指针，当前执行完的指令等等)，再读入下一个进程的状态，然后执行此进程。</p>
<h3 id="u7CFB_u7EDF_u8C03_u7528"><a href="#u7CFB_u7EDF_u8C03_u7528" class="headerlink" title="系统调用"></a>系统调用</h3><p>系统调用(System call)是程序向系统内核请求服务的方式。可以包括硬件相关的服务(例如，访问硬盘等)，或者创建新进程，调度其他进程等。系统调用是程序和操作系统之间的重要接口。</p>
<p>在讲系统调用之前，先说下进程的执行在系统上的两个级别：用户级和核心级，也称为用户态和系统态(user mode and kernel mode)。</p>
<p>程序的执行一般是在用户态下执行的，但当程序需要使用操作系统提供的服务时，比如说打开某一设备、创建文件、读写文件等，就需要向操作系统发出调用服务的请求，这就是系统调用。</p>
<p>Linux系统有专门的函数库来提供这些请求操作系统服务的入口，这个函数库中包含了操作系统所提供的对外服务的接口。当进程发出系统调用之后，它所处的运行状态就会由用户态变成核心态。但这个时候，进程本身其实并没有做什么事情，这个时候是由内核在做相应的操作，去完成进程所提出的这些请求。</p>
<p>系统调用和中断的关系就在于，当进程发出系统调用申请的时候，会产生一个软件中断。产生这个软件中断以后，系统会去对这个软中断进行处理，这个时候进程就处于核心态了。</p>
<p>那么用户态和核心态之间的区别是什么呢？（以下区别摘至《UNIX操作系统设计》）</p>
<ol>
<li>用户态的进程能存取它们自己的指令和数据，但不能存取内核指令和数据（或其他进程的指令和数据）。然而，核心态下的进程能够存取内核和用户地址</li>
<li>某些机器指令是特权指令，在用户态下执行特权指令会引起错误</li>
</ol>
<p>对此要理解的一个是，在系统中内核并不是作为一个与用户进程平行的估计的进程的集合，内核是为用户进程运行的。</p>
<h3 id="Semaphore/Mutex"><a href="#Semaphore/Mutex" class="headerlink" title="Semaphore/Mutex"></a>Semaphore/Mutex</h3><p>当用户创立多个线程／进程时，如果不同线程／进程同时读写相同的内容，则可能造成读写错误，或者数据不一致。此时，需要通过加锁的方式，控制核心区域(critical section)的访问权限。对于semaphore而言，在初始化变量的时候可以控制允许多少个线程／进程同时访问一个critical section，其他的线程／进程会被堵塞，直到有人解锁。</p>
<p>Mutex相当于只允许一个线程／进程访问的semaphore。此外，根据实际需要，人们还实现了一种读写锁(read-write lock)，它允许同时存在多个阅读者(reader)，但任何时候至多只有一个写者(writer)，且不能于读者共存。</p>
<p>信号量是一个确定的二元组（s，q），其中s是一个具有非负初值的整形变量，q是一个初始状态为空的队列，整形变量s表示系统中某类资源的数目：</p>
<ul>
<li>当其值 ≥ 0 时，表示系统中当前可用资源的数目</li>
<li>当其值 ＜ 0 时，其绝对值表示系统中因请求该类资源而被阻塞的进程数目</li>
</ul>
<p>除信号量的初值外，信号量的值仅能由P操作和V操作更改，操作系统利用它的状态对进程和资源进行管理</p>
<p><strong>P操作</strong></p>
<p>P 操作记为P(s)，其中s为一信号量，它执行时主要完成以下动作：</p>
<pre><code>s.value = s.value - 1；  /*可理解为占用1个资源，若原来就没有则记帐“欠”1个*/
</code></pre><p>若s.value ≥ 0，则进程继续执行，否则（即s.value &lt; 0），则进程被阻塞，并将该进程插入到信号量s的等待队列s.queue中</p>
<p>说明：实际上，P操作可以理解为分配资源的计数器，或是使进程处于等待状态的控制指令</p>
<p><strong>V操作</strong></p>
<p>V 操作记为V(s)，其中s为一信号量，它执行时，主要完成以下动作：</p>
<pre><code>s.value = s.value + 1；/*可理解为归还1个资源，若原来就没有则意义是用此资源还1个欠帐*/
</code></pre><p>若s.value &gt; 0，则进程继续执行，否则（即s.value ≤ 0）,则从信号量s的等待队s.queue中移出第一个进程，使其变为就绪状态，然后返回原进程继续执行</p>
<p>说明：实际上，V操作可以理解为归还资源的计数器，或是唤醒进程使其处于就绪状态的控制指令</p>
<p>信号量方法实现：生产者 − 消费者互斥与同步控制</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">semaphore fullBuffers = 0; /<span class="keyword">*</span>仓库中已填满的货架个数<span class="keyword">*</span>/</span><br><span class="line">semaphore emptyBuffers = BUFFER_SIZE;/<span class="keyword">*</span>仓库货架空闲个数<span class="keyword">*</span>/</span><br><span class="line">semaphore mutex = 1; /<span class="keyword">*</span>生产-消费互斥信号<span class="keyword">*</span>/</span><br><span class="line"></span><br><span class="line">Producer()</span><br><span class="line">&#123;</span><br><span class="line">    while(True)</span><br><span class="line">    &#123;</span><br><span class="line">       /<span class="keyword">*</span>生产产品item<span class="keyword">*</span>/</span><br><span class="line">       emptyBuffers.P();</span><br><span class="line">       mutex.P();</span><br><span class="line">       /<span class="keyword">*</span>item存入仓库buffer<span class="keyword">*</span>/</span><br><span class="line">       mutex.V();</span><br><span class="line">       fullBuffers.V();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Consumer()</span><br><span class="line">&#123;</span><br><span class="line">    while(True)</span><br><span class="line">    &#123;</span><br><span class="line">        fullBuffers.P();</span><br><span class="line">        mutex.P();</span><br><span class="line">        /<span class="keyword">*</span>从仓库buffer中取产品item<span class="keyword">*</span>/</span><br><span class="line">        mutex.V();</span><br><span class="line">        emptyBuffers.V();</span><br><span class="line">        /<span class="keyword">*</span>消费产品item<span class="keyword">*</span>/</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用pthread实现的生产者－消费者模型：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="preprocessor">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="preprocessor">#<span class="keyword">define</span> BUFFER_SIZE <span class="number">10</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> buffer[BUFFER_SIZE] = &#123; <span class="number">0</span> &#125;;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">pthread_t</span> consumer, producer;</span><br><span class="line"><span class="keyword">pthread_cond_t</span> cond_producer, cond_consumer;</span><br><span class="line"><span class="keyword">pthread_mutex_t</span> mutex;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span>* <span class="title">consume</span><span class="params">(<span class="keyword">void</span>* _)</span></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    <span class="keyword">while</span>(count == <span class="number">0</span>)&#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">"empty buffer, wait producer\n"</span>);</span><br><span class="line">      pthread_cond_wait(&amp;cond_consumer, &amp;mutex);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    count--;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"consume a item\n"</span>);</span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    pthread_cond_signal(&amp;cond_producer);</span><br><span class="line">    <span class="comment">//pthread_mutex_unlock(&amp;mutex);</span></span><br><span class="line">  &#125;</span><br><span class="line">  pthread_exit(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span>* <span class="title">produce</span><span class="params">(<span class="keyword">void</span>* _)</span></span>&#123;</span><br><span class="line">  <span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">    pthread_mutex_lock(&amp;mutex);</span><br><span class="line">    <span class="keyword">while</span>(count == BUFFER_SIZE)&#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">"full buffer, wait consumer\n"</span>);</span><br><span class="line">      pthread_cond_wait(&amp;cond_producer, &amp;mutex);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    count++;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"produce a item.\n"</span>);</span><br><span class="line">    pthread_mutex_unlock(&amp;mutex);</span><br><span class="line">    pthread_cond_signal(&amp;cond_consumer);</span><br><span class="line">    <span class="comment">//pthread_mutex_unlock(&amp;mutex);</span></span><br><span class="line">  &#125;</span><br><span class="line">  pthread_exit(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  pthread_mutex_init(&amp;mutex, <span class="literal">NULL</span>);</span><br><span class="line">  pthread_cond_init(&amp;cond_consumer, <span class="literal">NULL</span>);</span><br><span class="line">  pthread_cond_init(&amp;cond_producer, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> err = pthread_create(&amp;consumer, <span class="literal">NULL</span>, consume, (<span class="keyword">void</span>*)<span class="literal">NULL</span>);</span><br><span class="line">  <span class="keyword">if</span>(err != <span class="number">0</span>)&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"consumer thread created failed\n"</span>);</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  err = pthread_create(&amp;producer, <span class="literal">NULL</span>, produce, (<span class="keyword">void</span>*)<span class="literal">NULL</span>);</span><br><span class="line">  <span class="keyword">if</span>(err != <span class="number">0</span>)&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"producer thread created failed\n"</span>);</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  pthread_join(producer, <span class="literal">NULL</span>);</span><br><span class="line">  pthread_join(consumer, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//sleep(1000);</span></span><br><span class="line"></span><br><span class="line">  pthread_cond_destroy(&amp;cond_consumer);</span><br><span class="line">  pthread_cond_destroy(&amp;cond_producer);</span><br><span class="line">  pthread_mutex_destroy(&amp;mutex);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="u6B7B_u9501"><a href="#u6B7B_u9501" class="headerlink" title="死锁"></a>死锁</h3><p>在引入锁的同时，我们遇到了一个新的问题：死锁(Deadlock)。死锁是指两个或多个线程／进程之间相互阻塞，以至于任何一个都不能继续运行，因此也不能解锁其他线程／进程。例如，线程A占有lock A，并且尝试获取lock B；而线程2占有lock B，尝试获取lock A。此时，两者相互阻塞，都无法继续运行。</p>
<p>总结产生死锁的四个条件(只有当四个条件同时满足时才会产生死锁)：</p>
<ol>
<li>Mutual Exclusion – Only one process may use a resource at a time</li>
<li>Hold-and-Wait – Process holds resource while waiting for another</li>
<li>No Preemption – Can’t take a resource away from a process</li>
<li>Circular Wait – The waiting processes form a cycle</li>
</ol>
<h3 id="u751F_u4EA7_u8005_u6D88_u8D39_u8005"><a href="#u751F_u4EA7_u8005_u6D88_u8D39_u8005" class="headerlink" title="生产者消费者"></a>生产者消费者</h3><p>生产者消费者模型是一种常见的通信模型：生产者和消费者共享一个数据管道，生产者将数据写入buffer，消费者从另一头读取数据。对于数据管道，需要考虑为空和溢出的情况。同时，通常还需要将这部分共享内存用mutex加锁。在只有一个生产者一个消费者的情况下，可以设计无锁队列(lockless queue)，线程安全地直接读写数据。</p>
<h3 id="u8FDB_u7A0B_u95F4_u901A_u4FE1"><a href="#u8FDB_u7A0B_u95F4_u901A_u4FE1" class="headerlink" title="进程间通信"></a>进程间通信</h3><p>本地进程间通信的方式有很多，可以总结为下面四类：</p>
<ul>
<li>消息传递（管道、FIFO、消息队列）</li>
<li>同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量）</li>
<li>共享内存（匿名的和具名的）</li>
<li>远程过程调用（Solaris门和Sun RPC）</li>
</ul>
<p>在介绍进程的时候，我们提起过一个进程不能直接读写另一个进程的数据，两者之间的通信需要通过进程间通信(inter-process communication, IPC)进行。进程通信的方式通常遵从生产者消费者模型，需要实现数据交换和同步两大功能。</p>
<p>1) Shared-memory + semaphore</p>
<p>不同进程通过读写操作系统中特殊的共享内存进行数据交换，进程之间用semaphore实现同步。</p>
<p>2) Message passing</p>
<p>进程在操作系统内部注册一个port，并且监测有没有数据，其他进程直接写数据到该port。该通信方式更加接近于网络通信方式。事实上，网络通信也是一种IPC，只是进程分布在不同机器上而已。</p>
<p>逻辑地址/物理地址/虚拟内存</p>
<p>所谓的逻辑地址，是指计算机用户(例如程序开发者)，看到的地址。例如，当创建一个长度为100的整型数组时，操作系统返回一个逻辑上的连续空间：指针指向数组第一个元素的内存地址。由于整型元素的大小为4个字节，故第二个元素的地址时起始地址加4，以此类推。事实上，逻辑地址并不一定是元素存储的真实地址，即数组元素的物理地址(在内存条中所处的位置)，并非是连续的，只是操作系统通过地址映射，将逻辑地址映射成连续的，这样更符合人们的直观思维。</p>
<p>另一个重要概念是虚拟内存。操作系统读写内存的速度可以比读写磁盘的速度快几个量级。但是，内存价格也相对较高，不能大规模扩展。于是，操作系统可以通过将部分不太常用的数据移出内存，“存放到价格相对较低的磁盘缓存，以实现内存扩展。操作系统还可以通过算法预测哪部分存储到磁盘缓存的数据需要进行读写，提前把这部分数据读回内存。虚拟内存空间相对磁盘而言要小很多，因此，即使搜索虚拟内存空间也比直接搜索磁盘要快。唯一慢于磁盘的可能是，内存、虚拟内存中都没有所需要的数据，最终还需要从硬盘中直接读取。这就是为什么内存和虚拟内存中需要存储会被重复读写的数据，否则就失去了缓存的意义。</p>
<p>现代计算机中有一个专门的转译缓冲区(Translation Lookaside Buffer，TLB)，用来实现虚拟地址到物理地址的快速转换。</p>
<p>与内存／虚拟内存相关的还有如下两个概念：</p>
<p>1) Resident Set</p>
<p>当一个进程在运行的时候，操作系统不会一次性加载进程的所有数据到内存，只会加载一部分正在用，以及预期要用的数据。其他数据可能存储在虚拟内存，交换区和硬盘文件系统上。被加载到内存的部分就是resident set。</p>
<p>2) Thrashing</p>
<p>由于resident set包含预期要用的数据，理想情况下，进程运行过程中用到的数据都会逐步加载进resident set。但事实往往并非如此：每当需要的内存页面(page)不在resident set中时，操作系统必须从虚拟内存或硬盘中读数据，这个过程被称为内存页面错误(page faults)。当操作系统需要花费大量时间去处理页面错误的情况就是thrashing。</p>
<h3 id="u6587_u4EF6_u7CFB_u7EDF"><a href="#u6587_u4EF6_u7CFB_u7EDF" class="headerlink" title="文件系统"></a>文件系统</h3><p>Unix风格的文件系统利用树形结构管理文件。每个节点有多个指针，指向下一层节点或者文件的磁盘存储位置。文件节点还附有文件的操作信息(metadata)，包括修改时间，访问权限等等。</p>
<p>用户的访问权限通过访问控制表(Access Control List)和能力表(Capability List)实现。前者从文件角度出发，标注了每个用户可以对该文件进行何种操作。后者从用户角度出发，标注了某用户可以以什么权限操作哪些文件。</p>
<p>Unix的文件权限分为读、写和执行，用户组分为文件拥有者，组和所有用户。可以通过命令对三组用户分别设置权限。</p>
<h3 id="u5B9E_u65F6_vs-_u5206_u65F6_u64CD_u4F5C_u7CFB_u7EDF"><a href="#u5B9E_u65F6_vs-_u5206_u65F6_u64CD_u4F5C_u7CFB_u7EDF" class="headerlink" title="实时 vs.分时操作系统"></a>实时 vs.分时操作系统</h3><p>操作系统可以分为实时操作系统(Real-time system)，和分时操作系统(Sharing time system)。通常计算机采用的是sharing time，即多个进程／用户之间共享CPU，从形势上实现多任务。各个用户／进程之间的调度并非精准度特别高，如果一个进程被锁住，可以给它分配更多的时间。而实时操作系统则不同，软件和硬件必须遵从严格的deadline，超过时限的进程可能直接被终止。在这样的操作系统中，每次加锁都需要仔细考虑。</p>
<h3 id="u7F16_u8BD1_u5668"><a href="#u7F16_u8BD1_u5668" class="headerlink" title="编译器"></a>编译器</h3><p>对于高级语言来说，代码需要通过编译才能够运行。编译通过编译器(compiler)实现，是一个将程序源代码转换成二进制机器码的过程。计算机可以直接执行二进制代码。在编译的过程中，编译器需要进行词法分析(lexical analysis)，解析(parsing)和过渡代码生成(intermediate code generation)。编译器的好坏可以直接影响最终代码的执行效率。</p>
<h3 id="u4E2D_u65AD"><a href="#u4E2D_u65AD" class="headerlink" title="中断"></a>中断</h3><p>所谓的中断就是在计算机执行程序的过程中，由于出现了某些特殊事情，使得CPU暂停对程序的执行，转而去执行处理这一事件的程序。等这些特殊事情处理完之后再回去执行之前的程序。中断一般分为三类：</p>
<ol>
<li>由计算机硬件异常或故障引起的中断，称为内部异常中断；</li>
<li>由程序中执行了引起中断的指令而造成的中断，称为软中断（这也是和我们将要说明的系统调用相关的中断）；</li>
<li>由外部设备请求引起的中断，称为外部中断。简单来说，对中断的理解就是对一些特殊事情的处理。</li>
</ol>
<p>与中断紧密相连的一个概念就是中断处理程序了。当中断发生的时候，系统需要去对中断进行处理，对这些中断的处理是由操作系统内核中的特定函数进行的，这些处理中断的特定的函数就是我们所说的中断处理程序了。</p>
<p>另一个与中断紧密相连的概念就是中断的优先级。中断的优先级说明的是当一个中断正在被处理的时候，处理器能接受的中断的级别。中断的优先级也表明了中断需要被处理的紧急程度。每个中断都有一个对应的优先级，当处理器在处理某一中断的时候，只有比这个中断优先级高的中断可以被处理器接受并且被处理。优先级比这个当前正在被处理的中断优先级要低的中断将会被忽略。</p>
<p>典型的中断优先级如下所示：</p>
<p>机器错误 &gt; 时钟 &gt; 磁盘 &gt; 网络设备 &gt;  终端 &gt; 软件中断</p>
<p>当发生软件中断时，其他所有的中断都可能发生并被处理；但当发生磁盘中断时，就只有时钟中断和机器错误中断能被处理了。</p>
<p>系统调用</p>
<p>在讲系统调用之前，先说下进程的执行在系统上的两个级别：用户级和核心级，也称为用户态和系统态(user mode and kernel mode)。</p>
<p>程序的执行一般是在用户态下执行的，但当程序需要使用操作系统提供的服务时，比如说打开某一设备、创建文件、读写文件等，就需要向操作系统发出调用服务的请求，这就是系统调用。</p>
<p>Linux系统有专门的函数库来提供这些请求操作系统服务的入口，这个函数库中包含了操作系统所提供的对外服务的接口。当进程发出系统调用之后，它所处的运行状态就会由用户态变成核心态。但这个时候，进程本身其实并没有做什么事情，这个时候是由内核在做相应的操作，去完成进程所提出的这些请求。</p>
<p>系统调用和中断的关系就在于，当进程发出系统调用申请的时候，会产生一个软件中断。产生这个软件中断以后，系统会去对这个软中断进行处理，这个时候进程就处于核心态了。</p>
<p>那么用户态和核心态之间的区别是什么呢？（以下区别摘至《UNIX操作系统设计》）</p>
<ol>
<li>用户态的进程能存取它们自己的指令和数据，但不能存取内核指令和数据（或其他进程的指令和数据）。然而，核心态下的进程能够存取内核和用户地址</li>
<li>某些机器指令是特权指令，在用户态下执行特权指令会引起错误</li>
</ol>
<p>对此要理解的一个是，在系统中内核并不是作为一个与用户进程平行的估计的进程的集合，内核是为用户进程运行的。</p>
<h3 id="IO_u591A_u8DEF_u590D_u7528"><a href="#IO_u591A_u8DEF_u590D_u7528" class="headerlink" title="IO多路复用"></a>IO多路复用</h3><h4 id="u57FA_u672C_u6982_u5FF5"><a href="#u57FA_u672C_u6982_u5FF5" class="headerlink" title="基本概念"></a>基本概念</h4><p>IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。IO多路复用适用如下场合：</p>
<ol>
<li>当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。</li>
<li>当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。</li>
<li>如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。</li>
<li>如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。</li>
<li>如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。</li>
</ol>
<p>与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。</p>
<h4 id="u5E38_u89C1_u7684IO_u590D_u7528_u5B9E_u73B0"><a href="#u5E38_u89C1_u7684IO_u590D_u7528_u5B9E_u73B0" class="headerlink" title="常见的IO复用实现"></a>常见的IO复用实现</h4><p>select(Linux/Windows/BSD Unix), epoll(Linux)，kqueue(BSD/Mac OS X)</p>
<h3 id="u5185_u5B58_u5206_u914D"><a href="#u5185_u5B58_u5206_u914D" class="headerlink" title="内存分配"></a>内存分配</h3><ul>
<li>虚拟地址：用户编程时将代码（或数据）分成若干个段，每条代码或每个数据的地址由段名称 + 段内相对地址构成，这样的程序地址称为虚拟地址</li>
<li>逻辑地址：虚拟地址中，段内相对地址部分称为逻辑地址</li>
<li>物理地址：实际物理内存中所看到的存储地址称为物理地址</li>
<li>逻辑地址空间：在实际应用中，将虚拟地址和逻辑地址经常不加区分，通称为逻辑地址。逻辑地址的集合称为逻辑地址空间</li>
<li>线性地址空间：CPU地址总线可以访问的所有地址集合称为线性地址空间</li>
<li>物理地址空间：实际存在的可访问的物理内存地址集合称为物理地址空间</li>
<li>MMU(Memery Management Unit内存管理单元)：实现将用户程序的虚拟地址（逻辑地址） → 物理地址映射的CPU中的硬件电路</li>
<li>基地址：在进行地址映射时，经常以段或页为单位并以其最小地址（即起始地址）为基值来进行计算</li>
<li>偏移量：在以段或页为单位进行地址映射时，相对于基地址的地址值</li>
</ul>
<p>虚拟地址先经过分段机制映射到线性地址，然后线性地址通过分页机制映射到物理地址。</p>
<h3 id="u865A_u62DF_u5185_u5B58"><a href="#u865A_u62DF_u5185_u5B58" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><p>请求调页，也称按需调页，即对不在内存中的“页”，当进程执行时要用时才调入，否则有可能到程序结束时也不会调入</p>
<h3 id="u9875_u9762_u7F6E_u6362_u7B97_u6CD5"><a href="#u9875_u9762_u7F6E_u6362_u7B97_u6CD5" class="headerlink" title="页面置换算法"></a>页面置换算法</h3><ul>
<li>FIFO算法<ul>
<li>先入先出，即淘汰最早调入的页面。</li>
</ul>
</li>
<li>OPT(MIN)算法<ul>
<li>选未来最远将使用的页淘汰，是一种最优的方案，可以证明缺页数最小。</li>
<li>可惜，MIN需要知道将来发生的事，只能在理论中存在，实际不可应用。</li>
</ul>
</li>
<li>LRU(Least-Recently-Used)算法<ul>
<li>用过去的历史预测将来，选最近最长时间没有使用的页淘汰(也称最近最少使用)。</li>
<li>LRU准确实现：计数器法，页码栈法。</li>
<li>由于代价较高，通常不使用准确实现，而是采用近似实现，例如Clock算法。</li>
</ul>
</li>
</ul>
<p><strong>内存抖动现象</strong>：页面的频繁更换，导致整个系统效率急剧下降，这个现象称为内存抖动（或颠簸）。抖动一般是内存分配算法不好，内存太小引或者程序的算法不佳引起的。</p>
<p><strong>Belady现象</strong>：对有的页面置换算法，页错误率可能会随着分配帧数增加而增加。</p>
<p>FIFO会产生Belady异常。</p>
<p>栈式算法无Belady异常，LRU，LFU（最不经常使用），OPT都属于栈式算法。</p>
<h3 id="u78C1_u76D8_u8C03_u5EA6"><a href="#u78C1_u76D8_u8C03_u5EA6" class="headerlink" title="磁盘调度"></a>磁盘调度</h3><p>磁盘访问延迟 = 队列时间 + 控制器时间 + 寻道时间 + 旋转时间 + 传输时间</p>
<p>磁盘调度的目的是减小延迟，其中前两项可以忽略，寻道时间是主要矛盾。</p>
<h3 id="u78C1_u76D8_u8C03_u5EA6_u7B97_u6CD5"><a href="#u78C1_u76D8_u8C03_u5EA6_u7B97_u6CD5" class="headerlink" title="磁盘调度算法"></a>磁盘调度算法</h3><ul>
<li>FCFS<ul>
<li>先进先出的调度策略，这个策略具有公平的优点，因为每个请求都会得到处理，并且是按照接收到的顺序进行处理。</li>
</ul>
</li>
<li>SSTF(Shortest-seek-time First 最短寻道时间优先)<ul>
<li>选择使磁头从当前位置开始移动最少的磁盘I/O请求，所以 SSTF 总是选择导致最小寻道时间的请求。</li>
<li>总是选择最小寻找时间并不能保证平均寻找时间最小，但是能提供比 FCFS 算法更好的性能，会存在饥饿现象。</li>
</ul>
</li>
<li>SCAN<ul>
<li>SSTF+中途不回折，每个请求都有处理机会。</li>
<li>SCAN 要求磁头仅仅沿一个方向移动，并在途中满足所有未完成的请求，直到它到达这个方向上的最后一个磁道，或者在这个方向上没有其他请求为止。</li>
<li>由于磁头移动规律与电梯运行相似，SCAN 也被称为电梯算法。</li>
<li>SCAN 算法对最近扫描过的区域不公平，因此，它在访问局部性方面不如 FCFS 算法和 SSTF 算法好。</li>
</ul>
</li>
<li>C-SCAN<ul>
<li>SCAN+直接移到另一端，两端请求都能很快处理。</li>
<li>把扫描限定在一个方向，当访问到某个方向的最后一个磁道时，磁道返回磁盘相反方向磁道的末端，并再次开始扫描。</li>
<li>其中“C”是Circular（环）的意思。</li>
</ul>
</li>
<li>LOOK 和 C-LOOK<ul>
<li>釆用SCAN算法和C-SCAN算法时磁头总是严格地遵循从盘面的一端到另一端，显然，在实际使用时还可以改进，即磁头移动只需要到达最远端的一个请求即可返回，不需要到达磁盘端点。这种形式的SCAN算法和C-SCAN算法称为LOOK和C-LOOK调度。这是因为它们在朝一个给定方向移动前会查看是否有请求。</li>
</ul>
</li>
</ul>
<h3 id="u5206_u533A_u8868"><a href="#u5206_u533A_u8868" class="headerlink" title="分区表"></a>分区表</h3><ul>
<li>MBR：支持最大卷为2 TB（Terabytes）并且每个磁盘最多有4个主分区（或3个主分区，1个扩展分区和无限制的逻辑驱动器）</li>
<li>GPT：支持最大卷为18EB（Exabytes）并且每磁盘的分区数没有上限，只受到操作系统限制（由于分区表本身需要占用一定空间，最初规划硬盘分区时，留给分区表的空间决定了最多可以有多少个分区，IA-64版Windows限制最多有128个分区，这也是EFI标准规定的分区表的最小尺寸。另外，GPT分区磁盘有备份分区表来提高分区数据结构的完整性。</li>
</ul>
<h3 id="RAID__u6280_u672F"><a href="#RAID__u6280_u672F" class="headerlink" title="RAID 技术"></a>RAID 技术</h3><p>磁盘阵列（Redundant Arrays of Independent Disks，RAID），独立冗余磁盘阵列之。原理是利用数组方式来作磁盘组，配合数据分散排列的设计，提升数据的安全性。</p>
<ul>
<li>RAID 0<ul>
<li>RAID 0是最早出现的RAID模式，需要2块以上的硬盘，可以提高整个磁盘的性能和吞吐量。</li>
<li>RAID 0没有提供冗余或错误修复能力，其中一块硬盘损坏，所有数据将遗失。</li>
</ul>
</li>
<li>RAID 1<ul>
<li>RAID 1就是镜像，其原理为在主硬盘上存放数据的同时也在镜像硬盘上写一样的数据。</li>
<li>当主硬盘（物理）损坏时，镜像硬盘则代替主硬盘的工作。因为有镜像硬盘做数据备份，所以RAID 1的数据安全性在所有的RAID级别上来说是最好的。</li>
<li>但无论用多少磁盘做RAID 1，仅算一个磁盘的容量，是所有RAID中磁盘利用率最低的。</li>
</ul>
</li>
<li>RAID 2<ul>
<li>这是RAID 0的改良版，以汉明码（Hamming Code）的方式将数据进行编码后分区为独立的比特，并将数据分别写入硬盘中。因为在数据中加入了错误修正码（ECC，Error Correction Code），所以数据整体的容量会比原始数据大一些，RAID2最少要三台磁盘驱动器方能运作。</li>
</ul>
</li>
<li>RAID 3<ul>
<li>采用Bit－interleaving（数据交错存储）技术，它需要通过编码再将数据比特分割后分别存在硬盘中，而将同比特检查后单独存在一个硬盘中，但由于数据内的比特分散在不同的硬盘上，因此就算要读取一小段数据资料都可能需要所有的硬盘进行工作，所以这种规格比较适于读取大量数据时使用。</li>
</ul>
</li>
<li>RAID 4<ul>
<li>它与RAID 3不同的是它在分区时是以区块为单位分别存在硬盘中，但每次的数据访问都必须从同比特检查的那个硬盘中取出对应的同比特数据进行核对，由于过于频繁的使用，所以对硬盘的损耗可能会提高。（块交织技术，Block interleaving）</li>
</ul>
</li>
</ul>
<p><strong>RAID 2/3/4 在实际应用中很少使用</strong></p>
<ul>
<li>RAID 5<ul>
<li>RAID Level 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分区）技术。</li>
<li>RAID 5至少需要三块硬盘，RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储于不同的磁盘上。</li>
<li>RAID 5 允许一块硬盘损坏。</li>
<li>实际容量 Size = (N-1) * min(S1, S2, S3 … SN)</li>
</ul>
</li>
<li>RAID 6<ul>
<li>与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块。两个独立的奇偶系统使用不同的算法，数据的可靠性非常高，即使两块磁盘同时失效也不会影响数据的使用。</li>
<li>RAID 6 至少需要4块硬盘。</li>
<li>实际容量 Size = (N-2) * min(S1, S2, S3 … SN)</li>
</ul>
</li>
<li>RAID 10/01（RAID 1+0，RAID 0+1）<ul>
<li>RAID 10是先镜射再分区数据，再将所有硬盘分为两组，视为是RAID 0的最低组合，然后将这两组各自视为RAID 1运作。</li>
<li>RAID 01则是跟RAID 10的程序相反，是先分区再将数据镜射到两组硬盘。它将所有的硬盘分为两组，变成RAID 1的最低组合，而将两组硬盘各自视为RAID 0运作。</li>
<li>当RAID 10有一个硬盘受损，其余硬盘会继续运作。RAID 01只要有一个硬盘受损，同组RAID 0的所有硬盘都会停止运作，只剩下其他组的硬盘运作，可靠性较低。如果以六个硬盘建RAID 01，镜射再用三个建RAID 0，那么坏一个硬盘便会有三个硬盘脱机。因此，RAID 10远较RAID 01常用，零售主板绝大部份支持RAID 0/1/5/10，但不支持RAID 01。</li>
<li>RAID 10 至少需要4块硬盘，且硬盘数量必须为偶数。</li>
</ul>
</li>
</ul>
<h4 id="u5E38_u89C1_u6587_u4EF6_u7CFB_u7EDF"><a href="#u5E38_u89C1_u6587_u4EF6_u7CFB_u7EDF" class="headerlink" title="常见文件系统"></a>常见文件系统</h4><ul>
<li>Windows: FAT, FAT16, FAT32, NTFS</li>
<li>Linux: ext2/3/4, btrfs, ZFS</li>
<li>Mac OS X: HFS+</li>
</ul>
<h3 id="Linux_u6587_u4EF6_u6743_u9650"><a href="#Linux_u6587_u4EF6_u6743_u9650" class="headerlink" title="Linux文件权限"></a>Linux文件权限</h3><p>Linux文件采用10个标志位来表示文件权限，如下所示：</p>
<pre><code>-rw-r--r--  1 skyline  staff    20B  1 27 10:34 1.txt
drwxr-xr-x   5 skyline  staff   170B 12 23 19:01 ABTableViewCell
</code></pre><p>第一个字符一般用来区分文件和目录，其中：</p>
<ul>
<li>d：表示是一个目录，事实上在ext2fs中，目录是一个特殊的文件。</li>
<li>－：表示这是一个普通的文件。</li>
<li>l: 表示这是一个符号链接文件，实际上它指向另一个文件。</li>
<li>b、c：分别表示区块设备和其他的外围设备，是特殊类型的文件。</li>
<li>s、p：这些文件关系到系统的数据结构和管道，通常很少见到。</li>
</ul>
<p>第2～10个字符当中的每3个为一组，左边三个字符表示所有者权限，中间3个字符表示与所有者同一组的用户的权限，右边3个字符是其他用户的权限。</p>
<p>这三个一组共9个字符，代表的意义如下：</p>
<ul>
<li>r(Read，读取)：对文件而言，具有读取文件内容的权限；对目录来说，具有浏览目录的权限</li>
<li>w(Write,写入)：对文件而言，具有新增、修改文件内容的权限；对目录来说，具有删除、移动目录内文件的权限。</li>
<li>x(eXecute，执行)：对文件而言，具有执行文件的权限；对目录来说该用户具有进入目录的权限。</li>
</ul>
<p>权限的掩码可以使用十进制数字表示：</p>
<ul>
<li>如果可读，权限是二进制的100，十进制是4；</li>
<li>如果可写，权限是二进制的010，十进制是2；</li>
<li>如果可运行，权限是二进制的001，十进制是1；</li>
</ul>
<p><strong>具备多个权限，就把相应的 4、2、1 相加就可以了：</strong></p>
<pre><code>若要 rwx 则 4+2+1=7 若要 rw- 则 4+2=6 若要 r-x 则 4+1=5 若要 r-- 则 =4 若要 -wx 则 2+1=3 若要 -w- 则 =2 若要 --x 则 =1 若要 --- 则 =0
</code></pre><p>默认的权限可用umask命令修改，用法非常简单，只需执行umask 777命令，便代表屏蔽所有的权限，因而之后建立的文件或目录，其权限都变成000，</p>
<p>依次类推。通常root帐号搭配umask命令的数值为022、027和 077，普通用户则是采用002，这样所产生的权限依次为755、750、700、775。</p>
<h4 id="chmod_u547D_u4EE4"><a href="#chmod_u547D_u4EE4" class="headerlink" title="chmod命令"></a>chmod命令</h4><p>chmod命令非常重要，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。</p>
<p>该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。</p>
<ol>
<li>文字设定法<ul>
<li>chmod ［who］ ［+ | - | =］ ［mode］ 文件名</li>
<li>命令中各选项的含义为：</li>
<li>操作对象who可是下述字母中的任一个或者它们的组合：<ul>
<li>u 表示“用户（user）”，即文件或目录的所有者。</li>
<li>g 表示“同组（group）用户”，即与文件属主有相同组ID的所有用户。</li>
<li>o 表示“其他（others）用户”。</li>
<li>a 表示“所有（all）用户”。它是系统默认值。</li>
</ul>
</li>
<li>操作符号可以是：<ul>
<li>添加某个权限。</li>
<li>取消某个权限。</li>
<li>= 赋予给定权限并取消其他所有权限（如果有的话）。</li>
</ul>
</li>
<li>设置mode所表示的权限可用下述字母的任意组合：<ul>
<li>r 可读。</li>
<li>w 可写。</li>
<li>x 可执行。</li>
<li>X 只有目标文件对某些用户是可执行的或该目标文件是目录时才追加x 属性。</li>
<li>s 在文件执行时把进程的属主或组ID置为该文件的文件属主。方式“u＋s”设置文件的用户ID位，“g＋s”设置组ID位。</li>
<li>t 保存程序的文本到交换设备上。</li>
<li>u 与文件属主拥有一样的权限。</li>
<li>g 与和文件属主同组的用户拥有一样的权限。</li>
<li>o 与其他用户拥有一样的权限。</li>
</ul>
</li>
<li>文件名：以空格分开的要改变权限的文件列表，支持通配符。</li>
<li>在一个命令行中可给出多个权限方式，其间用逗号隔开。例如：chmod g+r，o+r example 使同组和其他用户对文件example 有读权限。</li>
</ul>
</li>
<li>数字设定法<ul>
<li>直接使用数字表示的权限来更改：</li>
<li>例： $ chmod 644 mm.txt</li>
</ul>
</li>
</ol>
<h4 id="chgrp_u547D_u4EE4"><a href="#chgrp_u547D_u4EE4" class="headerlink" title="chgrp命令"></a>chgrp命令</h4><ul>
<li>功能：改变文件或目录所属的组。</li>
<li>语法：chgrp ［选项］ group filename</li>
<li>例：$ chgrp - R book /opt/local /book</li>
<li>改变/opt/local /book/及其子目录下的所有文件的属组为book。</li>
</ul>
<h4 id="chown_u547D_u4EE4"><a href="#chown_u547D_u4EE4" class="headerlink" title="chown命令"></a>chown命令</h4><ul>
<li>功能：更改某个文件或目录的属主和属组。这个命令也很常用。例如root用户把自己的一个文件拷贝给用户xu，为了让用户xu能够存取这个文件，root用户应该把这个文件的属主设为xu，否则，用户xu无法存取这个文件。</li>
<li>语法：chown ［选项］ 用户或组 文件</li>
<li>说明：chown将指定文件的拥有者改为指定的用户或组。用户可以是用户名或用户ID。组可以是组名或组ID。文件是以空格分开的要改变权限的文件列表，支持通配符。</li>
<li>例：把文件shiyan.c的所有者改为wang。</li>
<li><code>chown wang shiyan.c</code></li>
</ul>
<h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="http://wdxtub.com/interview/14520603814585.html">After URL</a></li>
<li><a href="http://wdxtub.com/interview/14520603814632.html">Reliable UDP</a></li>
<li><a href="http://wdxtub.com/interview/14520603814674.html">TCP or UDP</a></li>
<li><a href="http://wdxtub.com/interview/14520607787127.html">Test Binary Search</a></li>
<li><a href="http://wdxtub.com/interview/14520607787180.html">Test a Login System</a></li>
<li><a href="http://wdxtub.com/interview/14520607787230.html">Test a Pen</a></li>
<li><a href="http://wdxtub.com/interview/14520607787281.html">Web Browser debug</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>这一章包括剩余一些比较基本的常识性知识，具体可能是以聊天的形式来进行交流，关键就在于理解，不要死记硬背。其实计算机学科的各种概念联系都比较紧密，梳理清晰自然就记住了。</p>]]>
    
    </summary>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="操作系统" scheme="http://wdxtub.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="数据库" scheme="http://wdxtub.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="网络" scheme="http://wdxtub.com/tags/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 11 课 面向对象]]></title>
    <link href="http://wdxtub.com/2016/01/23/programmer-startline-11/"/>
    <id>http://wdxtub.com/2016/01/23/programmer-startline-11/</id>
    <published>2016-01-23T22:48:04.000Z</published>
    <updated>2016-01-24T01:19:34.000Z</updated>
    <content type="html"><![CDATA[<p>设计题可以分成两个类别：系统架构设计和利用面向对象编程原理进行程序设计。重点是要体现出自己的想法和思路，毕竟设计类问题，没有所谓标准答案。</p>
<a id="more"></a>
<hr>
<ol>
<li>题目描述<ul>
<li>往往非常简单，如：设计一个XX系统。或者：你有没有用过XXX，给你看一下它的界面和功能，你来设计一个。</li>
</ul>
</li>
<li>阐述题意<ul>
<li>面试者需向面试官询问系统的具体要求。如，需要什么功能，需要承受的流量大小，是否需要考虑可靠性，容错性等等。</li>
</ul>
</li>
<li>面试者提供一个初步的系统设计</li>
<li>面试官这对初步的系统中提出一些后续的问题：如果要加某个功能怎么办，如果流量大了怎么办，如何考虑一致性，如果机器挂了怎么办。</li>
<li>面试者根据面试官的后续问题逐步完善系统设计</li>
<li>完成面试</li>
</ol>
<p>总体特点是以交流为主，画图和代码为辅。</p>
<p>根据我们面试别人和参与面试的经验，先从面试官的角度给出一些考量标准：</p>
<ul>
<li>适应变化的需求(Adapt to the changing requirements )</li>
<li>设计干净，优美，考虑周到的系统(Produce a system that is clean, elegant, well thought )</li>
<li>解释为何这么实现(Explain why you choose this implementation )</li>
<li>对自己的能力水平很熟练(Be familiar with your experience level to make decisions )</li>
<li>在一些高层结构和复杂性方面有设计(Answer in high level of scale and complexity )</li>
</ul>
<p>按照评分体系的化，分成下面4个等级</p>
<table>
<thead>
<tr>
<th style="text-align:center">Scoring</th>
<th style="text-align:center">Candidate</th>
<th style="text-align:center">Criteria</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.0</td>
<td style="text-align:center">Bad</td>
<td style="text-align:center">No sense of requirement, no scoping</td>
</tr>
<tr>
<td style="text-align:center">2.0</td>
<td style="text-align:center">Poor</td>
<td style="text-align:center">Limited knowledge, common sense</td>
</tr>
<tr>
<td style="text-align:center">3.0</td>
<td style="text-align:center">Good</td>
<td style="text-align:center">Reasonable Solution, explain clearly</td>
</tr>
<tr>
<td style="text-align:center">4.0</td>
<td style="text-align:center">Great</td>
<td style="text-align:center">Out of expectation, well thoughtful, trade-off</td>
</tr>
</tbody>
</table>
<p>其实大家大可不必追求完美，在真正的面试中，没有人能对答如流，往往面试官也会给出善意的提示，就算你没回答某个子问题，在面试后的评价中也会综合衡量，跟其他的面试者比较，最终打出一个分数</p>
<h2 id="u89E3_u9898_u7B56_u7565"><a href="#u89E3_u9898_u7B56_u7565" class="headerlink" title="解题策略"></a>解题策略</h2><h3 id="Abstractions_2C_Object_and_Decoupling"><a href="#Abstractions_2C_Object_and_Decoupling" class="headerlink" title="Abstractions, Object and Decoupling"></a>Abstractions, Object and Decoupling</h3><p>通常，关于OOP，面试官会让面试者设计一个程序框架，该程序能够实现一些特定的功能。比如，如何实现一个音乐播放器，如何设计一个车库管理程序等等。对于此类问题，设计的关键过程一般包括抽象(abstraction)，设计对象(object)和设计合理的层次／接口(decoupling)。这里，我们举一个例子简单说明这些过程分别需要做些什么，在“模式识别”给出更为具体和完整的实例。</p>
<h3 id="u7EE7_u627F/_u7EC4_u5408/_u53C2_u6570_u5316_u7C7B_u578B"><a href="#u7EE7_u627F/_u7EC4_u5408/_u53C2_u6570_u5316_u7C7B_u578B" class="headerlink" title="继承/组合/参数化类型"></a>继承/组合/参数化类型</h3><p>在面向对象中最常用的两种代码复用技术就是继承和组合。在设计对象的时候，“Is-A”表示一种继承关系。比如，班长“Is-A”学生，那么，学生就是基类，班长就是派生类。在确定了派生关系之后，我们需要分析什么是基类变量(base class variables)什么是子类变量(sub class variables)，并由此确定基类和派生类之间的联系。而“Has-A”表示一种从属关系，这就是组合。比如，班长“Has-A”眼镜，那就可以解释为班长实例中拥有一个眼镜实例变量(instance variable)。在具体实现的时候，班长类中定义一个眼镜的基类指针。“在生成班长实例的时候，同时生成一个眼镜实例，利用眼镜的基类指针指向这个实例。任何关于眼镜的操作函数都可以利用这个基类指针实现多态(polymorphism)。注意，多态是OOP相关的一个重要概念，也是面试常考的概念之一。关于多态的解释请见“工具箱”。</p>
<p>在通常情况下，我们更偏向于“Has-A”的设计模式。因为该模式减少了两个实例之间的相关性。对于继承的使用，通常情况下我们会定义一个虚基类，由此派生出多个不同的实例类。在业界的程序开发中，多重继承并不常见，Java甚至不允许从多个父类同时继承，产生一个子类。</p>
<p>此外，我们还要提及参数化类型。参数化类型，或者说模版类也是一种有效的代码复用技术。在C++的标准模版库中大量应用了这种方式。例如，在定义一个List<string>的变量时，List被另一个类型String所参数化。</string></p>
<p>设计模式着重于代码的复用，所以在选择复用技术上，有必要看看上述三种复用技术优劣。</p>
<p><strong>继承</strong></p>
<ul>
<li>通过继承方式，子类能够非常方便地改写父类方法，同时</li>
<li>保留部分父类方法，可以说是能够最快速地达到代码复用。</li>
<li>继承是在静态编译时候就定义了，所以无法再运行时刻改写父类方法。</li>
<li>因为子类没有改写父类方法的话，就相当于依赖了父类这个方法的实现细节,被认为破坏封装性。</li>
<li>并且如果父类接口定义需要更改时，子类也需要提更改响应接口。</li>
</ul>
<p><strong>组合</strong></p>
<ul>
<li>对象组合通过获得其他对象引用而在运行时刻动态定义的。</li>
<li>组合要求对象遵守彼此约定，进而要求更仔细地定义接口，而这些接口并不妨碍你将一个对象和另外一个对象一起使用。</li>
<li>对象只能够通过接口来访问，所以我们并没有破坏封装性。</li>
<li>而且只要抽象类型一致，对象是可以被替换的。</li>
<li>使用组合方式，我们可以将类层次限制在比较小的范围内，不容易产生类的爆炸。</li>
<li>相对于继承来说,组合可能需要编写“更多的代码。</li>
</ul>
<p><strong>参数化类型</strong></p>
<ul>
<li>参数化类型方式是基于接口的编程，在一定程度上消除了类型给程序设计语言带来的限制。</li>
<li>相对于组合方式来说，缺少的是动态修改能力。</li>
<li>因为参数化类型本身就不是面向对象语言的一个特征，所以在面向对象的设计模式里面，没有一种模式是于参数化类型相关的。</li>
<li>实践上我们方面是可以使用参数化类型来编写某种模式的。</li>
</ul>
<p><strong>总结</strong></p>
<ul>
<li>对象组合技术允许你在运行时刻改变被组合的行为，但是它存在间接性，相对来说比较低效。</li>
<li>继承允许你提供操作的缺省实现，通过子类来重定义这些操作，但是不能够在运行时改变。</li>
<li>参数化允许你改变所使用的类型，同样不能够在运行时改变。</li>
</ul>
<h2 id="u8BBE_u8BA1_u6A21_u5F0F"><a href="#u8BBE_u8BA1_u6A21_u5F0F" class="headerlink" title="设计模式"></a>设计模式</h2><p>所谓的设计模式是指人们在开发软件的过程中，对于一些普适需求而总结的设计模版。根据模式目的可以分为三类：</p>
<ul>
<li>创建型(Creational).创建型模式与对象的创建相关。</li>
<li>结构型(Structural).结构型模式处理类或者是对象的组合。</li>
<li>行为型(Behavioral).行为型模式对类或者是对象怎样交互和怎样分配职责进行描述。</li>
</ul>
<p>下面我们对每种类型进行介绍。具体的模式请见“工具箱”。值得提醒的是，在面试或工作中不可盲目相信设计模式。设计模式更多地只是提供一些思路，能够直接套用设计模式的情况并不多，更多的时候是对现成设计模式的改进和组合。所以对于设计模式的学习更多应该着眼于模式的意图，而不是模式的具体实现方法。</p>
<h3 id="u521B_u5EFA_u578B"><a href="#u521B_u5EFA_u578B" class="headerlink" title="创建型"></a>创建型</h3><p>一个类的创建型模式使用继承改变被实例化的类，而一个对象的创建型模式将实例化委托给另外一个对象。 在这些模式中有两种不断出现的主旋律：</p>
<ul>
<li>将该系统使用哪些具体的类封装起来</li>
<li>隐藏了实例是如何被创建和存储的</li>
</ul>
<p>总而言之，效果就是用户创建对象的结果是得到一个基类指针，用户通过基类指针调用继承类的方法。用户不需要知道在使用哪些继承类。</p>
<h4 id="u5355_u4F8B_u6A21_u5F0F"><a href="#u5355_u4F8B_u6A21_u5F0F" class="headerlink" title="单例模式"></a>单例模式</h4><p>意图：单例模式(Singleton Pattern)是一种常见的设计模式。其目的在于保证一个类仅仅有一个实例并且提供一个访问它的全局访问点。</p>
<p>这个模式主要的对比对象就是全局变量。相对于全局变量，单例有下面这些好处：</p>
<ul>
<li>全局变量不能够保证只有一个实例。</li>
<li>某些情况下面，我们需要稍微计算才能够初始化这个单例。全局变量也行但是不自然。</li>
<li>C++下面没有保证全局变量的初始化顺序.</li>
</ul>
<p>比如，在我们之前说的音乐播放器设计中，我们引入了歌曲管理器实现数据的存储。歌曲管理器在整个程序中应当实例化一次，其他所有关于数据的操作都应该在这个实例上进行。所以，歌曲管理器应该应用单例模式。实现单例模式的关键在于利用静态变量(static variable)，通过判断静态变量是否已经初始化判断该类是否已经实例化。此外，还需要把构造函数设为私有函数，通过公共接口getSharedInstance进行调用。我们举例如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Example for singleton pattern</span></span><br><span class="line"><span class="comment">// class definition</span></span><br><span class="line"><span class="keyword">class</span> MySingleton &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"><span class="comment">// Private Constructor</span></span><br><span class="line">    MySingleton();</span><br><span class="line"><span class="comment">// Stop the compiler generating methods of copy the object</span></span><br><span class="line">    MySingleton(<span class="keyword">const</span> MySingleton &amp;copy);    <span class="comment">// Not Implemented</span></span><br><span class="line">    MySingleton &amp;<span class="keyword">operator</span>=(<span class="keyword">const</span> MySingleton &amp;copy);    <span class="comment">// Not Implemented</span></span><br><span class="line">    <span class="keyword">static</span> MySingleton *m_pInstance;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">static</span> MySingleton *<span class="title">getSharedInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!m_pInstance) &#123;</span><br><span class="line">            m_pInstance = <span class="keyword">new</span> MySingleton;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> m_pInstance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// in the source file</span></span><br><span class="line">MySingleton *MySingleton::m_pInstance = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure>
<p>注意，本例中的实现方式针对非多线程的情况。如果有过个线程想要同时调用getSharedInstance函数，则需要用mutex保护下列代码：</p>
<pre><code>pthread_mutex_lock(&amp;mutex);
if (!m_pInstance) {
    m_pInstance = new MySingleton;
}
pthread_mutex_unlock(&amp;mutex);
</code></pre><h4 id="u5DE5_u5382_u6A21_u5F0F"><a href="#u5DE5_u5382_u6A21_u5F0F" class="headerlink" title="工厂模式"></a>工厂模式</h4><p>意图：抽象类需要创建一个对象时，让子类决定实例化哪一个类</p>
<p>所谓的工厂模式(Factory Pattern)，就是指定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类。通常，接口提供传入参数，用以决定实例化什么类。工厂模式常见于工具包和框架中，当需要生成一系列类似的子类时，可以考虑使用工厂模式。举例如下：</p>
<figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">// <span class="class"><span class="keyword">class</span> <span class="title">for</span> <span class="title">factory</span> <span class="title">pattern</span></span></span><br><span class="line">enum ImageType&#123;</span><br><span class="line">    GIF,</span><br><span class="line">    JPEG</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImageReader</span> &#123;</span></span><br><span class="line">    // implementation <span class="keyword">for</span> image reader base <span class="class"><span class="keyword">class</span></span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GIFReader</span> : <span class="title">public</span> <span class="title">ImageReader</span> &#123;</span></span><br><span class="line">    // implementation <span class="keyword">for</span> GIF reader derived <span class="class"><span class="keyword">class</span></span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JPEGReader</span> : <span class="title">public</span> <span class="title">ImageReader</span> &#123;</span></span><br><span class="line">    // implementation <span class="keyword">for</span> JPEG reader derived <span class="class"><span class="keyword">class</span></span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImageReaderFactory</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    static ImageReader *imageReaderFactoryMethod(ImageType imageType) &#123;</span><br><span class="line">        ImageReader *product = <span class="literal">NULL</span>;</span><br><span class="line">        switch (imageType) &#123;</span><br><span class="line">            <span class="keyword">case</span> GIF:</span><br><span class="line">                product = <span class="keyword">new</span> GIFReader();</span><br><span class="line">            <span class="keyword">case</span> JPEG:</span><br><span class="line">                product = <span class="keyword">new</span> JPEGReader();</span><br><span class="line">                //...</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> product;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="u7ED3_u6784_u578B"><a href="#u7ED3_u6784_u578B" class="headerlink" title="结构型"></a>结构型</h3><p>类的结构型模式采用继承机制来组合接口。对象的结构型模式不是对接口进行组合， 而是描述如何对一些对象进行组合，从而实现新功能。</p>
<h4 id="u9002_u914D_u5668"><a href="#u9002_u914D_u5668" class="headerlink" title="适配器"></a>适配器</h4><p>意图：适配器(Adapter)将一个类的接口转化成为客户希望的另外一个接口。</p>
<p>假设A实现了Foo()接口，但是B希望A同样实现一个Bar()接口，事实上Foo()基本实现了Bar()接口功能。 Adapter模式就是设计一个新类C，C提供Bar()接口，但实现的方式是内部调用 A的Foo()。</p>
<p>在实现层面上可以通过继承和组合两种方式达到目的：C可以继承A，或者C把A作为自己的成员变量。两者孰优孰劣需要视情况而定。</p>
<h3 id="u884C_u4E3A_u578B"><a href="#u884C_u4E3A_u578B" class="headerlink" title="行为型"></a>行为型</h3><p>行为型涉及到算法和对象之间职责的分配。行为模式不仅描述对象或者类的功能行为，还描述它们之间的通信模式。 这些模式刻画了在运行时难以追踪的控制流，它们将你的注意从控制流转移到对象之间的联系上来。</p>
<h4 id="u89C2_u5BDF_u8005"><a href="#u89C2_u5BDF_u8005" class="headerlink" title="观察者"></a>观察者</h4><p>意图：观察者模式(observer)定义对象之间的依赖关系，当一个对象“状态发生改变的话，所有依赖这个对象的对象都会被通知并且进行更新。</p>
<p>被观察的对象需要能够动态地增删观察者对象，这就要求观察者提供一个公共接口比如Update()。然后每个观察者实例注册到被观察对象里面去，在被观察对象状态更新时候能够遍历所有注册观察者并且调用Update()。</p>
<p>至于观察者和被观察之间是采用push还是pull模式完全取决于应用。对于观察这件事情来说的话， 我们还可以引入方面(Aspect)这样一个概念，在注册观察者的时候不仅仅只是一个观察者对象， 还包括一个Aspect参数，可以以此告诉被观察者仅在发生某些变化时通过调用Update()通知我。</p>
<h4 id="u72B6_u6001"><a href="#u72B6_u6001" class="headerlink" title="状态"></a>状态</h4><p>意图：状态模式(state)允许一个对象在其内部状态改变时改变它的行为。</p>
<p>这里状态模式意图是，对于实例A，当A的状态改变时，将A可能改变的行为封装成为一个类S(有多少种可能的状态就有多少个S的子类,比如S1,S2,S3等)。当A的状态转换时，在A内部切换S的实例。从A的用户角度来看，A的接口不变，但A的行为因A的状态改变而改变，这是因为行为的具体实现由S完成。</p>
<h2 id="u5DE5_u5177_u7BB1"><a href="#u5DE5_u5177_u7BB1" class="headerlink" title="工具箱"></a>工具箱</h2><h3 id="u6709_u9650_u72B6_u6001_u673A"><a href="#u6709_u9650_u72B6_u6001_u673A" class="headerlink" title="有限状态机"></a>有限状态机</h3><p>参见<a href="http://en.wikipedia.org/wiki/Finite-state_machine" target="_blank" rel="external">这里</a></p>
<h3 id="u591A_u6001"><a href="#u591A_u6001" class="headerlink" title="多态"></a>多态</h3><p>在C++中，最常见的多态指的是用基类指针指向一个派生类的实例，当用该指针调用一个基类中的虚函数时，实际调用的是派生类的函数实现，而不是基类函数。如果该指针指向另一个派生类实例，则调用另一个派生类的函数实现。因此，比如工厂模式返回一个实例，上层函数不需要知道实例来自哪个派生类，只需要用一个基类指针指向它，就可以直接获得需要的行为。从编译的角度来看，函数的调用地址并不是在编译阶段静态决定，而是在运行阶段，动态地决定函数的调用地址。</p>
<p>多态是通过虚函数表实现的。当基类中用virtual关键字定义函数时，系统自动分配一个指针，指向该类的虚函数表。虚函数表中存储的是函数指针。在生成派生类的时候，会将派生类中对应的函数的地址写到虚函数表。之后，当利用基类指针调用函数时，先通过虚函数表指针找到对应的虚函数表，再通过表内存储的函数指针调用对应函数。由于函数指针指向派生类的实现，因此函数行为自然也就是派生类中定义的行为了。</p>
<h3 id="u521B_u5EFA_u578B_u8BBE_u8BA1_u6A21_u5F0F_u8865_u5145"><a href="#u521B_u5EFA_u578B_u8BBE_u8BA1_u6A21_u5F0F_u8865_u5145" class="headerlink" title="创建型设计模式补充"></a>创建型设计模式补充</h3><h4 id="Builder"><a href="#Builder" class="headerlink" title="Builder"></a>Builder</h4><p><strong>意图：将一个复杂对象构建过程和元素表示分离。</strong></p>
<p>假设我们需要创建一个复杂对象，而这个复杂对象是由很多元素构成的。这些元素的组合逻辑可能非常复杂， 但是逻辑组合和创建这些元素是无关的，独立于这些元素本身的。</p>
<p>那么我们可以将元素的组合逻辑以及元素构建分离，元素构建我们单独放在Builder这样一个类里面，而元素的组合逻辑通过Director来指导，Director内部包含Builder对象。创建对象是通过Director来负责组合逻辑部分的， Director内部调用Builder来创建元素并且组装起来。最终通过Builder的GetResult来获得最终复杂对象。</p>
<h3 id="u7ED3_u6784_u578B_u8BBE_u8BA1_u6A21_u5F0F_u8865_u5145"><a href="#u7ED3_u6784_u578B_u8BBE_u8BA1_u6A21_u5F0F_u8865_u5145" class="headerlink" title="结构型设计模式补充"></a>结构型设计模式补充</h3><h4 id="Bridge"><a href="#Bridge" class="headerlink" title="Bridge"></a>Bridge</h4><p><strong>意图：将抽象部分和具体实现相分离，使得它们之间可以独立变化。</strong></p>
<p>一个很简单的例子就是类Shape,有个方法Draw[抽象]和DrawLine[具体]和DrawText[具体],而Square和SquareText 继承于Shape实现Draw()这个方法，Square调用DrawLine()，而SquareText调用DrawLine()+DrawText()。而且假设DrawLine和DrawText分别有LinuxDrawLine,LinuxDrawText和Win32DrawLine和Win32DrawText。如“果我们简单地 使用子类来实现的话，比如构造LinuxSquare,LinuxSquareText,Win32Square和Win32SquareText，那么很快就会类爆炸。</p>
<p>事实上我们没有必要在Shape这个类层面跟进变化，即通过继承Shape类实现跨平台，而只需要在实现底层跟进变化。为此我们就定义一套接口，如例子中的DrawLine和DrawText，然后在Linux和Win32下实现一个这样接口实例(比如称为跨平台GDI)，最终 Shape内部持有这个GDI对象，Shape的DrawLine和DrawText只是调用GDI的接口而已。这样，我们把Shape及其子类的DrawLine和DrawText功能Bridge到GDI，GDI可以通过工厂模式在不同平台下实现不同的实例。</p>
<p>例子中Shape成为了完全抽象的部分，具体实现完全交给GDI类，若以后需要增加更多的平台支持，开发者也不需要添加更多的Shape子类，只需要扩展GDI即可。总之，抽象部分是和具体实现部分需要独立开来的时候，就可以使用Bridge模式。</p>
<h4 id="Composite"><a href="#Composite" class="headerlink" title="Composite"></a>Composite</h4><p><strong>意图：将对象组合成为树形以表示层级结构，对于叶子和非叶子节点对象使用需要有一致性。</strong></p>
<p>Composite模式强调在这种层级结构下，叶子和非叶子节点需要一致对待，所以关键是需要定义一个抽象类，作为叶节点的子节点。 然后对于叶子节点操作没有特殊之处，而对于非叶子节点操作不仅仅需要操作自身，还要操作所管理的子节点。 至于遍历子节点和处理顺序是由应用决定的，在Composite模式里面并不做具体规定。</p>
<h4 id="Decorator"><a href="#Decorator" class="headerlink" title="Decorator"></a>Decorator</h4><p><strong>意图：动态地给对象添加一些额外职责，通过组合而非继承方式完成。</strong></p>
<p>给对象添加一些额外职责，例如增加新的方法，很容易会考虑使用子类方式来实现。使用子类方式实现很快但是却不通用，考虑一个抽象类X，子类有SubX1,SubX2等。现在需要为X提供一个附加方法echo，如果用继承的方式添加，那么需要为每个子类都实现echo方法，并且代码往往是重复的。我们可以考虑Decorator模式，定义一个新类，使其持有持有指向X基类的指针，并且新类只需要单独实现echo方法，而其他方法直接利用X基类指针通过多态调用即可。</p>
<p>值得注意的是，装饰出来的对象必须包含被装饰对象的所有接口。所以很明显这里存在一个问题， 那就是X一定不能够有过多的方法，不然Echo类里面需要把X方法全部转发一次(理论上说Echo类可以仅转发X的部分方法，但Decorator默认需要转发被装饰类的全部方法)。</p>
<h4 id="Fa_E7ade"><a href="#Fa_E7ade" class="headerlink" title="Façade"></a>Façade</h4><p><strong>意图：为子系统的一组接口提供一个一致的界面。</strong></p>
<p>编译器是一个非常好的的例子。对于编译器来说，有非常多的子系统包括词法语法解析，语义检查,中间代码生成，代码优化，以及代码生成这些逻辑部件。但是对于大多数用户来说，不关心这些子系统，而只是关心编译这一个过程。</p>
<p>所以我们可以提供Compiler的类，里面只有很简单的方法比如Compile()，让用户直接使用Compile()这个接口。 一方面用户使用起来简单，另外一方面子系统和用户界面耦合性也降低了。</p>
<p>Facade模式对于大部分用户都是满足需求的。对于少部分不能够满足需求的用户，可以让他们绕过Facade模式提供的界面， 直接控制子系统即可。就好比GCC提供了很多特殊优化选项来让高级用户来指定，而不是仅仅指定-O2这样的选项。</p>
<h4 id="Proxy"><a href="#Proxy" class="headerlink" title="Proxy"></a>Proxy</h4><p><strong>意图：为其他对象提供一种代理以控制对这个对象的访问。</strong></p>
<p>通常使用Proxy模式是想针对原本要访问的对象做一些手脚，以达到一定的目的，包括访问权限设置，访问速度优化，或者是加入一些自己特有的逻辑。至于实现方式上，不管是继承还是组合都行，可能代价稍微有些不同，视情况而定。但是偏向组合方式，因为对于Proxy而言，完全可以定义一套新的访问接口。</p>
<p>Adapter,Decorator以及Proxy之间比较相近，虽然说意图上差别很大，但是对于实践中， 三者都是通过引用对象来增加一个新类来完成的，但是这个新类在生成接口方面有点差别：</p>
<ul>
<li>Adapter模式的接口一定要和对接的接口相同。</li>
<li>Decorator模式的接口一定要包含原有接口，通常来说还要添加新接口。</li>
<li>Proxy模式完全可以重新定义一套新的接口</li>
</ul>
<h3 id="u884C_u4E3A_u578B_u8BBE_u8BA1_u6A21_u5F0F_u8865_u5145"><a href="#u884C_u4E3A_u578B_u8BBE_u8BA1_u6A21_u5F0F_u8865_u5145" class="headerlink" title="行为型设计模式补充"></a>行为型设计模式补充</h3><h4 id="Chain_of_Responsibility"><a href="#Chain_of_Responsibility" class="headerlink" title="Chain of Responsibility"></a>Chain of Responsibility</h4><p><strong>意图：将对象连成一条链并沿着链传递某个请求，直到有某个对象处理它为止。</strong></p>
<p>大部分情况下连接起来的对象本身就存在一定的层次结构关系，少数情况下面这些连接起来的对象是内部构造的。 职责链通常与Composite模式一起使用，一个构件的父构件可以作为它的后继结点。许多类库使用职责链模式来处理事件， 比如在UI部分的话View本来就是相互嵌套的，一个View对象可能存在Parent View对象。如果某个UI不能够处理事件的话， 那么完全可以交给Parent View来完成事件处理以此类推。 </p>
<h4 id="Command"><a href="#Command" class="headerlink" title="Command"></a>Command</h4><p><strong>意图：将一个请求封装成为一个对象。</strong></p>
<p>Command模式可以说是回调机制(Callback)的一个面向对象的替代品。对于回调函数来说需要传递一个上下文参数(context)， 同时内部附带一些逻辑。将上下文参数以及逻辑包装起来的话那么就是一个Command对象。 Command对象接口可以非常简单只有Execute/UnExecute，但是使用Command对象来管理请求之后， 就可以非常方便地实现命令的复用，排队，重做，撤销，事务等。</p>
<h4 id="Iterator"><a href="#Iterator" class="headerlink" title="Iterator"></a>Iterator</h4><p><strong>意图：提供一种方法顺序访问一个聚合对象中各个元素，但是又不需要暴露该对象内部表示。</strong></p>
<p>将遍历机制与聚合对象表示分离，使得我们可以定义不同的迭代器来实现不同的迭代策略，而无需在聚合对象接口上面列举他们。 一个健壮的迭代器,应该保证在聚合对象上面插入和删除操作不会干扰遍历，“同时不需要copy这个聚合对象。 一种实现方式就是在聚合对象上面注册某个迭代器，一旦聚合对象发生改变的话，需要调整迭代器内部的状态。</p>
<h4 id="Template_Method"><a href="#Template_Method" class="headerlink" title="Template Method"></a>Template Method</h4><p><strong>意图：定义一个操作里面算法的骨架，而将一些步骤延迟到子类。</strong></p>
<p>假设父类A里面有抽象方法Step1(),Step2(),默认方法Step3()。并且A提供一个操作X()，分别依次使用Step1(),Step2(),Step3()。对于A的子类，通过实现自己的Step1(),Step2() (选择性地实现Step3())，提供属于子类的X具体操作。 这里操作X()就是算法的骨架，子类需要复写其中部分step，但不改变X的执行流程。</p>
<p>很重要的一点是模板方法必须指明哪些操作是钩子操作(可以被重定义的，比如Step3),以及哪些操作是抽象操作“(必须被重定义，比如Step1和Step2)。要有效地重用一个抽象类，子类编写者必须明确了解哪些操作是设计为有待重定义的。</p>
<h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="http://wdxtub.com/interview/14520604447774.html">Web Crawler</a></li>
<li><a href="http://wdxtub.com/interview/14520604447653.html">Tiny URL</a></li>
<li><a href="http://wdxtub.com/interview/14520604447530.html">Stock Data</a></li>
<li><a href="http://wdxtub.com/interview/14520604447397.html">Social Network</a></li>
<li><a href="http://wdxtub.com/interview/14520604447289.html">Singleton</a></li>
<li><a href="http://wdxtub.com/interview/14520604447186.html">Sales Rank</a></li>
<li><a href="http://wdxtub.com/interview/14520604447071.html">Rank from Stream</a></li>
<li><a href="http://wdxtub.com/interview/14520604446948.html">Personal Financial Manager</a></li>
<li><a href="http://wdxtub.com/interview/14520604446839.html">Peeking Iterator</a></li>
<li><a href="http://wdxtub.com/interview/14520604446725.html">Pastebin</a></li>
<li><a href="http://wdxtub.com/interview/14520604446608.html">Parking Lot</a></li>
<li><a href="http://wdxtub.com/interview/14520604446509.html">Othello</a></li>
<li><a href="http://wdxtub.com/interview/14520604446403.html">Online Book Reader</a></li>
<li><a href="http://wdxtub.com/interview/14520604446344.html">Music Player</a></li>
<li><a href="http://wdxtub.com/interview/14520604446282.html">Minesweeper</a></li>
<li><a href="http://wdxtub.com/interview/14520604446223.html">LRU Cache</a></li>
<li><a href="http://wdxtub.com/interview/14520604446169.html">Jukebox</a></li>
<li><a href="http://wdxtub.com/interview/14520604446101.html">Jigsaw</a></li>
<li><a href="http://wdxtub.com/interview/14520604446041.html">Hash Table</a></li>
<li><a href="http://wdxtub.com/interview/14520604445970.html">File System</a></li>
<li><a href="http://wdxtub.com/interview/14520604445920.html">Elevator</a></li>
<li><a href="http://wdxtub.com/interview/14520604445872.html">Deck of Cards</a></li>
<li><a href="http://wdxtub.com/interview/14520604445829.html">Chat Server</a></li>
<li><a href="http://wdxtub.com/interview/14520604445788.html">Call Center</a></li>
<li><a href="http://wdxtub.com/interview/14520604445745.html">Animal Shelter</a></li>
<li><a href="http://wdxtub.com/interview/14520604445699.html">Add and Search Word - Data structure design</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>设计题可以分成两个类别：系统架构设计和利用面向对象编程原理进行程序设计。重点是要体现出自己的想法和思路，毕竟设计类问题，没有所谓标准答案。</p>]]>
    
    </summary>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="面向对象" scheme="http://wdxtub.com/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 10 课 位操作]]></title>
    <link href="http://wdxtub.com/2016/01/23/programmer-startline-10/"/>
    <id>http://wdxtub.com/2016/01/23/programmer-startline-10/</id>
    <published>2016-01-23T22:48:01.000Z</published>
    <updated>2016-01-24T00:50:38.000Z</updated>
    <content type="html"><![CDATA[<p>位运算是一个很多歪门邪道技巧的题目类型，就我感觉来说，很多基本靠脑洞，不过更多的还是比较基本的几个操作组合组合就可以完成了。</p>
<a id="more"></a>
<hr>
<p>对于网络、操作系统、嵌入式系统等职位的面试，位运算也是常见的题目类型之一。所谓的位运算，是指按二进制进行的运算。常见运算包括求反，与运算，或运算，异或运算及位移。</p>
<p>在C/C++中，基本的位运算符总结如下，其中运算符优先级为从上到下递减，且&lt;&lt;，&gt;&gt;优先级相同：</p>
<table>
<thead>
<tr>
<th style="text-align:center">操作符</th>
<th style="text-align:center">功能</th>
<th style="text-align:center">用法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">~</td>
<td style="text-align:center">位求反</td>
<td style="text-align:center">~var</td>
</tr>
<tr>
<td style="text-align:center">&lt;&lt;</td>
<td style="text-align:center">左移(乘法)</td>
<td style="text-align:center">var &lt;&lt; position</td>
</tr>
<tr>
<td style="text-align:center">&gt;&gt;</td>
<td style="text-align:center">右移(除法)</td>
<td style="text-align:center">var &gt;&gt; position</td>
</tr>
<tr>
<td style="text-align:center">&amp;</td>
<td style="text-align:center">位与</td>
<td style="text-align:center">var1 &amp; var2</td>
</tr>
<tr>
<td style="text-align:center">^</td>
<td style="text-align:center">位异或</td>
<td style="text-align:center">var1 ^ var2</td>
</tr>
<tr>
<td style="text-align:center">一条竖线</td>
<td style="text-align:center">位或</td>
<td style="text-align:center">var1 竖线 var2</td>
</tr>
</tbody>
</table>
<p>需要注意的是，位运算符只能用在带符号或无符号的char、short、int与long类型上。在实际应用中，建议用unsigned整型操作数，以免带符号操作数因为不同机器导致的结果不同：无符号数左移／右移默认移入的新比特是0。对于符号数，当最高位是1(代表负数)时，有的机器认为右移移入的新比特是1。此外，复杂的位运算建议都用括号强制计算顺序，而不是依赖于优先级，这样做可以增加可读性并避免错误。</p>
<p>用十六进制(hex)定义一个变量如下所示：</p>
<pre><code>unsigned short value = 0xFFFF;
</code></pre><p>等价于二进制(binary)定义：</p>
<pre><code>unsigned short value = 0b1111111111111111;
</code></pre><p>等价于十进制定义：</p>
<pre><code>unsigned short value = 65535;
</code></pre><h2 id="u89E3_u9898_u7B56_u7565"><a href="#u89E3_u9898_u7B56_u7565" class="headerlink" title="解题策略"></a>解题策略</h2><h3 id="u57FA_u672C_u7684_u4F4D_u8FD0_u7B97"><a href="#u57FA_u672C_u7684_u4F4D_u8FD0_u7B97" class="headerlink" title="基本的位运算"></a>基本的位运算</h3><p>最基本的操作包括获取位、设置位和清除位。获取位可以利用&amp;1：&amp;(0x1 &lt;&lt; pos) ；设置位可以利用|1: | (0x1 &lt;&lt; pos) ；清除位可以利用&amp;0: &amp;(~(0x1 &lt;&lt; pos))。判断某位是否相同用^：(A &amp; (0x1 &lt;&lt; pos)) ^ (B &amp; (0x1 &lt;&lt; pos))。</p>
<h3 id="u4F4D_u63A9_u7801"><a href="#u4F4D_u63A9_u7801" class="headerlink" title="位掩码"></a>位掩码</h3><p>选择合适的位掩码(bit mask)，然后与给定的二进制数进行基本位操作。而掩码，通常可以通过对~0，1 进行基本操作和加减法得到。例如，我们要构造一个第i到第j位为0，其他位为1的位掩码，则可以对~0进行左移操作获得形如111…0000的mask，再对~0进行右移操作，获得形如000…111的mask，最后通过位或(此处相当于相加)得到最终的位掩码。</p>
<p>在寻求得到一个特定的掩码时，还是利用最基本的获取位、设置位或清除位得到所需掩码的形态。另外，应当尽可能避免直接出现常数，比如使用32-i这样的情况(这里默认想要操作一个32bit的整型)，而应当定义一个意义明确的宏，以提高可读性：<code>#define INT_BIT_LENTH (32)</code>。</p>
<h3 id="XOR__u5F02_u6216"><a href="#XOR__u5F02_u6216" class="headerlink" title="XOR 异或"></a>XOR 异或</h3><blockquote>
<p>异或：相同为0，不同为1。也可用「不进位加法」来理解。</p>
</blockquote>
<p>异或操作的一些特点：</p>
<pre><code>x ^ 0 = x
x ^ 1s = ~x // 1s = ~0
x ^ (~x) = 1s
x ^ x = 0 // interesting and important!
a ^ b = c =&gt; a ^ c = b, b ^ c = a // swap
a ^ b ^ c = a ^ (b ^ c) = (a ^ b) ^ c // associative
</code></pre><h3 id="u79FB_u4F4D_u64CD_u4F5C"><a href="#u79FB_u4F4D_u64CD_u4F5C" class="headerlink" title="移位操作"></a>移位操作</h3><p>移位操作可近似为乘以/除以2的幂。0b0010 * 0b0110等价于0b0110 &lt;&lt; 2. 下面是一些常见的移位组合操作。</p>
<ol>
<li>将x最右边的n位清零 <code>x &amp; (~0 &lt;&lt; n)</code></li>
<li>获取x的第n位值(0或者1) <code>x &amp; (1 &lt;&lt; n)</code></li>
<li>获取x的第n位的幂值 <code>(x &gt;&gt; n) &amp; 1</code></li>
<li>仅将第n位置为1 <code>x | (1 &lt;&lt; n)</code></li>
<li>仅将第n位置为0 <code>x &amp; (~(1 &lt;&lt; n))</code></li>
<li>将x最高位至第n位(含)清零 <code>x &amp; ((1 &lt;&lt; n) - 1)</code></li>
<li>将第n位至第0位(含)清零 <code>x &amp; (~((1 &lt;&lt; (n + 1)) - 1))</code></li>
<li>仅更新第n位，写入值为v; v为1则更新为1，否则为0 <code>mask = ~(1 &lt;&lt; n); x = (x &amp; mask) | (v &lt;&lt; i)</code></li>
</ol>
<hr>
<ul>
<li>Two’s Complement - 负数可以看作是最高位的 1 为负，其他位为正，相加得到最后的值<ul>
<li>例如 -1 = (1111) 最高位的 1 表示 -8， 剩下三位等于 7，相加后等于 -1</li>
</ul>
</li>
<li>logical right shift - put a <code>0</code> in the most significant bit - <code>&gt;&gt;&gt;</code></li>
<li>arithmetic right shift - put a <code>1</code> in the most significant bit - <code>&gt;&gt;</code></li>
</ul>
<h3 id="Get_Bit"><a href="#Get_Bit" class="headerlink" title="Get Bit"></a>Get Bit</h3><p>Shifts 1 over by <code>i</code> bits, creating a value that looks like <code>00010000</code>. AND operation</p>
<pre><code>boolean getBit(int num, int i){
    return ((num &amp; (1 &lt;&lt; i)) != 0);
}
</code></pre><h3 id="Set_Bit"><a href="#Set_Bit" class="headerlink" title="Set Bit"></a>Set Bit</h3><p>Shifts 1 over by <code>i</code> bits, creating a value like <code>00010000</code>. OR operation</p>
<pre><code>int setBit(int num, int i){
    return num | (1 &lt;&lt; i);
}
</code></pre><h3 id="Clear_Bit"><a href="#Clear_Bit" class="headerlink" title="Clear Bit"></a>Clear Bit</h3><p>Create a number like <code>11101111</code> by creating the reverse of it (<code>00010000</code>). AND operation.</p>
<pre><code>int clearBit(int num, int i){
    int mask = ~(1 &lt;&lt; i);
    return num &amp; mask;
}
</code></pre><p>To clear all bits from the most significant bit through <code>i</code> (inclusive), we create a mask with a <code>1</code> at the ith bit(1 &lt;&lt; i). Then we subtract 1 from it, giving us a sequence of 0s followed by i 1s. AND operation.</p>
<pre><code>int clearBitsMSBthroughI(int num, int i){
    int mask = (1 &lt;&lt; i) - 1;
    return num &amp; mask;
}
</code></pre><p>To clear bits from i through 0 (inclusive), we take a sequence of 1s (which is -1) and shift it over by 31 - i bits.</p>
<pre><code>int clearBitsIthrough0(int num, int i){
    int mask = ~(-1 &gt;&gt;&gt; (31 - i));
    return num &amp; mask;
}
</code></pre><h3 id="Update_Bit"><a href="#Update_Bit" class="headerlink" title="Update Bit"></a>Update Bit</h3><p>Set the ith bit to a value <code>v</code></p>
<pre><code>int updateBit(int num, int i, boolean bitIs1){
    int value = bitIs1 ? 1 : 0;
    int mask = ~(1 &lt;&lt; i);
    return (num &amp; mask) | (value &lt;&lt; i);
}
</code></pre><h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="http://wdxtub.com/interview/14520596469127.html">Swap Bits</a></li>
<li><a href="http://wdxtub.com/interview/14520596469033.html">Square of Two</a></li>
<li><a href="http://wdxtub.com/interview/14520596468981.html">Single Element</a></li>
<li><a href="http://wdxtub.com/interview/14520596468879.html">Single Element II</a></li>
<li><a href="http://wdxtub.com/interview/14520596468931.html">Single Element III</a></li>
<li><a href="http://wdxtub.com/interview/14520596468825.html">Set Bits</a></li>
<li><a href="http://wdxtub.com/interview/14520596468781.html">Reverse Bits</a></li>
<li><a href="http://wdxtub.com/interview/14520596468734.html">Number of One</a></li>
<li><a href="http://wdxtub.com/interview/14520596468686.html">Next Number</a></li>
<li><a href="http://wdxtub.com/interview/14520596468613.html">Flip Bits</a></li>
<li><a href="http://wdxtub.com/interview/14520596468570.html">Draw Line</a></li>
<li><a href="http://wdxtub.com/interview/14520596468530.html">Divide Two Integers</a></li>
<li><a href="http://wdxtub.com/interview/14520596468493.html">Check Power of Two</a></li>
<li><a href="http://wdxtub.com/interview/14520596468456.html">Bitwise AND of Numbers Range</a></li>
<li><a href="http://wdxtub.com/interview/14520596468418.html">A Plus B</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>位运算是一个很多歪门邪道技巧的题目类型，就我感觉来说，很多基本靠脑洞，不过更多的还是比较基本的几个操作组合组合就可以完成了。</p>]]>
    
    </summary>
    
      <category term="位操作" scheme="http://wdxtub.com/tags/%E4%BD%8D%E6%93%8D%E4%BD%9C/"/>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 9 课 数学]]></title>
    <link href="http://wdxtub.com/2016/01/23/programmer-startline-9/"/>
    <id>http://wdxtub.com/2016/01/23/programmer-startline-9/</id>
    <published>2016-01-23T21:30:05.000Z</published>
    <updated>2016-01-24T01:00:10.000Z</updated>
    <content type="html"><![CDATA[<p>虽然说编程中用到的数学都不算特别复杂，但是在具体的实现中，还是有一些技巧和门道的。</p>
<a id="more"></a>
<hr>
<h2 id="u89E3_u9898_u7B56_u7565"><a href="#u89E3_u9898_u7B56_u7565" class="headerlink" title="解题策略"></a>解题策略</h2><p>数学的问题，比较突出的体现在，一些常见的数学形式，比方说：</p>
<ul>
<li>排列</li>
<li>组合</li>
<li>质数</li>
<li>开方</li>
<li>幂次</li>
</ul>
<p>还有一些概率的问题，需要一定的概率基础，这里就不再赘述了。具体更多可以参考题目。</p>
<p>最后一类是脑筋急转弯问题，也就是看脑洞的，这个就随缘了。</p>
<p>（这一章实在没啥好写的，数学这个东西，懂就是懂，不懂就是不懂，还真没太多技巧）</p>
<h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="http://wdxtub.com/interview/14520604913655.html">Kth Permuation</a></li>
<li><a href="http://wdxtub.com/interview/14520595470004.html">Check Permutation</a></li>
<li><a href="http://wdxtub.com/interview/14520604917011.html">Nth Prime</a></li>
<li><a href="http://wdxtub.com/interview/14520604918229.html">Pow(x, n)</a></li>
<li><a href="http://wdxtub.com/interview/14520604911732.html">Combinations</a></li>
<li><a href="http://wdxtub.com/interview/14520604910652.html">All Permutation</a></li>
<li><a href="http://wdxtub.com/interview/14520604910607.html">All Permutations II</a></li>
<li><a href="http://wdxtub.com/interview/14520606004545.html">Sqrt(x)</a></li>
<li><a href="http://wdxtub.com/interview/14520603231966.html">Remove Digit</a></li>
<li><a href="http://wdxtub.com/interview/14520603231831.html">Quick Pow</a></li>
<li><a href="http://wdxtub.com/interview/14520603231697.html">Previous Permuation</a></li>
<li><a href="http://wdxtub.com/interview/14520603231576.html">Poison</a></li>
<li><a href="http://wdxtub.com/interview/14520603231466.html">Permutation Sequence</a></li>
<li><a href="http://wdxtub.com/interview/14520603231334.html">Perfect Squares</a></li>
<li><a href="http://wdxtub.com/interview/14520603231230.html">Number of Digit</a></li>
<li><a href="http://wdxtub.com/interview/14520603231129.html">Number of Digit One</a></li>
<li><a href="http://wdxtub.com/interview/14520603231017.html">Next Permutation</a></li>
<li><a href="http://wdxtub.com/interview/14520603230913.html">Max Points on a Line</a></li>
<li><a href="http://wdxtub.com/interview/14520603230810.html">Jugs of Water</a></li>
<li><a href="http://wdxtub.com/interview/14520603230712.html">Index of Permuation</a></li>
<li><a href="http://wdxtub.com/interview/14520603230618.html">Index of Permutation II</a></li>
<li><a href="http://wdxtub.com/interview/14520603230526.html">The Heavy Pill</a></li>
<li><a href="http://wdxtub.com/interview/14520603230426.html">Hash Function</a></li>
<li><a href="http://wdxtub.com/interview/14520603230367.html">Happy Number</a></li>
<li><a href="http://wdxtub.com/interview/14520603230311.html">Fraction to Recurring Decimal</a></li>
<li><a href="http://wdxtub.com/interview/14520603230254.html">Factorial Trailing Zeroes</a></li>
<li><a href="http://wdxtub.com/interview/14520603230202.html">The Egg Drop Problem</a></li>
<li><a href="http://wdxtub.com/interview/14520603230148.html">Divide Number</a></li>
<li><a href="http://wdxtub.com/interview/14520603230094.html">均分 01</a></li>
<li><a href="http://wdxtub.com/interview/14520603230019.html">Count Primes</a></li>
<li><a href="http://wdxtub.com/interview/14520603229974.html">Cosine Similarity</a></li>
<li><a href="http://wdxtub.com/interview/14520603229929.html">Basketball</a></li>
<li><a href="http://wdxtub.com/interview/14520603229887.html">The Apocalypse</a></li>
<li><a href="http://wdxtub.com/interview/14520603229844.html">Ants on a Triangle</a></li>
<li><a href="http://wdxtub.com/interview/14520603229804.html">Add Digits</a></li>
<li><a href="http://wdxtub.com/interview/14520603229761.html">100 Lockers</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>虽然说编程中用到的数学都不算特别复杂，但是在具体的实现中，还是有一些技巧和门道的。</p>]]>
    
    </summary>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="数学" scheme="http://wdxtub.com/tags/%E6%95%B0%E5%AD%A6/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 8 课 排序和搜索]]></title>
    <link href="http://wdxtub.com/2016/01/23/programmer-startline-8/"/>
    <id>http://wdxtub.com/2016/01/23/programmer-startline-8/</id>
    <published>2016-01-23T14:20:57.000Z</published>
    <updated>2016-01-24T00:00:13.000Z</updated>
    <content type="html"><![CDATA[<p>排序和搜索其实比较相似，最重要的就是理解好二分的思想。无论是稍微复杂一点的排序算法，还是搜索，实际上都是分而治之思想的体现。</p>
<a id="more"></a>
<hr>
<h2 id="Bubble_Sort__u5192_u6CE1_u6392_u5E8F"><a href="#Bubble_Sort__u5192_u6CE1_u6392_u5E8F" class="headerlink" title="Bubble Sort 冒泡排序"></a>Bubble Sort 冒泡排序</h2><p>冒泡排序的原理非常简单，它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。</p>
<p>步骤：</p>
<ol>
<li>比较相邻的元素。如果第一个比第二个大，就交换他们两个。</li>
<li>对第0个到第n-1个数据做同样的工作。这时，最大的数就“浮”到了数组最后的位置上。</li>
<li>针对所有的元素重复以上的步骤，除了最后一个。</li>
<li>持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span><span class="params">(arry)</span>:</span></span><br><span class="line">    n = len(arry)                   <span class="comment">#获得数组的长度</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,n-i):</span><br><span class="line">            <span class="keyword">if</span>  arry[j-<span class="number">1</span>] &gt; arry[j] :       <span class="comment">#如果前者比后者大</span></span><br><span class="line">                arry[j-<span class="number">1</span>],arry[j] = arry[j],arry[j-<span class="number">1</span>]      <span class="comment">#则交换两者</span></span><br><span class="line">    <span class="keyword">return</span> arry</span><br></pre></td></tr></table></figure>
<p>针对上述代码还有两种优化方案。</p>
<p>优化1：某一趟遍历如果没有数据交换，则说明已经排好序了，因此不用再进行迭代了。用一个标记记录这个状态即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#优化1：某一趟遍历如果没有数据交换，则说明已经排好序了，因此不用再进行迭代了。</span></span><br><span class="line"><span class="comment">#用一个标记记录这个状态即可。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort2</span><span class="params">(ary)</span>:</span></span><br><span class="line">    n = len(ary)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        flag = <span class="number">1</span>                    <span class="comment">#标记</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,n-i):</span><br><span class="line">            <span class="keyword">if</span>  ary[j-<span class="number">1</span>] &gt; ary[j] :</span><br><span class="line">                ary[j-<span class="number">1</span>],ary[j] = ary[j],ary[j-<span class="number">1</span>]</span><br><span class="line">                flag = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> flag :                   <span class="comment">#全排好序了，直接跳出</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> ary</span><br></pre></td></tr></table></figure>
<p>优化2：记录某次遍历时最后发生数据交换的位置，这个位置之后的数据显然已经有序，不用再排序了。因此通过记录最后发生数据交换的位置就可以确定下次循环的范围了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#优化2：记录某次遍历时最后发生数据交换的位置，这个位置之后的数据显然已经有序了。</span></span><br><span class="line"><span class="comment"># 因此通过记录最后发生数据交换的位置就可以确定下次循环的范围了。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort3</span><span class="params">(ary)</span>:</span></span><br><span class="line">    n = len(ary)</span><br><span class="line">    k = n                           <span class="comment">#k为循环的范围，初始值n</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        flag = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,k):        <span class="comment">#只遍历到最后交换的位置即可</span></span><br><span class="line">            <span class="keyword">if</span>  ary[j-<span class="number">1</span>] &gt; ary[j] :</span><br><span class="line">                ary[j-<span class="number">1</span>],ary[j] = ary[j],ary[j-<span class="number">1</span>]</span><br><span class="line">                k = j               <span class="comment">#记录最后交换的位置</span></span><br><span class="line">                flag = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> flag :</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> ary</span><br></pre></td></tr></table></figure>
<h2 id="Selection_Sort__u9009_u62E9_u6392_u5E8F"><a href="#Selection_Sort__u9009_u62E9_u6392_u5E8F" class="headerlink" title="Selection Sort 选择排序"></a>Selection Sort 选择排序</h2><p>选择排序无疑是最简单直观的排序。它的工作原理如下。</p>
<p>步骤：</p>
<ol>
<li>在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。</li>
<li>再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。</li>
<li>以此类推，直到所有元素均排序完毕。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_sort</span><span class="params">(ary)</span>:</span></span><br><span class="line">    n = len(ary)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,n):</span><br><span class="line">        min = i                             <span class="comment">#最小元素下标标记</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>,n):</span><br><span class="line">            <span class="keyword">if</span> ary[j] &lt; ary[min] :</span><br><span class="line">                min = j                     <span class="comment">#找到最小值的下标</span></span><br><span class="line">        ary[min],ary[i] = ary[i],ary[min]   <span class="comment">#交换两者</span></span><br><span class="line">    <span class="keyword">return</span> ary</span><br></pre></td></tr></table></figure>
<h2 id="Insertion_Sort__u63D2_u5165_u6392_u5E8F"><a href="#Insertion_Sort__u63D2_u5165_u6392_u5E8F" class="headerlink" title="Insertion Sort 插入排序"></a>Insertion Sort 插入排序</h2><p>插入排序的工作原理是，对于每个未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p>
<p>步骤：</p>
<ol>
<li>从第一个元素开始，该元素可以认为已经被排序</li>
<li>取出下一个元素，在已经排序的元素序列中从后向前扫描</li>
<li>如果被扫描的元素（已排序）大于新元素，将该元素后移一位</li>
<li>重复步骤3，直到找到已排序的元素小于或者等于新元素的位置</li>
<li>将新元素插入到该位置后</li>
<li>重复步骤2~5</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_sort</span><span class="params">(ary)</span>:</span></span><br><span class="line">    n = len(ary)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n):</span><br><span class="line">        <span class="keyword">if</span> ary[i] &lt; ary[i-<span class="number">1</span>]:</span><br><span class="line">            temp = ary[i]</span><br><span class="line">            index = i           <span class="comment">#待插入的下标</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i-<span class="number">1</span>,-<span class="number">1</span>,-<span class="number">1</span>):  <span class="comment">#从i-1 循环到 0 (包括0)</span></span><br><span class="line">                <span class="keyword">if</span> ary[j] &gt; temp :</span><br><span class="line">                    ary[j+<span class="number">1</span>] = ary[j]</span><br><span class="line">                    index = j   <span class="comment">#记录待插入下标</span></span><br><span class="line">                <span class="keyword">else</span> :</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            ary[index] = temp</span><br><span class="line">    <span class="keyword">return</span> ary</span><br></pre></td></tr></table></figure>
<h2 id="Shell_Sort__u5E0C_u5C14_u6392_u5E8F"><a href="#Shell_Sort__u5E0C_u5C14_u6392_u5E8F" class="headerlink" title="Shell Sort 希尔排序"></a>Shell Sort 希尔排序</h2><p>希尔排序，也称递减增量排序算法，实质是分组插入排序。由 Donald Shell 于1959年提出。希尔排序是非稳定排序算法。</p>
<p>希尔排序的基本思想是：将数组列在一个表中并对列分别进行插入排序，重复这过程，不过每次用更长的列（步长更长了，列数更少了）来进行。最后整个表就只有一列了。将数组转换至表是为了更好地理解这算法，算法本身还是使用数组进行排序。</p>
<p>例如，假设有这样一组数<code>[ 13 14 94 33 82 25 59 94 65 23 45 27 73 25 39 10 ]</code>，如果我们以步长为5开始进行排序，我们可以通过将这列表放在有5列的表中来更好地描述算法，这样他们就应该看起来是这样：</p>
<pre><code>13 14 94 33 82
25 59 94 65 23
45 27 73 25 39
10
</code></pre><p>然后我们对每列进行排序：</p>
<pre><code>10 14 73 25 23
13 27 94 33 39
25 59 94 65 82
45
</code></pre><p>将上述四行数字，依序接在一起时我们得到：<code>[ 10 14 73 25 23 13 27 94 33 39 25 59 94 65 82 45 ]</code>。这时10已经移至正确位置了，然后再以3为步长进行排序：</p>
<pre><code>10 14 73
25 23 13
27 94 33
39 25 59
94 65 82
45
</code></pre><p>排序之后变为：</p>
<pre><code>10 14 13
25 23 33
27 25 59
39 65 73
45 94 82
94
</code></pre><p>最后以1步长进行排序（此时就是简单的插入排序了）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">shell_sort</span><span class="params">(ary)</span>:</span></span><br><span class="line">    n = len(ary)</span><br><span class="line">    gap = round(n/<span class="number">2</span>)       <span class="comment">#初始步长 , 用round四舍五入取整</span></span><br><span class="line">    <span class="keyword">while</span> gap &gt; <span class="number">0</span> :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(gap,n):        <span class="comment">#每一列进行插入排序 , 从gap 到 n-1</span></span><br><span class="line">            temp = ary[i]</span><br><span class="line">            j = i</span><br><span class="line">            <span class="keyword">while</span> ( j &gt;= gap <span class="keyword">and</span> ary[j-gap] &gt; temp ):    <span class="comment">#插入排序</span></span><br><span class="line">                ary[j] = ary[j-gap]</span><br><span class="line">                j = j - gap</span><br><span class="line">            ary[j] = temp</span><br><span class="line">        gap = round(gap/<span class="number">2</span>)                     <span class="comment">#重新设置步长</span></span><br><span class="line">    <span class="keyword">return</span> ary</span><br></pre></td></tr></table></figure>
<p>上面源码的步长的选择是从n/2开始，每次再减半，直至为0。步长的选择直接决定了希尔排序的复杂度</p>
<h2 id="Merge_Sort__u5F52_u5E76_u6392_u5E8F"><a href="#Merge_Sort__u5F52_u5E76_u6392_u5E8F" class="headerlink" title="Merge Sort 归并排序"></a>Merge Sort 归并排序</h2><p>归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，再合并数组。</p>
<p>先考虑合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可。</p>
<p>再考虑递归分解，基本思路是将数组分解成left和right，如果这两个数组内部数据是有序的，那么就可以用上面合并数组的方法将这两个数组合并排序。如何让这两个数组内部是有序的？可以再二分，直至分解出的小组只含有一个元素时为止，此时认为该小组内部已有序。然后合并排序相邻二个小组即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span><span class="params">(ary)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(ary) &lt;= <span class="number">1</span> : <span class="keyword">return</span> ary</span><br><span class="line">    num = int(len(ary)/<span class="number">2</span>)       <span class="comment">#二分分解</span></span><br><span class="line">    left = merge_sort(ary[:num])</span><br><span class="line">    right = merge_sort(ary[num:])</span><br><span class="line">    <span class="keyword">return</span> merge(left,right)    <span class="comment">#合并数组</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(left,right)</span>:</span></span><br><span class="line">    <span class="string">'''合并操作，</span><br><span class="line">    将两个有序数组left[]和right[]合并成一个大的有序数组'''</span></span><br><span class="line">    l,r = <span class="number">0</span>,<span class="number">0</span>           <span class="comment">#left与right数组的下标指针</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">while</span> l &lt; len(left) <span class="keyword">and</span> r &lt; len(right):</span><br><span class="line">        <span class="keyword">if</span> left[l] &lt; right[r]:</span><br><span class="line">            result.append(left[l])</span><br><span class="line">            l += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result.append(right[r])</span><br><span class="line">            r += <span class="number">1</span></span><br><span class="line">    result += left[l:]</span><br><span class="line">    result += right[r:]</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>
<h2 id="Quick_Sort__u5FEB_u901F_u6392_u5E8F"><a href="#Quick_Sort__u5FEB_u901F_u6392_u5E8F" class="headerlink" title="Quick Sort 快速排序"></a>Quick Sort 快速排序</h2><p>快速排序通常明显比同为Ο(n log n)的其他算法更快，因此常被采用，而且快排采用了分治法的思想，所以在很多笔试面试中能经常看到快排的影子。可见掌握快排的重要性。</p>
<p>步骤：</p>
<ol>
<li>从数列中挑出一个元素作为基准数。</li>
<li>分区过程，将比基准数大的放到右边，小于或等于它的数都放到左边。</li>
<li>再对左右区间递归执行第二步，直至各区间只有一个数。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span><span class="params">(ary)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> qsort(ary,<span class="number">0</span>,len(ary)-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">qsort</span><span class="params">(ary,left,right)</span>:</span></span><br><span class="line">    <span class="comment">#快排函数，ary为待排序数组，left为待排序的左边界，right为右边界</span></span><br><span class="line">    <span class="keyword">if</span> left &gt;= right : <span class="keyword">return</span> ary</span><br><span class="line">    key = ary[left]     <span class="comment">#取最左边的为基准数</span></span><br><span class="line">    lp = left           <span class="comment">#左指针</span></span><br><span class="line">    rp = right          <span class="comment">#右指针</span></span><br><span class="line">    <span class="keyword">while</span> lp &lt; rp :</span><br><span class="line">        <span class="keyword">while</span> ary[rp] &gt;= key <span class="keyword">and</span> lp &lt; rp :</span><br><span class="line">            rp -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> ary[lp] &lt;= key <span class="keyword">and</span> lp &lt; rp :</span><br><span class="line">            lp += <span class="number">1</span></span><br><span class="line">        ary[lp],ary[rp] = ary[rp],ary[lp]</span><br><span class="line">    ary[left],ary[lp] = ary[lp],ary[left]</span><br><span class="line">    qsort(ary,left,lp-<span class="number">1</span>)</span><br><span class="line">    qsort(ary,rp+<span class="number">1</span>,right)</span><br><span class="line">    <span class="keyword">return</span> ary</span><br></pre></td></tr></table></figure>
<h2 id="Heap_Sort__u5806_u6392_u5E8F"><a href="#Heap_Sort__u5806_u6392_u5E8F" class="headerlink" title="Heap Sort 堆排序"></a>Heap Sort 堆排序</h2><p>堆排序在 top K 问题中使用比较频繁。堆排序是采用二叉堆的数据结构来实现的，虽然实质上还是一维数组。二叉堆是一个近似完全二叉树 。</p>
<p><strong>二叉堆具有以下性质：</strong></p>
<ol>
<li>父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值。</li>
<li>每个节点的左右子树都是一个二叉堆（都是最大堆或最小堆）。</li>
</ol>
<p><strong>步骤：</strong></p>
<ol>
<li>构造最大堆（<code>Build_Max_Heap</code>）：若数组下标范围为0~n，考虑到单独一个元素是大根堆，则从下标n/2开始的元素均为大根堆。于是只要从n/2-1开始，向前依次构造大根堆，这样就能保证，构造到某个节点时，它的左右子树都已经是大根堆。</li>
<li>堆排序（HeapSort）：由于堆是用数组模拟的。得到一个大根堆后，数组内部并不是有序的。因此需要将堆化数组有序化。思想是移除根节点，并做最大堆调整的递归运算。第一次将heap[0]与heap[n-1]交换，再对heap[0…n-2]做最大堆调整。第二次将heap[0]与heap[n-2]交换，再对heap[0…n-3]做最大堆调整。重复该操作直至heap[0]和heap[1]交换。由于每次都是将最大的数并入到后面的有序区间，故操作完后整个数组就是有序的了。</li>
<li>最大堆调整（<code>Max_Heapify</code>）：该方法是提供给上述两个过程调用的。目的是将堆的末端子节点作调整，使得子节点永远小于父节点。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span><span class="params">(ary)</span> :</span></span><br><span class="line">    n = len(ary)</span><br><span class="line">    first = int(n/<span class="number">2</span>-<span class="number">1</span>)       <span class="comment">#最后一个非叶子节点</span></span><br><span class="line">    <span class="keyword">for</span> start <span class="keyword">in</span> range(first,-<span class="number">1</span>,-<span class="number">1</span>) :     <span class="comment">#构造大根堆</span></span><br><span class="line">        max_heapify(ary,start,n-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> end <span class="keyword">in</span> range(n-<span class="number">1</span>,<span class="number">0</span>,-<span class="number">1</span>):           <span class="comment">#堆排，将大根堆转换成有序数组</span></span><br><span class="line">        ary[end],ary[<span class="number">0</span>] = ary[<span class="number">0</span>],ary[end]</span><br><span class="line">        max_heapify(ary,<span class="number">0</span>,end-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> ary</span><br><span class="line"></span><br><span class="line"><span class="comment">#最大堆调整：将堆的末端子节点作调整，使得子节点永远小于父节点</span></span><br><span class="line"><span class="comment">#start为当前需要调整最大堆的位置，end为调整边界</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_heapify</span><span class="params">(ary,start,end)</span>:</span></span><br><span class="line">    root = start</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span> :</span><br><span class="line">        child = root*<span class="number">2</span> +<span class="number">1</span>               <span class="comment">#调整节点的子节点</span></span><br><span class="line">        <span class="keyword">if</span> child &gt; end : <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> child+<span class="number">1</span> &lt;= end <span class="keyword">and</span> ary[child] &lt; ary[child+<span class="number">1</span>] :</span><br><span class="line">            child = child+<span class="number">1</span>             <span class="comment">#取较大的子节点</span></span><br><span class="line">        <span class="keyword">if</span> ary[root] &lt; ary[child] :     <span class="comment">#较大的子节点成为父节点</span></span><br><span class="line">            ary[root],ary[child] = ary[child],ary[root]     <span class="comment">#交换</span></span><br><span class="line">            root = child</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<h2 id="u6307_u6807_u5BF9_u6BD4"><a href="#u6307_u6807_u5BF9_u6BD4" class="headerlink" title="指标对比"></a>指标对比</h2><table>
<thead>
<tr>
<th style="text-align:center">排序方法</th>
<th style="text-align:center">平均情况</th>
<th style="text-align:center">最好情况</th>
<th style="text-align:center">最坏情况</th>
<th style="text-align:center">辅助空间</th>
<th style="text-align:center">稳定性</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">冒泡排序</td>
<td style="text-align:center">O(n2)</td>
<td style="text-align:center">O(n)</td>
<td style="text-align:center">O(n2)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">稳定</td>
</tr>
<tr>
<td style="text-align:center">选择排序</td>
<td style="text-align:center">O(n2)</td>
<td style="text-align:center">O(n2)</td>
<td style="text-align:center">O(n2)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">不稳定</td>
</tr>
<tr>
<td style="text-align:center">插入排序</td>
<td style="text-align:center">O(n2)</td>
<td style="text-align:center">O(n)</td>
<td style="text-align:center">O(n2)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">稳定</td>
</tr>
<tr>
<td style="text-align:center">希尔排序</td>
<td style="text-align:center">O(nlogn)~O(n2)</td>
<td style="text-align:center">O(n1.3)</td>
<td style="text-align:center">O(n2)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">不稳定</td>
</tr>
<tr>
<td style="text-align:center">堆排序</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(1)</td>
<td style="text-align:center">不稳定</td>
</tr>
<tr>
<td style="text-align:center">归并排序</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(n)</td>
<td style="text-align:center">稳定</td>
</tr>
<tr>
<td style="text-align:center">快速排序</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(nlogn)</td>
<td style="text-align:center">O(n2)</td>
<td style="text-align:center">O(logn)~O(n)</td>
<td style="text-align:center">不稳定</td>
</tr>
</tbody>
</table>
<h2 id="Bucket_Sort__u6876_u6392_u5E8F"><a href="#Bucket_Sort__u6876_u6392_u5E8F" class="headerlink" title="Bucket Sort 桶排序"></a>Bucket Sort 桶排序</h2><p>桶排序和归并排序有那么点点类似，也使用了归并的思想。大致步骤如下：</p>
<ol>
<li>设置一个定量的数组当作空桶。</li>
<li>Divide - 从待排序数组中取出元素，将元素按照一定的规则塞进对应的桶子去。</li>
<li>对每个非空桶进行排序，通常可在塞元素入桶时进行插入排序。</li>
<li>Conquer - 从非空桶把元素再放回原来的数组中。”</li>
</ol>
<h2 id="Counting_Sort__u8BA1_u6570_u6392_u5E8F"><a href="#Counting_Sort__u8BA1_u6570_u6392_u5E8F" class="headerlink" title="Counting Sort 计数排序"></a>Counting Sort 计数排序</h2><p>计数排序，顾名思义，就是对待排序数组按元素进行计数。使用前提是需要先知道待排序数组的元素范围，将这些一定范围的元素置于新数组中，新数组的大小为待排序数组中最大元素与最小元素的差值。</p>
<p>维基上总结的四个步骤如下：</p>
<ol>
<li>定新数组大小——找出待排序的数组中最大和最小的元素</li>
<li>统计次数——统计数组中每个值为i的元素出现的次数，存入新数组C的第i项</li>
<li>对统计次数逐个累加——对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）</li>
<li>反向填充目标数组——将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1</li>
<li>其中反向填充主要是为了避免重复元素落入新数组的同一索引处。</li>
</ol>
<h2 id="u89E3_u9898_u7B56_u7565"><a href="#u89E3_u9898_u7B56_u7565" class="headerlink" title="解题策略"></a>解题策略</h2><h3 id="u52A8_u6001_u6570_u636E_u7ED3_u6784_u7684_u7EF4_u62A4"><a href="#u52A8_u6001_u6570_u636E_u7ED3_u6784_u7684_u7EF4_u62A4" class="headerlink" title="动态数据结构的维护"></a>动态数据结构的维护</h3><p>维护动态数据(data stream)的最大值、最小值或中位数，可以考虑使用堆。如果是动态数据求最大的k个元素，因为元素总数量不确定，不能使用quick select，这种情况下也应该用堆解决。</p>
<p>如果需要一个动态插入/删除的有序数据结构，那么可以使用二叉搜索树，因为它天生就是一个动态的有序数组，并且支持检索。</p>
<h3 id="u5BF9_u4E8E_u6709_u5E8F_uFF0F_u90E8_u5206_u6709_u5E8F_u5BB9_u5668_u7684_u641C_u7D22"><a href="#u5BF9_u4E8E_u6709_u5E8F_uFF0F_u90E8_u5206_u6709_u5E8F_u5BB9_u5668_u7684_u641C_u7D22" class="headerlink" title="对于有序／部分有序容器的搜索"></a>对于有序／部分有序容器的搜索</h3><p>用二分查找(binary search)。</p>
<h3 id="u6570_u636E_u8303_u56F4_u6709_u9650_u3001_u79BB_u6563"><a href="#u6570_u636E_u8303_u56F4_u6709_u9650_u3001_u79BB_u6563" class="headerlink" title="数据范围有限、离散"></a>数据范围有限、离散</h3><p>数据范围有限、离散(或存在大量重复数据，即密集数据)的排序问题，一般可以使用桶排序。对于有限位数的数据(如string, <code>vector&lt;int&gt;</code>, int)，可以利用基数排序进行数值序或词典序排序。</p>
<h3 id="Scalability__26amp_3B_Memory_Limits__u95EE_u9898"><a href="#Scalability__26amp_3B_Memory_Limits__u95EE_u9898" class="headerlink" title="Scalability &amp; Memory Limits 问题"></a>Scalability &amp; Memory Limits 问题</h3><p>对这类问题一般采用Divide &amp; Conquer策略，即对问题进行预处理，将问题的输入进行分割、归类(sorting)，放入相应的桶(单机上的某一块Chunk，或者分布式系统中的一台单机)，再对每个桶进行后期处理，最后合并结果。</p>
<p>整个过程中应该用到哈希函数: 对于Memory Limits问题，一般可以直接利用哈希函数建立对象到索引的直接映射；对Scalability问题，一般可以用哈希表来记录对象与存储该对象的机器之间的映射，在该机器上进一步做映射以获得索引。</p>
<h2 id="u5E38_u89C1_u7684_u5916_u6392_u5E8F_u7B97_u6CD5"><a href="#u5E38_u89C1_u7684_u5916_u6392_u5E8F_u7B97_u6CD5" class="headerlink" title="常见的外排序算法"></a>常见的外排序算法</h2><p>外排序算法的核心思路在于把文件分块读到内存，在内存中对每块文件依次进行排序，最后合并排序后的各块数据，依次按顺序写回文件。相比于内排序，外排序需要进行多次磁盘读写，因此执行效率往往低于内排序，时间主要花费于磁盘读写上。我们给出外排序的算法步骤如下：</p>
<p>假设文件需要分成k块读入，需要从小到大进行排序</p>
<ol>
<li>依次读入每个文件块，在内存中对当前文件块进行排序(应用恰当的内排序算法)。此时，每块文件相当于一个由小到大排列的有序队列</li>
<li>在内存中建立一个最小值堆，读入每块文件的队列头</li>
<li>弹出堆顶元素，如果元素来自第i块，则从第i块文件中补充一个元素到最小值堆。弹出的元素暂存至临时数组</li>
<li>当临时数组存满时，将数组写至磁盘，并清空数组内容。</li>
<li>重复过程3)，4)，直至所有文件块读取完毕</li>
</ol>
<h2 id="u5FEB_u901F_u9009_u62E9_u7B97_u6CD5__28quick_selection_algorithm_29"><a href="#u5FEB_u901F_u9009_u62E9_u7B97_u6CD5__28quick_selection_algorithm_29" class="headerlink" title="快速选择算法 (quick selection algorithm)"></a>快速选择算法 (quick selection algorithm)</h2><p>快速选择算法能够在平均O(n)时间内从一个无序数组中返回第k大的元素。算法实际上利用了快速排序的思想，将数组依照一个轴值分割成两个部分，左边元素都比轴值小，右边元素都比轴值大。由于轴值下标已知，则可以判断所求元素落在数组的哪一部分，并在那一部分继续进行上述操作，直至找到该元素。与快排不同，由于快速选择算法只在乎所求元素所在的那一部分，所以时间复杂度是O(n)。关于算法复杂度的理论分析请见“工具箱”给出的参考资料。我们给出算法实现如下：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">int <span class="built_in">partition</span>( int array[], int <span class="keyword">left</span>, int <span class="keyword">right</span> ) &#123;</span><br><span class="line">    int pivot = array[<span class="keyword">right</span>];</span><br><span class="line">    <span class="keyword">while</span>( <span class="keyword">left</span> != <span class="keyword">right</span> )&#123;</span><br><span class="line">        <span class="keyword">while</span>( array[<span class="keyword">left</span>] &lt; pivot &amp;&amp; <span class="keyword">left</span> &lt; <span class="keyword">right</span>)</span><br><span class="line">            <span class="keyword">left</span>++;</span><br><span class="line">            <span class="keyword">left</span>++;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">left</span> &lt; <span class="keyword">right</span>) &#123;</span><br><span class="line">            <span class="built_in">swap</span>( array[<span class="keyword">left</span>], array[<span class="keyword">right</span>--]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>( array[<span class="keyword">right</span>] &gt; pivot &amp;&amp; <span class="keyword">left</span> &lt; <span class="keyword">right</span>)</span><br><span class="line">            <span class="keyword">right</span>--;</span><br><span class="line">        <span class="keyword">if</span>( <span class="keyword">left</span> &lt; <span class="keyword">right</span> )</span><br><span class="line">            <span class="built_in">swap</span>( array[<span class="keyword">left</span>++], array[<span class="keyword">right</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">left</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int quick_select(int array[], int <span class="keyword">left</span>, int <span class="keyword">right</span>, int k)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> ( <span class="keyword">left</span> &gt;= <span class="keyword">right</span> )</span><br><span class="line">        <span class="keyword">return</span> array[<span class="keyword">left</span>];</span><br><span class="line">    int index = <span class="built_in">partition</span>(array, <span class="keyword">left</span>, <span class="keyword">right</span>);</span><br><span class="line">    int size = index - <span class="keyword">left</span> + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> ( size == k )</span><br><span class="line">        <span class="keyword">return</span> array[<span class="keyword">left</span> + k - <span class="number">1</span>]; <span class="comment">// the pivot is the kth largest element</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> ( size &gt; k )</span><br><span class="line">        <span class="keyword">return</span> quick_select(array, <span class="keyword">left</span>, index - <span class="number">1</span>, k);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> quick_select(array, index + <span class="number">1</span>, <span class="keyword">right</span> , k - size);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Get the k largest elements in an array with O(n) expected time, they don’t need to be sorted.</p>
</blockquote>
<p>解题分析：实际上和quick select的应用场景是一致的，先找到第k大的元素，再将数组重新整理，找出比第k大的元素小的所有元素。</p>
<blockquote>
<p>There are n points on a 2D plan, find the k points that are closest to origin ( x= 0, y= 0).</p>
</blockquote>
<p>解题分析：在这里已知点的数量，因此k个点到原点的距离构成size确定的静态数组，应该对这个数组使用快速选择算法。</p>
<h2 id="u4E8C_u5206_u67E5_u627E__28Binary_search_29"><a href="#u4E8C_u5206_u67E5_u627E__28Binary_search_29" class="headerlink" title="二分查找 (Binary search)"></a>二分查找 (Binary search)</h2><p>对于已排序的有序线性容器而言(比如数组，vector)，二分查找(Binary search)几乎总是最优的搜索方案。二分查找将容器等分为两部分，再根据中间节点与待搜索数据的相对大小关系，进一步搜索其中某一部分。二分查找的算法复杂度为O(logn)，算法复杂度的具体分析请见“工具箱”给出的参考资料。算法实现如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="keyword">int</span> *<span class="built_in">array</span>, <span class="keyword">int</span> left, <span class="keyword">int</span> right, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (left &gt; right) &#123;</span><br><span class="line">        <span class="comment">// value not found</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> mid = right - (right - left) / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">array</span>[mid] == value) &#123;</span><br><span class="line">        <span class="keyword">return</span> mid;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">array</span>[mid] &lt; value) &#123;</span><br><span class="line">        <span class="keyword">return</span> binarySearch(<span class="built_in">array</span>, mid + <span class="number">1</span>, right, value);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> binarySearch(<span class="built_in">array</span>, left, mid - <span class="number">1</span>, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于局部有序的数据，也可以根据其局部有序的特性，尽可能地利用逼近、剪枝，使用二分查找的变种进行搜索。</p>
<h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="http://wdxtub.com/interview/14520606004678.html">Stream Integer</a></li>
<li><a href="http://wdxtub.com/interview/14520606004412.html">Sparse Search</a></li>
<li><a href="http://wdxtub.com/interview/14520606004279.html">Sorted Search, No Size</a></li>
<li><a href="http://wdxtub.com/interview/14520606004147.html">Sort Colors</a></li>
<li><a href="http://wdxtub.com/interview/14520606003957.html">Sort Colors II</a></li>
<li><a href="http://wdxtub.com/interview/14520606003704.html">Sort Age</a></li>
<li><a href="http://wdxtub.com/interview/14520606003582.html">Social Network</a></li>
<li><a href="http://wdxtub.com/interview/14520606003458.html">Search Rotated Array</a></li>
<li><a href="http://wdxtub.com/interview/14520606003336.html">Search Range</a></li>
<li><a href="http://wdxtub.com/interview/14520606003219.html">Search Insert Position</a></li>
<li><a href="http://wdxtub.com/interview/14520606003106.html">Search 2D matrix</a></li>
<li><a href="http://wdxtub.com/interview/14520606002879.html">Nuts &amp; Bolts Problem</a></li>
<li><a href="http://wdxtub.com/interview/14520606002777.html">Missing Number</a></li>
<li><a href="http://wdxtub.com/interview/14520606002660.html">Find Minimum in Rotated Sorted Array</a></li>
<li><a href="http://wdxtub.com/interview/14520606002549.html">Median of Two Sorted Array</a></li>
<li><a href="http://wdxtub.com/interview/14520606002445.html">Maximum Gap</a></li>
<li><a href="http://wdxtub.com/interview/14520606002338.html">Kth Smallest Number</a></li>
<li><a href="http://wdxtub.com/interview/14520606002263.html">Kth Largest in Sorted Matrix</a></li>
<li><a href="http://wdxtub.com/interview/14520606002197.html">Kth Largest Element</a></li>
<li><a href="http://wdxtub.com/interview/14520606002136.html">Inverted Index</a></li>
<li><a href="http://wdxtub.com/interview/14520606002077.html">Index Equals to Value</a></li>
<li><a href="http://wdxtub.com/interview/14520606002015.html">Hit Counter</a></li>
<li><a href="http://wdxtub.com/interview/14520606001958.html">Group Anagrams</a></li>
<li><a href="http://wdxtub.com/interview/14520606001885.html">Group Anagrams List</a></li>
<li><a href="http://wdxtub.com/interview/14520606001824.html">First Missing Positive Number</a></li>
<li><a href="http://wdxtub.com/interview/14520606001769.html">First Error Version</a></li>
<li><a href="http://wdxtub.com/interview/14520606001720.html">Find Peak Element</a></li>
<li><a href="http://wdxtub.com/interview/14520606001667.html">名人问题</a></li>
<li><a href="http://wdxtub.com/interview/14520606001623.html">Count Plane</a></li>
<li><a href="http://wdxtub.com/interview/14520606001575.html">Binary Search</a></li>
<li><a href="http://wdxtub.com/interview/14520607214993.html">Cut Wood</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>排序和搜索其实比较相似，最重要的就是理解好二分的思想。无论是稍微复杂一点的排序算法，还是搜索，实际上都是分而治之思想的体现。</p>]]>
    
    </summary>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="排序" scheme="http://wdxtub.com/tags/%E6%8E%92%E5%BA%8F/"/>
    
      <category term="搜索" scheme="http://wdxtub.com/tags/%E6%90%9C%E7%B4%A2/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 7 课 树和图]]></title>
    <link href="http://wdxtub.com/2016/01/23/programmer-startline-7/"/>
    <id>http://wdxtub.com/2016/01/23/programmer-startline-7/</id>
    <published>2016-01-23T14:20:51.000Z</published>
    <updated>2016-01-23T23:57:19.000Z</updated>
    <content type="html"><![CDATA[<p>树和图的问题，说难也难，说简单也简单。难在思路和理解，简单在很多时候可以利用递归得到非常优雅的解法。</p>
<a id="more"></a>
<hr>
<h2 id="u89E3_u9898_u7B56_u7565"><a href="#u89E3_u9898_u7B56_u7565" class="headerlink" title="解题策略"></a>解题策略</h2><p>对于树和图的性质，一般全局解依赖于局部解。通常可以用DFS来判断子问题的解，然后综合得到当前的全局结论。</p>
<p>值得注意的是，当我们在传递节点指针的时候，其实其代表的不只是这个节点本身，而是指对整个子树、子图进行操作。只要每次递归的操作对象的结构一致，我们就可以选择Divide and Conquer(事实上对于树和图总是如此，因为subgraph和subtree仍然是graph和tree结构)。实现函数递归的步骤是：首先设置函数出口，就此类问题而言，递归出口往往是node == NULL。其次，在构造递归的时候，不妨将递归调用自身的部分视为黑盒，并想象它能够完整解决子问题。以二叉树的中序遍历为例，函数的实现为：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">InOrderTraversal</span><span class="params">(TreeNode *root)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (root == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    InOrderTraversal(root-&gt;left);</span><br><span class="line">    root-&gt;print();</span><br><span class="line">    InOrderTraversal(root-&gt;right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>想象递归调用的部分 <code>InOrderTraversal(root-&gt;left)／InOrderTraversal(root-&gt;right)</code>能够完整地中序遍历一棵子树，那么根据中序遍历“按中序遍历左子树；访问根结点；按中序遍历右子树”的定义，写出上述实现就显得很自然了。</p>
<h3 id="DFS__u5904_u7406_u6811_u7684_u95EE_u9898"><a href="#DFS__u5904_u7406_u6811_u7684_u95EE_u9898" class="headerlink" title="DFS 处理树的问题"></a>DFS 处理树的问题</h3><p>有一类关于树的问题是， 要求找出一条满足特定条件的路径 。对于这类问题，通常都是传入一个 vector 记录当前走过的路径(为尽可能模版化，统一记为path)，传入 path 的时候可以是引用，可以是值。还需要传入另一个 vector 引用记录所有符合条件的 path (为尽可能模版化，统一记为result)。注意， result 可以用引用或指针形式，相当于一个全局变量，或者就开辟一个独立于函数的成员变量。由于 path 通常是vector ，那么result就是 <vector> 。当然，那个特定条件，也是函数的一个输入变量。</vector></p>
<p>在解答此类问题的时候，通常都采用DFS来访问，利用回溯思想，直到无法继续访问再返回。值得注意的是，如果path本身是以引用(reference)的形式传入，那么需要在返回之前消除之前所做的影响(回溯)。因为传引用(Pass by reference)相当于把path也看作全局变量，对path的任何操作都会影响其他递归状态，而传值(pass by value)则不会。传引用的好处是可以减小空间开销。</p>
<h3 id="u6811_u548C_u5176_u4ED6_u6570_u636E_u7ED3_u6784_u7684_u76F8_u4E92_u8F6C_u6362"><a href="#u6811_u548C_u5176_u4ED6_u6570_u636E_u7ED3_u6784_u7684_u76F8_u4E92_u8F6C_u6362" class="headerlink" title="树和其他数据结构的相互转换"></a>树和其他数据结构的相互转换</h3><p>这类题目要求将树的结构转化成其他数据结构，例如链表、数组等，或者反之，从数组等结构构成一棵树。前者通常是通过树的遍历，合并局部解来得到全局解，而后者则可以利用D&amp;C的策略，递归将数据结构的两部分分别转换成子树，再合并。</p>
<h3 id="u5BFB_u627E_u7279_u5B9A_u8282_u70B9"><a href="#u5BFB_u627E_u7279_u5B9A_u8282_u70B9" class="headerlink" title="寻找特定节点"></a>寻找特定节点</h3><p>此类题目通常会传入一个当前节点，要求找到与此节点具有一定关系的特定节点：例如前驱、后继、左／右兄弟等。</p>
<p>对于这类题目，首先可以了解一下常见特定节点的定义及性质。在存在指向父节点指针的情况下，通常可以由当前节点出发，向上倒推解决。如果节点没有父节点指针，一般需要从根节点出发向下搜索，搜索的过程就是DFS。</p>
<h3 id="u56FE_u7684_u8BBF_u95EE"><a href="#u56FE_u7684_u8BBF_u95EE" class="headerlink" title="图的访问"></a>图的访问</h3><p>关于图的问题一般有两类。一类是前面提到的关于图的基本问题，例如图的遍历、最短路径、可达性等；另一类是将问题转化成图，再通过图的遍历解决问题。第二类问题有一定的难度，但也有一些规律可循：如果题目有一个起始点和一个终止点，可以考虑看成图的最短路径问题。</p>
<h2 id="u6811"><a href="#u6811" class="headerlink" title="树"></a>树</h2><h3 id="u6811_u7684_u6982_u5FF5"><a href="#u6811_u7684_u6982_u5FF5" class="headerlink" title="树的概念"></a>树的概念</h3><p>树(tree)是一种能够分层存储数据的重要数据结构，树中的每个元素被称为树的节点，每个节点有若干个指针指向子节点。从节点的角度来看，树是由唯一的起始节点引出的节点集合。这个起始结点称为根(root)。树中节点的子树数目称为节点的度(degree)。在面试中，关于树的面试问题非常常见，尤其是关于二叉树(binary tree)，二叉搜索树(Binary Search Tree, BST)的问题。</p>
<p>所谓的二叉树，是指对于树中的每个节点而言，至多有左右两个子节点，即任意节点的度小于等于2。而广义的树则没有如上限制。二叉树是最常见的树形结构。二分查找树是二叉树的一种特例，对于二分查找树的任意节点，该节点存储的数值一定比左子树的所有节点的值大比右子树的所有节点的值小“(与之完全对称的情况也是有效的：即该节点存储的数值一定比左子树的所有节点的值小比右子树的所有节点的值大)。</p>
<p>基于这个特性，二分查找树通常被用于维护有序数据。二分查找树查找、删除、插入的效率都会于一般的线性数据结构。事实上，对于二分查找树的操作相当于执行二分搜索，其执行效率与树的高度(depth)有关，检索任意数据的比较次数不会多于树的高度。这里需要引入高度的概念：对一棵树而言，从根节点到某个节点的路径长度称为该节点的层数(level)，根节点为第0层，非根节点的层数是其父节点的层数加1。树的高度定义为该树中层数最大的叶节点的层数加1，即相当于于从根节点到叶节点的最长路径加1。由此，对于n个数据，二分查找树应该以“尽可能小的高度存储所有数据。由于二叉树第L层至多可以存储 2^L 个节点，故树的高度应在logn量级，因此，二分查找树的搜索效率为O(logn)。</p>
<p>直观上看，尽可能地把二分查找树的每一层“塞满”数据可以使得搜索效率最高，但考虑到每次插入删除都需要维护二分查找树的性质，要实现这点并不容易。特别地，当二分查找树退化为一个由小到大排列的单链表(每个节点只有右孩子)，其搜索效率变为O(n)。为了解决这样的问题，人们引入平衡二叉树的概念。所谓平衡二叉树，是指一棵树的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。通过恰当的构造与调整，平衡二叉树能够保证每次插入删除之后都保持平衡性。平衡二叉树的具体实现算法包括AVL算法和红黑算法等。由于平衡二叉树的实现比较复杂，故一般面试官只会问些概念性的问题。</p>
<h3 id="u6811_u578B_u7684_u6982_u5FF5"><a href="#u6811_u578B_u7684_u6982_u5FF5" class="headerlink" title="树型的概念"></a>树型的概念</h3><p>满二叉树(full binary tree)：如果一棵二叉树的任何结点，或者是叶节点，或者左右子树都存在，则这棵二叉树称作满二叉树。</p>
<p>完全二叉树(complete binary tree)：如果一棵二叉树最多只有最下面的两层节点度数可以小于2，并且最下面一层的节点都集中在该层最左边的连续位置上，则此二叉树称作完全二叉树。</p>
<h3 id="u4E8C_u53C9_u6811_u7684_u904D_u5386"><a href="#u4E8C_u53C9_u6811_u7684_u904D_u5386" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h3><p>二叉树的常见操作包括树的遍历，即以一种特定的规律访问树中的所有节点。常见的遍历方式包括：</p>
<ul>
<li>前序遍历(Pre-order traversal)：访问根结点；按前序遍历左子树；按前序遍历右子树。</li>
<li>中序遍历(In-order traversal)：按中序遍历左子树；访问根结点；按中序遍历右子树。特别地，对于二分查找树而言，中序遍历可以获得一个由小到大或者由大到小的有序序列。</li>
<li>后续遍历(Post-order traversal)：按后序遍历左子树；按后序遍历右子树；访问根结点。</li>
</ul>
<p>以上三种遍历方式都是深度优先搜索算法(depth-first search)。深度优先算法最自然的实现方式是通过递归实现，事实上，大部分树相关的面试问题都可以优先考虑递归。此外，另一个值得注意的要点是：深度优先的算法往往都可以通过使用栈数据结构将递归化为非递归实现。这里利用了栈先进后出的特性，其数据的进出顺序与递归顺序一致(请见 Stack and Queue) 。</p>
<p>层次遍历(Level traversal)：首先访问第0层，也就是根结点所在的层；当第i层的所有结点访问完之后，再从左至右依次访问第i+1层的各个结点。层次遍历属于广度优先搜索算法(breadth-first search)。广度优先算法往往通过队列数据结构实现。</p>
<h2 id="Trie"><a href="#Trie" class="headerlink" title="Trie"></a>Trie</h2><p>字典树(trie or prefix tree)是一个26叉树，用于在一个集合中检索一个字符串，或者字符串前缀。字典树的每个节点有一个指针数组代表其所有子树，其本质上是一个哈希表，因为子树所在的位置(index)本身，就代表了节点对应的字母。节点与每个兄弟具有相同的前缀，这就是trie也被称为prefix tree的原因。</p>
<p>假设我们要存储如下名字，年龄：</p>
<pre><code>Amy 12
Ann 18
Bob 30
</code></pre><p>则构成的字典树如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">.                 root: level <span class="number">0</span></span><br><span class="line">a---------b       level <span class="number">1</span></span><br><span class="line">|         |  </span><br><span class="line">m---n     o       level <span class="number">2</span></span><br><span class="line">|   |     |</span><br><span class="line">y   n     b       level <span class="number">3</span></span><br><span class="line">|   |     |</span><br><span class="line"><span class="number">12</span>  <span class="number">18</span>   <span class="number">30</span>       level <span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>由于Amy和Ann共享前缀a，故第二个字母m和n构成兄弟关系。</p>
<p>字典树以及字典树节点的原型：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> TrieNode &#123;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        T mContent;</span><br><span class="line">        <span class="built_in">vector</span>&lt;TrieNode*&gt; mChildren;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        Node();</span><br><span class="line">        ~Node();</span><br><span class="line">        <span class="keyword">friend</span> <span class="keyword">class</span> Trie;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">class</span> Trie &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Trie();</span><br><span class="line">    ~Trie();</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">addWord</span><span class="params">(<span class="built_in">string</span> s)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">searchWord</span><span class="params">(<span class="built_in">string</span> s)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">deleteWord</span><span class="params">(<span class="built_in">string</span> s)</span></span>;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    TrieNode* root;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>字典树的基本功能如下：</p>
<p>1) void addWord(string key, int value);</p>
<p>添加一个键:值对。添加时从根节点出发，如果在第i层找到了字符串的第i个字母，则沿该节点方向下降一层(注意，如果下一层存储的是数据，则视为没有找到)。否则，将第i个字母作为新的兄弟插入到第i层。将键插入完成后插入值节点。</p>
<p>2) bool searchWord(string key, int &amp;value);</p>
<p>查找某个键是否存在，并返回值。从根节点出发，在第i层寻找字符串中第i个字母是否存在。如果是，沿着该节点方向下降一层；否则，返回false。</p>
<p>3) void deleteWord(string  key)</p>
<p>删除一个键:值对。删除时从底层向上删除节点，“直到遇到第一个有兄弟的节点(说明该节点向上都是与其他节点共享的前缀)，删除该节点。</p>
<h2 id="u5806_u4E0E_u4F18_u5148_u961F_u5217"><a href="#u5806_u4E0E_u4F18_u5148_u961F_u5217" class="headerlink" title="堆与优先队列"></a>堆与优先队列</h2><p>通常所说的堆(Heap)是指二叉堆，从结构上说是完全二叉树，从实现上说一般用数组。以数组的下标建立父子节点关系：对于下标为i的节点，其父节点为(int)i/2，其左子节点为2i，右子节点为2i+1。堆最重要的性质是，它满足部分有序(partial order)：最大(小)堆的父节点一定大于等于(小于等于)当前节点，且堆顶元素一定是当前所有元素的最大(小)值。</p>
<p>堆算法的核心在于插入，删除算法如何保持堆的性质(以下讨论均以最大堆为例):</p>
<p>下移(shift-down)操作：下移是堆算法的核心。对于最大值堆而言，对于某个节点的下移操作相当于比较当前节点与其左右子节点的相对大小。如果当前节点小于其子节点，则将当前节点与其左右子节点中较大的子节点对换，直至操作无法进行(即当前节点大于其左右子节点)。</p>
<p>建堆：假设堆数组长度为n，建堆过程如下，注意这里数组的下标是从 1 开始的：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="tag">i</span>, n/<span class="number">2</span> downto <span class="number">1</span></span><br><span class="line">    do <span class="function"><span class="title">shift-down</span><span class="params">(A,i)</span></span></span><br></pre></td></tr></table></figure>
<p>插入：将新元素插入堆的末尾，并且与父节点进行比较，如果新节点的值大于父节点，则与之交换，即上移(shift-up)，直至操作无法进行。</p>
<p>弹出堆顶元素：弹出堆顶元素(假设记为A[1]，堆尾元素记为A[n])并维护堆性质的过程如下：</p>
<figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output = <span class="literal">A</span>[<span class="number">1</span>]</span><br><span class="line">exchange <span class="literal">A</span>[<span class="number">1</span>] &lt;-&gt; <span class="literal">A</span>[n]</span><br><span class="line">heap size -= <span class="number">1</span></span><br><span class="line">shift-down(<span class="literal">A</span>,<span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p>值得注意的是，堆的插入操作逐层上移，耗时O(log(n))，与二叉搜索树的插入相同。但建堆通过下移所有非叶子节点(下标n/2至1)实现，耗时O(n)，小于BST的O(nlog(n))。</p>
<p>通过上述描述，不难发现堆其实就是一个优先队列。对于C++，标准模版库中的priority_queue是堆的一种具体实现。</p>
<h2 id="u56FE"><a href="#u56FE" class="headerlink" title="图"></a>图</h2><p>图(Graph)是节点集合的一个拓扑结构，节点之间通过边相连。图分为有向图和无向图。有向图的边具有指向性，即AB仅表示由A到B的路径，但并不意味着B可以连到A。与之对应地，无向图的每条边都表示一条双向路径。</p>
<p>图的数据表示方式也分为两种，即邻接表(adjacency list)和邻接矩阵(adjacency matrix)。对于节点A，A的邻接表将与A之间相连的所有节点以链表的形势存储起来，节点A为链表的头节点。这样，对于有V个节点的图而言，邻接表表示法包含V个链表。因此，链接表需要的空间复杂度为O(V+E)。邻接表适用于边数不多的稀疏图。但是，如果要确定图中边(u, v)是否存在，则只能在节点u对应的邻接表中以O(E)复杂度线性搜索。</p>
<p>对于有V个节点的图而言，邻接矩阵用V*V的二维矩阵形式表示一个图。矩阵中的元素Aij表示节点i到节点j之间是否直接有边相连。若有，则Aij数值为该边的权值，否则Aij数值为0。特别地，对于无向图，由于边的双向性，其邻接矩阵的转置矩阵为其本身。邻接矩阵的空间复杂度为O(V^2 )，适用于边较为密集的图。邻接矩阵在检索两个节点之间是否有边相连这样一个需求上，具有优势。</p>
<h2 id="u56FE_u7684_u904D_u5386"><a href="#u56FE_u7684_u904D_u5386" class="headerlink" title="图的遍历"></a>图的遍历</h2><p>对于图的遍历(Graph Transversal)类似于树的遍历(事实上，树可以看成是图的一个特例)，也分为广度优先搜索和深度优先搜索。算法描述如下：</p>
<h3 id="u5E7F_u5EA6_u4F18_u5148"><a href="#u5E7F_u5EA6_u4F18_u5148" class="headerlink" title="广度优先"></a>广度优先</h3><p>对于某个节点，广度优先会先访问其所有邻近节点，再访问其他节点。即，对于任意节点，算法首先发现距离为d的节点，当所有距离为d的节点都被访问后，算法才会访问距离为d+1的节点。广度优先算法将每个节点着色为白，灰或黑，白色表示未被发现，灰色表示被发现，黑色表示已访问。算法利用先进先出队列来管理所有灰色节点。一句话总结，广度优先算法先访问当前节点，一旦发现未被访问的邻近节点，推入队列，以待访问。</p>
<p>《算法导论》第22章图的基本算法给出了广度优先的伪代码实现，引用如下：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">BFS(<span class="keyword">G</span>, s)</span><br><span class="line"><span class="keyword">For</span> each vertex <span class="keyword">u</span> exept <span class="literal">s</span></span><br><span class="line">    <span class="keyword">Do</span> Color[<span class="keyword">u</span>] = WHITE</span><br><span class="line">        Distance[<span class="keyword">u</span>] = <span class="literal">MAX</span></span><br><span class="line">        Parent[<span class="keyword">u</span>] = NIL</span><br><span class="line">Color[s] = GRAY</span><br><span class="line">Distance[s] = 0</span><br><span class="line">Parent[s] = NIL</span><br><span class="line">Enqueue(Q, s)</span><br><span class="line"><span class="keyword">While</span> Q not empty</span><br><span class="line">    <span class="keyword">Do</span> <span class="keyword">u</span> = Dequeue(Q)</span><br><span class="line">        <span class="keyword">For</span> each v is the neighbor of <span class="keyword">u</span></span><br><span class="line">            <span class="keyword">Do</span> <span class="keyword">if</span> Color[v] == WHITE</span><br><span class="line">                Color[v] = GRAY</span><br><span class="line">                Distance[v] = Distance[<span class="keyword">u</span>] + 1</span><br><span class="line">                Parent[v] = <span class="keyword">u</span></span><br><span class="line">                Enqueue(Q, v)</span><br><span class="line">            Color[<span class="keyword">u</span>] = BLACK”</span><br></pre></td></tr></table></figure>
<h3 id="u6DF1_u5EA6_u4F18_u5148"><a href="#u6DF1_u5EA6_u4F18_u5148" class="headerlink" title="深度优先"></a>深度优先</h3><p>深度优先算法尽可能“深”地搜索一个图。对于某个节点v，如果它有未搜索的边，则沿着这条边继续搜索下去，直到该路径无法发现新的节点，回溯回节点v，继续搜索它的下一条边。深度优先算法也通过着色标记节点，白色表示未被发现，灰色表示被发现，黑色表示已访问。算法通过递归实现先进后出。一句话总结，深度优先算法一旦发现没被访问过的邻近节点，则立刻递归访问它，直到所有邻近节点都被访问过了，最后访问自己。</p>
<p>《算法导论》第22章图的基本算法给出了深度优先的伪代码实现，引用如下：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">DFS(<span class="keyword">G</span>)</span><br><span class="line"><span class="keyword">For</span> each vertex v <span class="keyword">in</span> <span class="keyword">G</span></span><br><span class="line">    <span class="keyword">Do</span> Color[v] = WHITE</span><br><span class="line">    Parent[v] = NIL</span><br><span class="line"><span class="keyword">For</span> each vertex v <span class="keyword">in</span> <span class="keyword">G</span></span><br><span class="line">    DFS_Visit(v)</span><br><span class="line"></span><br><span class="line">DFS_Visit(<span class="keyword">u</span>)</span><br><span class="line">Color[<span class="keyword">u</span>] = GRAY</span><br><span class="line"><span class="keyword">For</span> each v is the neighbor of <span class="keyword">u</span></span><br><span class="line">    <span class="keyword">If</span> Color[v] == WHITE</span><br><span class="line">        Parent[v] = <span class="keyword">u</span></span><br><span class="line">        DFS_Visit(v)</span><br><span class="line">Color[<span class="keyword">u</span>] = BLACK</span><br></pre></td></tr></table></figure>
<h2 id="u5355_u6E90_u6700_u77ED_u8DEF_u5F84_u95EE_u9898"><a href="#u5355_u6E90_u6700_u77ED_u8DEF_u5F84_u95EE_u9898" class="headerlink" title="单源最短路径问题"></a>单源最短路径问题</h2><p>对于每条边都有一个权值的图来说，单源最短路径问题是指从某个节点出发，到其他节点的最短距离。该问题的常见算法有Bellman-Ford和Dijkstra算法。前者适用于一般情况(包括存在负权值的情况，但不存在从源点可达的负权值回路)，后者仅适用于均为非负权值边的情况。Dijkstra的运行时间可以小于Bellman-Ford。本小节重点介绍Dijkstra算法。</p>
<p>特别地，如果每条边权值相同(无权图)，由于从源开始访问图遇到节点的最小深度 就等于到该节点的最短路径，因此 Priority Queue就退化成Queue，Dijkstra算法就退化成BFS。</p>
<p>Dijkstra的核心在于，构造一个节点集合S，对于S中的每一个节点，源点到该节点的最短距离已经确定。进一步地，对于不在S中的节点，“我们总是选择其中到源点最近的节点，将它加入S，并且更新其邻近节点到源点的距离。算法实现时需要依赖优先队列。一句话总结，Dijkstra算法利用贪心的思想，在剩下的节点中选取离源点最近的那个加入集合，并且更新其邻近节点到源点的距离，直至所有节点都被加入集合。关于Dijkstra算法的正确性分析，可以使用数学归纳法证明，详见《算法导论》第24章，单源最短路径。 给出伪代码如下：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DIJKSTRA(G, s)</span><br><span class="line">S = EMPTY</span><br><span class="line"><span class="operator"><span class="keyword">Insert</span> all vertexes <span class="keyword">into</span> Q</span><br><span class="line"><span class="keyword">While</span> Q <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">empty</span></span><br><span class="line">    u = Q.top</span><br><span class="line">    S.<span class="keyword">insert</span>(u)</span><br><span class="line">    <span class="keyword">For</span> <span class="keyword">each</span> v <span class="keyword">is</span> the neighbor <span class="keyword">of</span> u</span><br><span class="line">        <span class="keyword">If</span> <span class="keyword">d</span>[v] &gt; <span class="keyword">d</span>[u] + weight(u, v)</span><br><span class="line">            <span class="keyword">d</span>[v] = <span class="keyword">d</span>[u] + weight(u, v)</span><br><span class="line">            <span class="keyword">parent</span>[v] = u</span></span><br></pre></td></tr></table></figure>
<h2 id="u4EFB_u610F_u4E24_u70B9_u4E4B_u95F4_u7684_u6700_u77ED_u8DDD_u79BB"><a href="#u4EFB_u610F_u4E24_u70B9_u4E4B_u95F4_u7684_u6700_u77ED_u8DDD_u79BB" class="headerlink" title="任意两点之间的最短距离"></a>任意两点之间的最短距离</h2><p>另一个关于图常见的算法是，如何获得任意两点之间的最短距离(All-pairs shortest paths)。直观的想法是，可以对于每个节点运行Dijkstra算法，该方法可行，但更适合的算法是Floyd-Warshall算法。</p>
<p>Floyd算法的核心是动态编程，利用二维矩阵存储i，j之间的最短距离，矩阵的初始值为i，j之间的权值，如果i，j不直接相连，则值为正无穷。动态编程的递归式为：d(k)ij = min(d(k-1)ij, d(k-1)ik+ d(k-1)kj)  (1&lt;= k &lt;= n)。直观上理解，对于第k次更新，我们比较从i到j只经过节点编号小于k的中间节点(d(k-1)ij)，和从i到k，从k到j的距离之和(d(k-1)ik+ d(k-1)kj)。Floyd算法的复杂度是O(n^3)。关于Floyd算法的理论分析，请见《算法导论》第25章，每对顶点间的最短路径。 给出伪代码如下：</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">FLOYD<span class="list">(<span class="keyword">G</span>)</span></span><br><span class="line">Distance<span class="list">(<span class="number">0</span>)</span> = Weight<span class="list">(<span class="keyword">G</span>)</span></span><br><span class="line">For k = <span class="number">1</span> to n</span><br><span class="line">    For i = <span class="number">1</span> to n</span><br><span class="line">        For j = <span class="number">1</span> to n</span><br><span class="line">Distance<span class="list">(<span class="keyword">k</span>)</span>ij = min<span class="list">(<span class="keyword">Distance</span> <span class="list">(<span class="keyword">k-1</span>)</span>ij, Distance <span class="list">(<span class="keyword">k-1</span>)</span>ik+ Distance<span class="list">(<span class="keyword">k-1</span>)</span>kj)</span>  </span><br><span class="line">Return Distance<span class="list">(<span class="keyword">n</span>)</span></span><br></pre></td></tr></table></figure>
<h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="http://wdxtub.com/interview/14520607221934.html">Zigzag Level Order Traversal</a></li>
<li><a href="http://wdxtub.com/interview/14520607221747.html">Word Ladder</a></li>
<li><a href="http://wdxtub.com/interview/14520607221562.html">Word Ladder II</a></li>
<li><a href="http://wdxtub.com/interview/14520607221359.html">Valid Binary Search Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607221154.html">Unique Binary Search Trees</a></li>
<li><a href="http://wdxtub.com/interview/14520607220949.html">Unique Binary Search Trees II</a></li>
<li><a href="http://wdxtub.com/interview/14520607220765.html">Implement Trie (Prefix Tree)</a></li>
<li><a href="http://wdxtub.com/interview/14520607220590.html">Topological Sort</a></li>
<li><a href="http://wdxtub.com/interview/14520607220397.html">Convert Sorted List to Binary Search Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607220201.html">Sorted Array to Binary Search Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607220001.html">Serialize and Deserialize</a></li>
<li><a href="http://wdxtub.com/interview/14520607219827.html">Search Range</a></li>
<li><a href="http://wdxtub.com/interview/14520607219664.html">Scramble String</a></li>
<li><a href="http://wdxtub.com/interview/14520607219495.html">Route Between Nodes</a></li>
<li><a href="http://wdxtub.com/interview/14520607219333.html">Root Path Sum</a></li>
<li><a href="http://wdxtub.com/interview/14520607219173.html">Binary Tree Right Side View</a></li>
<li><a href="http://wdxtub.com/interview/14520607219009.html">Reverse Binary Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607218845.html">Recover Binary Search Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607218687.html">Preorder Traversal</a></li>
<li><a href="http://wdxtub.com/interview/14520607218530.html">Postorder Traversal</a></li>
<li><a href="http://wdxtub.com/interview/14520607218372.html">Node Path Sum</a></li>
<li><a href="http://wdxtub.com/interview/14520607218218.html">Paths with Sum II</a></li>
<li><a href="http://wdxtub.com/interview/14520607218066.html">Populating Next Right Pointers in Each Node</a></li>
<li><a href="http://wdxtub.com/interview/14520607217915.html">Next Node without Parent</a></li>
<li><a href="http://wdxtub.com/interview/14520607217765.html">Next Node</a></li>
<li><a href="http://wdxtub.com/interview/14520607217620.html">Next Node in BST</a></li>
<li><a href="http://wdxtub.com/interview/14520607217464.html">Neighbor Node</a></li>
<li><a href="http://wdxtub.com/interview/14520607217318.html">Minimum Path Sum</a></li>
<li><a href="http://wdxtub.com/interview/14520607217172.html">Min Height of Binary Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607217172.html">Min Height of Binary Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607217030.html">Maximum Path Sum</a></li>
<li><a href="http://wdxtub.com/interview/14520607216892.html">Height of Binary Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607216756.html">Level Order Traversal</a></li>
<li><a href="http://wdxtub.com/interview/14520607216621.html">Level Order Traversal II</a></li>
<li><a href="http://wdxtub.com/interview/14520607216488.html">Leaf Path Sum</a></li>
<li><a href="http://wdxtub.com/interview/14520607216345.html">Kth Smallest Element in a BST</a></li>
<li><a href="http://wdxtub.com/interview/14520607216180.html">Is Subtree</a></li>
<li><a href="http://wdxtub.com/interview/14520607216053.html">Insert node to BST</a></li>
<li><a href="http://wdxtub.com/interview/14520607215936.html">Inorder Traversal</a></li>
<li><a href="http://wdxtub.com/interview/14520607215811.html">Flatten Binary Tree to Linked List</a></li>
<li><a href="http://wdxtub.com/interview/14520607215690.html">First Common Ancestor</a></li>
<li><a href="http://wdxtub.com/interview/14520607215576.html">First Common Ancestor of a Binary Search Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607215459.html">Different BST</a></li>
<li><a href="http://wdxtub.com/interview/14520607215341.html">Different BST II</a></li>
<li><a href="http://wdxtub.com/interview/14520607214882.html">Course Schedule</a></li>
<li><a href="http://wdxtub.com/interview/14520607214780.html">Course Schedule II</a></li>
<li><a href="http://wdxtub.com/interview/14520607214651.html">Connected Nodes in Undirected Graph</a></li>
<li><a href="http://wdxtub.com/interview/14520607214579.html">Complete Tree Node Count</a></li>
<li><a href="http://wdxtub.com/interview/14520607214515.html">Clone Graph</a></li>
<li><a href="http://wdxtub.com/interview/14520607214451.html">Symmetric Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607214387.html">Same Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607214326.html">Build Order</a></li>
<li><a href="http://wdxtub.com/interview/14520607214254.html">BST Sequences</a></li>
<li><a href="http://wdxtub.com/interview/14520607214194.html">Binary Tree to Linked List</a></li>
<li><a href="http://wdxtub.com/interview/14520607214136.html">Construct Binary Tree from Preorder and Inorder Traversal</a></li>
<li><a href="http://wdxtub.com/interview/14520607214067.html">Construct Binary Tree from Inorder and Postorder Traversal</a></li>
<li><a href="http://wdxtub.com/interview/14520607214003.html">Binary Tree Depth</a></li>
<li><a href="http://wdxtub.com/interview/14520607213955.html">Binary Search Tree Iterator</a></li>
<li><a href="http://wdxtub.com/interview/14520607213899.html">Balance Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607213899.html">Balance Tree</a></li>
<li><a href="http://wdxtub.com/interview/14520607213844.html">All Path</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>树和图的问题，说难也难，说简单也简单。难在思路和理解，简单在很多时候可以利用递归得到非常优雅的解法。</p>]]>
    
    </summary>
    
      <category term="图" scheme="http://wdxtub.com/tags/%E5%9B%BE/"/>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="树" scheme="http://wdxtub.com/tags/%E6%A0%91/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 6 课 递归与动态规划]]></title>
    <link href="http://wdxtub.com/2016/01/23/programmer-startline-6/"/>
    <id>http://wdxtub.com/2016/01/23/programmer-startline-6/</id>
    <published>2016-01-23T14:20:47.000Z</published>
    <updated>2016-01-23T23:54:26.000Z</updated>
    <content type="html"><![CDATA[<p>递归和动态规划应该算是算法问题中的难点。核心解法很简单，就是要找到状态转移方程，也就是如何把原问题分解成子问题，然后分而治之。所以说，更多像是一种思维方式，而不是具体的步骤技巧。</p>
<a id="more"></a>
<hr>
<h2 id="u89E3_u9898_u7B56_u7565"><a href="#u89E3_u9898_u7B56_u7565" class="headerlink" title="解题策略"></a>解题策略</h2><h3 id="u7528_u52A8_u6001_u7F16_u7A0B_28_u81EA_u5E95_u5411_u4E0A_29_u89E3_u51B3_u6536_u655B_u7ED3_u6784_u95EE_u9898"><a href="#u7528_u52A8_u6001_u7F16_u7A0B_28_u81EA_u5E95_u5411_u4E0A_29_u89E3_u51B3_u6536_u655B_u7ED3_u6784_u95EE_u9898" class="headerlink" title="用动态编程(自底向上)解决收敛结构问题"></a>用动态编程(自底向上)解决收敛结构问题</h3><p>具有强收敛性属性的问题（特解，或最值，或总和，或数量的问题），都可以用整数坐标映射所有节点，且当前节点的解只依赖于前驱节点(无论是顺序还是倒序)。那么，这类问题往往可以用DP解决。解决的关键是建立子问题的解之间的递推关系：</p>
<p>$$ f(n) = G[f(n-1), f(n-2), … , f(1)] $$</p>
<p>或 </p>
<p>$$ f(i, j) = G[f(i-1, j-1), f(i, j -1), f(i-1,j)] $$</p>
<p>其中 G[ ] 表示子问题到原问题的映射关系，例如对于斐波那契数列，有递推式：</p>
<p>$$ f(n) = G[f(n-1), f(n-2)] = f(n-1) + f(n-2) $$</p>
<p>解决这类问题的时候，可以把上述递推关系写在手边，这样做非常有利于理清算法实现的思路。实际实现算法时，往往以问题的一端为循环开端，另一端为循环终止条件，将当前节点的解（或往往是，以当前节点为末节点的问题的解，抑或是以当前两个坐标为输入的问题的解）用 DP 数组记录下来（如果当前节点只由之前紧接的若干个节点决定，那么用若干个变量也够了），数组的下标即为子问题的输入变量，也就是递推关系中的函数参数，只是把 <code>f(i,j)</code> 表示成<code>array[i][j]</code> 而已。</p>
<p>如果问题除了要计算动归终点的数值以外，还需要记录具体的到达路径，则可记录每个节点的前驱节点（<code>prev[n]</code>）或前驱路径（<code>vector&lt;vector&lt;int&gt;&gt; prev</code>），然后用终点出发通过回溯处理成 path。这时候记录的前驱们都是经过了 DP 的剪枝，每一条路径都是符合条件的正确路径。</p>
<p>注意，如果出现类似于“所有解”，“所有路径”等关键词，则用自上而下方法更为直接。</p>
<h3 id="u7528_Memorization_28Top-Down_29_u89E3_u51B3_u6536_u655B_u7ED3_u6784_u95EE_u9898"><a href="#u7528_Memorization_28Top-Down_29_u89E3_u51B3_u6536_u655B_u7ED3_u6784_u95EE_u9898" class="headerlink" title="用 Memorization(Top-Down)解决收敛结构问题"></a>用 Memorization(Top-Down)解决收敛结构问题</h3><p>Memorization 是自顶向下形式的动态编程，并且受到的制约更少 ，自然也可以用来解决前述的问题（但空间上可能效率不及自底向上形式的DP）。</p>
<p>Memorization 的核心在于，在原有递归框架下，存储子问题的计算结果，在重复计算子问题时返回已经计算的值。</p>
<p>值得注意的是，这里所谓的“重复计算子问题”，在自顶向下结构下必须与前驱节点无关，因为子问题并不知道原问题是如何到达当前节点的。举例来说，求二叉树从根节点到叶节点的权值最大路径，对于当前节点到叶节点的路径与之前如何到达当前节点没有关系，只要计算当前节点到叶节点的路径，就一定是重复的计算，可以直接返回结果。作为反例，在一个字母矩阵当中寻找词典中的单词，当前路径能否构成单词，不仅与之后走的过程有关，也与之前的过程有关。因此，从当前节点出发，哪怕走过相同的路径，也不能看成是重复计算的子问题。</p>
<h3 id="u7528_u56DE_u6EAF_u6CD5_28_u81EA_u4E0A_u800C_u4E0B_29_u89E3_u51B3_u53D1_u6563_u7ED3_u6784_u95EE_u9898"><a href="#u7528_u56DE_u6EAF_u6CD5_28_u81EA_u4E0A_u800C_u4E0B_29_u89E3_u51B3_u53D1_u6563_u7ED3_u6784_u95EE_u9898" class="headerlink" title="用回溯法(自上而下)解决发散结构问题"></a>用回溯法(自上而下)解决发散结构问题</h3><p>对于发散性问题(例如“所有组合”，“全部解”)，可以选取其问题空间“收敛”的一端作为起点，沿着节点发散的方向(或者说，当前节点的多种选择)进行递归，直到</p>
<ol>
<li>当前节点“不合法” 或</li>
<li>当前节点发散方向搜索完毕，才会return</li>
</ol>
<p>举例来说，考虑树的遍历：根节点方向就是“收敛”的一端，节点发散的方向就是子节点。对于某个树的节点，其孩子就是当前决策的多种选择。当达到叶节点是，其孩子为NULL，即达到“不合法”的边界条件。回溯法的核心在于选择哪些方向/决策，才是最合理，不重复的。所谓“剪枝”(pruning)，就是指：只选择尽可能少的、可能到达“胜利条件”的方向，而不是搜索当前节点的所有发散方向。这样，可能将幂指数级的复杂度降低到阶乘级。</p>
<p>值得注意的是，invalid前的最末节点未必意味着胜利(不是所有的问题走通就算满足条件)，胜利的节点也未必代表不需要继续走下去(比如寻找到一个单词之后，继续走下去可能能找到以这个单词为前缀的另一个单词)。因此我们强烈推荐将invalid的判定与胜利条件的判定总是分开，即使在某些题目中它们是一致的。当然，如果经过充分剪枝之后，所有搜索只会沿着“正确”的方向行进，那么当前节点“不合法”往往也就意味着胜利条件。</p>
<p>如果需要记录决策的路径，可以用 <code>vector&lt;int&gt; &amp;path</code> 沿着搜索的方向记录，在满足胜利条件时记录当前 <code>path</code> (通常是将 <code>path</code> 存入 <code>vector&lt;vector&lt;int&gt;&gt; &amp;paths</code>)。</p>
<p>注意，我们传入的 path 是引用形式，属于全局变量。Backtracking(回溯)本身隐含的含义是，在访问完这个节点返回时，需要恢复原本的状态(即回到该节点)，以访问其他路径。具体实现时，意味着需要:</p>
<ol>
<li>在 return 前，删除 path 中的当前节点。</li>
<li>如果搜索的方向有出现环路的可能，那么可以使用 <code>bool []</code> 或<code>unordered_map</code> 来记录该节点是否已被使用，在访问时以及 return 前维护。</li>
</ol>
<p>如果以传值形式传入 path，由于 path 成了局部变量，故在某些情况下不需要显式回溯，相当于把状态复制给了子问题。可能有人觉得这样做比较直观，但其缺点是需要额外的空间。</p>
<p>回溯法的典型模板如下所示：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">backtracking</span><span class="params">( P node, <span class="built_in">vector</span>&lt;P&gt; &amp;path, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;P&gt; &gt;&amp;paths )</span></span>&#123;</span><br><span class="line">	<span class="keyword">if</span>(!node )  <span class="comment">// invalid node</span></span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	</span><br><span class="line">	path.push_back(node);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">bool</span> success =  ;  <span class="comment">// condition for success</span></span><br><span class="line">	<span class="keyword">if</span>( success )  </span><br><span class="line">		paths.push_back( <span class="built_in">vector</span>&lt;P&gt;(path.begin(),path.end()) ); </span><br><span class="line">     <span class="comment">// don't return here</span></span><br><span class="line">        </span><br><span class="line">	<span class="keyword">for</span>( P next: all directions )</span><br><span class="line">		backtracking( next, path, paths );</span><br><span class="line">	</span><br><span class="line">	path.pop_back();	</span><br><span class="line">	<span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="u7528_Divide_and_Conquer__u89E3_u51B3_u72EC_u7ACB_u5B50_u95EE_u9898"><a href="#u7528_Divide_and_Conquer__u89E3_u51B3_u72EC_u7ACB_u5B50_u95EE_u9898" class="headerlink" title="用 Divide and Conquer 解决独立子问题"></a>用 Divide and Conquer 解决独立子问题</h3><p>如果能将问题由几个孤立但类似的部分组成，则可以优先选择使用D&amp;C策略：将问题分割解决，再合并结果。特别地，如果期望将问题的复杂度由O(n)进一步降低到O(logn)，一般总是可以联想到使用D&amp;C策略，将问题分割而治。</p>
<h3 id="u4ECE_u5B50_u95EE_u9898_u5F97_u5230_u6700_u7EC8_u89E3"><a href="#u4ECE_u5B50_u95EE_u9898_u5F97_u5230_u6700_u7EC8_u89E3" class="headerlink" title="从子问题得到最终解"></a>从子问题得到最终解</h3><p>递归和动态编程能解决的问题都有一个特性：原问题(problem)可以分解成若干个子问题(sub-problem)，只有先解决了子问题才能进一步解决原问题。子问题的解决方式形式上与原问题一致。从题目描述来看，可以提示我们尝试用递归、DP解决的关键词有：compute nth element (value, sum, max, etc.), return all the paths, return all the combinations, return all the solutions…</p>
<p>既然动规与递归都能解决相同类型的问题，那么DP和递归有什么不同？最大的区别在于，DP存储子问题的结果，当子问题已经被计算过，直接返回结果。因此，当需要重复计算子问题时，DP的时间效率高很多，但需要额外的空间。</p>
<p>特别地，具有聚合属性的问题(Aggregate)，例如在所有组合中寻找符合特定条件的特解(比如二叉树求一条从根节点到叶节点和为定值的路径，或第n个元素)，或最优解(包括最值)，或总和，或数量的问题(其实看一下SQL里的聚合函数(aggregate function)就明白了)。因为这些问题它们只需要一个聚合的或者特殊的结果，而不是所有满足条件的集合，所以它们具有很强的收敛性质。这类问题往往也可以用DP来解决。</p>
<p>这里将问题处理的每一个最小的元素/步骤，称为节点，就好比一维/二维/三维数组中的一个element，或者每一次递归中独立解决的那个元操作。 我们把节点空间“两端收敛”的问题，归结为收敛结构；将节点空间“发散”的问题，归结为发散结构。形象地说，收敛问题是由若干个子问题共同决定当前状态，即状态的总数逐渐“收敛”，例如斐波那契数列问题(前两个节点决定当前节点)；发散问题是当前状态会衍生出多个下一状态，例如遍历已知根节点的二叉树(下一层的状态以指数形式增加)。抽象地说，能够在多项式时间内解决的问题，是收敛问题(P类问题)，不能在多项式内解决的问题(如阶乘级或指数级)，是发散问题(NP类问题)。定义“收敛”和“发散”是为了方便本章节描述和区分这两类问题，并非是公认的准则。</p>
<p>我们再次强调：动态编程的核心在于，如果在一个问题的解决方案中，子问题被重复计算，那么就可以利用记录中间结果，达到用空间换取时间的目的。</p>
<h2 id="u7B97_u6CD5_u7B56_u7565"><a href="#u7B97_u6CD5_u7B56_u7565" class="headerlink" title="算法策略"></a>算法策略</h2><p>以下回顾一些利用到DP思想的经典算法策略：</p>
<ul>
<li>分而治之(Divide and Conquer)<ul>
<li>这里只谈狭义的D&amp;C，即将问题分成几个部分，每一部分相互独立，互不重叠，假定每个部分都可以得到解决来进行递归调用，合并每一部分的结果。</li>
<li>例如Merge Sort， Quick Sort (Merge Sort的divide容易，但Conquer/Merge复杂，Quick Sort的divide复杂，但Conquer/Merge容易)</li>
</ul>
</li>
<li>动态编程(Dynamic Programming)<ul>
<li>尽可能不重复计算每个子问题，而是将计算结果存储下来，以确定后驱问题的解。</li>
<li>与贪心算法的区别是，会记录下所有可能通向全局最优解的局部解，以便在计算后驱问题时综合考虑多个前驱问题的解。</li>
</ul>
</li>
<li>贪婪算法(Greedy Algorithm)<ul>
<li>只做出当下最优的判断，并且以此为基础进行下一步计算。当前判断最优时，不考虑对全局/未来的影响，所以所以从全局来说并不能保证总是最优。</li>
<li>贪心算法每次更新当前的最优解。如Dijkstra算法就是贪心算法的实例之一。</li>
</ul>
</li>
<li>回溯 (Backtracking)<ul>
<li>一种暴力(穷举)的深度优先搜索法：搜索，直到节点空间的尽头，然后再返回到上次的节点，再往其他方向深度搜索。</li>
<li>树或图的DFS是回溯的实例之一。</li>
</ul>
</li>
</ul>
<h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><ul>
<li>动态规划<ul>
<li><a href="http://wdxtub.com/interview/14520604921847.html">Word Break</a></li>
<li><a href="http://wdxtub.com/interview/14520604921620.html">Word Break II</a></li>
<li><a href="http://wdxtub.com/interview/14520604921399.html">Wildcard Matching</a></li>
<li><a href="http://wdxtub.com/interview/14520604918826.html">Regular Expression Matching</a></li>
<li><a href="http://wdxtub.com/interview/14520604921164.html">Unique Path</a></li>
<li><a href="http://wdxtub.com/interview/14520604920947.html">Unique Path II</a></li>
<li><a href="http://wdxtub.com/interview/14520604920730.html">Ugly Number</a></li>
<li><a href="http://wdxtub.com/interview/14520604920507.html">Ugly Number II</a></li>
<li><a href="http://wdxtub.com/interview/14520604920305.html">Trap Water</a></li>
<li><a href="http://wdxtub.com/interview/14520595472823.html">Longest Consecutive Sequence</a></li>
<li><a href="http://wdxtub.com/interview/14520604919653.html">Continuous Subarray Sum</a></li>
<li><a href="http://wdxtub.com/interview/14520604919436.html">Subarray Sum to K</a></li>
<li><a href="http://wdxtub.com/interview/14520604918412.html">Product of Array Except Self</a></li>
<li><a href="http://wdxtub.com/interview/14520604917885.html">Palindrom Partition</a></li>
<li><a href="http://wdxtub.com/interview/14520604918057.html">Palindrome Partitioning II</a></li>
<li><a href="http://wdxtub.com/interview/14520604917521.html">Package Problem</a></li>
<li><a href="http://wdxtub.com/interview/14520604917350.html">Package Problem II</a></li>
<li><a href="http://wdxtub.com/interview/14520604916850.html">N Queen</a></li>
<li><a href="http://wdxtub.com/interview/14520604916662.html">N-Queens II</a></li>
<li><a href="http://wdxtub.com/interview/14520604916164.html">Min Sum Subarray</a></li>
<li><a href="http://wdxtub.com/interview/14520604916010.html">Min Adjustment Cost</a></li>
<li><a href="http://wdxtub.com/interview/14520604915856.html">Maximum Subarray</a></li>
<li><a href="http://wdxtub.com/interview/14520604915702.html">Max Sum Subarray Index</a></li>
<li><a href="http://wdxtub.com/interview/14520604915546.html">Max Sum 2 Subarray</a></li>
<li><a href="http://wdxtub.com/interview/14520604915394.html">Max Square</a></li>
<li><a href="http://wdxtub.com/interview/14520604915232.html">Maximal Rectangle</a></li>
<li><a href="http://wdxtub.com/interview/14520604915082.html">Max Product Subarray</a></li>
<li><a href="http://wdxtub.com/interview/14520595474431.html">Min Difference 2 Array</a></li>
<li><a href="http://wdxtub.com/interview/14520604914933.html">Max Difference 2 Subarray</a></li>
<li><a href="http://wdxtub.com/interview/14520604914337.html">Longest Increasing Sequence</a></li>
<li><a href="http://wdxtub.com/interview/14520604914202.html">Longest Increasing Consecutive Sequence</a></li>
<li><a href="http://wdxtub.com/interview/14520604914067.html">Longest Common Substring</a></li>
<li><a href="http://wdxtub.com/interview/14520604913939.html">Longest Common Subsequence</a></li>
<li><a href="http://wdxtub.com/interview/14520604913809.html">Largest Rectangle in Histogram</a></li>
<li><a href="http://wdxtub.com/interview/14520604913528.html">Jump Game</a></li>
<li><a href="http://wdxtub.com/interview/14520604913406.html">Jump Game II</a></li>
<li><a href="http://wdxtub.com/interview/14520604913280.html">Interleaving String</a></li>
<li><a href="http://wdxtub.com/interview/14520604913150.html">House Robbery</a></li>
<li><a href="http://wdxtub.com/interview/14520604912979.html">House Robbery II</a></li>
<li><a href="http://wdxtub.com/interview/14520604912743.html">Gas Station</a></li>
<li><a href="http://wdxtub.com/interview/14520604912625.html">Fibonacci</a></li>
<li><a href="http://wdxtub.com/interview/14520604912393.html">Edit Distance</a></li>
<li><a href="http://wdxtub.com/interview/14520604912043.html">Different Subsequence</a></li>
<li><a href="http://wdxtub.com/interview/14520604911938.html">Decode Ways</a></li>
<li><a href="http://wdxtub.com/interview/14520604911834.html">Container with Most Water</a></li>
<li><a href="http://wdxtub.com/interview/14520604911320.html">Coin</a></li>
<li><a href="http://wdxtub.com/interview/14520604911261.html">Coin Game</a></li>
<li><a href="http://wdxtub.com/interview/14520604911204.html">Coin Game II</a></li>
<li><a href="http://wdxtub.com/interview/14520604911145.html">Climb Stairs</a></li>
<li><a href="http://wdxtub.com/interview/14520604911084.html">Climb Stairs - Triple Step</a></li>
<li><a href="http://wdxtub.com/interview/14520604911019.html">Boggle Game - Word Search</a></li>
<li><a href="http://wdxtub.com/interview/14520604910956.html">Boggle Game: Word Search II</a></li>
<li><a href="http://wdxtub.com/interview/14520604910906.html">Best Time to Buy and Sell Stock</a></li>
<li><a href="http://wdxtub.com/interview/14520604910739.html">Best Time to Buy and Sell Stock II</a></li>
<li><a href="http://wdxtub.com/interview/14520604910785.html">Best Time to Buy and Sell Stock III</a></li>
<li><a href="http://wdxtub.com/interview/14520604910834.html">Best Time to Buy and Sell Stock IV</a></li>
</ul>
</li>
<li>递归<ul>
<li><a href="http://wdxtub.com/interview/14520604920091.html">Towers of Hanoi</a></li>
<li><a href="http://wdxtub.com/interview/14520604919872.html">Surrounded Regions</a></li>
<li><a href="http://wdxtub.com/interview/14520604919240.html">Stack of Box</a></li>
<li><a href="http://wdxtub.com/interview/14520604919038.html">Restore IP Addresses</a></li>
<li><a href="http://wdxtub.com/interview/14520604918618.html">Recursive Multiply</a></li>
<li><a href="http://wdxtub.com/interview/14520604917714.html">Paint Fill</a></li>
<li><a href="http://wdxtub.com/interview/14520604917181.html">Number of Island</a></li>
<li><a href="http://wdxtub.com/interview/14520604912864.html">Generate Parentheses</a></li>
<li><a href="http://wdxtub.com/interview/14520604912510.html">Expression Add Operators</a></li>
<li><a href="http://wdxtub.com/interview/14520604912257.html">Dungeon Game</a></li>
<li><a href="http://wdxtub.com/interview/14520604912153.html">Different Ways to Add Parentheses</a></li>
<li><a href="http://wdxtub.com/interview/14520604911617.html">Combination Sum</a></li>
<li><a href="http://wdxtub.com/interview/14520604911420.html">Combination Sum II</a></li>
<li><a href="http://wdxtub.com/interview/14520604911516.html">Combination Sum III</a></li>
<li><a href="http://wdxtub.com/interview/14520604910695.html">All Subsets</a></li>
<li><a href="http://wdxtub.com/interview/14520606002989.html">Recursive Integer Traversal</a></li>
</ul>
</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>递归和动态规划应该算是算法问题中的难点。核心解法很简单，就是要找到状态转移方程，也就是如何把原问题分解成子问题，然后分而治之。所以说，更多像是一种思维方式，而不是具体的步骤技巧。</p>]]>
    
    </summary>
    
      <category term="动态规划" scheme="http://wdxtub.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="递归" scheme="http://wdxtub.com/tags/%E9%80%92%E5%BD%92/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 5 课 链表]]></title>
    <link href="http://wdxtub.com/2016/01/22/programmer-startline-5/"/>
    <id>http://wdxtub.com/2016/01/22/programmer-startline-5/</id>
    <published>2016-01-22T20:51:05.000Z</published>
    <updated>2016-01-23T22:42:12.000Z</updated>
    <content type="html"><![CDATA[<p>链表，作为在内存中非连续分配的数据结构，因为其灵活性往往容易出错，这里我们会通过深入理解来教大家一些解决链表问题的基本方法。</p>
<a id="more"></a>
<hr>
<h2 id="u89E3_u9898_u7B56_u7565"><a href="#u89E3_u9898_u7B56_u7565" class="headerlink" title="解题策略"></a>解题策略</h2><p>链表(linked list)是一种常见的线性数据结构。对于单向链表(singly linked list)，每个节点有一个 next 指针指向后一个节点，还有一个成员变量用以存储数值；对于双向链表(doubly Linked List)，还有一个 prev 指针指向前一个节点。与数组类似，搜索链表需要O(n)的时间复杂度，但是链表不能通过常数时间 O(1) 读取第k个数据。链表的优势在于能够以较高的效率在任意位置插入或删除一个节点。</p>
<ul>
<li>当涉及对头节点的操作，我们不妨考虑创建哑节点</li>
<li>由于题目涉及在链表中寻找特定位置，我们用两个指针变量以不同的速度遍历该链表</li>
<li>实现链表的逆转时，循环遍历链表, 每次只处理当前指针的 next 变量</li>
</ul>
<h3 id="u94FE_u8868_u7684_u57FA_u672C_u64CD_u4F5C"><a href="#u94FE_u8868_u7684_u57FA_u672C_u64CD_u4F5C" class="headerlink" title="链表的基本操作"></a>链表的基本操作</h3><p>凡是修改单向链表的操作，只需考虑：</p>
<ol>
<li>哪个节点的next指针会受到影响，则需要修正该指针；</li>
<li>如果待删除节点是动态开辟的内存空间，则需要释放这部分空间(C/C++)</li>
</ol>
<p>毕竟，一个链表节点，无非是包含value和next这两个成员变量的数据结构而已。对于双向链表，类似的，则只需额外考虑谁的prev指针会受到影响。</p>
<p>举例如下：</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void delNode(<span class="constant">ListNode </span>*prev) &#123;</span><br><span class="line">  <span class="constant">ListNode </span>*curr = prev-&gt;<span class="keyword">next</span>;</span><br><span class="line">  <span class="regexp">//</span> 删除curr节点只会使prev节点的<span class="keyword">next</span>受到影响</span><br><span class="line">  prev-&gt;<span class="keyword">next</span> = curr-&gt;<span class="keyword">next</span>;    </span><br><span class="line">  delete curr;    <span class="regexp">//</span> 清理trash指针</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注：操作链表时务必注意边界条件：curr == head, curr == tail 或者 curr == NULL</p>
<ul>
<li><strong>两种存储方式</strong><ul>
<li>顺序存储结构：随机读取，访问时是 O(1)</li>
<li>链式存储结构：插入和删除 O(1)，访问时最坏是 O(n)</li>
</ul>
</li>
<li>分类（根据指针域）<ul>
<li>单向链表</li>
<li>双向链表</li>
<li>循环链表</li>
</ul>
</li>
</ul>
<h3 id="u53CD_u8F6C_u94FE_u8868"><a href="#u53CD_u8F6C_u94FE_u8868" class="headerlink" title="反转链表"></a>反转链表</h3><ul>
<li>访问某个节点 <code>curt.next</code> 时，要检验 <code>curt</code> 是否为 <code>null</code></li>
<li>要把反转后的最后一个节点（即第一个节点）指向 <code>null</code></li>
</ul>
<h3 id="u5220_u9664_u67D0_u4E2A_u8282_u70B9"><a href="#u5220_u9664_u67D0_u4E2A_u8282_u70B9" class="headerlink" title="删除某个节点"></a>删除某个节点</h3><ul>
<li>由于需要知道前继节点的信息，而前继节点可能会导致表头产生变化，所以需要一些技巧 <code>Dummy Node</code></li>
<li>链表指针的鲁棒性<ul>
<li>访问某个节点 <code>curt.next</code> 时，要检验 <code>curt</code> 是否为 <code>null</code></li>
<li>全部操作结束后，判断是否有环；若有，则置其中一端为 <code>null</code></li>
</ul>
</li>
</ul>
<h3 id="Dummy_Node"><a href="#Dummy_Node" class="headerlink" title="Dummy Node"></a>Dummy Node</h3><ul>
<li>是一个虚拟节点 <code>dummy.next = head</code></li>
<li>针对单向链表没有前向指针的问题，保证链表的 <code>head</code> 不会在删除操作中丢失</li>
<li>也可以用来进行 <code>head</code> 节点（但比较少见）</li>
<li>当链表的 <code>head</code> 可能有变化时，使用 dummy node 可以简化代码，最后返回 <code>dummy.next</code> 即可</li>
</ul>
<h3 id="u5FEB_u6162_u6307_u9488"><a href="#u5FEB_u6162_u6307_u9488" class="headerlink" title="快慢指针"></a>快慢指针</h3><ul>
<li>快慢指的是指针向前移动的步长，一般来说，快指针每次移动 2，慢指针每次移动 1</li>
<li>主要有两个应用<ul>
<li><strong>快速找出未知长度单链表的中间节点</strong><ul>
<li>设置两个指针 <code>*fast</code> 和 <code>*slow</code> 都指向头节点</li>
<li><code>*fast</code> 移动速度是 <code>*slow</code> 的两倍</li>
<li><code>*fast</code> 指向末尾节点时，<code>*slow</code> 正好就在中间</li>
</ul>
</li>
<li><strong>判断单链表是否有环</strong><ul>
<li>设置两个指针 <code>*fast</code> 和 <code>*slow</code> 都指向头节点</li>
<li><code>*fast</code> 移动速度是 <code>*slow</code> 的两倍</li>
<li>如果 <code>*fast == null</code> 说明该单链表不是循环链表</li>
<li>如果 <code>*fast == *slow</code> 说明该链表是循环链表</li>
</ul>
</li>
</ul>
</li>
<li>其他应用<ul>
<li><strong>找倒数第 N 个节点</strong><ul>
<li>设置两个指针 <code>*fast</code> 和 <code>*slow</code> 都指向头节点</li>
<li><code>*fast</code> 先移动 N 步，然后两个指针一起前进</li>
<li><code>*fast</code> 到达末尾时，<code>*slow</code> 即为倒数第 N 个节点</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="http://wdxtub.com/interview/14520597852720.html">Swap Adjacent Node</a></li>
<li><a href="http://wdxtub.com/interview/14520597852604.html">Start of Circle</a></li>
<li><a href="http://wdxtub.com/interview/14520597852502.html">Sort List</a></li>
<li><a href="http://wdxtub.com/interview/14520597852382.html">Rotate List</a></li>
<li><a href="http://wdxtub.com/interview/14520597852276.html">Reversely List Traverse</a></li>
<li><a href="http://wdxtub.com/interview/14520597852177.html">Reverse Nodes in k-Group</a></li>
<li><a href="http://wdxtub.com/interview/14520597852065.html">Reverse List</a></li>
<li><a href="http://wdxtub.com/interview/14520597851968.html">Reverse List Range</a></li>
<li><a href="http://wdxtub.com/interview/14520597851880.html">Reorder List</a></li>
<li><a href="http://wdxtub.com/interview/14520597851782.html">Remove Linked List Elements</a></li>
<li><a href="http://wdxtub.com/interview/14520597851695.html">Remove Duplicates from Unsorted List</a></li>
<li><a href="http://wdxtub.com/interview/14520597851601.html">Remove Duplicates from Sorted List</a></li>
<li><a href="http://wdxtub.com/interview/14520597851549.html">Remove Duplicates from Sorted List II</a></li>
<li><a href="http://wdxtub.com/interview/14520597851500.html">Partition Linked List</a></li>
<li><a href="http://wdxtub.com/interview/14520597851449.html">Partitiom List Sorted</a></li>
<li><a href="http://wdxtub.com/interview/14520597851399.html">Middle of List</a></li>
<li><a href="http://wdxtub.com/interview/14520597851346.html">Merge Two Lists</a></li>
<li><a href="http://wdxtub.com/interview/14520597851075.html">Merge K Linked List</a></li>
<li><a href="http://wdxtub.com/interview/14520597851031.html">Kth to Last</a></li>
<li><a href="http://wdxtub.com/interview/14520597850990.html">Insertion Sort List</a></li>
<li><a href="http://wdxtub.com/interview/14520597850946.html">Copy List with Random Pointer</a></li>
<li><a href="http://wdxtub.com/interview/14520597850907.html">Palindrome Linked List</a></li>
<li><a href="http://wdxtub.com/interview/14520597850871.html">Check Intersection</a></li>
<li><a href="http://wdxtub.com/interview/14520597850832.html">Check Cycle</a></li>
<li><a href="http://wdxtub.com/interview/14520597850789.html">Add Two Numbers</a></li>
<li><a href="http://wdxtub.com/interview/14520607215217.html">Delete Node in a Linked List</a></li>
<li><a href="http://wdxtub.com/interview/14520607215107.html">Delete Middle Node</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>链表，作为在内存中非连续分配的数据结构，因为其灵活性往往容易出错，这里我们会通过深入理解来教大家一些解决链表问题的基本方法。</p>]]>
    
    </summary>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="链表" scheme="http://wdxtub.com/tags/%E9%93%BE%E8%A1%A8/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[编程起跑线 第 4 课 栈和队列]]></title>
    <link href="http://wdxtub.com/2016/01/22/programmer-startline-4/"/>
    <id>http://wdxtub.com/2016/01/22/programmer-startline-4/</id>
    <published>2016-01-22T20:51:02.000Z</published>
    <updated>2016-01-23T05:22:52.000Z</updated>
    <content type="html"><![CDATA[<p>栈和队列，因为其特殊的性质，如果巧妙利用，可以解决许多原本比较复杂的问题，而且还是 BFS 和 DFS 的基础，这一讲我们就来看看对于栈和队列的相关知识。</p>
<a id="more"></a>
<hr>
<h2 id="u89E3_u9898_u7B56_u7565"><a href="#u89E3_u9898_u7B56_u7565" class="headerlink" title="解题策略"></a>解题策略</h2><p>对于栈和队列的题目，一定要意识到这两个数据结构背后所代表的含义。</p>
<p>比方说，有一类问题有这样的特性：当前节点的解依赖后驱节点。也就是说，对于某个当前节点，如果不能获知后驱节点，就无法得到有意义的解。这类问题可以通过栈(或等同于栈的若干个临时变量)解决：先将当前节点入栈，然后看其后继节点的值，直到其依赖的所有节点都完备时，再从栈中弹出该节点求解。某些时候，甚至需要反复这个过程：将当前节点的计算结果再次入栈，直到其依赖的后继节点完备。</p>
<p>更进一步来看，只要是利用递归的过程，其实都可以去用栈来模拟，毕竟递归实际上就是一个隐式的栈调用。</p>
<p>具体解题的时候，从最基本的情况出发，根据题意推倒整个计算流程。这样做的好处是：</p>
<ol>
<li>确保自己正确地理解了题目 </li>
<li>从简单的情况出发，找找解题思路。该方法特别适用于递归，动态编程等题目类型</li>
</ol>
<h2 id="u9644_u5F55"><a href="#u9644_u5F55" class="headerlink" title="附录"></a>附录</h2><ul>
<li><a href="http://wdxtub.com/interview/14520595470575.html">Evaluate Reverse Polish Notation</a></li>
<li><a href="http://wdxtub.com/interview/14520606685840.html">Implement Stack using Queues</a></li>
<li><a href="http://wdxtub.com/interview/14520606685720.html">Stack of Plates</a></li>
<li><a href="http://wdxtub.com/interview/14520606685665.html">Sort Stack</a></li>
<li><a href="http://wdxtub.com/interview/14520606685606.html">Queue of Stack</a></li>
<li><a href="http://wdxtub.com/interview/14520606685544.html">Min Stack</a></li>
<li><a href="http://wdxtub.com/interview/14520606685475.html">Max Stack</a></li>
<li><a href="http://wdxtub.com/interview/14520606685419.html">Longest Valid Parentheses</a></li>
<li><a href="http://wdxtub.com/interview/14520606685367.html">In Order Travesal with Stack</a></li>
<li><a href="http://wdxtub.com/interview/14520606685319.html">Hanoi Tower with Stack</a></li>
<li><a href="http://wdxtub.com/interview/14520606685269.html">Basic Calculator</a></li>
<li><a href="http://wdxtub.com/interview/14520606685216.html">Basic Calculator II</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>栈和队列，因为其特殊的性质，如果巧妙利用，可以解决许多原本比较复杂的问题，而且还是 BFS 和 DFS 的基础，这一讲我们就来看看对于栈和队列的相关知识。</p>]]>
    
    </summary>
    
      <category term="思维" scheme="http://wdxtub.com/tags/%E6%80%9D%E7%BB%B4/"/>
    
      <category term="技能" scheme="http://wdxtub.com/tags/%E6%8A%80%E8%83%BD/"/>
    
      <category term="栈" scheme="http://wdxtub.com/tags/%E6%A0%88/"/>
    
      <category term="程序员" scheme="http://wdxtub.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"/>
    
      <category term="队列" scheme="http://wdxtub.com/tags/%E9%98%9F%E5%88%97/"/>
    
      <category term="Technique" scheme="http://wdxtub.com/categories/Technique/"/>
    
  </entry>
  
</feed>
